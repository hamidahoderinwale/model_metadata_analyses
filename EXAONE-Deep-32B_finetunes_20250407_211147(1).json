{
    "models": [
        {
            "model_id": "LGAI-EXAONE/EXAONE-Deep-32B",
            "metadata": "{\"id\": \"LGAI-EXAONE/EXAONE-Deep-32B\", \"author\": \"LGAI-EXAONE\", \"sha\": \"c8855d52a8238a4ec5d781aedbada550336d903f\", \"last_modified\": \"2025-03-19 07:58:51+00:00\", \"created_at\": \"2025-03-12 04:44:03+00:00\", \"private\": false, \"gated\": false, \"disabled\": false, \"downloads\": 23952, \"downloads_all_time\": null, \"likes\": 283, \"library_name\": \"transformers\", \"gguf\": null, \"inference\": null, \"inference_provider_mapping\": null, \"tags\": [\"transformers\", \"safetensors\", \"exaone\", \"text-generation\", \"lg-ai\", \"exaone-deep\", \"conversational\", \"custom_code\", \"en\", \"ko\", \"arxiv:2503.12524\", \"base_model:LGAI-EXAONE/EXAONE-3.5-32B-Instruct\", \"base_model:finetune:LGAI-EXAONE/EXAONE-3.5-32B-Instruct\", \"license:other\", \"autotrain_compatible\", \"region:us\"], \"pipeline_tag\": \"text-generation\", \"mask_token\": null, \"trending_score\": null, \"card_data\": \"base_model: LGAI-EXAONE/EXAONE-3.5-32B-Instruct\\nlanguage:\\n- en\\n- ko\\nlibrary_name: transformers\\nlicense: other\\nlicense_name: exaone\\nlicense_link: LICENSE\\npipeline_tag: text-generation\\ntags:\\n- lg-ai\\n- exaone\\n- exaone-deep\\nbase_model_relation: finetune\", \"widget_data\": [{\"text\": \"Hi, what can you help me with?\"}, {\"text\": \"What is 84 * 3 / 2?\"}, {\"text\": \"Tell me an interesting fact about the universe!\"}, {\"text\": \"Explain quantum computing in simple terms.\"}], \"model_index\": null, \"config\": {\"architectures\": [\"ExaoneForCausalLM\"], \"auto_map\": {\"AutoConfig\": \"configuration_exaone.ExaoneConfig\", \"AutoModelForCausalLM\": \"modeling_exaone.ExaoneForCausalLM\", \"AutoModelForSequenceClassification\": \"modeling_exaone.ExaoneForSequenceClassification\"}, \"model_type\": \"exaone\", \"tokenizer_config\": {\"bos_token\": \"[BOS]\", \"chat_template\": \"{% for message in messages %}{% if loop.first and message['role'] != 'system' %}{{ '[|system|][|endofturn|]\\n' }}{% endif %}{% set content = message['content'] %}{% if '</thought>' in content %}{% set content = content.split('</thought>')[-1].lstrip('\\\\n') %}{% endif %}{{ '[|' + message['role'] + '|]' + content }}{% if not message['role'] == 'user' %}{{ '[|endofturn|]' }}{% endif %}{% if not loop.last %}{{ '\\n' }}{% endif %}{% endfor %}{% if add_generation_prompt %}{{ '\\n[|assistant|]<thought>\\n' }}{% endif %}\", \"eos_token\": \"[|endofturn|]\", \"pad_token\": \"[PAD]\", \"unk_token\": \"[UNK]\"}}, \"transformers_info\": {\"auto_model\": \"AutoModelForCausalLM\", \"custom_class\": \"modeling_exaone.ExaoneForCausalLM\", \"pipeline_tag\": \"text-generation\", \"processor\": null}, \"siblings\": [\"RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='LICENSE', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='assets/EXAONE_Symbol+BI_3d.png', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='assets/exaone_deep_overall_performance.png', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='configuration_exaone.py', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='generation_config.json', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='merges.txt', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model-00001-of-00014.safetensors', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model-00002-of-00014.safetensors', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model-00003-of-00014.safetensors', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model-00004-of-00014.safetensors', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model-00005-of-00014.safetensors', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model-00006-of-00014.safetensors', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model-00007-of-00014.safetensors', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model-00008-of-00014.safetensors', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model-00009-of-00014.safetensors', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model-00010-of-00014.safetensors', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model-00011-of-00014.safetensors', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model-00012-of-00014.safetensors', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model-00013-of-00014.safetensors', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model-00014-of-00014.safetensors', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model.safetensors.index.json', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='modeling_exaone.py', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='vocab.json', size=None, blob_id=None, lfs=None)\"], \"spaces\": [], \"safetensors\": {\"parameters\": {\"BF16\": 32003200000}, \"total\": 32003200000}, \"security_repo_status\": null, \"xet_enabled\": null, \"lastModified\": \"2025-03-19 07:58:51+00:00\", \"cardData\": \"base_model: LGAI-EXAONE/EXAONE-3.5-32B-Instruct\\nlanguage:\\n- en\\n- ko\\nlibrary_name: transformers\\nlicense: other\\nlicense_name: exaone\\nlicense_link: LICENSE\\npipeline_tag: text-generation\\ntags:\\n- lg-ai\\n- exaone\\n- exaone-deep\\nbase_model_relation: finetune\", \"transformersInfo\": {\"auto_model\": \"AutoModelForCausalLM\", \"custom_class\": \"modeling_exaone.ExaoneForCausalLM\", \"pipeline_tag\": \"text-generation\", \"processor\": null}, \"_id\": \"67d111137be76de1a407165b\", \"modelId\": \"LGAI-EXAONE/EXAONE-Deep-32B\", \"usedStorage\": 64006576520}",
            "depth": 0,
            "children": [
                "https://huggingface.co/alexgusevski/EXAONE-Deep-32B-mlx-fp16",
                "https://huggingface.co/alexgusevski/EXAONE-Deep-32B-mlx-4Bit",
                "https://huggingface.co/mlx-community/EXAONE-Deep-32B-6bit",
                "https://huggingface.co/mlx-community/EXAONE-Deep-32B-8bit",
                "https://huggingface.co/alexgusevski/EXAONE-Deep-32B-mlx-8Bit",
                "https://huggingface.co/mlx-community/EXAONE-Deep-32B-4bit",
                "https://huggingface.co/BlackBeenie/EXAONE-Deep-32B-Q4_K_M-GGUF",
                "https://huggingface.co/AGCobra/EXAONE-Deep-32B-mlx-4Bit",
                "https://huggingface.co/mlx-community/EXAONE-Deep-32B-3bit",
                "https://huggingface.co/KYUNGYONG/EXAONE-Deep-32B-mlx-3Bit",
                "https://huggingface.co/alexgusevski/EXAONE-Deep-32B-mlx-3Bit",
                "https://huggingface.co/mlx-community/EXAONE-Deep-32B-mlx-8Bit",
                "https://huggingface.co/KYUNGYONG/EXAONE-Deep-32B-mlx-4Bit",
                "https://huggingface.co/mlx-community/EXAONE-Deep-32B-bf16",
                "https://huggingface.co/alexgusevski/EXAONE-Deep-32B-mlx-6Bit"
            ],
            "children_count": 15
        },
        {
            "model_id": "alexgusevski/EXAONE-Deep-32B-mlx-fp16",
            "metadata": "{\"id\": \"alexgusevski/EXAONE-Deep-32B-mlx-fp16\", \"author\": \"alexgusevski\", \"sha\": \"6d06d544126bf725129187e98a84a03b8eaedb7f\", \"last_modified\": \"2025-03-18 14:39:30+00:00\", \"created_at\": \"2025-03-18 13:51:38+00:00\", \"private\": false, \"gated\": false, \"disabled\": false, \"downloads\": 14, \"downloads_all_time\": null, \"likes\": 0, \"library_name\": \"transformers\", \"gguf\": null, \"inference\": null, \"inference_provider_mapping\": null, \"tags\": [\"transformers\", \"safetensors\", \"exaone\", \"text-generation\", \"lg-ai\", \"exaone-deep\", \"mlx\", \"mlx-my-repo\", \"conversational\", \"custom_code\", \"en\", \"ko\", \"base_model:LGAI-EXAONE/EXAONE-Deep-32B\", \"base_model:finetune:LGAI-EXAONE/EXAONE-Deep-32B\", \"license:other\", \"autotrain_compatible\", \"region:us\"], \"pipeline_tag\": \"text-generation\", \"mask_token\": null, \"trending_score\": null, \"card_data\": \"base_model: LGAI-EXAONE/EXAONE-Deep-32B\\nlanguage:\\n- en\\n- ko\\nlibrary_name: transformers\\nlicense: other\\nlicense_name: exaone\\nlicense_link: LICENSE\\npipeline_tag: text-generation\\ntags:\\n- lg-ai\\n- exaone\\n- exaone-deep\\n- mlx\\n- mlx-my-repo\\nbase_model_relation: finetune\", \"widget_data\": [{\"text\": \"Hi, what can you help me with?\"}, {\"text\": \"What is 84 * 3 / 2?\"}, {\"text\": \"Tell me an interesting fact about the universe!\"}, {\"text\": \"Explain quantum computing in simple terms.\"}], \"model_index\": null, \"config\": {\"architectures\": [\"ExaoneForCausalLM\"], \"auto_map\": {\"AutoConfig\": \"configuration_exaone.ExaoneConfig\", \"AutoModelForCausalLM\": \"modeling_exaone.ExaoneForCausalLM\", \"AutoModelForSequenceClassification\": \"modeling_exaone.ExaoneForSequenceClassification\"}, \"model_type\": \"exaone\", \"tokenizer_config\": {\"bos_token\": \"[BOS]\", \"chat_template\": \"{% for message in messages %}{% if loop.first and message['role'] != 'system' %}{{ '[|system|][|endofturn|]\\n' }}{% endif %}{% set content = message['content'] %}{% if '</thought>' in content %}{% set content = content.split('</thought>')[-1].lstrip('\\\\n') %}{% endif %}{{ '[|' + message['role'] + '|]' + content }}{% if not message['role'] == 'user' %}{{ '[|endofturn|]' }}{% endif %}{% if not loop.last %}{{ '\\n' }}{% endif %}{% endfor %}{% if add_generation_prompt %}{{ '\\n[|assistant|]<thought>\\n' }}{% endif %}\", \"eos_token\": \"[|endofturn|]\", \"pad_token\": \"[PAD]\", \"unk_token\": \"[UNK]\"}}, \"transformers_info\": {\"auto_model\": \"AutoModelForCausalLM\", \"custom_class\": \"modeling_exaone.ExaoneForCausalLM\", \"pipeline_tag\": \"text-generation\", \"processor\": null}, \"siblings\": [\"RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='configuration_exaone.py', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='merges.txt', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model-00001-of-00013.safetensors', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model-00002-of-00013.safetensors', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model-00003-of-00013.safetensors', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model-00004-of-00013.safetensors', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model-00005-of-00013.safetensors', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model-00006-of-00013.safetensors', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model-00007-of-00013.safetensors', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model-00008-of-00013.safetensors', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model-00009-of-00013.safetensors', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model-00010-of-00013.safetensors', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model-00011-of-00013.safetensors', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model-00012-of-00013.safetensors', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model-00013-of-00013.safetensors', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model.safetensors.index.json', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='modeling_exaone.py', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='vocab.json', size=None, blob_id=None, lfs=None)\"], \"spaces\": [], \"safetensors\": {\"parameters\": {\"F16\": 32003200000}, \"total\": 32003200000}, \"security_repo_status\": null, \"xet_enabled\": null, \"lastModified\": \"2025-03-18 14:39:30+00:00\", \"cardData\": \"base_model: LGAI-EXAONE/EXAONE-Deep-32B\\nlanguage:\\n- en\\n- ko\\nlibrary_name: transformers\\nlicense: other\\nlicense_name: exaone\\nlicense_link: LICENSE\\npipeline_tag: text-generation\\ntags:\\n- lg-ai\\n- exaone\\n- exaone-deep\\n- mlx\\n- mlx-my-repo\\nbase_model_relation: finetune\", \"transformersInfo\": {\"auto_model\": \"AutoModelForCausalLM\", \"custom_class\": \"modeling_exaone.ExaoneForCausalLM\", \"pipeline_tag\": \"text-generation\", \"processor\": null}, \"_id\": \"67d97a6a8250c36eda7d586f\", \"modelId\": \"alexgusevski/EXAONE-Deep-32B-mlx-fp16\", \"usedStorage\": 64006466552}",
            "depth": 1,
            "children": [],
            "children_count": 0
        },
        {
            "model_id": "alexgusevski/EXAONE-Deep-32B-mlx-4Bit",
            "metadata": "{\"id\": \"alexgusevski/EXAONE-Deep-32B-mlx-4Bit\", \"author\": \"alexgusevski\", \"sha\": \"02c42836eff0259343ddc06f23d853e0f1492051\", \"last_modified\": \"2025-03-18 14:39:01+00:00\", \"created_at\": \"2025-03-18 13:13:50+00:00\", \"private\": false, \"gated\": false, \"disabled\": false, \"downloads\": 7, \"downloads_all_time\": null, \"likes\": 0, \"library_name\": \"transformers\", \"gguf\": null, \"inference\": null, \"inference_provider_mapping\": null, \"tags\": [\"transformers\", \"safetensors\", \"exaone\", \"text-generation\", \"lg-ai\", \"exaone-deep\", \"mlx\", \"mlx-my-repo\", \"conversational\", \"custom_code\", \"en\", \"ko\", \"base_model:LGAI-EXAONE/EXAONE-Deep-32B\", \"base_model:finetune:LGAI-EXAONE/EXAONE-Deep-32B\", \"license:other\", \"autotrain_compatible\", \"4-bit\", \"region:us\"], \"pipeline_tag\": \"text-generation\", \"mask_token\": null, \"trending_score\": null, \"card_data\": \"base_model: LGAI-EXAONE/EXAONE-Deep-32B\\nlanguage:\\n- en\\n- ko\\nlibrary_name: transformers\\nlicense: other\\nlicense_name: exaone\\nlicense_link: LICENSE\\npipeline_tag: text-generation\\ntags:\\n- lg-ai\\n- exaone\\n- exaone-deep\\n- mlx\\n- mlx-my-repo\\nbase_model_relation: finetune\", \"widget_data\": [{\"text\": \"Hi, what can you help me with?\"}, {\"text\": \"What is 84 * 3 / 2?\"}, {\"text\": \"Tell me an interesting fact about the universe!\"}, {\"text\": \"Explain quantum computing in simple terms.\"}], \"model_index\": null, \"config\": {\"architectures\": [\"ExaoneForCausalLM\"], \"auto_map\": {\"AutoConfig\": \"configuration_exaone.ExaoneConfig\", \"AutoModelForCausalLM\": \"modeling_exaone.ExaoneForCausalLM\", \"AutoModelForSequenceClassification\": \"modeling_exaone.ExaoneForSequenceClassification\"}, \"model_type\": \"exaone\", \"quantization_config\": {\"bits\": 4}, \"tokenizer_config\": {\"bos_token\": \"[BOS]\", \"chat_template\": \"{% for message in messages %}{% if loop.first and message['role'] != 'system' %}{{ '[|system|][|endofturn|]\\n' }}{% endif %}{% set content = message['content'] %}{% if '</thought>' in content %}{% set content = content.split('</thought>')[-1].lstrip('\\\\n') %}{% endif %}{{ '[|' + message['role'] + '|]' + content }}{% if not message['role'] == 'user' %}{{ '[|endofturn|]' }}{% endif %}{% if not loop.last %}{{ '\\n' }}{% endif %}{% endfor %}{% if add_generation_prompt %}{{ '\\n[|assistant|]<thought>\\n' }}{% endif %}\", \"eos_token\": \"[|endofturn|]\", \"pad_token\": \"[PAD]\", \"unk_token\": \"[UNK]\"}}, \"transformers_info\": {\"auto_model\": \"AutoModelForCausalLM\", \"custom_class\": \"modeling_exaone.ExaoneForCausalLM\", \"pipeline_tag\": \"text-generation\", \"processor\": null}, \"siblings\": [\"RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='configuration_exaone.py', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='merges.txt', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model-00001-of-00004.safetensors', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model-00002-of-00004.safetensors', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model-00003-of-00004.safetensors', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model-00004-of-00004.safetensors', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model.safetensors.index.json', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='modeling_exaone.py', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='vocab.json', size=None, blob_id=None, lfs=None)\"], \"spaces\": [], \"safetensors\": {\"parameters\": {\"F16\": 1000739840, \"U32\": 4000317440}, \"total\": 5001057280}, \"security_repo_status\": null, \"xet_enabled\": null, \"lastModified\": \"2025-03-18 14:39:01+00:00\", \"cardData\": \"base_model: LGAI-EXAONE/EXAONE-Deep-32B\\nlanguage:\\n- en\\n- ko\\nlibrary_name: transformers\\nlicense: other\\nlicense_name: exaone\\nlicense_link: LICENSE\\npipeline_tag: text-generation\\ntags:\\n- lg-ai\\n- exaone\\n- exaone-deep\\n- mlx\\n- mlx-my-repo\\nbase_model_relation: finetune\", \"transformersInfo\": {\"auto_model\": \"AutoModelForCausalLM\", \"custom_class\": \"modeling_exaone.ExaoneForCausalLM\", \"pipeline_tag\": \"text-generation\", \"processor\": null}, \"_id\": \"67d9718e5c83eff5b58ab4d9\", \"modelId\": \"alexgusevski/EXAONE-Deep-32B-mlx-4Bit\", \"usedStorage\": 18002919934}",
            "depth": 1,
            "children": [],
            "children_count": 0
        },
        {
            "model_id": "mlx-community/EXAONE-Deep-32B-6bit",
            "metadata": "{\"id\": \"mlx-community/EXAONE-Deep-32B-6bit\", \"author\": \"mlx-community\", \"sha\": \"59e942a5a5d14bfb57c5bdca961f4cc325a047fd\", \"last_modified\": \"2025-03-18 22:56:39+00:00\", \"created_at\": \"2025-03-18 22:47:32+00:00\", \"private\": false, \"gated\": false, \"disabled\": false, \"downloads\": 20, \"downloads_all_time\": null, \"likes\": 0, \"library_name\": \"transformers\", \"gguf\": null, \"inference\": null, \"inference_provider_mapping\": null, \"tags\": [\"transformers\", \"safetensors\", \"exaone\", \"text-generation\", \"lg-ai\", \"exaone-deep\", \"mlx\", \"conversational\", \"custom_code\", \"en\", \"ko\", \"base_model:LGAI-EXAONE/EXAONE-Deep-32B\", \"base_model:finetune:LGAI-EXAONE/EXAONE-Deep-32B\", \"license:other\", \"autotrain_compatible\", \"6-bit\", \"region:us\"], \"pipeline_tag\": \"text-generation\", \"mask_token\": null, \"trending_score\": null, \"card_data\": \"base_model: LGAI-EXAONE/EXAONE-Deep-32B\\nlanguage:\\n- en\\n- ko\\nlibrary_name: transformers\\nlicense: other\\nlicense_name: exaone\\nlicense_link: LICENSE\\npipeline_tag: text-generation\\ntags:\\n- lg-ai\\n- exaone\\n- exaone-deep\\n- mlx\\nbase_model_relation: finetune\", \"widget_data\": [{\"text\": \"Hi, what can you help me with?\"}, {\"text\": \"What is 84 * 3 / 2?\"}, {\"text\": \"Tell me an interesting fact about the universe!\"}, {\"text\": \"Explain quantum computing in simple terms.\"}], \"model_index\": null, \"config\": {\"architectures\": [\"ExaoneForCausalLM\"], \"auto_map\": {\"AutoConfig\": \"configuration_exaone.ExaoneConfig\", \"AutoModelForCausalLM\": \"modeling_exaone.ExaoneForCausalLM\", \"AutoModelForSequenceClassification\": \"modeling_exaone.ExaoneForSequenceClassification\"}, \"model_type\": \"exaone\", \"quantization_config\": {\"bits\": 6}, \"tokenizer_config\": {\"bos_token\": \"[BOS]\", \"chat_template\": \"{% for message in messages %}{% if loop.first and message['role'] != 'system' %}{{ '[|system|][|endofturn|]\\n' }}{% endif %}{% set content = message['content'] %}{% if '</thought>' in content %}{% set content = content.split('</thought>')[-1].lstrip('\\\\n') %}{% endif %}{{ '[|' + message['role'] + '|]' + content }}{% if not message['role'] == 'user' %}{{ '[|endofturn|]' }}{% endif %}{% if not loop.last %}{{ '\\n' }}{% endif %}{% endfor %}{% if add_generation_prompt %}{{ '\\n[|assistant|]<thought>\\n' }}{% endif %}\", \"eos_token\": \"[|endofturn|]\", \"pad_token\": \"[PAD]\", \"unk_token\": \"[UNK]\"}}, \"transformers_info\": {\"auto_model\": \"AutoModelForCausalLM\", \"custom_class\": \"modeling_exaone.ExaoneForCausalLM\", \"pipeline_tag\": \"text-generation\", \"processor\": null}, \"siblings\": [\"RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='configuration_exaone.py', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='merges.txt', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model-00001-of-00005.safetensors', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model-00002-of-00005.safetensors', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model-00003-of-00005.safetensors', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model-00004-of-00005.safetensors', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model-00005-of-00005.safetensors', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model.safetensors.index.json', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='modeling_exaone.py', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='vocab.json', size=None, blob_id=None, lfs=None)\"], \"spaces\": [], \"safetensors\": {\"parameters\": {\"F16\": 1000739840, \"U32\": 6000476160}, \"total\": 7001216000}, \"security_repo_status\": null, \"xet_enabled\": null, \"lastModified\": \"2025-03-18 22:56:39+00:00\", \"cardData\": \"base_model: LGAI-EXAONE/EXAONE-Deep-32B\\nlanguage:\\n- en\\n- ko\\nlibrary_name: transformers\\nlicense: other\\nlicense_name: exaone\\nlicense_link: LICENSE\\npipeline_tag: text-generation\\ntags:\\n- lg-ai\\n- exaone\\n- exaone-deep\\n- mlx\\nbase_model_relation: finetune\", \"transformersInfo\": {\"auto_model\": \"AutoModelForCausalLM\", \"custom_class\": \"modeling_exaone.ExaoneForCausalLM\", \"pipeline_tag\": \"text-generation\", \"processor\": null}, \"_id\": \"67d9f804ebd22f04803fd29a\", \"modelId\": \"mlx-community/EXAONE-Deep-32B-6bit\", \"usedStorage\": 26003554928}",
            "depth": 1,
            "children": [],
            "children_count": 0
        },
        {
            "model_id": "mlx-community/EXAONE-Deep-32B-8bit",
            "metadata": "{\"id\": \"mlx-community/EXAONE-Deep-32B-8bit\", \"author\": \"mlx-community\", \"sha\": \"5477c567d72d29b716697d3822cf05ba35d4e744\", \"last_modified\": \"2025-03-18 23:07:11+00:00\", \"created_at\": \"2025-03-18 22:57:32+00:00\", \"private\": false, \"gated\": false, \"disabled\": false, \"downloads\": 43, \"downloads_all_time\": null, \"likes\": 0, \"library_name\": \"transformers\", \"gguf\": null, \"inference\": null, \"inference_provider_mapping\": null, \"tags\": [\"transformers\", \"safetensors\", \"exaone\", \"text-generation\", \"lg-ai\", \"exaone-deep\", \"mlx\", \"conversational\", \"custom_code\", \"en\", \"ko\", \"base_model:LGAI-EXAONE/EXAONE-Deep-32B\", \"base_model:finetune:LGAI-EXAONE/EXAONE-Deep-32B\", \"license:other\", \"autotrain_compatible\", \"8-bit\", \"region:us\"], \"pipeline_tag\": \"text-generation\", \"mask_token\": null, \"trending_score\": null, \"card_data\": \"base_model: LGAI-EXAONE/EXAONE-Deep-32B\\nlanguage:\\n- en\\n- ko\\nlibrary_name: transformers\\nlicense: other\\nlicense_name: exaone\\nlicense_link: LICENSE\\npipeline_tag: text-generation\\ntags:\\n- lg-ai\\n- exaone\\n- exaone-deep\\n- mlx\\nbase_model_relation: finetune\", \"widget_data\": [{\"text\": \"Hi, what can you help me with?\"}, {\"text\": \"What is 84 * 3 / 2?\"}, {\"text\": \"Tell me an interesting fact about the universe!\"}, {\"text\": \"Explain quantum computing in simple terms.\"}], \"model_index\": null, \"config\": {\"architectures\": [\"ExaoneForCausalLM\"], \"auto_map\": {\"AutoConfig\": \"configuration_exaone.ExaoneConfig\", \"AutoModelForCausalLM\": \"modeling_exaone.ExaoneForCausalLM\", \"AutoModelForSequenceClassification\": \"modeling_exaone.ExaoneForSequenceClassification\"}, \"model_type\": \"exaone\", \"quantization_config\": {\"bits\": 8}, \"tokenizer_config\": {\"bos_token\": \"[BOS]\", \"chat_template\": \"{% for message in messages %}{% if loop.first and message['role'] != 'system' %}{{ '[|system|][|endofturn|]\\n' }}{% endif %}{% set content = message['content'] %}{% if '</thought>' in content %}{% set content = content.split('</thought>')[-1].lstrip('\\\\n') %}{% endif %}{{ '[|' + message['role'] + '|]' + content }}{% if not message['role'] == 'user' %}{{ '[|endofturn|]' }}{% endif %}{% if not loop.last %}{{ '\\n' }}{% endif %}{% endfor %}{% if add_generation_prompt %}{{ '\\n[|assistant|]<thought>\\n' }}{% endif %}\", \"eos_token\": \"[|endofturn|]\", \"pad_token\": \"[PAD]\", \"unk_token\": \"[UNK]\"}}, \"transformers_info\": {\"auto_model\": \"AutoModelForCausalLM\", \"custom_class\": \"modeling_exaone.ExaoneForCausalLM\", \"pipeline_tag\": \"text-generation\", \"processor\": null}, \"siblings\": [\"RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='configuration_exaone.py', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='merges.txt', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model-00001-of-00007.safetensors', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model-00002-of-00007.safetensors', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model-00003-of-00007.safetensors', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model-00004-of-00007.safetensors', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model-00005-of-00007.safetensors', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model-00006-of-00007.safetensors', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model-00007-of-00007.safetensors', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model.safetensors.index.json', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='modeling_exaone.py', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='vocab.json', size=None, blob_id=None, lfs=None)\"], \"spaces\": [], \"safetensors\": {\"parameters\": {\"F16\": 1000739840, \"U32\": 8000634880}, \"total\": 9001374720}, \"security_repo_status\": null, \"xet_enabled\": null, \"lastModified\": \"2025-03-18 23:07:11+00:00\", \"cardData\": \"base_model: LGAI-EXAONE/EXAONE-Deep-32B\\nlanguage:\\n- en\\n- ko\\nlibrary_name: transformers\\nlicense: other\\nlicense_name: exaone\\nlicense_link: LICENSE\\npipeline_tag: text-generation\\ntags:\\n- lg-ai\\n- exaone\\n- exaone-deep\\n- mlx\\nbase_model_relation: finetune\", \"transformersInfo\": {\"auto_model\": \"AutoModelForCausalLM\", \"custom_class\": \"modeling_exaone.ExaoneForCausalLM\", \"pipeline_tag\": \"text-generation\", \"processor\": null}, \"_id\": \"67d9fa5cf1cdeb60d7d489da\", \"modelId\": \"mlx-community/EXAONE-Deep-32B-8bit\", \"usedStorage\": 34004190106}",
            "depth": 1,
            "children": [],
            "children_count": 0
        },
        {
            "model_id": "alexgusevski/EXAONE-Deep-32B-mlx-8Bit",
            "metadata": "{\"id\": \"alexgusevski/EXAONE-Deep-32B-mlx-8Bit\", \"author\": \"alexgusevski\", \"sha\": \"7a728d10397de13fbbcf5a8005a2b19d13fb31f7\", \"last_modified\": \"2025-03-18 14:39:23+00:00\", \"created_at\": \"2025-03-18 13:46:04+00:00\", \"private\": false, \"gated\": false, \"disabled\": false, \"downloads\": 29, \"downloads_all_time\": null, \"likes\": 0, \"library_name\": \"transformers\", \"gguf\": null, \"inference\": null, \"inference_provider_mapping\": null, \"tags\": [\"transformers\", \"safetensors\", \"exaone\", \"text-generation\", \"lg-ai\", \"exaone-deep\", \"mlx\", \"mlx-my-repo\", \"conversational\", \"custom_code\", \"en\", \"ko\", \"base_model:LGAI-EXAONE/EXAONE-Deep-32B\", \"base_model:finetune:LGAI-EXAONE/EXAONE-Deep-32B\", \"license:other\", \"autotrain_compatible\", \"8-bit\", \"region:us\"], \"pipeline_tag\": \"text-generation\", \"mask_token\": null, \"trending_score\": null, \"card_data\": \"base_model: LGAI-EXAONE/EXAONE-Deep-32B\\nlanguage:\\n- en\\n- ko\\nlibrary_name: transformers\\nlicense: other\\nlicense_name: exaone\\nlicense_link: LICENSE\\npipeline_tag: text-generation\\ntags:\\n- lg-ai\\n- exaone\\n- exaone-deep\\n- mlx\\n- mlx-my-repo\\nbase_model_relation: finetune\", \"widget_data\": [{\"text\": \"Hi, what can you help me with?\"}, {\"text\": \"What is 84 * 3 / 2?\"}, {\"text\": \"Tell me an interesting fact about the universe!\"}, {\"text\": \"Explain quantum computing in simple terms.\"}], \"model_index\": null, \"config\": {\"architectures\": [\"ExaoneForCausalLM\"], \"auto_map\": {\"AutoConfig\": \"configuration_exaone.ExaoneConfig\", \"AutoModelForCausalLM\": \"modeling_exaone.ExaoneForCausalLM\", \"AutoModelForSequenceClassification\": \"modeling_exaone.ExaoneForSequenceClassification\"}, \"model_type\": \"exaone\", \"quantization_config\": {\"bits\": 8}, \"tokenizer_config\": {\"bos_token\": \"[BOS]\", \"chat_template\": \"{% for message in messages %}{% if loop.first and message['role'] != 'system' %}{{ '[|system|][|endofturn|]\\n' }}{% endif %}{% set content = message['content'] %}{% if '</thought>' in content %}{% set content = content.split('</thought>')[-1].lstrip('\\\\n') %}{% endif %}{{ '[|' + message['role'] + '|]' + content }}{% if not message['role'] == 'user' %}{{ '[|endofturn|]' }}{% endif %}{% if not loop.last %}{{ '\\n' }}{% endif %}{% endfor %}{% if add_generation_prompt %}{{ '\\n[|assistant|]<thought>\\n' }}{% endif %}\", \"eos_token\": \"[|endofturn|]\", \"pad_token\": \"[PAD]\", \"unk_token\": \"[UNK]\"}}, \"transformers_info\": {\"auto_model\": \"AutoModelForCausalLM\", \"custom_class\": \"modeling_exaone.ExaoneForCausalLM\", \"pipeline_tag\": \"text-generation\", \"processor\": null}, \"siblings\": [\"RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='configuration_exaone.py', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='merges.txt', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model-00001-of-00007.safetensors', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model-00002-of-00007.safetensors', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model-00003-of-00007.safetensors', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model-00004-of-00007.safetensors', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model-00005-of-00007.safetensors', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model-00006-of-00007.safetensors', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model-00007-of-00007.safetensors', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model.safetensors.index.json', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='modeling_exaone.py', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='vocab.json', size=None, blob_id=None, lfs=None)\"], \"spaces\": [], \"safetensors\": {\"parameters\": {\"F16\": 1000739840, \"U32\": 8000634880}, \"total\": 9001374720}, \"security_repo_status\": null, \"xet_enabled\": null, \"lastModified\": \"2025-03-18 14:39:23+00:00\", \"cardData\": \"base_model: LGAI-EXAONE/EXAONE-Deep-32B\\nlanguage:\\n- en\\n- ko\\nlibrary_name: transformers\\nlicense: other\\nlicense_name: exaone\\nlicense_link: LICENSE\\npipeline_tag: text-generation\\ntags:\\n- lg-ai\\n- exaone\\n- exaone-deep\\n- mlx\\n- mlx-my-repo\\nbase_model_relation: finetune\", \"transformersInfo\": {\"auto_model\": \"AutoModelForCausalLM\", \"custom_class\": \"modeling_exaone.ExaoneForCausalLM\", \"pipeline_tag\": \"text-generation\", \"processor\": null}, \"_id\": \"67d9791c0bf05cb1a6735b4f\", \"modelId\": \"alexgusevski/EXAONE-Deep-32B-mlx-8Bit\", \"usedStorage\": 34004190126}",
            "depth": 1,
            "children": [],
            "children_count": 0
        },
        {
            "model_id": "mlx-community/EXAONE-Deep-32B-4bit",
            "metadata": "{\"id\": \"mlx-community/EXAONE-Deep-32B-4bit\", \"author\": \"mlx-community\", \"sha\": \"55451587f43faeba43d871d7e5c26b2fc0cea18e\", \"last_modified\": \"2025-03-18 22:38:44+00:00\", \"created_at\": \"2025-03-18 22:33:21+00:00\", \"private\": false, \"gated\": false, \"disabled\": false, \"downloads\": 100, \"downloads_all_time\": null, \"likes\": 1, \"library_name\": \"transformers\", \"gguf\": null, \"inference\": null, \"inference_provider_mapping\": null, \"tags\": [\"transformers\", \"safetensors\", \"exaone\", \"text-generation\", \"lg-ai\", \"exaone-deep\", \"mlx\", \"conversational\", \"custom_code\", \"en\", \"ko\", \"base_model:LGAI-EXAONE/EXAONE-Deep-32B\", \"base_model:finetune:LGAI-EXAONE/EXAONE-Deep-32B\", \"license:other\", \"autotrain_compatible\", \"4-bit\", \"region:us\"], \"pipeline_tag\": \"text-generation\", \"mask_token\": null, \"trending_score\": null, \"card_data\": \"base_model: LGAI-EXAONE/EXAONE-Deep-32B\\nlanguage:\\n- en\\n- ko\\nlibrary_name: transformers\\nlicense: other\\nlicense_name: exaone\\nlicense_link: LICENSE\\npipeline_tag: text-generation\\ntags:\\n- lg-ai\\n- exaone\\n- exaone-deep\\n- mlx\\nbase_model_relation: finetune\", \"widget_data\": [{\"text\": \"Hi, what can you help me with?\"}, {\"text\": \"What is 84 * 3 / 2?\"}, {\"text\": \"Tell me an interesting fact about the universe!\"}, {\"text\": \"Explain quantum computing in simple terms.\"}], \"model_index\": null, \"config\": {\"architectures\": [\"ExaoneForCausalLM\"], \"auto_map\": {\"AutoConfig\": \"configuration_exaone.ExaoneConfig\", \"AutoModelForCausalLM\": \"modeling_exaone.ExaoneForCausalLM\", \"AutoModelForSequenceClassification\": \"modeling_exaone.ExaoneForSequenceClassification\"}, \"model_type\": \"exaone\", \"quantization_config\": {\"bits\": 4}, \"tokenizer_config\": {\"bos_token\": \"[BOS]\", \"chat_template\": \"{% for message in messages %}{% if loop.first and message['role'] != 'system' %}{{ '[|system|][|endofturn|]\\n' }}{% endif %}{% set content = message['content'] %}{% if '</thought>' in content %}{% set content = content.split('</thought>')[-1].lstrip('\\\\n') %}{% endif %}{{ '[|' + message['role'] + '|]' + content }}{% if not message['role'] == 'user' %}{{ '[|endofturn|]' }}{% endif %}{% if not loop.last %}{{ '\\n' }}{% endif %}{% endfor %}{% if add_generation_prompt %}{{ '\\n[|assistant|]<thought>\\n' }}{% endif %}\", \"eos_token\": \"[|endofturn|]\", \"pad_token\": \"[PAD]\", \"unk_token\": \"[UNK]\"}}, \"transformers_info\": {\"auto_model\": \"AutoModelForCausalLM\", \"custom_class\": \"modeling_exaone.ExaoneForCausalLM\", \"pipeline_tag\": \"text-generation\", \"processor\": null}, \"siblings\": [\"RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='configuration_exaone.py', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='merges.txt', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model-00001-of-00004.safetensors', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model-00002-of-00004.safetensors', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model-00003-of-00004.safetensors', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model-00004-of-00004.safetensors', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model.safetensors.index.json', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='modeling_exaone.py', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='vocab.json', size=None, blob_id=None, lfs=None)\"], \"spaces\": [], \"safetensors\": {\"parameters\": {\"F16\": 1000739840, \"U32\": 4000317440}, \"total\": 5001057280}, \"security_repo_status\": null, \"xet_enabled\": null, \"lastModified\": \"2025-03-18 22:38:44+00:00\", \"cardData\": \"base_model: LGAI-EXAONE/EXAONE-Deep-32B\\nlanguage:\\n- en\\n- ko\\nlibrary_name: transformers\\nlicense: other\\nlicense_name: exaone\\nlicense_link: LICENSE\\npipeline_tag: text-generation\\ntags:\\n- lg-ai\\n- exaone\\n- exaone-deep\\n- mlx\\nbase_model_relation: finetune\", \"transformersInfo\": {\"auto_model\": \"AutoModelForCausalLM\", \"custom_class\": \"modeling_exaone.ExaoneForCausalLM\", \"pipeline_tag\": \"text-generation\", \"processor\": null}, \"_id\": \"67d9f4b1f5ff03f1caf7e0bc\", \"modelId\": \"mlx-community/EXAONE-Deep-32B-4bit\", \"usedStorage\": 18002919870}",
            "depth": 1,
            "children": [],
            "children_count": 0
        },
        {
            "model_id": "BlackBeenie/EXAONE-Deep-32B-Q4_K_M-GGUF",
            "metadata": "{\"id\": \"BlackBeenie/EXAONE-Deep-32B-Q4_K_M-GGUF\", \"author\": \"BlackBeenie\", \"sha\": \"8d0f556dbf962cff33ad91c6a51198ea2bef0ce8\", \"last_modified\": \"2025-03-19 08:58:10+00:00\", \"created_at\": \"2025-03-19 08:56:41+00:00\", \"private\": false, \"gated\": false, \"disabled\": false, \"downloads\": 51, \"downloads_all_time\": null, \"likes\": 0, \"library_name\": \"transformers\", \"gguf\": {\"total\": 32003200064, \"architecture\": \"exaone\", \"context_length\": 32768, \"chat_template\": \"{% for message in messages %}{% if loop.first and message['role'] != 'system' %}{{ '[|system|][|endofturn|]\\n' }}{% endif %}{% set content = message['content'] %}{% if '</thought>' in content %}{% set content = content.split('</thought>')[-1].lstrip('\\\\n') %}{% endif %}{{ '[|' + message['role'] + '|]' + content }}{% if not message['role'] == 'user' %}{{ '[|endofturn|]' }}{% endif %}{% if not loop.last %}{{ '\\n' }}{% endif %}{% endfor %}{% if add_generation_prompt %}{{ '\\n[|assistant|]<thought>\\n' }}{% endif %}\", \"bos_token\": \"[BOS]\", \"eos_token\": \"[|endofturn|]\"}, \"inference\": null, \"inference_provider_mapping\": null, \"tags\": [\"transformers\", \"gguf\", \"lg-ai\", \"exaone\", \"exaone-deep\", \"llama-cpp\", \"gguf-my-repo\", \"text-generation\", \"en\", \"ko\", \"base_model:LGAI-EXAONE/EXAONE-Deep-32B\", \"base_model:finetune:LGAI-EXAONE/EXAONE-Deep-32B\", \"license:other\", \"endpoints_compatible\", \"region:us\", \"conversational\"], \"pipeline_tag\": \"text-generation\", \"mask_token\": null, \"trending_score\": null, \"card_data\": \"base_model: LGAI-EXAONE/EXAONE-Deep-32B\\nlanguage:\\n- en\\n- ko\\nlibrary_name: transformers\\nlicense: other\\nlicense_name: exaone\\nlicense_link: LICENSE\\npipeline_tag: text-generation\\ntags:\\n- lg-ai\\n- exaone\\n- exaone-deep\\n- llama-cpp\\n- gguf-my-repo\\nbase_model_relation: finetune\", \"widget_data\": [{\"text\": \"Hi, what can you help me with?\"}, {\"text\": \"What is 84 * 3 / 2?\"}, {\"text\": \"Tell me an interesting fact about the universe!\"}, {\"text\": \"Explain quantum computing in simple terms.\"}], \"model_index\": null, \"config\": null, \"transformers_info\": {\"auto_model\": \"AutoModel\", \"custom_class\": null, \"pipeline_tag\": null, \"processor\": null}, \"siblings\": [\"RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='exaone-deep-32b-q4_k_m.gguf', size=None, blob_id=None, lfs=None)\"], \"spaces\": [], \"safetensors\": null, \"security_repo_status\": null, \"xet_enabled\": null, \"lastModified\": \"2025-03-19 08:58:10+00:00\", \"cardData\": \"base_model: LGAI-EXAONE/EXAONE-Deep-32B\\nlanguage:\\n- en\\n- ko\\nlibrary_name: transformers\\nlicense: other\\nlicense_name: exaone\\nlicense_link: LICENSE\\npipeline_tag: text-generation\\ntags:\\n- lg-ai\\n- exaone\\n- exaone-deep\\n- llama-cpp\\n- gguf-my-repo\\nbase_model_relation: finetune\", \"transformersInfo\": {\"auto_model\": \"AutoModel\", \"custom_class\": null, \"pipeline_tag\": null, \"processor\": null}, \"_id\": \"67da86c91a7fc590e799f8ea\", \"modelId\": \"BlackBeenie/EXAONE-Deep-32B-Q4_K_M-GGUF\", \"usedStorage\": 19343748224}",
            "depth": 1,
            "children": [],
            "children_count": 0
        },
        {
            "model_id": "AGCobra/EXAONE-Deep-32B-mlx-4Bit",
            "metadata": "{\"id\": \"AGCobra/EXAONE-Deep-32B-mlx-4Bit\", \"author\": \"AGCobra\", \"sha\": \"16eebd64c05694fc2924f6b701d8780da144314a\", \"last_modified\": \"2025-03-21 05:38:50+00:00\", \"created_at\": \"2025-03-21 05:37:36+00:00\", \"private\": false, \"gated\": false, \"disabled\": false, \"downloads\": 10, \"downloads_all_time\": null, \"likes\": 0, \"library_name\": \"transformers\", \"gguf\": null, \"inference\": null, \"inference_provider_mapping\": null, \"tags\": [\"transformers\", \"safetensors\", \"exaone\", \"text-generation\", \"lg-ai\", \"exaone-deep\", \"mlx\", \"mlx-my-repo\", \"conversational\", \"custom_code\", \"en\", \"ko\", \"base_model:LGAI-EXAONE/EXAONE-Deep-32B\", \"base_model:finetune:LGAI-EXAONE/EXAONE-Deep-32B\", \"license:other\", \"autotrain_compatible\", \"4-bit\", \"region:us\"], \"pipeline_tag\": \"text-generation\", \"mask_token\": null, \"trending_score\": null, \"card_data\": \"base_model: LGAI-EXAONE/EXAONE-Deep-32B\\nlanguage:\\n- en\\n- ko\\nlibrary_name: transformers\\nlicense: other\\nlicense_name: exaone\\nlicense_link: LICENSE\\npipeline_tag: text-generation\\ntags:\\n- lg-ai\\n- exaone\\n- exaone-deep\\n- mlx\\n- mlx-my-repo\\nbase_model_relation: finetune\", \"widget_data\": [{\"text\": \"Hi, what can you help me with?\"}, {\"text\": \"What is 84 * 3 / 2?\"}, {\"text\": \"Tell me an interesting fact about the universe!\"}, {\"text\": \"Explain quantum computing in simple terms.\"}], \"model_index\": null, \"config\": {\"architectures\": [\"ExaoneForCausalLM\"], \"auto_map\": {\"AutoConfig\": \"configuration_exaone.ExaoneConfig\", \"AutoModelForCausalLM\": \"modeling_exaone.ExaoneForCausalLM\", \"AutoModelForSequenceClassification\": \"modeling_exaone.ExaoneForSequenceClassification\"}, \"model_type\": \"exaone\", \"quantization_config\": {\"bits\": 4}, \"tokenizer_config\": {\"bos_token\": \"[BOS]\", \"chat_template\": \"{% for message in messages %}{% if loop.first and message['role'] != 'system' %}{{ '[|system|][|endofturn|]\\n' }}{% endif %}{% set content = message['content'] %}{% if '</thought>' in content %}{% set content = content.split('</thought>')[-1].lstrip('\\\\n') %}{% endif %}{{ '[|' + message['role'] + '|]' + content }}{% if not message['role'] == 'user' %}{{ '[|endofturn|]' }}{% endif %}{% if not loop.last %}{{ '\\n' }}{% endif %}{% endfor %}{% if add_generation_prompt %}{{ '\\n[|assistant|]<thought>\\n' }}{% endif %}\", \"eos_token\": \"[|endofturn|]\", \"pad_token\": \"[PAD]\", \"unk_token\": \"[UNK]\"}}, \"transformers_info\": {\"auto_model\": \"AutoModelForCausalLM\", \"custom_class\": \"modeling_exaone.ExaoneForCausalLM\", \"pipeline_tag\": \"text-generation\", \"processor\": null}, \"siblings\": [\"RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='configuration_exaone.py', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='merges.txt', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model-00001-of-00004.safetensors', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model-00002-of-00004.safetensors', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model-00003-of-00004.safetensors', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model-00004-of-00004.safetensors', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model.safetensors.index.json', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='modeling_exaone.py', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='vocab.json', size=None, blob_id=None, lfs=None)\"], \"spaces\": [], \"safetensors\": {\"parameters\": {\"F16\": 1000739840, \"U32\": 4000317440}, \"total\": 5001057280}, \"security_repo_status\": null, \"xet_enabled\": null, \"lastModified\": \"2025-03-21 05:38:50+00:00\", \"cardData\": \"base_model: LGAI-EXAONE/EXAONE-Deep-32B\\nlanguage:\\n- en\\n- ko\\nlibrary_name: transformers\\nlicense: other\\nlicense_name: exaone\\nlicense_link: LICENSE\\npipeline_tag: text-generation\\ntags:\\n- lg-ai\\n- exaone\\n- exaone-deep\\n- mlx\\n- mlx-my-repo\\nbase_model_relation: finetune\", \"transformersInfo\": {\"auto_model\": \"AutoModelForCausalLM\", \"custom_class\": \"modeling_exaone.ExaoneForCausalLM\", \"pipeline_tag\": \"text-generation\", \"processor\": null}, \"_id\": \"67dcfb203713a0e1da24b2ec\", \"modelId\": \"AGCobra/EXAONE-Deep-32B-mlx-4Bit\", \"usedStorage\": 18002919934}",
            "depth": 1,
            "children": [],
            "children_count": 0
        },
        {
            "model_id": "mlx-community/EXAONE-Deep-32B-3bit",
            "metadata": "{\"id\": \"mlx-community/EXAONE-Deep-32B-3bit\", \"author\": \"mlx-community\", \"sha\": \"18247baad488789a61978fdd1817a3fc7f958b6b\", \"last_modified\": \"2025-03-18 22:46:21+00:00\", \"created_at\": \"2025-03-18 22:41:19+00:00\", \"private\": false, \"gated\": false, \"disabled\": false, \"downloads\": 7, \"downloads_all_time\": null, \"likes\": 0, \"library_name\": \"transformers\", \"gguf\": null, \"inference\": null, \"inference_provider_mapping\": null, \"tags\": [\"transformers\", \"safetensors\", \"exaone\", \"text-generation\", \"lg-ai\", \"exaone-deep\", \"mlx\", \"conversational\", \"custom_code\", \"en\", \"ko\", \"base_model:LGAI-EXAONE/EXAONE-Deep-32B\", \"base_model:finetune:LGAI-EXAONE/EXAONE-Deep-32B\", \"license:other\", \"autotrain_compatible\", \"3-bit\", \"region:us\"], \"pipeline_tag\": \"text-generation\", \"mask_token\": null, \"trending_score\": null, \"card_data\": \"base_model: LGAI-EXAONE/EXAONE-Deep-32B\\nlanguage:\\n- en\\n- ko\\nlibrary_name: transformers\\nlicense: other\\nlicense_name: exaone\\nlicense_link: LICENSE\\npipeline_tag: text-generation\\ntags:\\n- lg-ai\\n- exaone\\n- exaone-deep\\n- mlx\\nbase_model_relation: finetune\", \"widget_data\": [{\"text\": \"Hi, what can you help me with?\"}, {\"text\": \"What is 84 * 3 / 2?\"}, {\"text\": \"Tell me an interesting fact about the universe!\"}, {\"text\": \"Explain quantum computing in simple terms.\"}], \"model_index\": null, \"config\": {\"architectures\": [\"ExaoneForCausalLM\"], \"auto_map\": {\"AutoConfig\": \"configuration_exaone.ExaoneConfig\", \"AutoModelForCausalLM\": \"modeling_exaone.ExaoneForCausalLM\", \"AutoModelForSequenceClassification\": \"modeling_exaone.ExaoneForSequenceClassification\"}, \"model_type\": \"exaone\", \"quantization_config\": {\"bits\": 3}, \"tokenizer_config\": {\"bos_token\": \"[BOS]\", \"chat_template\": \"{% for message in messages %}{% if loop.first and message['role'] != 'system' %}{{ '[|system|][|endofturn|]\\n' }}{% endif %}{% set content = message['content'] %}{% if '</thought>' in content %}{% set content = content.split('</thought>')[-1].lstrip('\\\\n') %}{% endif %}{{ '[|' + message['role'] + '|]' + content }}{% if not message['role'] == 'user' %}{{ '[|endofturn|]' }}{% endif %}{% if not loop.last %}{{ '\\n' }}{% endif %}{% endfor %}{% if add_generation_prompt %}{{ '\\n[|assistant|]<thought>\\n' }}{% endif %}\", \"eos_token\": \"[|endofturn|]\", \"pad_token\": \"[PAD]\", \"unk_token\": \"[UNK]\"}}, \"transformers_info\": {\"auto_model\": \"AutoModelForCausalLM\", \"custom_class\": \"modeling_exaone.ExaoneForCausalLM\", \"pipeline_tag\": \"text-generation\", \"processor\": null}, \"siblings\": [\"RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='configuration_exaone.py', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='merges.txt', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model-00001-of-00003.safetensors', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model-00002-of-00003.safetensors', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model-00003-of-00003.safetensors', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model.safetensors.index.json', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='modeling_exaone.py', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='vocab.json', size=None, blob_id=None, lfs=None)\"], \"spaces\": [], \"safetensors\": {\"parameters\": {\"F16\": 1000739840, \"U32\": 3000238080}, \"total\": 4000977920}, \"security_repo_status\": null, \"xet_enabled\": null, \"lastModified\": \"2025-03-18 22:46:21+00:00\", \"cardData\": \"base_model: LGAI-EXAONE/EXAONE-Deep-32B\\nlanguage:\\n- en\\n- ko\\nlibrary_name: transformers\\nlicense: other\\nlicense_name: exaone\\nlicense_link: LICENSE\\npipeline_tag: text-generation\\ntags:\\n- lg-ai\\n- exaone\\n- exaone-deep\\n- mlx\\nbase_model_relation: finetune\", \"transformersInfo\": {\"auto_model\": \"AutoModelForCausalLM\", \"custom_class\": \"modeling_exaone.ExaoneForCausalLM\", \"pipeline_tag\": \"text-generation\", \"processor\": null}, \"_id\": \"67d9f68f12ee0e2aaaf35198\", \"modelId\": \"mlx-community/EXAONE-Deep-32B-3bit\", \"usedStorage\": 14002602500}",
            "depth": 1,
            "children": [],
            "children_count": 0
        },
        {
            "model_id": "KYUNGYONG/EXAONE-Deep-32B-mlx-3Bit",
            "metadata": "{\"id\": \"KYUNGYONG/EXAONE-Deep-32B-mlx-3Bit\", \"author\": \"KYUNGYONG\", \"sha\": \"cecfa74f0ca5cce5f38028adf793adb7a594cf9e\", \"last_modified\": \"2025-03-18 02:28:34+00:00\", \"created_at\": \"2025-03-18 02:27:36+00:00\", \"private\": false, \"gated\": false, \"disabled\": false, \"downloads\": 13, \"downloads_all_time\": null, \"likes\": 0, \"library_name\": \"transformers\", \"gguf\": null, \"inference\": null, \"inference_provider_mapping\": null, \"tags\": [\"transformers\", \"safetensors\", \"exaone\", \"text-generation\", \"lg-ai\", \"exaone-deep\", \"mlx\", \"mlx-my-repo\", \"conversational\", \"custom_code\", \"en\", \"ko\", \"base_model:LGAI-EXAONE/EXAONE-Deep-32B\", \"base_model:finetune:LGAI-EXAONE/EXAONE-Deep-32B\", \"license:other\", \"autotrain_compatible\", \"3-bit\", \"region:us\"], \"pipeline_tag\": \"text-generation\", \"mask_token\": null, \"trending_score\": null, \"card_data\": \"base_model: LGAI-EXAONE/EXAONE-Deep-32B\\nlanguage:\\n- en\\n- ko\\nlibrary_name: transformers\\nlicense: other\\nlicense_name: exaone\\nlicense_link: LICENSE\\npipeline_tag: text-generation\\ntags:\\n- lg-ai\\n- exaone\\n- exaone-deep\\n- mlx\\n- mlx-my-repo\\nbase_model_relation: finetune\", \"widget_data\": [{\"text\": \"Hi, what can you help me with?\"}, {\"text\": \"What is 84 * 3 / 2?\"}, {\"text\": \"Tell me an interesting fact about the universe!\"}, {\"text\": \"Explain quantum computing in simple terms.\"}], \"model_index\": null, \"config\": {\"architectures\": [\"ExaoneForCausalLM\"], \"auto_map\": {\"AutoConfig\": \"configuration_exaone.ExaoneConfig\", \"AutoModelForCausalLM\": \"modeling_exaone.ExaoneForCausalLM\", \"AutoModelForSequenceClassification\": \"modeling_exaone.ExaoneForSequenceClassification\"}, \"model_type\": \"exaone\", \"quantization_config\": {\"bits\": 3}, \"tokenizer_config\": {\"bos_token\": \"[BOS]\", \"chat_template\": \"{% for message in messages %}{% if loop.first and message['role'] != 'system' %}{{ '[|system|][|endofturn|]\\n' }}{% endif %}{% set content = message['content'] %}{% if '</thought>' in content %}{% set content = content.split('</thought>')[-1].lstrip('\\\\n') %}{% endif %}{{ '[|' + message['role'] + '|]' + content }}{% if not message['role'] == 'user' %}{{ '[|endofturn|]' }}{% endif %}{% if not loop.last %}{{ '\\n' }}{% endif %}{% endfor %}{% if add_generation_prompt %}{{ '\\n[|assistant|]<thought>\\n' }}{% endif %}\", \"eos_token\": \"[|endofturn|]\", \"pad_token\": \"[PAD]\", \"unk_token\": \"[UNK]\"}}, \"transformers_info\": {\"auto_model\": \"AutoModelForCausalLM\", \"custom_class\": \"modeling_exaone.ExaoneForCausalLM\", \"pipeline_tag\": \"text-generation\", \"processor\": null}, \"siblings\": [\"RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='configuration_exaone.py', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='merges.txt', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model-00001-of-00003.safetensors', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model-00002-of-00003.safetensors', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model-00003-of-00003.safetensors', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model.safetensors.index.json', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='modeling_exaone.py', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='vocab.json', size=None, blob_id=None, lfs=None)\"], \"spaces\": [], \"safetensors\": {\"parameters\": {\"F16\": 1000739840, \"U32\": 3000238080}, \"total\": 4000977920}, \"security_repo_status\": null, \"xet_enabled\": null, \"lastModified\": \"2025-03-18 02:28:34+00:00\", \"cardData\": \"base_model: LGAI-EXAONE/EXAONE-Deep-32B\\nlanguage:\\n- en\\n- ko\\nlibrary_name: transformers\\nlicense: other\\nlicense_name: exaone\\nlicense_link: LICENSE\\npipeline_tag: text-generation\\ntags:\\n- lg-ai\\n- exaone\\n- exaone-deep\\n- mlx\\n- mlx-my-repo\\nbase_model_relation: finetune\", \"transformersInfo\": {\"auto_model\": \"AutoModelForCausalLM\", \"custom_class\": \"modeling_exaone.ExaoneForCausalLM\", \"pipeline_tag\": \"text-generation\", \"processor\": null}, \"_id\": \"67d8da1846f8b818c7498fb7\", \"modelId\": \"KYUNGYONG/EXAONE-Deep-32B-mlx-3Bit\", \"usedStorage\": 14002602474}",
            "depth": 1,
            "children": [],
            "children_count": 0
        },
        {
            "model_id": "alexgusevski/EXAONE-Deep-32B-mlx-3Bit",
            "metadata": "{\"id\": \"alexgusevski/EXAONE-Deep-32B-mlx-3Bit\", \"author\": \"alexgusevski\", \"sha\": \"4a5f5db4c395d2c442b3d2c46583538739c1fb10\", \"last_modified\": \"2025-03-18 14:38:55+00:00\", \"created_at\": \"2025-03-18 12:09:07+00:00\", \"private\": false, \"gated\": false, \"disabled\": false, \"downloads\": 5, \"downloads_all_time\": null, \"likes\": 0, \"library_name\": \"transformers\", \"gguf\": null, \"inference\": null, \"inference_provider_mapping\": null, \"tags\": [\"transformers\", \"safetensors\", \"exaone\", \"text-generation\", \"lg-ai\", \"exaone-deep\", \"mlx\", \"mlx-my-repo\", \"conversational\", \"custom_code\", \"en\", \"ko\", \"base_model:LGAI-EXAONE/EXAONE-Deep-32B\", \"base_model:finetune:LGAI-EXAONE/EXAONE-Deep-32B\", \"license:other\", \"autotrain_compatible\", \"3-bit\", \"region:us\"], \"pipeline_tag\": \"text-generation\", \"mask_token\": null, \"trending_score\": null, \"card_data\": \"base_model: LGAI-EXAONE/EXAONE-Deep-32B\\nlanguage:\\n- en\\n- ko\\nlibrary_name: transformers\\nlicense: other\\nlicense_name: exaone\\nlicense_link: LICENSE\\npipeline_tag: text-generation\\ntags:\\n- lg-ai\\n- exaone\\n- exaone-deep\\n- mlx\\n- mlx-my-repo\\nbase_model_relation: finetune\", \"widget_data\": [{\"text\": \"Hi, what can you help me with?\"}, {\"text\": \"What is 84 * 3 / 2?\"}, {\"text\": \"Tell me an interesting fact about the universe!\"}, {\"text\": \"Explain quantum computing in simple terms.\"}], \"model_index\": null, \"config\": {\"architectures\": [\"ExaoneForCausalLM\"], \"auto_map\": {\"AutoConfig\": \"configuration_exaone.ExaoneConfig\", \"AutoModelForCausalLM\": \"modeling_exaone.ExaoneForCausalLM\", \"AutoModelForSequenceClassification\": \"modeling_exaone.ExaoneForSequenceClassification\"}, \"model_type\": \"exaone\", \"quantization_config\": {\"bits\": 3}, \"tokenizer_config\": {\"bos_token\": \"[BOS]\", \"chat_template\": \"{% for message in messages %}{% if loop.first and message['role'] != 'system' %}{{ '[|system|][|endofturn|]\\n' }}{% endif %}{% set content = message['content'] %}{% if '</thought>' in content %}{% set content = content.split('</thought>')[-1].lstrip('\\\\n') %}{% endif %}{{ '[|' + message['role'] + '|]' + content }}{% if not message['role'] == 'user' %}{{ '[|endofturn|]' }}{% endif %}{% if not loop.last %}{{ '\\n' }}{% endif %}{% endfor %}{% if add_generation_prompt %}{{ '\\n[|assistant|]<thought>\\n' }}{% endif %}\", \"eos_token\": \"[|endofturn|]\", \"pad_token\": \"[PAD]\", \"unk_token\": \"[UNK]\"}}, \"transformers_info\": {\"auto_model\": \"AutoModelForCausalLM\", \"custom_class\": \"modeling_exaone.ExaoneForCausalLM\", \"pipeline_tag\": \"text-generation\", \"processor\": null}, \"siblings\": [\"RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='configuration_exaone.py', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='merges.txt', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model-00001-of-00003.safetensors', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model-00002-of-00003.safetensors', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model-00003-of-00003.safetensors', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model.safetensors.index.json', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='modeling_exaone.py', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='vocab.json', size=None, blob_id=None, lfs=None)\"], \"spaces\": [], \"safetensors\": {\"parameters\": {\"F16\": 1000739840, \"U32\": 3000238080}, \"total\": 4000977920}, \"security_repo_status\": null, \"xet_enabled\": null, \"lastModified\": \"2025-03-18 14:38:55+00:00\", \"cardData\": \"base_model: LGAI-EXAONE/EXAONE-Deep-32B\\nlanguage:\\n- en\\n- ko\\nlibrary_name: transformers\\nlicense: other\\nlicense_name: exaone\\nlicense_link: LICENSE\\npipeline_tag: text-generation\\ntags:\\n- lg-ai\\n- exaone\\n- exaone-deep\\n- mlx\\n- mlx-my-repo\\nbase_model_relation: finetune\", \"transformersInfo\": {\"auto_model\": \"AutoModelForCausalLM\", \"custom_class\": \"modeling_exaone.ExaoneForCausalLM\", \"pipeline_tag\": \"text-generation\", \"processor\": null}, \"_id\": \"67d96263e71ef26f5e130da4\", \"modelId\": \"alexgusevski/EXAONE-Deep-32B-mlx-3Bit\", \"usedStorage\": 14002602474}",
            "depth": 1,
            "children": [],
            "children_count": 0
        },
        {
            "model_id": "mlx-community/EXAONE-Deep-32B-mlx-8Bit",
            "metadata": "{\"id\": \"mlx-community/EXAONE-Deep-32B-mlx-8Bit\", \"author\": \"mlx-community\", \"sha\": \"ad514edef912831aaf3f65be700a659f12d46a98\", \"last_modified\": \"2025-03-21 06:33:48+00:00\", \"created_at\": \"2025-03-21 06:09:51+00:00\", \"private\": false, \"gated\": false, \"disabled\": false, \"downloads\": 36, \"downloads_all_time\": null, \"likes\": 0, \"library_name\": \"transformers\", \"gguf\": null, \"inference\": null, \"inference_provider_mapping\": null, \"tags\": [\"transformers\", \"safetensors\", \"exaone\", \"text-generation\", \"lg-ai\", \"exaone-deep\", \"mlx\", \"mlx-my-repo\", \"conversational\", \"custom_code\", \"en\", \"ko\", \"base_model:LGAI-EXAONE/EXAONE-Deep-32B\", \"base_model:finetune:LGAI-EXAONE/EXAONE-Deep-32B\", \"license:other\", \"autotrain_compatible\", \"8-bit\", \"region:us\"], \"pipeline_tag\": \"text-generation\", \"mask_token\": null, \"trending_score\": null, \"card_data\": \"base_model: LGAI-EXAONE/EXAONE-Deep-32B\\nlanguage:\\n- en\\n- ko\\nlibrary_name: transformers\\nlicense: other\\nlicense_name: exaone\\nlicense_link: LICENSE\\npipeline_tag: text-generation\\ntags:\\n- lg-ai\\n- exaone\\n- exaone-deep\\n- mlx\\n- mlx-my-repo\\nbase_model_relation: finetune\", \"widget_data\": [{\"text\": \"Hi, what can you help me with?\"}, {\"text\": \"What is 84 * 3 / 2?\"}, {\"text\": \"Tell me an interesting fact about the universe!\"}, {\"text\": \"Explain quantum computing in simple terms.\"}], \"model_index\": null, \"config\": {\"architectures\": [\"ExaoneForCausalLM\"], \"auto_map\": {\"AutoConfig\": \"configuration_exaone.ExaoneConfig\", \"AutoModelForCausalLM\": \"modeling_exaone.ExaoneForCausalLM\", \"AutoModelForSequenceClassification\": \"modeling_exaone.ExaoneForSequenceClassification\"}, \"model_type\": \"exaone\", \"quantization_config\": {\"bits\": 8}, \"tokenizer_config\": {\"bos_token\": \"[BOS]\", \"chat_template\": \"{% for message in messages %}{% if loop.first and message['role'] != 'system' %}{{ '[|system|][|endofturn|]\\n' }}{% endif %}{% set content = message['content'] %}{% if '</thought>' in content %}{% set content = content.split('</thought>')[-1].lstrip('\\\\n') %}{% endif %}{{ '[|' + message['role'] + '|]' + content }}{% if not message['role'] == 'user' %}{{ '[|endofturn|]' }}{% endif %}{% if not loop.last %}{{ '\\n' }}{% endif %}{% endfor %}{% if add_generation_prompt %}{{ '\\n[|assistant|]<thought>\\n' }}{% endif %}\", \"eos_token\": \"[|endofturn|]\", \"pad_token\": \"[PAD]\", \"unk_token\": \"[UNK]\"}}, \"transformers_info\": {\"auto_model\": \"AutoModelForCausalLM\", \"custom_class\": \"modeling_exaone.ExaoneForCausalLM\", \"pipeline_tag\": \"text-generation\", \"processor\": null}, \"siblings\": [\"RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='configuration_exaone.py', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='merges.txt', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model-00001-of-00007.safetensors', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model-00002-of-00007.safetensors', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model-00003-of-00007.safetensors', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model-00004-of-00007.safetensors', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model-00005-of-00007.safetensors', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model-00006-of-00007.safetensors', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model-00007-of-00007.safetensors', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model.safetensors.index.json', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='modeling_exaone.py', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='vocab.json', size=None, blob_id=None, lfs=None)\"], \"spaces\": [], \"safetensors\": {\"parameters\": {\"F16\": 1000739840, \"U32\": 8000634880}, \"total\": 9001374720}, \"security_repo_status\": null, \"xet_enabled\": null, \"lastModified\": \"2025-03-21 06:33:48+00:00\", \"cardData\": \"base_model: LGAI-EXAONE/EXAONE-Deep-32B\\nlanguage:\\n- en\\n- ko\\nlibrary_name: transformers\\nlicense: other\\nlicense_name: exaone\\nlicense_link: LICENSE\\npipeline_tag: text-generation\\ntags:\\n- lg-ai\\n- exaone\\n- exaone-deep\\n- mlx\\n- mlx-my-repo\\nbase_model_relation: finetune\", \"transformersInfo\": {\"auto_model\": \"AutoModelForCausalLM\", \"custom_class\": \"modeling_exaone.ExaoneForCausalLM\", \"pipeline_tag\": \"text-generation\", \"processor\": null}, \"_id\": \"67dd02af42687f2747ab229f\", \"modelId\": \"mlx-community/EXAONE-Deep-32B-mlx-8Bit\", \"usedStorage\": 34004190126}",
            "depth": 1,
            "children": [],
            "children_count": 0
        },
        {
            "model_id": "KYUNGYONG/EXAONE-Deep-32B-mlx-4Bit",
            "metadata": "{\"id\": \"KYUNGYONG/EXAONE-Deep-32B-mlx-4Bit\", \"author\": \"KYUNGYONG\", \"sha\": \"63f060a1a762c5b81a2bc0b2a345781487ae59d9\", \"last_modified\": \"2025-03-18 03:00:34+00:00\", \"created_at\": \"2025-03-18 02:59:16+00:00\", \"private\": false, \"gated\": false, \"disabled\": false, \"downloads\": 19, \"downloads_all_time\": null, \"likes\": 0, \"library_name\": \"transformers\", \"gguf\": null, \"inference\": null, \"inference_provider_mapping\": null, \"tags\": [\"transformers\", \"safetensors\", \"exaone\", \"text-generation\", \"lg-ai\", \"exaone-deep\", \"mlx\", \"mlx-my-repo\", \"conversational\", \"custom_code\", \"en\", \"ko\", \"base_model:LGAI-EXAONE/EXAONE-Deep-32B\", \"base_model:finetune:LGAI-EXAONE/EXAONE-Deep-32B\", \"license:other\", \"autotrain_compatible\", \"4-bit\", \"region:us\"], \"pipeline_tag\": \"text-generation\", \"mask_token\": null, \"trending_score\": null, \"card_data\": \"base_model: LGAI-EXAONE/EXAONE-Deep-32B\\nlanguage:\\n- en\\n- ko\\nlibrary_name: transformers\\nlicense: other\\nlicense_name: exaone\\nlicense_link: LICENSE\\npipeline_tag: text-generation\\ntags:\\n- lg-ai\\n- exaone\\n- exaone-deep\\n- mlx\\n- mlx-my-repo\\nbase_model_relation: finetune\", \"widget_data\": [{\"text\": \"Hi, what can you help me with?\"}, {\"text\": \"What is 84 * 3 / 2?\"}, {\"text\": \"Tell me an interesting fact about the universe!\"}, {\"text\": \"Explain quantum computing in simple terms.\"}], \"model_index\": null, \"config\": {\"architectures\": [\"ExaoneForCausalLM\"], \"auto_map\": {\"AutoConfig\": \"configuration_exaone.ExaoneConfig\", \"AutoModelForCausalLM\": \"modeling_exaone.ExaoneForCausalLM\", \"AutoModelForSequenceClassification\": \"modeling_exaone.ExaoneForSequenceClassification\"}, \"model_type\": \"exaone\", \"quantization_config\": {\"bits\": 4}, \"tokenizer_config\": {\"bos_token\": \"[BOS]\", \"chat_template\": \"{% for message in messages %}{% if loop.first and message['role'] != 'system' %}{{ '[|system|][|endofturn|]\\n' }}{% endif %}{% set content = message['content'] %}{% if '</thought>' in content %}{% set content = content.split('</thought>')[-1].lstrip('\\\\n') %}{% endif %}{{ '[|' + message['role'] + '|]' + content }}{% if not message['role'] == 'user' %}{{ '[|endofturn|]' }}{% endif %}{% if not loop.last %}{{ '\\n' }}{% endif %}{% endfor %}{% if add_generation_prompt %}{{ '\\n[|assistant|]<thought>\\n' }}{% endif %}\", \"eos_token\": \"[|endofturn|]\", \"pad_token\": \"[PAD]\", \"unk_token\": \"[UNK]\"}}, \"transformers_info\": {\"auto_model\": \"AutoModelForCausalLM\", \"custom_class\": \"modeling_exaone.ExaoneForCausalLM\", \"pipeline_tag\": \"text-generation\", \"processor\": null}, \"siblings\": [\"RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='configuration_exaone.py', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='merges.txt', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model-00001-of-00004.safetensors', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model-00002-of-00004.safetensors', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model-00003-of-00004.safetensors', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model-00004-of-00004.safetensors', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model.safetensors.index.json', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='modeling_exaone.py', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='vocab.json', size=None, blob_id=None, lfs=None)\"], \"spaces\": [], \"safetensors\": {\"parameters\": {\"F16\": 1000739840, \"U32\": 4000317440}, \"total\": 5001057280}, \"security_repo_status\": null, \"xet_enabled\": null, \"lastModified\": \"2025-03-18 03:00:34+00:00\", \"cardData\": \"base_model: LGAI-EXAONE/EXAONE-Deep-32B\\nlanguage:\\n- en\\n- ko\\nlibrary_name: transformers\\nlicense: other\\nlicense_name: exaone\\nlicense_link: LICENSE\\npipeline_tag: text-generation\\ntags:\\n- lg-ai\\n- exaone\\n- exaone-deep\\n- mlx\\n- mlx-my-repo\\nbase_model_relation: finetune\", \"transformersInfo\": {\"auto_model\": \"AutoModelForCausalLM\", \"custom_class\": \"modeling_exaone.ExaoneForCausalLM\", \"pipeline_tag\": \"text-generation\", \"processor\": null}, \"_id\": \"67d8e184bbc08d7bb8c5abec\", \"modelId\": \"KYUNGYONG/EXAONE-Deep-32B-mlx-4Bit\", \"usedStorage\": 18002919934}",
            "depth": 1,
            "children": [],
            "children_count": 0
        },
        {
            "model_id": "mlx-community/EXAONE-Deep-32B-bf16",
            "metadata": "{\"id\": \"mlx-community/EXAONE-Deep-32B-bf16\", \"author\": \"mlx-community\", \"sha\": \"ae19166154cf6f866df311eff4ccadbfd76b6201\", \"last_modified\": \"2025-03-18 23:56:48+00:00\", \"created_at\": \"2025-03-18 23:08:05+00:00\", \"private\": false, \"gated\": false, \"disabled\": false, \"downloads\": 22, \"downloads_all_time\": null, \"likes\": 0, \"library_name\": \"transformers\", \"gguf\": null, \"inference\": null, \"inference_provider_mapping\": null, \"tags\": [\"transformers\", \"safetensors\", \"exaone\", \"text-generation\", \"lg-ai\", \"exaone-deep\", \"mlx\", \"conversational\", \"custom_code\", \"en\", \"ko\", \"base_model:LGAI-EXAONE/EXAONE-Deep-32B\", \"base_model:finetune:LGAI-EXAONE/EXAONE-Deep-32B\", \"license:other\", \"autotrain_compatible\", \"region:us\"], \"pipeline_tag\": \"text-generation\", \"mask_token\": null, \"trending_score\": null, \"card_data\": \"base_model: LGAI-EXAONE/EXAONE-Deep-32B\\nlanguage:\\n- en\\n- ko\\nlibrary_name: transformers\\nlicense: other\\nlicense_name: exaone\\nlicense_link: LICENSE\\npipeline_tag: text-generation\\ntags:\\n- lg-ai\\n- exaone\\n- exaone-deep\\n- mlx\\nbase_model_relation: finetune\", \"widget_data\": [{\"text\": \"Hi, what can you help me with?\"}, {\"text\": \"What is 84 * 3 / 2?\"}, {\"text\": \"Tell me an interesting fact about the universe!\"}, {\"text\": \"Explain quantum computing in simple terms.\"}], \"model_index\": null, \"config\": {\"architectures\": [\"ExaoneForCausalLM\"], \"auto_map\": {\"AutoConfig\": \"configuration_exaone.ExaoneConfig\", \"AutoModelForCausalLM\": \"modeling_exaone.ExaoneForCausalLM\", \"AutoModelForSequenceClassification\": \"modeling_exaone.ExaoneForSequenceClassification\"}, \"model_type\": \"exaone\", \"tokenizer_config\": {\"bos_token\": \"[BOS]\", \"chat_template\": \"{% for message in messages %}{% if loop.first and message['role'] != 'system' %}{{ '[|system|][|endofturn|]\\n' }}{% endif %}{% set content = message['content'] %}{% if '</thought>' in content %}{% set content = content.split('</thought>')[-1].lstrip('\\\\n') %}{% endif %}{{ '[|' + message['role'] + '|]' + content }}{% if not message['role'] == 'user' %}{{ '[|endofturn|]' }}{% endif %}{% if not loop.last %}{{ '\\n' }}{% endif %}{% endfor %}{% if add_generation_prompt %}{{ '\\n[|assistant|]<thought>\\n' }}{% endif %}\", \"eos_token\": \"[|endofturn|]\", \"pad_token\": \"[PAD]\", \"unk_token\": \"[UNK]\"}}, \"transformers_info\": {\"auto_model\": \"AutoModelForCausalLM\", \"custom_class\": \"modeling_exaone.ExaoneForCausalLM\", \"pipeline_tag\": \"text-generation\", \"processor\": null}, \"siblings\": [\"RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='configuration_exaone.py', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='merges.txt', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model-00001-of-00004.safetensors', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model-00001-of-00013.safetensors', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model-00002-of-00004.safetensors', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model-00002-of-00013.safetensors', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model-00003-of-00004.safetensors', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model-00003-of-00013.safetensors', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model-00004-of-00004.safetensors', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model-00004-of-00013.safetensors', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model-00005-of-00013.safetensors', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model-00006-of-00013.safetensors', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model-00007-of-00013.safetensors', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model-00008-of-00013.safetensors', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model-00009-of-00013.safetensors', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model-00010-of-00013.safetensors', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model-00011-of-00013.safetensors', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model-00012-of-00013.safetensors', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model-00013-of-00013.safetensors', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model.safetensors.index.json', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='modeling_exaone.py', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='vocab.json', size=None, blob_id=None, lfs=None)\"], \"spaces\": [], \"safetensors\": {\"parameters\": {\"BF16\": 32003200000}, \"total\": 32003200000}, \"security_repo_status\": null, \"xet_enabled\": null, \"lastModified\": \"2025-03-18 23:56:48+00:00\", \"cardData\": \"base_model: LGAI-EXAONE/EXAONE-Deep-32B\\nlanguage:\\n- en\\n- ko\\nlibrary_name: transformers\\nlicense: other\\nlicense_name: exaone\\nlicense_link: LICENSE\\npipeline_tag: text-generation\\ntags:\\n- lg-ai\\n- exaone\\n- exaone-deep\\n- mlx\\nbase_model_relation: finetune\", \"transformersInfo\": {\"auto_model\": \"AutoModelForCausalLM\", \"custom_class\": \"modeling_exaone.ExaoneForCausalLM\", \"pipeline_tag\": \"text-generation\", \"processor\": null}, \"_id\": \"67d9fcd50ac2e1218a42ee00\", \"modelId\": \"mlx-community/EXAONE-Deep-32B-bf16\", \"usedStorage\": 82009388034}",
            "depth": 1,
            "children": [],
            "children_count": 0
        },
        {
            "model_id": "alexgusevski/EXAONE-Deep-32B-mlx-6Bit",
            "metadata": "{\"id\": \"alexgusevski/EXAONE-Deep-32B-mlx-6Bit\", \"author\": \"alexgusevski\", \"sha\": \"787edac1b367c06586a9c84536277bb7da6e3be0\", \"last_modified\": \"2025-03-18 14:39:09+00:00\", \"created_at\": \"2025-03-18 13:14:00+00:00\", \"private\": false, \"gated\": false, \"disabled\": false, \"downloads\": 14, \"downloads_all_time\": null, \"likes\": 0, \"library_name\": \"transformers\", \"gguf\": null, \"inference\": null, \"inference_provider_mapping\": null, \"tags\": [\"transformers\", \"safetensors\", \"exaone\", \"text-generation\", \"lg-ai\", \"exaone-deep\", \"mlx\", \"mlx-my-repo\", \"conversational\", \"custom_code\", \"en\", \"ko\", \"base_model:LGAI-EXAONE/EXAONE-Deep-32B\", \"base_model:finetune:LGAI-EXAONE/EXAONE-Deep-32B\", \"license:other\", \"autotrain_compatible\", \"6-bit\", \"region:us\"], \"pipeline_tag\": \"text-generation\", \"mask_token\": null, \"trending_score\": null, \"card_data\": \"base_model: LGAI-EXAONE/EXAONE-Deep-32B\\nlanguage:\\n- en\\n- ko\\nlibrary_name: transformers\\nlicense: other\\nlicense_name: exaone\\nlicense_link: LICENSE\\npipeline_tag: text-generation\\ntags:\\n- lg-ai\\n- exaone\\n- exaone-deep\\n- mlx\\n- mlx-my-repo\\nbase_model_relation: finetune\", \"widget_data\": [{\"text\": \"Hi, what can you help me with?\"}, {\"text\": \"What is 84 * 3 / 2?\"}, {\"text\": \"Tell me an interesting fact about the universe!\"}, {\"text\": \"Explain quantum computing in simple terms.\"}], \"model_index\": null, \"config\": {\"architectures\": [\"ExaoneForCausalLM\"], \"auto_map\": {\"AutoConfig\": \"configuration_exaone.ExaoneConfig\", \"AutoModelForCausalLM\": \"modeling_exaone.ExaoneForCausalLM\", \"AutoModelForSequenceClassification\": \"modeling_exaone.ExaoneForSequenceClassification\"}, \"model_type\": \"exaone\", \"quantization_config\": {\"bits\": 6}, \"tokenizer_config\": {\"bos_token\": \"[BOS]\", \"chat_template\": \"{% for message in messages %}{% if loop.first and message['role'] != 'system' %}{{ '[|system|][|endofturn|]\\n' }}{% endif %}{% set content = message['content'] %}{% if '</thought>' in content %}{% set content = content.split('</thought>')[-1].lstrip('\\\\n') %}{% endif %}{{ '[|' + message['role'] + '|]' + content }}{% if not message['role'] == 'user' %}{{ '[|endofturn|]' }}{% endif %}{% if not loop.last %}{{ '\\n' }}{% endif %}{% endfor %}{% if add_generation_prompt %}{{ '\\n[|assistant|]<thought>\\n' }}{% endif %}\", \"eos_token\": \"[|endofturn|]\", \"pad_token\": \"[PAD]\", \"unk_token\": \"[UNK]\"}}, \"transformers_info\": {\"auto_model\": \"AutoModelForCausalLM\", \"custom_class\": \"modeling_exaone.ExaoneForCausalLM\", \"pipeline_tag\": \"text-generation\", \"processor\": null}, \"siblings\": [\"RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='configuration_exaone.py', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='merges.txt', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model-00001-of-00005.safetensors', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model-00002-of-00005.safetensors', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model-00003-of-00005.safetensors', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model-00004-of-00005.safetensors', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model-00005-of-00005.safetensors', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model.safetensors.index.json', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='modeling_exaone.py', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='vocab.json', size=None, blob_id=None, lfs=None)\"], \"spaces\": [], \"safetensors\": {\"parameters\": {\"F16\": 1000739840, \"U32\": 6000476160}, \"total\": 7001216000}, \"security_repo_status\": null, \"xet_enabled\": null, \"lastModified\": \"2025-03-18 14:39:09+00:00\", \"cardData\": \"base_model: LGAI-EXAONE/EXAONE-Deep-32B\\nlanguage:\\n- en\\n- ko\\nlibrary_name: transformers\\nlicense: other\\nlicense_name: exaone\\nlicense_link: LICENSE\\npipeline_tag: text-generation\\ntags:\\n- lg-ai\\n- exaone\\n- exaone-deep\\n- mlx\\n- mlx-my-repo\\nbase_model_relation: finetune\", \"transformersInfo\": {\"auto_model\": \"AutoModelForCausalLM\", \"custom_class\": \"modeling_exaone.ExaoneForCausalLM\", \"pipeline_tag\": \"text-generation\", \"processor\": null}, \"_id\": \"67d971984c854a4a983dac37\", \"modelId\": \"alexgusevski/EXAONE-Deep-32B-mlx-6Bit\", \"usedStorage\": 26003554890}",
            "depth": 1,
            "children": [],
            "children_count": 0
        }
    ]
}
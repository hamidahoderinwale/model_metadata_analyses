model_id,card,metadata,depth,children,children_count,quantized,quantized_count,merges,merges_count,spaces,spaces_count,adapters,adapters_count
google/gemma-7b,"---
library_name: transformers
license: gemma
extra_gated_heading: Access Gemma on Hugging Face
extra_gated_prompt: To access Gemma on Hugging Face, you’re required to review and
  agree to Google’s usage license. To do this, please ensure you’re logged-in to Hugging
  Face and click below. Requests are processed immediately.
extra_gated_button_content: Acknowledge license
---

# Gemma Model Card

**Model Page**: [Gemma](https://ai.google.dev/gemma/docs)

This model card corresponds to the 7B base version of the Gemma model. You can also visit the model card of the [2B base model](https://huggingface.co/google/gemma-2b), [7B instruct model](https://huggingface.co/google/gemma-7b-it), and [2B instruct model](https://huggingface.co/google/gemma-2b-it). 

**Resources and Technical Documentation**:

* [Gemma Technical Report](https://storage.googleapis.com/deepmind-media/gemma/gemma-report.pdf)
* [Responsible Generative AI Toolkit](https://ai.google.dev/responsible)
* [Gemma on Kaggle](https://www.kaggle.com/models/google/gemma)
* [Gemma on Vertex Model Garden](https://console.cloud.google.com/vertex-ai/publishers/google/model-garden/335?version=gemma-7b-gg-hf)

**Terms of Use**: [Terms](https://www.kaggle.com/models/google/gemma/license/consent/verify/huggingface?returnModelRepoId=google/gemma-7b)

**Authors**: Google

## Model Information

Summary description and brief definition of inputs and outputs.

### Description

Gemma is a family of lightweight, state-of-the-art open models from Google,
built from the same research and technology used to create the Gemini models.
They are text-to-text, decoder-only large language models, available in English,
with open weights, pre-trained variants, and instruction-tuned variants. Gemma
models are well-suited for a variety of text generation tasks, including
question answering, summarization, and reasoning. Their relatively small size
makes it possible to deploy them in environments with limited resources such as
a laptop, desktop or your own cloud infrastructure, democratizing access to
state of the art AI models and helping foster innovation for everyone.

### Context Length
Models are trained on a context length of 8192 tokens.

### Usage

Below we share some code snippets on how to get quickly started with running the model. First make sure to `pip install -U transformers`, then copy the snippet from the section that is relevant for your usecase.

#### Fine-tuning examples

You can find fine-tuning notebooks under the [`examples/` directory](https://huggingface.co/google/gemma-7b/tree/main/examples). We provide:

* A script to perform Supervised Fine-Tuning (SFT) on UltraChat dataset using [QLoRA](https://huggingface.co/papers/2305.14314)
* A script to perform SFT using FSDP on TPU devices
* A notebook that you can run on a free-tier Google Colab instance to perform SFT on English quotes dataset. You can also find the copy of the notebook [here](https://github.com/huggingface/notebooks/blob/main/peft/gemma_7b_english_quotes.ipynb).

#### Running the model on a CPU


```python
from transformers import AutoTokenizer, AutoModelForCausalLM

tokenizer = AutoTokenizer.from_pretrained(""google/gemma-7b"")
model = AutoModelForCausalLM.from_pretrained(""google/gemma-7b"")

input_text = ""Write me a poem about Machine Learning.""
input_ids = tokenizer(input_text, return_tensors=""pt"")

outputs = model.generate(**input_ids)
print(tokenizer.decode(outputs[0]))
```


#### Running the model on a single / multi GPU


```python
# pip install accelerate
from transformers import AutoTokenizer, AutoModelForCausalLM

tokenizer = AutoTokenizer.from_pretrained(""google/gemma-7b"")
model = AutoModelForCausalLM.from_pretrained(""google/gemma-7b"", device_map=""auto"")

input_text = ""Write me a poem about Machine Learning.""
input_ids = tokenizer(input_text, return_tensors=""pt"").to(""cuda"")

outputs = model.generate(**input_ids)
print(tokenizer.decode(outputs[0]))
```


#### Running the model on a GPU using different precisions

* _Using `torch.float16`_

```python
# pip install accelerate
from transformers import AutoTokenizer, AutoModelForCausalLM

tokenizer = AutoTokenizer.from_pretrained(""google/gemma-7b"")
model = AutoModelForCausalLM.from_pretrained(""google/gemma-7b"", device_map=""auto"", revision=""float16"")

input_text = ""Write me a poem about Machine Learning.""
input_ids = tokenizer(input_text, return_tensors=""pt"").to(""cuda"")

outputs = model.generate(**input_ids)
print(tokenizer.decode(outputs[0]))
```

* _Using `torch.bfloat16`_

```python
# pip install accelerate
from transformers import AutoTokenizer, AutoModelForCausalLM

tokenizer = AutoTokenizer.from_pretrained(""google/gemma-7b"")
model = AutoModelForCausalLM.from_pretrained(""google/gemma-7b"", device_map=""auto"", torch_dtype=torch.bfloat16)

input_text = ""Write me a poem about Machine Learning.""
input_ids = tokenizer(input_text, return_tensors=""pt"").to(""cuda"")

outputs = model.generate(**input_ids)
print(tokenizer.decode(outputs[0]))
```

#### Quantized Versions through `bitsandbytes`

* _Using 8-bit precision (int8)_

```python
# pip install bitsandbytes accelerate
from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig

quantization_config = BitsAndBytesConfig(load_in_8bit=True)

tokenizer = AutoTokenizer.from_pretrained(""google/gemma-7b"")
model = AutoModelForCausalLM.from_pretrained(""google/gemma-7b"", quantization_config=quantization_config)

input_text = ""Write me a poem about Machine Learning.""
input_ids = tokenizer(input_text, return_tensors=""pt"").to(""cuda"")

outputs = model.generate(**input_ids)
print(tokenizer.decode(outputs[0]))
```

* _Using 4-bit precision_

```python
# pip install bitsandbytes accelerate
from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig

quantization_config = BitsAndBytesConfig(load_in_4bit=True)

tokenizer = AutoTokenizer.from_pretrained(""google/gemma-7b"")
model = AutoModelForCausalLM.from_pretrained(""google/gemma-7b"", quantization_config=quantization_config)

input_text = ""Write me a poem about Machine Learning.""
input_ids = tokenizer(input_text, return_tensors=""pt"").to(""cuda"")

outputs = model.generate(**input_ids)
print(tokenizer.decode(outputs[0]))
```


#### Other optimizations

* _Flash Attention 2_

First make sure to install `flash-attn` in your environment `pip install flash-attn`

```diff
model = AutoModelForCausalLM.from_pretrained(
    model_id, 
    torch_dtype=torch.float16, 
+   attn_implementation=""flash_attention_2""
).to(0)
```

### Inputs and outputs

*   **Input:** Text string, such as a question, a prompt, or a document to be
    summarized.
*   **Output:** Generated English-language text in response to the input, such
    as an answer to a question, or a summary of a document.

## Model Data

Data used for model training and how the data was processed.

### Training Dataset

These models were trained on a dataset of text data that includes a wide variety
of sources, totaling 6 trillion tokens. Here are the key components:

* Web Documents: A diverse collection of web text ensures the model is exposed
  to a broad range of linguistic styles, topics, and vocabulary. Primarily
  English-language content.
* Code: Exposing the model to code helps it to learn the syntax and patterns of
  programming languages, which improves its ability to generate code or
  understand code-related questions.
* Mathematics: Training on mathematical text helps the model learn logical
  reasoning, symbolic representation, and to address mathematical queries.

The combination of these diverse data sources is crucial for training a powerful
language model that can handle a wide variety of different tasks and text
formats.

### Data Preprocessing

Here are the key data cleaning and filtering methods applied to the training
data:

* CSAM Filtering: Rigorous CSAM (Child Sexual Abuse Material) filtering was
  applied at multiple stages in the data preparation process to ensure the
  exclusion of harmful and illegal content
* Sensitive Data Filtering: As part of making Gemma pre-trained models safe and
  reliable, automated techniques were used to filter out certain personal
  information and other sensitive data from training sets.
* Additional methods: Filtering based on content quality and safely in line with
  [our policies](https://storage.googleapis.com/gweb-uniblog-publish-prod/documents/2023_Google_AI_Principles_Progress_Update.pdf#page=11).

## Implementation Information

Details about the model internals.

### Hardware

Gemma was trained using the latest generation of
[Tensor Processing Unit (TPU)](https://cloud.google.com/tpu/docs/intro-to-tpu) hardware (TPUv5e).

Training large language models requires significant computational power. TPUs,
designed specifically for matrix operations common in machine learning, offer
several advantages in this domain:

* Performance: TPUs are specifically designed to handle the massive computations
  involved in training LLMs. They can speed up training considerably compared to
  CPUs.
* Memory: TPUs often come with large amounts of high-bandwidth memory, allowing
  for the handling of large models and batch sizes during training. This can
  lead to better model quality.
* Scalability: TPU Pods (large clusters of TPUs) provide a scalable solution for
  handling the growing complexity of large foundation models. You can distribute
  training across multiple TPU devices for faster and more efficient processing.
* Cost-effectiveness: In many scenarios, TPUs can provide a more cost-effective
  solution for training large models compared to CPU-based infrastructure,
  especially when considering the time and resources saved due to faster
  training.
* These advantages are aligned with
  [Google's commitments to operate sustainably](https://sustainability.google/operating-sustainably/).

### Software

Training was done using [JAX](https://github.com/google/jax) and [ML Pathways](https://blog.google/technology/ai/introducing-pathways-next-generation-ai-architecture).

JAX allows researchers to take advantage of the latest generation of hardware,
including TPUs, for faster and more efficient training of large models.

ML Pathways is Google's latest effort to build artificially intelligent systems
capable of generalizing across multiple tasks. This is specially suitable for
[foundation models](https://ai.google/discover/foundation-models/), including large language models like
these ones.

Together, JAX and ML Pathways are used as described in the
[paper about the Gemini family of models](https://arxiv.org/abs/2312.11805); ""the 'single
controller' programming model of Jax and Pathways allows a single Python
process to orchestrate the entire training run, dramatically simplifying the
development workflow.""

## Evaluation

Model evaluation metrics and results.

### Benchmark Results

These models were evaluated against a large collection of different datasets and
metrics to cover different aspects of text generation:

| Benchmark                      | Metric        | 2B Params | 7B Params |
| ------------------------------ | ------------- | ----------- | --------- |
| [MMLU](https://arxiv.org/abs/2009.03300)                   | 5-shot, top-1 | 42.3        | 64.3      |
| [HellaSwag](https://arxiv.org/abs/1905.07830)         | 0-shot        |71.4        | 81.2      |
| [PIQA](https://arxiv.org/abs/1911.11641)                   | 0-shot        | 77.3        | 81.2      |
| [SocialIQA](https://arxiv.org/abs/1904.09728)      | 0-shot        | 49.7        | 51.8      |
| [BooIQ](https://arxiv.org/abs/1905.10044)                | 0-shot        | 69.4        | 83.2      |
| [WinoGrande](https://arxiv.org/abs/1907.10641)       | partial score | 65.4        | 72.3      |
| [CommonsenseQA](https://arxiv.org/abs/1811.00937) | 7-shot        | 65.3        | 71.3      |
| [OpenBookQA](https://arxiv.org/abs/1809.02789)       |               | 47.8        | 52.8      |
| [ARC-e](https://arxiv.org/abs/1911.01547)                  |               | 73.2        | 81.5      |
| [ARC-c](https://arxiv.org/abs/1911.01547)                   |               | 42.1        | 53.2      |
| [TriviaQA](https://arxiv.org/abs/1705.03551)           | 5-shot        | 53.2        | 63.4      |
| [Natural Questions](https://github.com/google-research-datasets/natural-questions)  | 5-shot        | 12.5       | 23        |
| [HumanEval](https://arxiv.org/abs/2107.03374)      | pass@1        | 22.0        | 32.3      |
| [MBPP](https://arxiv.org/abs/2108.07732)                   | 3-shot        | 29.2        | 44.4      |
| [GSM8K](https://arxiv.org/abs/2110.14168)                | maj@1         | 17.7        | 46.4      |
| [MATH](https://arxiv.org/abs/2108.07732)                   | 4-shot        | 11.8          | 24.3      |
| [AGIEval](https://arxiv.org/abs/2304.06364)           |               | 24.2        | 41.7      |
| [BIG-Bench](https://arxiv.org/abs/2206.04615)         |               | 35.2        | 55.1      |
| ------------------------------ | ------------- | ----------- | --------- |
| **Average**                    |               | **45.0**    | **56.9**  |


## Ethics and Safety

Ethics and safety evaluation approach and results.

### Evaluation Approach

Our evaluation methods include structured evaluations and internal red-teaming
testing of relevant content policies. Red-teaming was conducted by a number of
different teams, each with different goals and human evaluation metrics. These
models were evaluated against a number of different categories relevant to
ethics and safety, including:

* Text-to-Text Content Safety: Human evaluation on prompts covering safety
  policies including child sexual abuse and exploitation, harassment, violence
  and gore, and hate speech.
* Text-to-Text Representational Harms: Benchmark against relevant academic
  datasets such as [WinoBias](https://arxiv.org/abs/1804.06876) and [BBQ Dataset](https://arxiv.org/abs/2110.08193v2).
* Memorization: Automated evaluation of memorization of training data, including
  the risk of personally identifiable information exposure.
* Large-scale harm: Tests for ""dangerous capabilities,"" such as chemical,
  biological, radiological, and nuclear (CBRN) risks.

### Evaluation Results

The results of ethics and safety evaluations are within acceptable thresholds
for meeting [internal policies](https://storage.googleapis.com/gweb-uniblog-publish-prod/documents/2023_Google_AI_Principles_Progress_Update.pdf#page=11) for categories such as child
safety, content safety, representational harms, memorization, large-scale harms.
On top of robust internal evaluations, the results of well known safety
benchmarks like BBQ, BOLD, Winogender, Winobias, RealToxicity, and TruthfulQA
are shown here.

| Benchmark                      | Metric        | 2B Params   | 7B Params |
| ------------------------------ | ------------- | ----------- | --------- |
| [RealToxicity](https://arxiv.org/abs/2009.11462)        | average       | 6.86        | 7.90      |
| [BOLD](https://arxiv.org/abs/2101.11718)                   |               | 45.57       | 49.08     |
| [CrowS-Pairs](https://aclanthology.org/2020.emnlp-main.154/)        | top-1         | 45.82       | 51.33     |
| [BBQ Ambig](https://arxiv.org/abs/2110.08193v2)               | 1-shot, top-1 | 62.58       | 92.54     |
| [BBQ Disambig](https://arxiv.org/abs/2110.08193v2)            | top-1         | 54.62       | 71.99     |
| [Winogender](https://arxiv.org/abs/1804.09301)       | top-1         | 51.25       | 54.17     |
| [TruthfulQA](https://arxiv.org/abs/2109.07958)       |               | 44.84       | 31.81     |
| [Winobias 1_2](https://arxiv.org/abs/1804.06876)       |               | 56.12       | 59.09     |
| [Winobias 2_2](https://arxiv.org/abs/1804.06876)       |               | 91.10       | 92.23     |
| [Toxigen](https://arxiv.org/abs/2203.09509)             |               | 29.77       | 39.59     |
| ------------------------------ | ------------- | ----------- | --------- |


## Usage and Limitations

These models have certain limitations that users should be aware of.

### Intended Usage

Open Large Language Models (LLMs) have a wide range of applications across
various industries and domains. The following list of potential uses is not
comprehensive. The purpose of this list is to provide contextual information
about the possible use-cases that the model creators considered as part of model
training and development.

* Content Creation and Communication
  * Text Generation: These models can be used to generate creative text formats
    such as poems, scripts, code, marketing copy, and email drafts.
  * Chatbots and Conversational AI: Power conversational interfaces for customer
    service, virtual assistants, or interactive applications.
  * Text Summarization: Generate concise summaries of a text corpus, research
    papers, or reports.
* Research and Education
  * Natural Language Processing (NLP) Research: These models can serve as a
    foundation for researchers to experiment with NLP techniques, develop
    algorithms, and contribute to the advancement of the field.
  * Language Learning Tools: Support interactive language learning experiences,
    aiding in grammar correction or providing writing practice.
  * Knowledge Exploration: Assist researchers in exploring large bodies of text
    by generating summaries or answering questions about specific topics.

### Limitations

* Training Data
  * The quality and diversity of the training data significantly influence the
    model's capabilities. Biases or gaps in the training data can lead to
    limitations in the model's responses.
  * The scope of the training dataset determines the subject areas the model can
    handle effectively.
* Context and Task Complexity
  * LLMs are better at tasks that can be framed with clear prompts and
    instructions. Open-ended or highly complex tasks might be challenging.
  * A model's performance can be influenced by the amount of context provided
    (longer context generally leads to better outputs, up to a certain point).
* Language Ambiguity and Nuance
  * Natural language is inherently complex. LLMs might struggle to grasp subtle
    nuances, sarcasm, or figurative language.
* Factual Accuracy
  * LLMs generate responses based on information they learned from their
    training datasets, but they are not knowledge bases. They may generate
    incorrect or outdated factual statements.
* Common Sense
  * LLMs rely on statistical patterns in language. They might lack the ability
    to apply common sense reasoning in certain situations.

### Ethical Considerations and Risks

The development of large language models (LLMs) raises several ethical concerns.
In creating an open model, we have carefully considered the following:

* Bias and Fairness
  * LLMs trained on large-scale, real-world text data can reflect socio-cultural
    biases embedded in the training material. These models underwent careful
    scrutiny, input data pre-processing described and posterior evaluations
    reported in this card.
* Misinformation and Misuse
  * LLMs can be misused to generate text that is false, misleading, or harmful.
  * Guidelines are provided for responsible use with the model, see the
    [Responsible Generative AI Toolkit](http://ai.google.dev/gemma/responsible).
* Transparency and Accountability:
  * This model card summarizes details on the models' architecture,
    capabilities, limitations, and evaluation processes.
  * A responsibly developed open model offers the opportunity to share
    innovation by making LLM technology accessible to developers and researchers
    across the AI ecosystem.

Risks identified and mitigations:

* Perpetuation of biases: It's encouraged to perform continuous monitoring
  (using evaluation metrics, human review) and the exploration of de-biasing
  techniques during model training, fine-tuning, and other use cases.
* Generation of harmful content: Mechanisms and guidelines for content safety
  are essential. Developers are encouraged to exercise caution and implement
  appropriate content safety safeguards based on their specific product policies
  and application use cases.
* Misuse for malicious purposes: Technical limitations and developer and
  end-user education can help mitigate against malicious applications of LLMs.
  Educational resources and reporting mechanisms for users to flag misuse are
  provided. Prohibited uses of Gemma models are outlined in the
  [Gemma Prohibited Use Policy](https://ai.google.dev/gemma/prohibited_use_policy).
* Privacy violations: Models were trained on data filtered for removal of PII
  (Personally Identifiable Information). Developers are encouraged to adhere to
  privacy regulations with privacy-preserving techniques.

### Benefits

At the time of release, this family of models provides high-performance open
large language model implementations designed from the ground up for Responsible
AI development compared to similarly sized models.

Using the benchmark evaluation metrics described in this document, these models
have shown to provide superior performance to other, comparably-sized open model
alternatives.","{""id"": ""google/gemma-7b"", ""author"": ""google"", ""sha"": ""ff6768d9368919a1f025a54f9f5aa0ee591730bb"", ""last_modified"": ""2024-06-27 14:09:40+00:00"", ""created_at"": ""2024-02-08 22:36:43+00:00"", ""private"": false, ""gated"": ""manual"", ""disabled"": false, ""downloads"": 56148, ""downloads_all_time"": null, ""likes"": 3155, ""library_name"": ""transformers"", ""gguf"": {""total"": 8538074112, ""architecture"": ""gemma"", ""context_length"": 8192, ""bos_token"": ""<bos>"", ""eos_token"": ""<eos>""}, ""inference"": null, ""tags"": [""transformers"", ""safetensors"", ""gguf"", ""gemma"", ""text-generation"", ""arxiv:2305.14314"", ""arxiv:2312.11805"", ""arxiv:2009.03300"", ""arxiv:1905.07830"", ""arxiv:1911.11641"", ""arxiv:1904.09728"", ""arxiv:1905.10044"", ""arxiv:1907.10641"", ""arxiv:1811.00937"", ""arxiv:1809.02789"", ""arxiv:1911.01547"", ""arxiv:1705.03551"", ""arxiv:2107.03374"", ""arxiv:2108.07732"", ""arxiv:2110.14168"", ""arxiv:2304.06364"", ""arxiv:2206.04615"", ""arxiv:1804.06876"", ""arxiv:2110.08193"", ""arxiv:2009.11462"", ""arxiv:2101.11718"", ""arxiv:1804.09301"", ""arxiv:2109.07958"", ""arxiv:2203.09509"", ""license:gemma"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""library_name: transformers\nlicense: gemma\nextra_gated_heading: Access Gemma on Hugging Face\nextra_gated_prompt: To access Gemma on Hugging Face, you\u2019re required to review and\n  agree to Google\u2019s usage license. To do this, please ensure you\u2019re logged-in to Hugging\n  Face and click below. Requests are processed immediately.\nextra_gated_button_content: Acknowledge license"", ""widget_data"": [{""text"": ""My name is Julien and I like to""}, {""text"": ""I like traveling by train because""}, {""text"": ""Paris is an amazing place to visit,""}, {""text"": ""Once upon a time,""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='examples/example_fsdp.py', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='examples/example_sft_qlora.py', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='examples/notebook_sft_peft.ipynb', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='gemma-7b.gguf', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='generation_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00001-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00002-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00003-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00004-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model.safetensors.index.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)""], ""spaces"": [""eduagarcia/open_pt_llm_leaderboard"", ""Omnibus/google-gemma"", ""logikon/open_cot_leaderboard"", ""yenniejun/tokenizers-languages"", ""Omnibus/Chatbot-Compare"", ""KBaba7/Quant"", ""ngebodh/SimpleChatbot"", ""Cognitive-Lab/indic_llm_leaderboard"", ""allenai/URIAL-Bench"", ""CosmoAI/BhagwatGeeta"", ""evanperez/CTP-week3-demo"", ""prometheus-eval/BiGGen-Bench-Leaderboard"", ""Omnibus/InferenceClient_Chatbots"", ""Justinrune/LLaMA-Factory"", ""cot-leaderboard/open-cot-dashboard"", ""yhavinga/dutch-tokenizer-arena"", ""taka-yamakoshi/tokenizer-demo"", ""kenken999/fastapi_django_main_live"", ""quantpi/llm-assessments"", ""Tomoniai/gemma-chat"", ""open-llm-leaderboard/GenerationVisualizer"", ""bhaskartripathi/LLM_Quantization"", ""Sagar23p/mistralAI_chatBoat"", ""5w4n/burmese-tokenizers"", ""totolook/Quant"", ""FallnAI/Quantize-HF-Models"", ""fantos/Chatbot-Compare"", ""amirgame197/Gemma-Chat"", ""aadya1762/GemmaDemoSt2"", ""CosmoAI/ChitChat"", ""jonathanjordan21/chat_with_me"", ""Kvikontent/google-gemma-7b"", ""Nymbo/LangHub"", ""dwb2023/model_explorer2"", ""pavel321/huggingface-cli-completion"", ""nikhilkomakula/nk-openpages-intellibot"", ""soroushsrd/Pubmed_QA"", ""rudolphjhs/Universal-Pivot-7b"", ""SejaMenath2025/google-gemma-7b"", ""LAYEK-143/google-gemma-7b"", ""TrinitySlr/google-gemma-7b"", ""javayhu/google-gemma-7b"", ""lxc0422/google-gemma-7b"", ""shanimalik389/google-gemma-7b"", ""ahricat/google-gemma-7b"", ""Mrzn10/google-gemma-7b"", ""AilexGPT/Chatbot-Compare"", ""Krats/google-gemma-7b"", ""Yahir/gemmaw"", ""damiandata/google-gemma-7b"", ""saneowl/google_gemma_model_demo"", ""dwb2023/model_explorer4"", ""ruslanmv/convert_to_gguf"", ""pjay6120/Resume_Bot"", ""sakuexe/thesizer"", ""Yezid72-ie/google-gemma-7b"", ""Comos19/Gemma-7b"", ""Lyte/tokenizer-leaderboard"", ""astroknotsheep/gemmaft"", ""alexkueck/LIRAGTest"", ""MuNian/google-gemma-7b"", ""DeeKaa/google-gemma-7b"", ""FREE-AI/google-gemma"", ""BRJDEV/google-gemma-7b"", ""baebl/google-gemma-7b"", ""vico24826/google-gemma-7b"", ""AyushDey/google-gemma-7b"", ""AshhadDevLab/google-gemma-7b"", ""negismohit123/gemmaLiBot"", ""Megasazou/google-gemma-7b"", ""Nymbo/Chatbot-Compare"", ""pmv-hou/linkedin_post_generator"", ""132codeli/google-gemma-7b"", ""eNuminous/google-gemma-7b"", ""whatnextalgo/LLMsIntro"", ""Shankarm08/google-gemma-7b"", ""negismohit123/test_Gradio"", ""negismohit123/LinkedIn_Bot_Gemma_Streamlit"", ""rothbencc/google-gemma-7b"", ""arifhosan/google-gemma-7b"", ""Ivan1579/google-gemma-7b"", ""avilbopalia/learnllm"", ""bishka/google-gemma-7b"", ""jesuswithclinton/bibleai_1"", ""DemonicAK/google-gemma-7b"", ""Ultrazartrex/google-gemma-7b"", ""allknowingroger/google-gemma-7b"", ""darkstar94/gemma-7b"", ""Sripathy/google-gemma-7b"", ""vonshed/SimpleChatbot"", ""Ehsanjahanbakhsh/google-gemma-7b"", ""mbenachour/google-gemma-7b"", ""SilentWraith/google-gemma-dev2"", ""lazarusx/google-gemma-7b"", ""ajeetkhf/gemmaFirstHW"", ""Ya2023/google-gemma-7b"", ""zhaofan2024/google-gemma-7b"", ""yitlian/google-gemma"", ""tanishdt/google-gemma-7b"", ""Zoory/google-gemma""], ""safetensors"": {""parameters"": {""BF16"": 8537680896}, ""total"": 8537680896}, ""security_repo_status"": null, ""lastModified"": ""2024-06-27 14:09:40+00:00"", ""cardData"": ""library_name: transformers\nlicense: gemma\nextra_gated_heading: Access Gemma on Hugging Face\nextra_gated_prompt: To access Gemma on Hugging Face, you\u2019re required to review and\n  agree to Google\u2019s usage license. To do this, please ensure you\u2019re logged-in to Hugging\n  Face and click below. Requests are processed immediately.\nextra_gated_button_content: Acknowledge license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""65c5577b1080431ea9e083cd"", ""modelId"": ""google/gemma-7b"", ""usedStorage"": 214855095088}",0,"https://huggingface.co/Junfeng5/Liquid_V1_7B, https://huggingface.co/google/gemma-7b-it, https://huggingface.co/wandb/gemma-7b-zephyr-sft, https://huggingface.co/Telugu-LLM-Labs/Indic-gemma-7b-finetuned-sft-Navarasa-2.0, https://huggingface.co/google/gemma-7b-aps-it, https://huggingface.co/seojeongsoo/AI_Pet_code, https://huggingface.co/mlabonne/gemma-7b-dare, https://huggingface.co/sohug/gemma-7b_banglo_qlora, https://huggingface.co/mlabonne/Gemmalpaca-7B, https://huggingface.co/arcee-ai/gemma-7b-slerp, https://huggingface.co/Telugu-LLM-Labs/Telugu-gemma-7b-finetuned-sft, https://huggingface.co/OpenBuddy/openbuddy-gemma-7b-v19.1-4k, https://huggingface.co/lewtun/gemma-7b-sft-full-dolly-v0, https://huggingface.co/lewtun/gemma-7b-sft-full-dolly-v1, https://huggingface.co/lewtun/gemma-7b-sft-full-dolly-v2, https://huggingface.co/lewtun/gemma-7b-sft-full-dolly-v3, https://huggingface.co/lewtun/gemma-7b-sft-full-ultrachat-v0, https://huggingface.co/lewtun/gemma-7b-sft-full-longest-1k-v0, https://huggingface.co/lewtun/gemma-7b-sft-full-longest-1k-v1, https://huggingface.co/lewtun/gemma-7b-sft-full-deita-10k-v0, https://huggingface.co/philschmid/gemma-7b-chatml-orca-100k-test, https://huggingface.co/lewtun/gemma-7b-sft-full-openhermes-v0, https://huggingface.co/HuggingFaceH4/zephyr-7b-gemma-sft-v0.1, https://huggingface.co/bartowski/zephyr-7b-gemma-sft-v0.1-exl2, https://huggingface.co/LoneStriker/zephyr-7b-gemma-sft-v0.1-3.0bpw-h6-exl2, https://huggingface.co/LoneStriker/zephyr-7b-gemma-sft-v0.1-4.0bpw-h6-exl2, https://huggingface.co/LoneStriker/zephyr-7b-gemma-sft-v0.1-5.0bpw-h6-exl2, https://huggingface.co/LoneStriker/zephyr-7b-gemma-sft-v0.1-6.0bpw-h6-exl2, https://huggingface.co/LoneStriker/zephyr-7b-gemma-sft-v0.1-8.0bpw-h8-exl2, https://huggingface.co/LoneStriker/openbuddy-gemma-7b-v19.1-4k-3.0bpw-h6-exl2, https://huggingface.co/LoneStriker/openbuddy-gemma-7b-v19.1-4k-4.0bpw-h6-exl2, https://huggingface.co/LoneStriker/openbuddy-gemma-7b-v19.1-4k-5.0bpw-h6-exl2, https://huggingface.co/LoneStriker/openbuddy-gemma-7b-v19.1-4k-6.0bpw-h6-exl2, https://huggingface.co/LoneStriker/openbuddy-gemma-7b-v19.1-4k-8.0bpw-h8-exl2, https://huggingface.co/bartowski/openbuddy-gemma-7b-v19.1-4k-exl2, https://huggingface.co/Telugu-LLM-Labs/Indic-gemma-7b-finetuned-sft-Navarasa, https://huggingface.co/grayhacker91/gemma-7b-open-platypus-commercial, https://huggingface.co/saucam/gemma-samvaad-7b, https://huggingface.co/mervinpraison/tamil-large-language-model-7b-v1.0, https://huggingface.co/danilopeixoto/pandora-7b-chat, https://huggingface.co/Omickeyee/Marathi_Gemma_7B, https://huggingface.co/somosnlp/gemma-7b-it-legal-refugiados-es, https://huggingface.co/saucam/Rudra-7b-qlora, https://huggingface.co/beratcmn/cem-v0.1, https://huggingface.co/kykim0/gemma-7b-ultrachat-sft, https://huggingface.co/Omickeyee/Marathi_Gemma_7B_52k, https://huggingface.co/Omickeyee/Marathi_Gemma_7B_5k, https://huggingface.co/Omickeyee/Marathi_Gemma_7B_10k, https://huggingface.co/Omickeyee/Marathi_Gemma_7B_20k, https://huggingface.co/masakhane/zephyr-7b-gemma-sft-african-ultrachat, https://huggingface.co/masakhane/zephyr-7b-gemma-sft-african-alpaca, https://huggingface.co/Omickeyee/Marathi_Gemma_7B_40k, https://huggingface.co/masakhane/zephyr-7b-gemma-sft-african-ultrachat-5k, https://huggingface.co/masakhane/zephyr-7b-gemma-sft-african-ultrachat-100k, https://huggingface.co/karakuri-ai/karakuri-lm-7b-apm-v0.1, https://huggingface.co/pkarypis/gemma-lima, https://huggingface.co/masakhane/zephyr-7b-gemma-sft-african-ultrachat-200k, https://huggingface.co/PrunaAI/google-gemma-7b-HQQ-2bit-smashed, https://huggingface.co/PrunaAI/google-gemma-7b-HQQ-1bit-smashed, https://huggingface.co/PrunaAI/google-gemma-7b-HQQ-4bit-smashed, https://huggingface.co/Ahjeong/MMPO_Gemma_7b_gamma1.1_epoch3, https://huggingface.co/masakhane/African-ultrachat-alpaca, https://huggingface.co/webbigdata/C3TR-Adapter_hqq, https://huggingface.co/yimingzhang/zephyr-7b-gemma-sft, https://huggingface.co/yimingzhang/gemma-backtrack-0522, https://huggingface.co/tanliboy/zephyr-7b-gemma-sft, https://huggingface.co/Eteims/gemma_ft_quote, https://huggingface.co/OpenLLM-Ro/RoGemma-7b-Instruct-2024-06-28, https://huggingface.co/ale-bay/zephyr-7b-gemma-sft, https://huggingface.co/ale-bay/zephyr-7b-gemma-dpo, https://huggingface.co/vasimakram01/dawah_fine_tune_gemma_7b, https://huggingface.co/TitanML/gemma-7b-it, https://huggingface.co/silviasapora/gemma-7b-orpo, https://huggingface.co/silviasapora/gemma-7b-orpo-low-quality, https://huggingface.co/silviasapora/gemma-7b-borpo-low-quality, https://huggingface.co/silviasapora/gemma-7b-borpo, https://huggingface.co/c-alfano/gemma-7b-borpo-low-quality-v2, https://huggingface.co/c-alfano/gemma-7b-borpo-low-quality-v3, https://huggingface.co/c-alfano/gemma-7b-borpo-low-quality-v4, https://huggingface.co/OpenLLM-Ro/RoGemma-7b-Instruct-2024-10-09, https://huggingface.co/klcsp/gemma7b-gpt4o_1k_summarize-fft, https://huggingface.co/klcsp/gemma7b-gpt4o_1k_classification-fft, https://huggingface.co/klcsp/gemma7b-gpt4o_1k_coding-fft, https://huggingface.co/klcsp/gemma7b-gpt4o_1k_closedqa-fft, https://huggingface.co/c-alfano/gemma-7b-borpo-low-quality-v5, https://huggingface.co/OpenLLM-Ro/RoGemma-7b-Instruct, https://huggingface.co/jcantu217/gemma-2-7b-invasive-plant-chatbot, https://huggingface.co/OpenVINO/gemma-7b-fp16-ov, https://huggingface.co/vermouthliu/gemma_298, https://huggingface.co/baidu/HH-RLHF-Gemma-7B-MA-PPO-Fixed5, https://huggingface.co/baidu/TLDR-Gemma-7B-MA-PPO-Fixed5, https://huggingface.co/klcsp/gemma7b-fft-classification-11-v1, https://huggingface.co/klcsp/gemma7b-fft-alpaca-11-v1, https://huggingface.co/klcsp/gemma7b-fft-closedqa-11-v1, https://huggingface.co/klcsp/gemma7b-fft-coding-11-v1, https://huggingface.co/klcsp/gemma7b-fft-summarization-11-v1, https://huggingface.co/YingL19/5epoch_1e5_1124, https://huggingface.co/YingL19/gemma_10epoch_1e5_lincoln, https://huggingface.co/YingL19/gemma_10epoch_1e5_lincoln1, https://huggingface.co/YingL19/gemma_10epoch_1e5_sherlock, https://huggingface.co/daphne604/EHR_Mort_DS_gemma-7b_PEFT, https://huggingface.co/AmberYifan/Gemma-7b-sft-ultrachat, https://huggingface.co/silviasapora/gemma-7b-orpo-noisy-4e-5, https://huggingface.co/silviasapora/gemma-7b-borpo-noisy-6e-5, https://huggingface.co/silviasapora/gemma-7b-borpo-shuffled-5e-5, https://huggingface.co/silviasapora/gemma-7b-borpo-noisy-5e-5, https://huggingface.co/silviasapora/gemma-7b-orpo-noisy-5e-5, https://huggingface.co/silviasapora/gemma-7b-borpo-shuffled-6e-5, https://huggingface.co/silviasapora/gemma-7b-orpo-shuffled-6e-5, https://huggingface.co/silviasapora/gemma-7b-orpo-noisy-6e-5, https://huggingface.co/silviasapora/gemma-7b-borpo-noisy-5e-5-norm, https://huggingface.co/silviasapora/gemma-7b-borpo-shuffled-1e-5-norm, https://huggingface.co/silviasapora/gemma-7b-borpo-shuffled-5e-5-norm, https://huggingface.co/silviasapora/gemma-7b-borpo-shuffled-7e-5-norm, https://huggingface.co/silviasapora/gemma-7b-borpo-noisy-1e-5-norm, https://huggingface.co/silviasapora/gemma-7b-orpo-noisy-1e-5-norm, https://huggingface.co/silviasapora/gemma-7b-orpo-shuffled-1e-5-norm, https://huggingface.co/silviasapora/gemma-7b-orpo-noisy-5e-6-norm, https://huggingface.co/silviasapora/gemma-7b-orpo-noisy-7e-5-norm, https://huggingface.co/silviasapora/gemma-7b-orpo-shuffled-7e-5-norm, https://huggingface.co/silviasapora/gemma-7b-orpo-shuffled-5e-5-norm, https://huggingface.co/silviasapora/gemma-7b-orpo-noisy-5e-5-norm, https://huggingface.co/silviasapora/gemma-7b-borpo-noisy-7e-5-norm, https://huggingface.co/silviasapora/gemma-7b-borpo-shuffled-5e-6-norm, https://huggingface.co/silviasapora/gemma-7b-borpo-noisy-5e-6-norm, https://huggingface.co/silviasapora/gemma-7b-borpo-shuffled-5e-5-norm2, https://huggingface.co/silviasapora/gemma-7b-borpo-shuffled-5e-5-norm-shuf, https://huggingface.co/silviasapora/gemma-7b-borpo-noisy-7e-5-norm2, https://huggingface.co/silviasapora/gemma-7b-borpo-noisy-1e-5-norm2, https://huggingface.co/silviasapora/gemma-7b-borpo-noisy-5e-6-norm2, https://huggingface.co/silviasapora/gemma-7b-borpo-noisy-5e-5-005-norm2, https://huggingface.co/silviasapora/gemma-7b-borpo-noisy-5e-5-02-norm2, https://huggingface.co/silviasapora/gemma-7b-borpo-noisy-5e-5-04-norm2, https://huggingface.co/silviasapora/gemma-7b-borpo-noisy-5e-5-01-norm2, https://huggingface.co/silviasapora/gemma-7b-orpo-5e-5-norm2, https://huggingface.co/silviasapora/gemma-7b-borpo-5e-5-04-norm2, https://huggingface.co/silviasapora/gemma-7b-simpo-noisy-5e-5, https://huggingface.co/silviasapora/gemma-7b-simpo-basic-5e-5, https://huggingface.co/silviasapora/gemma-7b-leakyrelu-noisy-5e-5, https://huggingface.co/silviasapora/gemma-7b-softplus-noisy-5e-5, https://huggingface.co/silviasapora/gemma-7b-softplus-basic-5e-5, https://huggingface.co/silviasapora/gemma-7b-leakyrelu-basic-5e-5, https://huggingface.co/silviasapora/gemma-7b-silvia-basic-5e-5-v4, https://huggingface.co/silviasapora/gemma-7b-borpo-basic-5e-5-v4, https://huggingface.co/silviasapora/gemma-7b-leakyrelu-basic-5e-5-v4, https://huggingface.co/silviasapora/gemma-7b-borpo-basic-5e-5-1-v4, https://huggingface.co/silviasapora/gemma-7b-borpo-basic-5e-5-02-v4, https://huggingface.co/silviasapora/gemma-7b-simpo-basic-5e-5-02-v4, https://huggingface.co/silviasapora/gemma-7b-simpo-basic-5e-5-05-v4, https://huggingface.co/silviasapora/gemma-7b-cpo-noisy-5e-5-v4, https://huggingface.co/silviasapora/gemma-7b-softplus-basic-5e-5-v4, https://huggingface.co/silviasapora/gemma-7b-borpo-noisy-5e-5-v4, https://huggingface.co/silviasapora/gemma-7b-simpo-basic-5e-5-v4, https://huggingface.co/silviasapora/gemma-7b-borpo-noisy-5e-5-1-v4, https://huggingface.co/silviasapora/gemma-7b-borpo-noisy-5e-5-02-v4, https://huggingface.co/silviasapora/gemma-7b-leakyrelu-noisy-5e-5-v4, https://huggingface.co/silviasapora/gemma-7b-silvia-noisy-5e-5-v4, https://huggingface.co/silviasapora/gemma-7b-softplus-noisy-5e-5-v4, https://huggingface.co/silviasapora/gemma-7b-simpo-noisy-5e-5-v4, https://huggingface.co/silviasapora/gemma-7b-borpo-shuffled-5e-5-01-v4, https://huggingface.co/silviasapora/gemma-7b-borpo-shuffled-5e-5-02-v4, https://huggingface.co/silviasapora/gemma-7b-silvia-shuffled-5e-5-v4, https://huggingface.co/silviasapora/gemma-7b-cpo-shuffled-5e-5-v4, https://huggingface.co/silviasapora/gemma-7b-borpo-shuffled-5e-5-v4, https://huggingface.co/silviasapora/gemma-7b-leakyrelu-shuffled-5e-5-v4, https://huggingface.co/silviasapora/gemma-7b-borpo-shuffled-5e-5-04-v4, https://huggingface.co/silviasapora/gemma-7b-softplus-shuffled-5e-5-v4, https://huggingface.co/silviasapora/gemma-7b-simpo-shuffled-5e-5-v4, https://huggingface.co/silviasapora/gemma-7b-cpo-basic-5e-5-v5, https://huggingface.co/silviasapora/gemma-7b-cpo-noisy-5e-5-v5, https://huggingface.co/silviasapora/gemma-7b-borpo-shuffled-5e-5-v5, https://huggingface.co/silviasapora/gemma-7b-borpo-basic-5e-5-v5, https://huggingface.co/silviasapora/gemma-7b-orpo-noisy-5e-5-v5, https://huggingface.co/silviasapora/gemma-7b-borpo-noisy-5e-5-v5, https://huggingface.co/silviasapora/gemma-7b-orpo-shuffled-5e-5-v5, https://huggingface.co/silviasapora/gemma-7b-cpo-shuffled-5e-5-v5, https://huggingface.co/silviasapora/gemma-7b-borpo-basic-5e-5-02-v5, https://huggingface.co/silviasapora/gemma-7b-orpo-basic-5e-5-05-v5, https://huggingface.co/silviasapora/gemma-7b-silvia-shuffled-5e-5-05-v5, https://huggingface.co/silviasapora/gemma-7b-silvia-basic-5e-5-05-v5, https://huggingface.co/silviasapora/gemma-7b-borpo-basic-5e-5-005-v5, https://huggingface.co/silviasapora/gemma-7b-silvia-basic-5e-5-02-v5, https://huggingface.co/silviasapora/gemma-7b-borpo-basic-5e-5-01-v5, https://huggingface.co/silviasapora/gemma-7b-silvia-basic-5e-5-01-v5, https://huggingface.co/silviasapora/gemma-7b-borpo-basic-5e-5-05-v5, https://huggingface.co/silviasapora/gemma-7b-silvia-shuffled-5e-5-02-v5, https://huggingface.co/silviasapora/gemma-7b-borpo-shuffled-5e-5-05-v5, https://huggingface.co/silviasapora/gemma-7b-slic-basic-5e-5-05-v5, https://huggingface.co/silviasapora/gemma-7b-slic-shuffled-5e-5-05-v5, https://huggingface.co/silviasapora/gemma-7b-silvia-shuffled-5e-5-05-v6-08sftt, https://huggingface.co/silviasapora/gemma-7b-silvia-shuffled-5e-5-05-v6-1sftt, https://huggingface.co/silviasapora/gemma-7b-slic-basic-5e-5-05-v5-1sftt-gamma10, https://huggingface.co/silviasapora/gemma-7b-silvia-basic-5e-5-05-v5-1sftt-gamma10, https://huggingface.co/silviasapora/gemma-7b-silvia-basic-5e-5-05-v5-1sftt-gamma5, https://huggingface.co/silviasapora/gemma-7b-silvia-basic-5e-5-05-v5-05sftt-gamma5, https://huggingface.co/silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp1, https://huggingface.co/silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp0, https://huggingface.co/silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp3, https://huggingface.co/silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp2, https://huggingface.co/silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp5, https://huggingface.co/silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp4, https://huggingface.co/silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp7, https://huggingface.co/silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp6, https://huggingface.co/silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp9, https://huggingface.co/silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp8, https://huggingface.co/silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp10, https://huggingface.co/silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp11, https://huggingface.co/silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp12, https://huggingface.co/silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp13, https://huggingface.co/silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp14, https://huggingface.co/silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp15, https://huggingface.co/silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp17, https://huggingface.co/silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp16, https://huggingface.co/silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp19, https://huggingface.co/silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp18, https://huggingface.co/silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp20, https://huggingface.co/silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp21, https://huggingface.co/silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp23, https://huggingface.co/silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp22, https://huggingface.co/silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp26, https://huggingface.co/silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp25, https://huggingface.co/silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp24, https://huggingface.co/silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp29, https://huggingface.co/silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp28, https://huggingface.co/silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp27, https://huggingface.co/silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp30, https://huggingface.co/silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp31, https://huggingface.co/silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp32, https://huggingface.co/silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp33, https://huggingface.co/silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp34, https://huggingface.co/silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp35, https://huggingface.co/silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp37, https://huggingface.co/silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp36, https://huggingface.co/silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp38, https://huggingface.co/silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp39, https://huggingface.co/silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp40, https://huggingface.co/silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp41, https://huggingface.co/silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp43, https://huggingface.co/silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp44, https://huggingface.co/silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp42, https://huggingface.co/silviasapora/gemma-7b-sft-basic-5e-5-05-vshp0, https://huggingface.co/silviasapora/gemma-7b-silvia-basic-5e-5-05-vsh2p1, https://huggingface.co/silviasapora/gemma-7b-silvia-basic-5e-5-05-vsh2p0, https://huggingface.co/silviasapora/gemma-7b-silvia-basic-5e-5-05-vsh2p3, https://huggingface.co/silviasapora/gemma-7b-silvia-basic-5e-5-05-vsh2p2, https://huggingface.co/silviasapora/gemma-7b-silvia-basic-5e-5-05-vsh2p7, https://huggingface.co/silviasapora/gemma-7b-silvia-basic-5e-5-05-vsh2p5, https://huggingface.co/silviasapora/gemma-7b-silvia-basic-5e-5-05-vsh2p4, https://huggingface.co/silviasapora/gemma-7b-silvia-basic-5e-5-05-vsh2p6, https://huggingface.co/silviasapora/gemma-7b-silvia-basic-5e-5-05-vsh2p11, https://huggingface.co/silviasapora/gemma-7b-silvia-basic-5e-5-05-vsh2p9, https://huggingface.co/silviasapora/gemma-7b-silvia-basic-5e-5-05-vsh2p10, https://huggingface.co/silviasapora/gemma-7b-silvia-basic-5e-5-05-vsh2p8, https://huggingface.co/MatteoKhan/MistralGemma-7B-Merged, https://huggingface.co/silviasapora/gemma-7b-sft-basic-5e-5-05-vsh3p4, https://huggingface.co/silviasapora/gemma-7b-silvia-basic-5e-5-05-vsh3p1, https://huggingface.co/silviasapora/gemma-7b-silvia-basic-5e-5-05-vsh3p0, https://huggingface.co/silviasapora/gemma-7b-silvia-basic-5e-5-05-vsh3p3, https://huggingface.co/silviasapora/gemma-7b-silvia-basic-5e-5-05-vsh3p2, https://huggingface.co/silviasapora/gemma-7b-silvia-basic-5e-5-05-vsh3p4, https://huggingface.co/silviasapora/gemma-7b-silvia-basic-5e-5-05-vsh3p5, https://huggingface.co/silviasapora/gemma-7b-silvia-basic-5e-5-05-vsh3p6, https://huggingface.co/silviasapora/gemma-7b-silvia-basic-5e-5-05-vsh3p7, https://huggingface.co/silviasapora/gemma-7b-silvia-basic-5e-5-05-vsh3p8, https://huggingface.co/silviasapora/gemma-7b-cpo-basic-5e-5-005-vshp1, https://huggingface.co/silviasapora/gemma-7b-slic-basic-5e-5-005-vshp3, https://huggingface.co/silviasapora/gemma-7b-silvia-basic-5e-5-005-vshp0, https://huggingface.co/silviasapora/gemma-7b-orpo-basic-5e-5-005-vshp2, https://huggingface.co/silviasapora/gemma-7b-silvia-basic-5e-5-05-v72, https://huggingface.co/silviasapora/gemma-7b-silvia-basic-5e-5-05-v71, https://huggingface.co/silviasapora/gemma-7b-silvia-basic-5e-5-05-v70, https://huggingface.co/silviasapora/gemma-7b-cpo-basic-5e-5-05-v70, https://huggingface.co/silviasapora/gemma-7b-orpo-basic-5e-5-05-v71, https://huggingface.co/silviasapora/gemma-7b-silvia-basic-5e-5-05-v81, https://huggingface.co/silviasapora/gemma-7b-silvia-basic-5e-5-05-v80, https://huggingface.co/silviasapora/gemma-7b-silvia-basic-5e-5-05-v82, https://huggingface.co/silviasapora/gemma-7b-slic-basic-5e-5-05-v72, https://huggingface.co/silviasapora/gemma-7b-silvia-basic-5e-5-05-v93, https://huggingface.co/silviasapora/gemma-7b-silvia-basic-5e-5-05-v91, https://huggingface.co/silviasapora/gemma-7b-silvia-basic-5e-5-05-v92, https://huggingface.co/silviasapora/gemma-7b-silvia-basic-5e-5-05-v90, https://huggingface.co/silviasapora/gemma-7b-silvia-basic-5e-5-05-v96, https://huggingface.co/silviasapora/gemma-7b-silvia-basic-5e-5-05-v95, https://huggingface.co/silviasapora/gemma-7b-silvia-basic-5e-5-05-v97, https://huggingface.co/silviasapora/gemma-7b-silvia-basic-5e-5-05-v94, https://huggingface.co/silviasapora/gemma-7b-silvia-basic-5e-5-05-v911, https://huggingface.co/silviasapora/gemma-7b-silvia-basic-5e-5-05-v98, https://huggingface.co/silviasapora/gemma-7b-silvia-basic-5e-5-05-v99, https://huggingface.co/silviasapora/gemma-7b-silvia-basic-5e-5-05-v910, https://huggingface.co/silviasapora/gemma-7b-silvia-basic-5e-5-05-v914, https://huggingface.co/silviasapora/gemma-7b-silvia-basic-5e-5-05-v915, https://huggingface.co/silviasapora/gemma-7b-silvia-basic-5e-5-05-v912, https://huggingface.co/silviasapora/gemma-7b-silvia-basic-5e-5-05-v913, https://huggingface.co/silviasapora/gemma-7b-silvia-basic-5e-5-05-v917, https://huggingface.co/silviasapora/gemma-7b-silvia-basic-5e-5-05-v916, https://huggingface.co/silviasapora/gemma-7b-silvia-basic-5e-5-05-v101, https://huggingface.co/silviasapora/gemma-7b-silvia-basic-5e-5-05-v102, https://huggingface.co/silviasapora/gemma-7b-silvia-basic-5e-5-05-v103, https://huggingface.co/silviasapora/gemma-7b-silvia-basic-5e-5-05-v100, https://huggingface.co/silviasapora/gemma-7b-silvia_cpo-basic-5e-5-05-v110, https://huggingface.co/silviasapora/gemma-7b-silvia_cpo-basic-5e-5-05-v111, https://huggingface.co/silviasapora/gemma-7b-silvia_cpo-basic-5e-5-05-v112, https://huggingface.co/silviasapora/gemma-7b-silvia_cpo-basic-5e-5-05-v113, https://huggingface.co/silviasapora/gemma-7b-silvia_cpo-basic-5e-5-05-v114, https://huggingface.co/silviasapora/gemma-7b-silvia_cpo-basic-5e-5-05-v115, https://huggingface.co/silviasapora/gemma-7b-cpo-basic-5e-5-05-v110, https://huggingface.co/silviasapora/gemma-7b-orpo-basic-5e-5-05-v111, https://huggingface.co/silviasapora/gemma-7b-silvia_cpo-basic_long-5e-5-05-v120, https://huggingface.co/silviasapora/gemma-7b-cpo-basic_long-5e-5-05-v120, https://huggingface.co/silviasapora/gemma-7b-silvia_cpo-basic_long-5e-5-05-v130, https://huggingface.co/silviasapora/gemma-7b-cpo-basic_long-5e-5-05-v130, https://huggingface.co/silviasapora/gemma-7b-silvia_cpo-basic_long-5e-5-025-v130, https://huggingface.co/silviasapora/gemma-7b-cpo-basic_long-5e-5-025-v130, https://huggingface.co/silviasapora/gemma-7b-sft-basic-5e-5-00-v130, https://huggingface.co/silviasapora/gemma-7b-silvia_cpo-basic_long-5e-5-025-v131, https://huggingface.co/silviasapora/gemma-7b-silvia_cpo-basic_capibara-5e-5-01-v131, https://huggingface.co/silviasapora/gemma-7b-silvia_cpo-basic_capibara-5e-5-01-v132, https://huggingface.co/silviasapora/gemma-7b-silvia_cpo-basic_capibara-5e-5-025-v133, https://huggingface.co/silviasapora/gemma-7b-cpo-basic_capibara-5e-5-01-v131, https://huggingface.co/silviasapora/gemma-7b-sft-dpo-basic-5e-7-001-v131, https://huggingface.co/silviasapora/gemma-7b-silvia_cpo-basic_capibara-5e-5-025-v134, https://huggingface.co/silviasapora/gemma-7b-sft-dpo-basic-5e-7-005-v132, https://huggingface.co/silviasapora/gemma-7b-cpo-basic_capibara-5e-5-025-v132, https://huggingface.co/silviasapora/gemma-7b-orpo-basic_capibara-5e-5-025-v140, https://huggingface.co/silviasapora/gemma-7b-silvia_cpo-basic_capibara-5e-5-025-v140, https://huggingface.co/silviasapora/gemma-7b-silvia_cpo-basic_capibara-5e-5-025-v141, https://huggingface.co/silviasapora/gemma-7b-silvia_cpo-basic_capibara-5e-5-025-v142, https://huggingface.co/silviasapora/gemma-7b-cpo-basic_capibara-5e-5-025-v140, https://huggingface.co/silviasapora/gemma-7b-orpo-basic-5e-5-05-v140, https://huggingface.co/silviasapora/gemma-7b-slic-basic-5e-5-05-v140, https://huggingface.co/silviasapora/gemma-7b-slic-basic_capibara-5e-5-025-v140, https://huggingface.co/silviasapora/gemma-7b-silvia_cpo-basic_capibara-5e-5-025-v150, https://huggingface.co/silviasapora/gemma-7b-silvia_cpo-basic_capibara-5e-5-025-v151, https://huggingface.co/silviasapora/gemma-7b-sft-basic_capibara-5e-5-000-v131, https://huggingface.co/silviasapora/gemma-7b-sft-basic_capibara-5e-5-000-v133, https://huggingface.co/selincildam/medical-assistant-gemma",336,"https://huggingface.co/MaziyarPanahi/gemma-7b-GGUF, https://huggingface.co/brittlewis12/gemma-7b-GGUF, https://huggingface.co/sayhan/gemma-7b-GGUF-quantized, https://huggingface.co/LoneStriker/zephyr-7b-gemma-sft-v0.1-GGUF, https://huggingface.co/LoneStriker/openbuddy-gemma-7b-v19.1-4k-GGUF, https://huggingface.co/Telugu-LLM-Labs/Indic-gemma-7b-finetuned-sft-Navarasa-2.0-gguf, https://huggingface.co/leliuga/gemma-7b-bnb-4bit, https://huggingface.co/PrunaAI/google-gemma-7b-AWQ-4bit-smashed, https://huggingface.co/PrunaAI/google-gemma-7b-bnb-4bit-smashed, https://huggingface.co/PrunaAI/gemma-7b-AWQ-4bit-smashed, https://huggingface.co/chansung/mental_health_counseling_merged_v0.1, https://huggingface.co/webbigdata/C3TR-Adapter_gptq, https://huggingface.co/julioc-p/CNCF, https://huggingface.co/ddtsoftware/Train06, https://huggingface.co/fedric95/gemma-7b-GGUF, https://huggingface.co/QuantFactory/gemma-7b-aps-it-GGUF, https://huggingface.co/OpenVINO/gemma-7b-int4-ov, https://huggingface.co/OpenVINO/gemma-7b-int8-ov, https://huggingface.co/subho123/gemma-7b-finetune, https://huggingface.co/mradermacher/gemma-7b-GGUF, https://huggingface.co/mradermacher/gemma-7b-i1-GGUF, https://huggingface.co/PrunaAI/google-gemma-7b-GGUF-smashed, https://huggingface.co/goromlagche/gemma-7b-Q4_K_M-GGUF",23,"https://huggingface.co/Or4cl3-1/Agent_Gemma_7b, https://huggingface.co/johnsutor/mixture-of-gemmas, https://huggingface.co/johnsutor/mixture-of-gemmas-ties, https://huggingface.co/johnsutor/mixture-of-gemmas-dare-linear, https://huggingface.co/johnsutor/mixture-of-gemmas-dare-ties, https://huggingface.co/johnsutor/mixture-of-gemmas-linear, https://huggingface.co/johnsutor/mixture-of-gemmas-slerp",7,"Cognitive-Lab/indic_llm_leaderboard, Justinrune/LLaMA-Factory, KBaba7/Quant, Omnibus/Chatbot-Compare, allenai/URIAL-Bench, cot-leaderboard/open-cot-dashboard, eduagarcia/open_pt_llm_leaderboard, huggingface/InferenceSupport/discussions/890, logikon/open_cot_leaderboard, ngebodh/SimpleChatbot, prometheus-eval/BiGGen-Bench-Leaderboard, taka-yamakoshi/tokenizer-demo, yhavinga/dutch-tokenizer-arena",13,,
Junfeng5/Liquid_V1_7B,"---
license: mit
library_name: transformers
datasets:
- mlfoundations/dclm-baseline-1.0
- cerebras/SlimPajama-627B
- bigcode/starcoderdata
- JourneyDB/JourneyDB
language:
- en
base_model:
- google/gemma-7b
pipeline_tag: any-to-any
---

## Model Details

We present Liquid, an auto-regressive generation paradigm that seamlessly integrates visual comprehension and generation by tokenizing images into discrete codes and learning these code embeddings alongside text tokens within a shared feature space for both vision and language. Unlike previous multimodal large language model (MLLM), Liquid achieves this integration using a single large language model (LLM), eliminating the need for external pretrained visual embeddings such as CLIP. Liquid explores the scaling law of this multimodal hybrid model and discovers the phenomenon of mutual promotion between understanding and generation tasks. 



**Variations** Liquid comes in six sizes — 0.5B, 1B, 2B, 7B, 9B, 32B parameters (from multi modal families) in pre-trained variant, and 7B (from GEMMA) in instruction tuned variant.

**Input** Models input text and image.

**Output** Models generate text or generated image.

**Model Architecture** Liquid is an auto-regressive model extending from existing LLMs that uses an transformer architecture.


**Citation instructions** 

@article{wu2024liquid,

    title={Liquid: Language Models are Scalable Multi-modal Generators},
    
    author={Wu, Junfeng and Jiang, Yi and Ma, Chuofan and Liu, Yuliang and Zhao, Hengshuang and Yuan, Zehuan and Bai, Song and Bai, Xiang},
    
    journal={arXiv preprint arXiv:2412.04332},
    
    year={2024}
    
}","{""id"": ""Junfeng5/Liquid_V1_7B"", ""author"": ""Junfeng5"", ""sha"": ""a0e7b763fe3869d383a22c64cde1a9dcaab65160"", ""last_modified"": ""2025-03-20 10:16:20+00:00"", ""created_at"": ""2025-02-21 09:09:41+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 10793, ""downloads_all_time"": null, ""likes"": 81, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""safetensors"", ""gemma"", ""text-generation"", ""any-to-any"", ""en"", ""dataset:mlfoundations/dclm-baseline-1.0"", ""dataset:cerebras/SlimPajama-627B"", ""dataset:bigcode/starcoderdata"", ""dataset:JourneyDB/JourneyDB"", ""arxiv:2412.04332"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""license:mit"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""any-to-any"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model:\n- google/gemma-7b\ndatasets:\n- mlfoundations/dclm-baseline-1.0\n- cerebras/SlimPajama-627B\n- bigcode/starcoderdata\n- JourneyDB/JourneyDB\nlanguage:\n- en\nlibrary_name: transformers\nlicense: mit\npipeline_tag: any-to-any"", ""widget_data"": null, ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='generation_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00001-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00002-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00003-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00004-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model.safetensors.index.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)""], ""spaces"": [""Junfeng5/Liquid_demo""], ""safetensors"": {""parameters"": {""BF16"": 8562846720}, ""total"": 8562846720}, ""security_repo_status"": null, ""lastModified"": ""2025-03-20 10:16:20+00:00"", ""cardData"": ""base_model:\n- google/gemma-7b\ndatasets:\n- mlfoundations/dclm-baseline-1.0\n- cerebras/SlimPajama-627B\n- bigcode/starcoderdata\n- JourneyDB/JourneyDB\nlanguage:\n- en\nlibrary_name: transformers\nlicense: mit\npipeline_tag: any-to-any"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67b842d559bdaeb14b8acde8"", ""modelId"": ""Junfeng5/Liquid_V1_7B"", ""usedStorage"": 17143241490}",1,,0,,0,,0,"Junfeng5/Liquid_demo, huggingface/InferenceSupport/discussions/new?title=Junfeng5/Liquid_V1_7B&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5BJunfeng5%2FLiquid_V1_7B%5D(%2FJunfeng5%2FLiquid_V1_7B)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A",2,,
google/gemma-7b-it,"---
library_name: transformers
license: gemma
tags: []
widget:
- messages:
  - role: user
    content: How does the brain work?
inference:
  parameters:
    max_new_tokens: 200
extra_gated_heading: Access Gemma on Hugging Face
extra_gated_prompt: To access Gemma on Hugging Face, you’re required to review and
  agree to Google’s usage license. To do this, please ensure you’re logged-in to Hugging
  Face and click below. Requests are processed immediately.
extra_gated_button_content: Acknowledge license
base_model: google/gemma-7b
base_model_relation: finetune
---

# Gemma Model Card

**Model Page**: [Gemma](https://ai.google.dev/gemma/docs)

This model card corresponds to the 7B instruct version of the Gemma model. You can also visit the model card of the [2B base model](https://huggingface.co/google/gemma-2b), [7B base model](https://huggingface.co/google/gemma-7b), and [2B instruct model](https://huggingface.co/google/gemma-2b-it). 

**Resources and Technical Documentation**:

* [Responsible Generative AI Toolkit](https://ai.google.dev/responsible)
* [Gemma on Kaggle](https://www.kaggle.com/models/google/gemma)
* [Gemma on Vertex Model Garden](https://console.cloud.google.com/vertex-ai/publishers/google/model-garden/335?version=gemma-7b-it-gg-hf)

**Terms of Use**: [Terms](https://www.kaggle.com/models/google/gemma/license/consent/verify/huggingface?returnModelRepoId=google/gemma-7b-it)

**Authors**: Google

## Model Information

Summary description and brief definition of inputs and outputs.

### Description

Gemma is a family of lightweight, state-of-the-art open models from Google,
built from the same research and technology used to create the Gemini models.
They are text-to-text, decoder-only large language models, available in English,
with open weights, pre-trained variants, and instruction-tuned variants. Gemma
models are well-suited for a variety of text generation tasks, including
question answering, summarization, and reasoning. Their relatively small size
makes it possible to deploy them in environments with limited resources such as
a laptop, desktop or your own cloud infrastructure, democratizing access to
state of the art AI models and helping foster innovation for everyone.

### Usage

Below we share some code snippets on how to get quickly started with running the model. First make sure to `pip install -U transformers`, then copy the snippet from the section that is relevant for your usecase.

#### Fine-tuning the model

You can find fine-tuning scripts and notebook under the [`examples/` directory](https://huggingface.co/google/gemma-7b/tree/main/examples) of [`google/gemma-7b`](https://huggingface.co/google/gemma-7b) repository. To adapt it to this model, simply change the model-id to `google/gemma-7b-it`.
In that repository, we provide:

* A script to perform Supervised Fine-Tuning (SFT) on UltraChat dataset using QLoRA
* A script to perform SFT using FSDP on TPU devices
* A notebook that you can run on a free-tier Google Colab instance to perform SFT on English quotes dataset


#### Running the model on a CPU

As explained below, we recommend `torch.bfloat16` as the default dtype. You can use [a different precision](#precisions) if necessary.

```python
from transformers import AutoTokenizer, AutoModelForCausalLM
import torch

tokenizer = AutoTokenizer.from_pretrained(""google/gemma-7b-it"")
model = AutoModelForCausalLM.from_pretrained(
    ""google/gemma-7b-it"",
    torch_dtype=torch.bfloat16
)

input_text = ""Write me a poem about Machine Learning.""
input_ids = tokenizer(input_text, return_tensors=""pt"")

outputs = model.generate(**input_ids)
print(tokenizer.decode(outputs[0]))
```


#### Running the model on a single / multi GPU


```python
# pip install accelerate
from transformers import AutoTokenizer, AutoModelForCausalLM
import torch

tokenizer = AutoTokenizer.from_pretrained(""google/gemma-7b-it"")
model = AutoModelForCausalLM.from_pretrained(
    ""google/gemma-7b-it"",
    device_map=""auto"",
    torch_dtype=torch.bfloat16
)

input_text = ""Write me a poem about Machine Learning.""
input_ids = tokenizer(input_text, return_tensors=""pt"").to(""cuda"")

outputs = model.generate(**input_ids)
print(tokenizer.decode(outputs[0]))
```

<a name=""precisions""></a>
#### Running the model on a GPU using different precisions

The native weights of this model were exported in `bfloat16` precision. You can use `float16`, which may be faster on certain hardware, indicating the `torch_dtype` when loading the model. For convenience, the `float16` revision of the repo contains a copy of the weights already converted to that precision.

You can also use `float32` if you skip the dtype, but no precision increase will occur (model weights will just be upcasted to `float32`). See examples below.

* _Using `torch.float16`_

```python
# pip install accelerate
from transformers import AutoTokenizer, AutoModelForCausalLM
import torch

tokenizer = AutoTokenizer.from_pretrained(""google/gemma-7b-it"")
model = AutoModelForCausalLM.from_pretrained(
    ""google/gemma-7b-it"",
    device_map=""auto"",
    torch_dtype=torch.float16,
    revision=""float16"",
)

input_text = ""Write me a poem about Machine Learning.""
input_ids = tokenizer(input_text, return_tensors=""pt"").to(""cuda"")

outputs = model.generate(**input_ids)
print(tokenizer.decode(outputs[0]))
```

* _Using `torch.bfloat16`_

```python
# pip install accelerate
from transformers import AutoTokenizer, AutoModelForCausalLM

tokenizer = AutoTokenizer.from_pretrained(""google/gemma-7b-it"")
model = AutoModelForCausalLM.from_pretrained(""google/gemma-7b-it"", device_map=""auto"", torch_dtype=torch.bfloat16)

input_text = ""Write me a poem about Machine Learning.""
input_ids = tokenizer(input_text, return_tensors=""pt"").to(""cuda"")

outputs = model.generate(**input_ids)
print(tokenizer.decode(outputs[0]))
```

* _Upcasting to `torch.float32`_

```python
# pip install accelerate
from transformers import AutoTokenizer, AutoModelForCausalLM

tokenizer = AutoTokenizer.from_pretrained(""google/gemma-7b-it"")
model = AutoModelForCausalLM.from_pretrained(
    ""google/gemma-7b-it"",
    device_map=""auto""
)

input_text = ""Write me a poem about Machine Learning.""
input_ids = tokenizer(input_text, return_tensors=""pt"").to(""cuda"")

outputs = model.generate(**input_ids)
print(tokenizer.decode(outputs[0]))
```

#### Quantized Versions through `bitsandbytes`

* _Using 8-bit precision (int8)_

```python
# pip install bitsandbytes accelerate
from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig

quantization_config = BitsAndBytesConfig(load_in_8bit=True)

tokenizer = AutoTokenizer.from_pretrained(""google/gemma-7b-it"")
model = AutoModelForCausalLM.from_pretrained(""google/gemma-7b-it"", quantization_config=quantization_config)

input_text = ""Write me a poem about Machine Learning.""
input_ids = tokenizer(input_text, return_tensors=""pt"").to(""cuda"")

outputs = model.generate(**input_ids)
print(tokenizer.decode(outputs[0]))
```

* _Using 4-bit precision_

```python
# pip install bitsandbytes accelerate
from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig

quantization_config = BitsAndBytesConfig(load_in_4bit=True)

tokenizer = AutoTokenizer.from_pretrained(""google/gemma-7b-it"")
model = AutoModelForCausalLM.from_pretrained(""google/gemma-7b-it"", quantization_config=quantization_config)

input_text = ""Write me a poem about Machine Learning.""
input_ids = tokenizer(input_text, return_tensors=""pt"").to(""cuda"")

outputs = model.generate(**input_ids)
print(tokenizer.decode(outputs[0]))
```


#### Other optimizations

* _Flash Attention 2_

First make sure to install `flash-attn` in your environment `pip install flash-attn`

```diff
model = AutoModelForCausalLM.from_pretrained(
    model_id, 
    torch_dtype=torch.float16, 
+   attn_implementation=""flash_attention_2""
).to(0)
```

### Chat Template

The instruction-tuned models use a chat template that must be adhered to for conversational use.
The easiest way to apply it is using the tokenizer's built-in chat template, as shown in the following snippet.

Let's load the model and apply the chat template to a conversation. In this example, we'll start with a single user interaction:

```py
from transformers import AutoTokenizer, AutoModelForCausalLM
import transformers
import torch

model_id = ""google/gemma-7b-it""
dtype = torch.bfloat16

tokenizer = AutoTokenizer.from_pretrained(model_id)
model = AutoModelForCausalLM.from_pretrained(
    model_id,
    device_map=""cuda"",
    torch_dtype=dtype,
)

chat = [
    { ""role"": ""user"", ""content"": ""Write a hello world program"" },
]
prompt = tokenizer.apply_chat_template(chat, tokenize=False, add_generation_prompt=True)
```

At this point, the prompt contains the following text:

```
<bos><start_of_turn>user
Write a hello world program<end_of_turn>
<start_of_turn>model
```

As you can see, each turn is preceded by a `<start_of_turn>` delimiter and then the role of the entity
(either `user`, for content supplied by the user, or `model` for LLM responses). Turns finish with
the `<end_of_turn>` token.

You can follow this format to build the prompt manually, if you need to do it without the tokenizer's
chat template.

After the prompt is ready, generation can be performed like this:

```py
inputs = tokenizer.encode(prompt, add_special_tokens=False, return_tensors=""pt"")
outputs = model.generate(input_ids=inputs.to(model.device), max_new_tokens=150)
print(tokenizer.decode(outputs[0]))
```

### Inputs and outputs

*   **Input:** Text string, such as a question, a prompt, or a document to be
    summarized.
*   **Output:** Generated English-language text in response to the input, such
    as an answer to a question, or a summary of a document.

## Model Data

Data used for model training and how the data was processed.

### Training Dataset

These models were trained on a dataset of text data that includes a wide variety
of sources, totaling 6 trillion tokens. Here are the key components:

* Web Documents: A diverse collection of web text ensures the model is exposed
  to a broad range of linguistic styles, topics, and vocabulary. Primarily
  English-language content.
* Code: Exposing the model to code helps it to learn the syntax and patterns of
  programming languages, which improves its ability to generate code or
  understand code-related questions.
* Mathematics: Training on mathematical text helps the model learn logical
  reasoning, symbolic representation, and to address mathematical queries.

The combination of these diverse data sources is crucial for training a powerful
language model that can handle a wide variety of different tasks and text
formats.

### Data Preprocessing

Here are the key data cleaning and filtering methods applied to the training
data:

* CSAM Filtering: Rigorous CSAM (Child Sexual Abuse Material) filtering was
  applied at multiple stages in the data preparation process to ensure the
  exclusion of harmful and illegal content
* Sensitive Data Filtering: As part of making Gemma pre-trained models safe and
  reliable, automated techniques were used to filter out certain personal
  information and other sensitive data from training sets.
* Additional methods: Filtering based on content quality and safely in line with
  [our policies](https://storage.googleapis.com/gweb-uniblog-publish-prod/documents/2023_Google_AI_Principles_Progress_Update.pdf#page=11).

## Implementation Information

Details about the model internals.

### Hardware

Gemma was trained using the latest generation of
[Tensor Processing Unit (TPU)](https://cloud.google.com/tpu/docs/intro-to-tpu) hardware (TPUv5e).

Training large language models requires significant computational power. TPUs,
designed specifically for matrix operations common in machine learning, offer
several advantages in this domain:

* Performance: TPUs are specifically designed to handle the massive computations
  involved in training LLMs. They can speed up training considerably compared to
  CPUs.
* Memory: TPUs often come with large amounts of high-bandwidth memory, allowing
  for the handling of large models and batch sizes during training. This can
  lead to better model quality.
* Scalability: TPU Pods (large clusters of TPUs) provide a scalable solution for
  handling the growing complexity of large foundation models. You can distribute
  training across multiple TPU devices for faster and more efficient processing.
* Cost-effectiveness: In many scenarios, TPUs can provide a more cost-effective
  solution for training large models compared to CPU-based infrastructure,
  especially when considering the time and resources saved due to faster
  training.
* These advantages are aligned with
  [Google's commitments to operate sustainably](https://sustainability.google/operating-sustainably/).

### Software

Training was done using [JAX](https://github.com/google/jax) and [ML Pathways](https://blog.google/technology/ai/introducing-pathways-next-generation-ai-architecture).

JAX allows researchers to take advantage of the latest generation of hardware,
including TPUs, for faster and more efficient training of large models.

ML Pathways is Google's latest effort to build artificially intelligent systems
capable of generalizing across multiple tasks. This is specially suitable for
[foundation models](https://ai.google/discover/foundation-models/), including large language models like
these ones.

Together, JAX and ML Pathways are used as described in the
[paper about the Gemini family of models](https://arxiv.org/abs/2312.11805); ""the 'single
controller' programming model of Jax and Pathways allows a single Python
process to orchestrate the entire training run, dramatically simplifying the
development workflow.""

## Evaluation

Model evaluation metrics and results.

### Benchmark Results

These models were evaluated against a large collection of different datasets and
metrics to cover different aspects of text generation:

| Benchmark                      | Metric        | 2B Params | 7B Params |
| ------------------------------ | ------------- | ----------- | --------- |
| [MMLU](https://arxiv.org/abs/2009.03300)                   | 5-shot, top-1 | 42.3        | 64.3      |
| [HellaSwag](https://arxiv.org/abs/1905.07830)         | 0-shot        |71.4        | 81.2      |
| [PIQA](https://arxiv.org/abs/1911.11641)                   | 0-shot        | 77.3        | 81.2      |
| [SocialIQA](https://arxiv.org/abs/1904.09728)      | 0-shot        | 49.7        | 51.8      |
| [BooIQ](https://arxiv.org/abs/1905.10044)                | 0-shot        | 69.4        | 83.2      |
| [WinoGrande](https://arxiv.org/abs/1907.10641)       | partial score | 65.4        | 72.3      |
| [CommonsenseQA](https://arxiv.org/abs/1811.00937) | 7-shot        | 65.3        | 71.3      |
| [OpenBookQA](https://arxiv.org/abs/1809.02789)       |               | 47.8        | 52.8      |
| [ARC-e](https://arxiv.org/abs/1911.01547)                  |               | 73.2        | 81.5      |
| [ARC-c](https://arxiv.org/abs/1911.01547)                   |               | 42.1        | 53.2      |
| [TriviaQA](https://arxiv.org/abs/1705.03551)           | 5-shot        | 53.2        | 63.4      |
| [Natural Questions](https://github.com/google-research-datasets/natural-questions)  | 5-shot        | 12.5       | 23        |
| [HumanEval](https://arxiv.org/abs/2107.03374)      | pass@1        | 22.0        | 32.3      |
| [MBPP](https://arxiv.org/abs/2108.07732)                   | 3-shot        | 29.2        | 44.4      |
| [GSM8K](https://arxiv.org/abs/2110.14168)                | maj@1         | 17.7        | 46.4      |
| [MATH](https://arxiv.org/abs/2108.07732)                   | 4-shot        | 11.8          | 24.3      |
| [AGIEval](https://arxiv.org/abs/2304.06364)           |               | 24.2        | 41.7      |
| [BIG-Bench](https://arxiv.org/abs/2206.04615)         |               | 35.2        | 55.1      |
| ------------------------------ | ------------- | ----------- | --------- |
| **Average**                    |               | **45.0**    | **56.9**  |


## Ethics and Safety

Ethics and safety evaluation approach and results.

### Evaluation Approach

Our evaluation methods include structured evaluations and internal red-teaming
testing of relevant content policies. Red-teaming was conducted by a number of
different teams, each with different goals and human evaluation metrics. These
models were evaluated against a number of different categories relevant to
ethics and safety, including:

* Text-to-Text Content Safety: Human evaluation on prompts covering safety
  policies including child sexual abuse and exploitation, harassment, violence
  and gore, and hate speech.
* Text-to-Text Representational Harms: Benchmark against relevant academic
  datasets such as [WinoBias](https://arxiv.org/abs/1804.06876) and [BBQ Dataset](https://arxiv.org/abs/2110.08193v2).
* Memorization: Automated evaluation of memorization of training data, including
  the risk of personally identifiable information exposure.
* Large-scale harm: Tests for ""dangerous capabilities,"" such as chemical,
  biological, radiological, and nuclear (CBRN) risks.

### Evaluation Results

The results of ethics and safety evaluations are within acceptable thresholds
for meeting [internal policies](https://storage.googleapis.com/gweb-uniblog-publish-prod/documents/2023_Google_AI_Principles_Progress_Update.pdf#page=11) for categories such as child
safety, content safety, representational harms, memorization, large-scale harms.
On top of robust internal evaluations, the results of well known safety
benchmarks like BBQ, BOLD, Winogender, Winobias, RealToxicity, and TruthfulQA
are shown here.

| Benchmark                      | Metric        | 2B Params   | 7B Params |
| ------------------------------ | ------------- | ----------- | --------- |
| [RealToxicity](https://arxiv.org/abs/2009.11462)        | average       | 6.86        | 7.90      |
| [BOLD](https://arxiv.org/abs/2101.11718)                   |               | 45.57       | 49.08     |
| [CrowS-Pairs](https://aclanthology.org/2020.emnlp-main.154/)        | top-1         | 45.82       | 51.33     |
| [BBQ Ambig](https://arxiv.org/abs/2110.08193v2)               | 1-shot, top-1 | 62.58       | 92.54     |
| [BBQ Disambig](https://arxiv.org/abs/2110.08193v2)            | top-1         | 54.62       | 71.99     |
| [Winogender](https://arxiv.org/abs/1804.09301)       | top-1         | 51.25       | 54.17     |
| [TruthfulQA](https://arxiv.org/abs/2109.07958)       |               | 44.84       | 31.81     |
| [Winobias 1_2](https://arxiv.org/abs/1804.06876)       |               | 56.12       | 59.09     |
| [Winobias 2_2](https://arxiv.org/abs/1804.06876)       |               | 91.10       | 92.23     |
| [Toxigen](https://arxiv.org/abs/2203.09509)             |               | 29.77       | 39.59     |
| ------------------------------ | ------------- | ----------- | --------- |


## Usage and Limitations

These models have certain limitations that users should be aware of.

### Intended Usage

Open Large Language Models (LLMs) have a wide range of applications across
various industries and domains. The following list of potential uses is not
comprehensive. The purpose of this list is to provide contextual information
about the possible use-cases that the model creators considered as part of model
training and development.

* Content Creation and Communication
  * Text Generation: These models can be used to generate creative text formats
    such as poems, scripts, code, marketing copy, and email drafts.
  * Chatbots and Conversational AI: Power conversational interfaces for customer
    service, virtual assistants, or interactive applications.
  * Text Summarization: Generate concise summaries of a text corpus, research
    papers, or reports.
* Research and Education
  * Natural Language Processing (NLP) Research: These models can serve as a
    foundation for researchers to experiment with NLP techniques, develop
    algorithms, and contribute to the advancement of the field.
  * Language Learning Tools: Support interactive language learning experiences,
    aiding in grammar correction or providing writing practice.
  * Knowledge Exploration: Assist researchers in exploring large bodies of text
    by generating summaries or answering questions about specific topics.

### Limitations

* Training Data
  * The quality and diversity of the training data significantly influence the
    model's capabilities. Biases or gaps in the training data can lead to
    limitations in the model's responses.
  * The scope of the training dataset determines the subject areas the model can
    handle effectively.
* Context and Task Complexity
  * LLMs are better at tasks that can be framed with clear prompts and
    instructions. Open-ended or highly complex tasks might be challenging.
  * A model's performance can be influenced by the amount of context provided
    (longer context generally leads to better outputs, up to a certain point).
* Language Ambiguity and Nuance
  * Natural language is inherently complex. LLMs might struggle to grasp subtle
    nuances, sarcasm, or figurative language.
* Factual Accuracy
  * LLMs generate responses based on information they learned from their
    training datasets, but they are not knowledge bases. They may generate
    incorrect or outdated factual statements.
* Common Sense
  * LLMs rely on statistical patterns in language. They might lack the ability
    to apply common sense reasoning in certain situations.

### Ethical Considerations and Risks

The development of large language models (LLMs) raises several ethical concerns.
In creating an open model, we have carefully considered the following:

* Bias and Fairness
  * LLMs trained on large-scale, real-world text data can reflect socio-cultural
    biases embedded in the training material. These models underwent careful
    scrutiny, input data pre-processing described and posterior evaluations
    reported in this card.
* Misinformation and Misuse
  * LLMs can be misused to generate text that is false, misleading, or harmful.
  * Guidelines are provided for responsible use with the model, see the
    [Responsible Generative AI Toolkit](http://ai.google.dev/gemma/responsible).
* Transparency and Accountability:
  * This model card summarizes details on the models' architecture,
    capabilities, limitations, and evaluation processes.
  * A responsibly developed open model offers the opportunity to share
    innovation by making LLM technology accessible to developers and researchers
    across the AI ecosystem.

Risks identified and mitigations:

* Perpetuation of biases: It's encouraged to perform continuous monitoring
  (using evaluation metrics, human review) and the exploration of de-biasing
  techniques during model training, fine-tuning, and other use cases.
* Generation of harmful content: Mechanisms and guidelines for content safety
  are essential. Developers are encouraged to exercise caution and implement
  appropriate content safety safeguards based on their specific product policies
  and application use cases.
* Misuse for malicious purposes: Technical limitations and developer and
  end-user education can help mitigate against malicious applications of LLMs.
  Educational resources and reporting mechanisms for users to flag misuse are
  provided. Prohibited uses of Gemma models are outlined in the
  [Gemma Prohibited Use Policy](https://ai.google.dev/gemma/prohibited_use_policy).
* Privacy violations: Models were trained on data filtered for removal of PII
  (Personally Identifiable Information). Developers are encouraged to adhere to
  privacy regulations with privacy-preserving techniques.

### Benefits

At the time of release, this family of models provides high-performance open
large language model implementations designed from the ground up for Responsible
AI development compared to similarly sized models.

Using the benchmark evaluation metrics described in this document, these models
have shown to provide superior performance to other, comparably-sized open model
alternatives.

","{""id"": ""google/gemma-7b-it"", ""author"": ""google"", ""sha"": ""9c5798d27f588501ce1e108079d2a19e4c3a2353"", ""last_modified"": ""2024-08-14 08:36:20+00:00"", ""created_at"": ""2024-02-13 01:07:30+00:00"", ""private"": false, ""gated"": ""manual"", ""disabled"": false, ""downloads"": 63932, ""downloads_all_time"": null, ""likes"": 1163, ""library_name"": ""transformers"", ""gguf"": {""total"": 8538074112, ""architecture"": ""gemma"", ""context_length"": 8192}, ""inference"": null, ""tags"": [""transformers"", ""safetensors"", ""gguf"", ""gemma"", ""text-generation"", ""conversational"", ""arxiv:2312.11805"", ""arxiv:2009.03300"", ""arxiv:1905.07830"", ""arxiv:1911.11641"", ""arxiv:1904.09728"", ""arxiv:1905.10044"", ""arxiv:1907.10641"", ""arxiv:1811.00937"", ""arxiv:1809.02789"", ""arxiv:1911.01547"", ""arxiv:1705.03551"", ""arxiv:2107.03374"", ""arxiv:2108.07732"", ""arxiv:2110.14168"", ""arxiv:2304.06364"", ""arxiv:2206.04615"", ""arxiv:1804.06876"", ""arxiv:2110.08193"", ""arxiv:2009.11462"", ""arxiv:2101.11718"", ""arxiv:1804.09301"", ""arxiv:2109.07958"", ""arxiv:2203.09509"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""license:gemma"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\nlibrary_name: transformers\nlicense: gemma\ntags: []\nwidget:\n- messages:\n  - role: user\n    content: How does the brain work?\ninference:\n  parameters:\n    max_new_tokens: 200\nextra_gated_heading: Access Gemma on Hugging Face\nextra_gated_prompt: To access Gemma on Hugging Face, you\u2019re required to review and\n  agree to Google\u2019s usage license. To do this, please ensure you\u2019re logged-in to Hugging\n  Face and click below. Requests are processed immediately.\nextra_gated_button_content: Acknowledge license\nbase_model_relation: finetune"", ""widget_data"": [{""messages"": [{""role"": ""user"", ""content"": ""How does the brain work?""}]}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'user') != (loop.index0 % 2 == 0) %}{{ raise_exception('Conversation roles must alternate user/assistant/user/assistant/...') }}{% endif %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='gemma-7b-it.gguf', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='generation_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00001-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00002-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00003-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00004-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model.safetensors.index.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)""], ""spaces"": [""allenai/WildBench"", ""eduagarcia/open_pt_llm_leaderboard"", ""Omnibus/google-gemma"", ""allenai/ZebraLogic"", ""awacke1/GPT-4o-omni-text-audio-image-video"", ""logikon/open_cot_leaderboard"", ""Sarath0x8f/Document-QA-bot"", ""Omnibus/Chatbot-Compare"", ""KBaba7/Quant"", ""gabrielchua/hey-gemma"", ""rishiraj/heygemini"", ""Hansimov/hf-llm-api"", ""awacke1/Arxiv-Paper-Search-And-QA-RAG-Pattern"", ""meval/multilingual-chatbot-arena-leaderboard"", ""not-lain/text-streaming"", ""prometheus-eval/BiGGen-Bench-Leaderboard"", ""Omnibus/InferenceClient_Chatbots"", ""Justinrune/LLaMA-Factory"", ""cot-leaderboard/open-cot-dashboard"", ""hynky/CZ-EVAL"", ""kenken999/fastapi_django_main_live"", ""WildEval/ZebraLogic"", ""Tomoniai/gemma-chat"", ""lightmate/llm-chatbot"", ""awacke1/Multimodal-Science-and-Music-Lab"", ""AamirAli123/chat_with_pdf"", ""bhaskartripathi/LLM_Quantization"", ""JohnSmith9982/ChuanhuChatGPT_Beta"", ""awacke1/ScienceBrain.AI"", ""Pavan178/pdf-chatbot"", ""totolook/Quant"", ""FallnAI/Quantize-HF-Models"", ""lone17/kotaemon-app"", ""awacke1/The_Music_Of_New_Orleans_MoE"", ""fantos/Chatbot-Compare"", ""santuchal/pdf_chat_bot"", ""mehdirab/ResumeParser"", ""amirgame197/Gemma-Chat"", ""li-qing/FIRE"", ""mariagrandury/pdf_qa"", ""ali121300/pdf_chat_bot"", ""Sambhavnoobcoder/pdf-chatbot"", ""awacke1/Arxiv-Paper-Search-QA-RAG-Streamlit-Gradio-API"", ""Alfasign/pdf-chatbot-opensource-llm"", ""saneowl/google-gemma-7b-it"", ""Nymbo/LangHub"", ""Nymbo/GPT-4o-omni-text-audio-image-video"", ""NCTCMumbai/nctc-pdf-chatbot"", ""alsaeth/Arxiv-CS-RAG-LMM"", ""ka1kuk/LLM-api"", ""med-llm-tutorial/llm-playground-demo"", ""rafaaa2105/text-generation"", ""awacke1/Arxiv-RAG-Mistal-Mixtral-MoE-n-Gemma"", ""namanroxx/pdf-chatbot"", ""sifujohn/GemmaGPT"", ""awacke1/Scholarly-Article-Document-Search-With-Memory"", ""Grafaffel/google-gemma-7b"", ""liwanx/google-gemma-7b-it"", ""sangdinhhuy/Vtech_Extract_informations_from_PDF"", ""Mrzn10/google-gemma-7b"", ""AilexGPT/Chatbot-Compare"", ""Eevee8856/google-gemma-7b-it"", ""prateekbh/product-description-maker"", ""muhammadfiaz/GemGPT"", ""orinachum/google-gemma-7b-it"", ""MAsad789565/llm-api"", ""Yahir/gemmaw"", ""awacke1/PDF-Document-QA-Chatbot"", ""saneowl/google_gemma_model_demo"", ""anubhav100rao/pdf-chatbot"", ""malvika2003/openvino_notebooks"", ""ruslanmv/convert_to_gguf"", ""Pyboxs/hf-llm-api"", ""Akshayram1/vit"", ""KABURAKURIA/chat_with_pdf"", ""supertakerin2/COMCOMGPTfree"", ""Jeff28/CipherReadPDF"", ""awacke1/AzureCosmosDBUI"", ""Arieff22/google-gemma-7b-it"", ""farmax/pdf-rag-chatbot"", ""yasserrmd/IntegrityChecker"", ""Veerammal/Pdf_chatbot_for_CBSE"", ""othertales/storybook"", ""smedia1404/sat"", ""mfoud444/research"", ""IS2Lab/S-Eval"", ""nnngoc/chatbot_bk"", ""y8z1990/google-gemma-7b-it"", ""FREE-AI/google-gemma"", ""BRJDEV/google-gemma-7b-it"", ""negismohit123/gemmaLiBot"", ""AiMan435/google-gemma-7b-it"", ""greatzy/google-gemma-7b-it"", ""MuntasirHossain/Gemma-7B-IT-Chat"", ""Nymbo/Chatbot-Compare"", ""atepper/tracklist-analysis"", ""YassoCodes/google-gemma-7b-it"", ""negismohit123/LinkedIn_Bot_Gemma_Streamlit"", ""negismohit123/test_Gradio"", ""oliverangyal/freezlet-llm""], ""safetensors"": {""parameters"": {""BF16"": 8537680896}, ""total"": 8537680896}, ""security_repo_status"": null, ""lastModified"": ""2024-08-14 08:36:20+00:00"", ""cardData"": ""base_model: google/gemma-7b\nlibrary_name: transformers\nlicense: gemma\ntags: []\nwidget:\n- messages:\n  - role: user\n    content: How does the brain work?\ninference:\n  parameters:\n    max_new_tokens: 200\nextra_gated_heading: Access Gemma on Hugging Face\nextra_gated_prompt: To access Gemma on Hugging Face, you\u2019re required to review and\n  agree to Google\u2019s usage license. To do this, please ensure you\u2019re logged-in to Hugging\n  Face and click below. Requests are processed immediately.\nextra_gated_button_content: Acknowledge license\nbase_model_relation: finetune"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""65cac0d27faf059c56a5821f"", ""modelId"": ""google/gemma-7b-it"", ""usedStorage"": 138266183581}",1,"https://huggingface.co/Intel/llava-gemma-7b, https://huggingface.co/abideen/gemma-7b-openhermes, https://huggingface.co/bartowski/gemma-7b-openhermes-exl2, https://huggingface.co/QueryloopAI/gemma-7b-openhermes, https://huggingface.co/ihopper/ko-gemma-7b-sft-dpo-v1.0, https://huggingface.co/yhkim9362/gemma-en-ko-7b-v0.1, https://huggingface.co/yhkim9362/gemma-en-ko-7b-v0.2, https://huggingface.co/PrunaAI/google-gemma-7b-it-HQQ-2bit-smashed, https://huggingface.co/PrunaAI/google-gemma-7b-it-HQQ-1bit-smashed, https://huggingface.co/PrunaAI/google-gemma-7b-it-HQQ-4bit-smashed, https://huggingface.co/shisa-ai/shisa-v1-gemma-8b, https://huggingface.co/Punthon/gemma-5-sdgs, https://huggingface.co/Punthon/gemma-5-sdgs-100rows, https://huggingface.co/Punthon/gemma-5-sdgs-200rows, https://huggingface.co/terry69/feedback_gemma, https://huggingface.co/terry69/feedback_gemma_dirty, https://huggingface.co/OpenVINO/gemma-7b-it-fp16-ov, https://huggingface.co/hyokwan/familidata_gemma7b, https://huggingface.co/hyokwan/gemma_7b_hkcode20241126, https://huggingface.co/hyokwan/kopo_gemma_7b_it_20241202, https://huggingface.co/atm77777/model77, https://huggingface.co/doubleyyh/exit-gemma-7b, https://huggingface.co/matrixportal/gemma-7b-it-GGUF",23,"https://huggingface.co/google/gemma-7b-it-GGUF, https://huggingface.co/MaziyarPanahi/gemma-7b-it-GGUF, https://huggingface.co/sayhan/gemma-7b-it-GGUF-quantized, https://huggingface.co/second-state/Gemma-7b-it-GGUF, https://huggingface.co/brittlewis12/gemma-7b-it-GGUF, https://huggingface.co/mlc-ai/gemma-7b-it-q0f16-MLC, https://huggingface.co/mlc-ai/gemma-7b-it-q4f16_2-MLC, https://huggingface.co/leliuga/gemma-7b-it-bnb-4bit, https://huggingface.co/PrunaAI/google-gemma-7b-it-AWQ-4bit-smashed, https://huggingface.co/PrunaAI/google-gemma-7b-it-bnb-4bit-smashed, https://huggingface.co/Esperanto/gemma-7b-it-kvc-fp16-onnx, https://huggingface.co/Esperanto/gemma-7b-it-kvc-AWQ-int4-onnx, https://huggingface.co/llmware/gemma-7b-it-ov, https://huggingface.co/OpenVINO/gemma-7b-it-int4-ov, https://huggingface.co/OpenVINO/gemma-7b-it-int8-ov, https://huggingface.co/mradermacher/gemma-7b-it-GGUF, https://huggingface.co/mradermacher/gemma-7b-it-i1-GGUF, https://huggingface.co/espressor/google.gemma-7b-it_W8A8_FP8, https://huggingface.co/agraj07/gemma_7b_it_quantized",19,,0,"Hansimov/hf-llm-api, KBaba7/Quant, Omnibus/Chatbot-Compare, Sarath0x8f/Document-QA-bot, allenai/WildBench, allenai/ZebraLogic, awacke1/GPT-4o-omni-text-audio-image-video, eduagarcia/open_pt_llm_leaderboard, huggingface/InferenceSupport/discussions/new?title=google/gemma-7b-it&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bgoogle%2Fgemma-7b-it%5D(%2Fgoogle%2Fgemma-7b-it)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A, logikon/open_cot_leaderboard, meval/multilingual-chatbot-arena-leaderboard, not-lain/text-streaming, prometheus-eval/BiGGen-Bench-Leaderboard",13,,
Intel/llava-gemma-7b,"---
language:
- en
license_name: intel-research-use-license
license_link: LICENSE.md
base_model: google/gemma-7b-it
tags:
- LLM
- Intel
model-index:
- name: llava-gemma-7b
  results:
  - task:
      type: Large Language Model
      name: Large Language Model
    metrics:
    - type: GQA
      name: GQA
      value: 0.472
    - type: MME Cog.
      name: MME Cog.
      value: 254
    - type: MME Per.
      name: MME Per.
      value: 895
    - type: MM-Vet
      name: MM-Vet
      value: 18.2  
    - type: POPE Acc.
      name: POPE Acc.
      value: 0.848
    - type: POPE F1
      name: POPE F1
      value: 0.829
    - type: VQAv2
      name: VQAv2
      value: 68.7
    - type: MMVP
      name: MMVP
      value: 0.327  
    - type: ScienceQA Image
      name: ScienceQA Image
      value: 0.625
library_name: transformers
pipeline_tag: image-text-to-text
---

## Model Details:  LLaVA-Gemma-7b

`llava-gemma-7b` is a large multimodal model (LMM) trained using the [LLaVA-v1.5 framework](https://arxiv.org/abs/2310.03744) with the 7-billion parameter [google/gemma-7b-it](https://huggingface.co/google/gemma-7b-it) model as language backbone and the CLIP-based vision encoder.

**_NOTE:_** As of 06/03/2024, we have not yet converted the weights of this model to the HuggingFace LLaVA format. This model card will be updated when we do.

| Model Details | Description |
| ----------- | ----------- | 
| Authors | Intel: [Musashi Hinck](https://huggingface.co/musashihinck), [Matthew Olson](https://huggingface.co/matthewlyleolson), [David Cobbley](https://huggingface.co/djcobble), [Shao-Yen Tseng](https://huggingface.co/shaoyent), [Vasudev Lal](https://huggingface.co/vasudevlal) | 
| Date | March 2024 | 
| Version | 1 | 
| Type | Large multimodal model (LMM) | 
| Paper or Other Resources | [LLaVA-Gemma: Accelerating Multimodal Foundation Models with a Compact Language Model](https://arxiv.org/abs/2404.01331) | 
| License | [Gemma](https://ai.google.dev/gemma/terms) |
| Questions or Comments | [Community Tab](https://huggingface.co/Intel/llava-gemma-7b/discussions) and [Intel DevHub Discord](https://discord.gg/rv2Gp55UJQ)|

This model card was created by [Benjamin Consolvo](https://huggingface.co/bconsolvo) and the authors listed above.

## Intended Use

| Intended Use | Description |
| ----------- | ----------- | 
| Primary intended uses | The model has been finetuned for multimodal benchmark evaluations, but can also be used as a multimodal chatbot. | 
| Primary intended users | Anyone using or evaluating multimodal models. | 
| Out-of-scope uses | This model is not intended for uses that require high levels of factuality, high stakes situations, mental health or medical applications, generating misinformation or disinformation, impersonating others, facilitating or inciting harassment or violence, any use that could lead to the violation of a human right under the UN Declaration of Human Rights. |

### How to use

Currently, using `llava-gemma` requires a [modified preprocessor](./processing_llavagemma.py). _We are currently working on modifying the `LlavaProcessor` class to streamline usage (see [PR #30030](https://github.com/huggingface/transformers/pull/30030)). Expect updates soon._

For current usage, see [`usage.py`](./usage.py) or the following code block:

```python
import requests
from PIL import Image
from transformers import (
  LlavaForConditionalGeneration,
  AutoTokenizer,
  CLIPImageProcessor
)
from processing_llavagemma import LlavaGemmaProcessor # This is in this repo

checkpoint = ""Intel/llava-gemma-7b""

# Load model
model = LlavaForConditionalGeneration.from_pretrained(checkpoint)
processor = LlavaGemmaProcessor(
    tokenizer=AutoTokenizer.from_pretrained(checkpoint),
    image_processor=CLIPImageProcessor.from_pretrained(checkpoint)
)

# Prepare inputs
# Use gemma chat template
prompt = processor.tokenizer.apply_chat_template(
    [{'role': 'user', 'content': ""<image>\nWhat's the content of the image?""}],
    tokenize=False,
    add_generation_prompt=True
)
url = ""https://www.ilankelman.org/stopsigns/australia.jpg""
image = Image.open(requests.get(url, stream=True).raw)
inputs = processor(text=prompt, images=image, return_tensors=""pt"")

# Generate
generate_ids = model.generate(**inputs, max_length=30)
output = processor.batch_decode(generate_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]
print(output)
```

For straightforward use as a chatbot (without images), you can modify the last portion of code to the following:

```python
# Prepare inputs
# Use gemma chat template
prompt = processor.tokenizer.apply_chat_template(
    [{'role': 'user', 'content': ""Summarize the following paragraph? In this paper, we introduced LLaVA-Gemma, a compact vision-language model leveraging the Gemma Large Language Model in two variants, Gemma-2B and Gemma-7B. Our work provides a unique opportunity for researchers to explore the trade-offs between computational efficiency and multimodal understanding in small-scale models. The availability of both variants allows for a comparative analysis that sheds light on how model size impacts performance in various tasks. Our evaluations demonstrate the versatility and effectiveness of LLaVA-Gemma across a range of datasets, highlighting its potential as a benchmark for future research in small-scale vision-language models. With these models, future practitioners can optimize the performance of small-scale multimodal models more directly.""}],
    tokenize=False,
    add_generation_prompt=True
)
# url = ""https://www.ilankelman.org/stopsigns/australia.jpg""
# image = Image.open(requests.get(url, stream=True).raw)
inputs = processor(text=prompt, images=None, return_tensors=""pt"")

# Generate
generate_ids = model.generate(**inputs, max_length=300)
output = processor.batch_decode(generate_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]
print(output)
```

## Factors

| Factors | Description | 
| ----------- | ----------- | 
| Groups | - | 
| Instrumentation | - |
| Environment | Trained for 4 hours on 8 Intel Gaudi 2 AI accelerators. |
| Card Prompts | Model training and deployment on alternate hardware and software will change model performance |

## Metrics

| Metrics | Description | 
| ----------- | ----------- | 
| Model performance measures | We evaluate the LlaVA-Gemma models on a similar collection of benchmarks to other LMM works: GQA; MME; MM-Vet; POPE (accuracy and F1); VQAv2; MMVP; the image subset of ScienceQA. Our experiments provide insights into the efficacy of various design choices within the LLaVA framework. |
| Decision thresholds | - | 
| Approaches to uncertainty and variability | - | 

## Training Data

The model was trained using the LLaVA-v1.5 data mixture. This is listed as follows:

- 558K filtered image-text pairs from LAION/CC/SBU, captioned by BLIP.
- 158K GPT-generated multimodal instruction-following data.
- 450K academic-task-oriented VQA data mixture.
- 40K ShareGPT data.

## Quantitative Analyses

Performance of LLaVA-Gemma models across seven benchmarks. Highlighted box indicates strongest performance amongst LLaVA-Gemma models. Bottom two rows show self-reported performance of Llava Phi-2 and LLaVA-v1.5 respectively. The bolded **gemma-7b-it** is the current model used here in this model card.

| LM Backbone | Vision Model | Pretrained Connector | GQA   | MME cognition | MME perception | MM-Vet | POPE accuracy | POPE F1 | VQAv2 | ScienceQA Image | MMVP  |
| ----------- | ------------ | -------------------- | ----- | ------------- | -------------- | ------ | ------------- | ------- | ----- | --------------- | ----- |
| gemma-2b-it | CLIP         | Yes                  | 0.531 | 236           | 1130           | 17.7   | 0.850         |<mark>0.839</mark>| 70.65 | 0.564  | 0.287 |
| gemma-2b-it | CLIP         | No                   | 0.481 | 248           | 935            | 13.1   | 0.784         | 0.762   | 61.74 | 0.549           | 0.180 |
| gemma-2b-it | DinoV2       | Yes                  |<mark>0.587</mark>| 307| <mark>1133</mark>   |<mark>19.1</mark>| <mark>0.853</mark>   | 0.838   |<mark>71.37</mark>| 0.555         | 0.227 |
| gemma-2b-it | DinoV2       | No                   | 0.501 | <mark>309</mark>| 959          | 14.5   | 0.793         | 0.772   | 61.65 | 0.568           | 0.180 |
|             |              |                      |       |               |                |        |               |         |       |                 |       |
| **gemma-7b-it** | CLIP         | Yes                  | 0.472 | 253           | 895            | 18.2   | 0.848         | 0.829   | 68.7  | 0.625           | <mark>0.327</mark> |
| gemma-7b-it | CLIP         | No                   | 0.472 | 278           | 857            | 19.1   | 0.782         | 0.734   | 65.1 | <mark>0.636</mark>           | 0.240 |
| gemma-7b-it | DinoV2       | Yes                  | 0.519 | 257           | 1021           | 14.3   | 0.794         | 0.762   | 65.2 | 0.628           | <mark>0.327</mark> |
| gemma-7b-it | DinoV2       | No                   | 0.459 | 226           | 771            | 12.2   | 0.693         | 0.567   | 57.4 | 0.598           | 0.267 |
|             |              |                      |       |               |                |        |               |         |       |                 |       |
| Phi-2b      | CLIP         | Yes                  | -     | -             | 1335           | 28.9   | -             | 0.850   | 71.4  | 0.684           | - |
| Llama-2-7b  | CLIP         | Yes                  | 0.620 | 348           | 1511           | 30.6   | 0.850         | 0.859   | 78.5  | 0.704           | 46.1 |

## Ethical Considerations

Intel is committed to respecting human rights and avoiding causing or contributing to adverse impacts on human rights. See [Intel’s Global Human Rights Principles](https://www.intel.com/content/dam/www/central-libraries/us/en/documents/policy-human-rights.pdf). Intel’s products and software are intended only to be used in applications that do not cause or contribute to adverse impacts on human rights.

| Ethical Considerations | Description | 
| ----------- | ----------- | 
| Data | The model was trained using the LLaVA-v1.5 data mixture as described above. |
| Human life | The model is not intended to inform decisions central to human life or flourishing. | 
| Mitigations | No additional risk mitigation strategies were considered during model development. |
| Risks and harms | This model has not been assessed for harm or biases, and should not be used for sensitive applications where it may cause harm. |
| Use cases | - | 

## Caveats and Recommendations

Users (both direct and downstream) should be made aware of the risks, biases and limitations of the model.

## Citation details
```bibtex
@misc{hinck2024llavagemma,
      title={LLaVA-Gemma: Accelerating Multimodal Foundation Models with a Compact Language Model}, 
      author={Musashi Hinck and Matthew L. Olson and David Cobbley and Shao-Yen Tseng and Vasudev Lal},
      year={2024},
      eprint={2404.01331},
      url={https://arxiv.org/abs/2404.01331},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
```","{""id"": ""Intel/llava-gemma-7b"", ""author"": ""Intel"", ""sha"": ""5d5baaf95551c35512c3844e66b166324511b468"", ""last_modified"": ""2024-06-04 22:17:14+00:00"", ""created_at"": ""2024-03-26 22:39:27+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 189, ""downloads_all_time"": null, ""likes"": 11, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""safetensors"", ""optimum_habana"", ""llava_gemma"", ""text-generation"", ""LLM"", ""Intel"", ""image-text-to-text"", ""conversational"", ""en"", ""arxiv:2310.03744"", ""arxiv:2404.01331"", ""base_model:google/gemma-7b-it"", ""base_model:finetune:google/gemma-7b-it"", ""model-index"", ""autotrain_compatible"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""image-text-to-text"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b-it\nlanguage:\n- en\nlibrary_name: transformers\nlicense_name: intel-research-use-license\nlicense_link: LICENSE.md\npipeline_tag: image-text-to-text\ntags:\n- LLM\n- Intel"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": [{""name"": ""llava-gemma-7b"", ""results"": [{""task"": {""type"": ""Large Language Model"", ""name"": ""Large Language Model""}, ""metrics"": [{""type"": ""GQA"", ""name"": ""GQA"", ""value"": 0.472, ""verified"": false}, {""type"": ""MME Cog."", ""name"": ""MME Cog."", ""value"": 254, ""verified"": false}, {""type"": ""MME Per."", ""name"": ""MME Per."", ""value"": 895, ""verified"": false}, {""type"": ""MM-Vet"", ""name"": ""MM-Vet"", ""value"": 18.2, ""verified"": false}, {""type"": ""POPE Acc."", ""name"": ""POPE Acc."", ""value"": 0.848, ""verified"": false}, {""type"": ""POPE F1"", ""name"": ""POPE F1"", ""value"": 0.829, ""verified"": false}, {""type"": ""VQAv2"", ""name"": ""VQAv2"", ""value"": 68.7, ""verified"": false}, {""type"": ""MMVP"", ""name"": ""MMVP"", ""value"": 0.327, ""verified"": false}, {""type"": ""ScienceQA Image"", ""name"": ""ScienceQA Image"", ""value"": 0.625, ""verified"": false}]}]}], ""config"": {""architectures"": [""LlavaGemmaForCausalLM""], ""model_type"": ""llava_gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'user') != (loop.index0 % 2 == 0) %}{{ raise_exception('Conversation roles must alternate user/assistant/user/assistant/...') }}{% endif %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<unk>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": null}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='LICENSE.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='gaudi_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='generation_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00001-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00002-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00003-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00004-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model.safetensors.index.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model_state_dict.bin', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='preprocessor_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": {""parameters"": {""BF16"": 9640209408}, ""total"": 9640209408}, ""security_repo_status"": null, ""lastModified"": ""2024-06-04 22:17:14+00:00"", ""cardData"": ""base_model: google/gemma-7b-it\nlanguage:\n- en\nlibrary_name: transformers\nlicense_name: intel-research-use-license\nlicense_link: LICENSE.md\npipeline_tag: image-text-to-text\ntags:\n- LLM\n- Intel"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": null}, ""_id"": ""66034e9f79ed63106e72c53d"", ""modelId"": ""Intel/llava-gemma-7b"", ""usedStorage"": 37599618581}",2,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=Intel/llava-gemma-7b&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5BIntel%2Fllava-gemma-7b%5D(%2FIntel%2Fllava-gemma-7b)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
abideen/gemma-7b-openhermes,"---
license: cc-by-nc-4.0
base_model: google/gemma-7b-it
tags:
- generated_from_trainer
- axolotl
- gemma
- instruct
- finetune
- chatml
- gpt4
- synthetic data
- distillation
model-index:
- name: gemma-7b-openhermes
  results: []
datasets:
- mlabonne/chatml-OpenHermes2.5-dpo-binarized-alpha
language:
- en
library_name: transformers
pipeline_tag: text-generation
---
<!-- This model card has been generated automatically according to the information the Trainer had access to. You
should probably proofread and complete it, then remove this comment. -->

# gemma-7b-openhermes



![image/jpeg](https://cdn-uploads.huggingface.co/production/uploads/64e380b2e12618b261fa6ba0/mh-NUO_aNbQpD_NAuFv7g.jpeg)

gemma-7b-openhermes is a variant of the Gemma 7B language model, which has been further fine-tuned on the OpenHermes-2.5 preference dataset 
using QLoRA.


* [google/gemma-7b-it](https://huggingface.co/google/gemma-7b-it)
* [mlabonne/chatml-OpenHermes2.5-dpo-binarized-alpha](https://huggingface.co/datasets/mlabonne/chatml-OpenHermes2.5-dpo-binarized-alpha)

</details><br>

## Usage

### Chat Template

The instruction-tuned models use a chat template that must be adhered to for conversational use.
The easiest way to apply it is using the tokenizer's built-in chat template, as shown in the following snippet.

Let's load the model and apply the chat template to a conversation. In this example, we'll start with a single user interaction:

```py
from transformers import AutoTokenizer, AutoModelForCausalLM
import transformers
import torch

model_id = ""abideen/gemma-7b-openhermes""
dtype = torch.bfloat16

tokenizer = AutoTokenizer.from_pretrained(model_id)
model = AutoModelForCausalLM.from_pretrained(
    model_id,
    device_map=""cuda"",
    torch_dtype=dtype,
)

chat = [{ ""role"": ""user"", ""content"": ""What is a Language Model?"" }]
prompt = tokenizer.apply_chat_template(chat, tokenize=False, add_generation_prompt=True)
```

After the prompt is ready, generation can be performed like this:

```py
inputs = tokenizer.encode(prompt, add_special_tokens=True, return_tensors=""pt"")
outputs = model.generate(input_ids=inputs.to(model.device), max_new_tokens=250)
print(tokenizer.decode(outputs[0]))
```

### Inputs and outputs

*   **Input:** Text string, such as a question, a prompt, or a document to be
    summarized.
*   **Output:** Generated English-language text in response to the input, such
    as an answer to a question, or a summary of a document.

## 🏆 Evaluation results

# Nous Benchmark

Agieval

| Task                                      | Version | Metric | Value |   | StdErr |
|-------------------------------------------|---------|--------|-------|---|---------|
| agieval\_aqua\_rat                        | 0       | acc    | 24.80 | _ | 2.72    |
| agieval\_aqua\_rat                        | 0       | acc\_norm | 24.80 | _ | 2.72    |
| agieval\_logiqa\_en                      | 0       | acc    | 20.89 | _ | 1.59    |
| agieval\_logiqa\_en                      | 0       | acc\_norm | 23.35 | _ | 1.66    |
| agieval\_lsat\_ar                        | 0       | acc    | 21.74 | _ | 2.73    |
| agieval\_lsat\_ar                        | 0       | acc\_norm | 20.43 | _ | 2.66    |
| agieval\_lsat\_lr                        | 0       | acc    | 15.49 | _ | 1.60    |
| agieval\_lsat\_lr                        | 0       | acc\_norm | 20.59 | _ | 1.79    |
| agieval\_lsat\_rc                        | 0       | acc    | 17.10 | _ | 2.30    |
| agieval\_lsat\_rc                        | 0       | acc\_norm | 17.84 | _ | 2.34    |
| agieval\_sat\_en                         | 0       | acc    | 29.61 | _ | 3.19    |
| agieval\_sat\_en                         | 0       | acc\_norm | 29.61 | _ | 3.19    |
| agieval\_sat\_en\_without\_passage       | 0       | acc    | 26.21 | _ | 3.07    |
| agieval\_sat\_en\_without\_passage       | 0       | acc\_norm | 24.76 | _ | 3.01    |
| agieval\_sat\_math                        | 0       | acc    | 22.73 | _ | 2.83    |
| agieval\_sat\_math                        | 0       | acc\_norm | 22.73 | _ | 2.83    |
Average: 22.29

GPT4ALL

| Task          | Version | Metric     | Value   |   | StdErr      |
|---------------|---------|------------|---------|---|-------------|
| arc_challenge | 0       | acc        | 20.14   | _ | 1.17        |
| arc_challenge | 0       | acc_norm   | 22.87   | _ | 1.23        |
| arc_easy      | 0       | acc        | 32.37   | _ | 0.96        |
| arc_easy      | 0       | acc_norm   | 31.61   | _ | 0.95        |
| boolq         | 1       | acc        | 45.78   | _ | 0.87        |
| hellaswag     | 0       | acc        | 32.03   | _ | 0.47        |
| hellaswag     | 0       | acc_norm   | 35.18   | _ | 0.48        |
| openbookqa    | 0       | acc        | 17.8    | _ | 1.71        |
| openbookqa    | 0       | acc_norm   | 29.8    | _ | 2.05        |
| piqa          | 0       | acc        | 54.46   | _ | 1.16        |
| piqa          | 0       | acc_norm   | 54.57   | _ | 1.16        |
| winogrande    | 0       | acc        | 48.30   | _ | 1.40        |
Average: 32.00


TruthfulQA

| Task                             | Version | Metric | Value | Std Err |
|----------------------------------|---------|--------|--------|----------|
| truthfulqa\_mc                   | 1       | mc1    | 30.11  | 1.61    |
| truthfulqa\_mc                   | 1       | mc2    | 47.69  | 1.61    |
Average: 38.90


# Openllm Benchmark

|    Task     |Version| Metric |Value|   |Stderr|
|-------------|------:|--------|----:|---|-----:|
|arc_challenge|      0|acc     |48.12|±  |  1.46|
|             |       |acc_norm|51.27|±  |  1.46|
|hellaswag    |      0|acc     |55.4 |±  |  0.49|
|             |       |acc_norm|71.92|±  |  0.42|
|gsm8k        |      0|acc     |29.87|±  |  1.2 |
|winogrande   |      0|acc     |68.19|±  |  1.3 |
|mmlu         |      0|acc     |53.62  |±|  0.6 |

Average: 73.5%

### TruthfulQA
|    Task     |Version|Metric|Value|   |Stderr|
|-------------|------:|------|----:|---|-----:|
|truthfulqa_mc|      1|mc1   |30.23|±  |  1.60|
|             |       |mc2   |47.17|±  |  1.63|



### Training hyperparameters

The following hyperparameters were used during training:
- learning_rate: 5e-07
- train_batch_size: 1
- eval_batch_size: 8
- seed: 42
- gradient_accumulation_steps: 8
- total_train_batch_size: 8
- optimizer: Adam with betas=(0.9,0.999) and epsilon=1e-08
- lr_scheduler_type: cosine
- lr_scheduler_warmup_steps: 100
- training_steps: 1000


### 📝 Axolotl Configuration

```yaml
base_model: google/gemma-7b-it
model_type: GemmaForCausalLM
tokenizer_type: GemmaTokenizer
trust_remote_code: true

load_in_8bit: false
load_in_4bit: true
strict: false

rl: dpo
chat_template: chatml
datasets:
  - path: mlabonne/chatml-OpenHermes2.5-dpo-binarized-alpha
    split: train
    type: chatml.intel
dataset_prepared_path:
val_set_size: 0.01
output_dir: ./out

adapter: qlora
lora_model_dir:

sequence_len: 1800
sample_packing: false
pad_to_sequence_len: false

lora_r: 16
lora_alpha: 16
lora_dropout: 0.05
lora_target_linear: true
lora_fan_in_fan_out:
lora_target_modules:

wandb_project: gemma
wandb_entity:
wandb_watch:
wandb_name:
wandb_log_model:

gradient_accumulation_steps: 8
micro_batch_size: 1
num_epochs: 1
optimizer: paged_adamw_32bit
lr_scheduler: cosine
learning_rate: 5e-7

train_on_inputs: false
group_by_length: false
bf16: true
fp16: false
tf32: true

gradient_checkpointing: true
early_stopping_patience:
resume_from_checkpoint:
local_rank:
logging_steps: 1
xformers_attention:
flash_attention: false

warmup_steps: 100
evals_per_epoch: 1
eval_table_size:
eval_table_max_new_tokens: 128
save_steps: 1000
max_steps: 1000
debug:
deepspeed:
weight_decay: 0.0
fsdp:
fsdp_config:
special_tokens:
```


### Framework versions

- Transformers 4.39.0.dev0
- Pytorch 2.1.2+cu118
- Datasets 2.17.0
- Tokenizers 0.15.0
- axolotl: 0.4.0

[<img src=""https://raw.githubusercontent.com/OpenAccess-AI-Collective/axolotl/main/image/axolotl-badge-web.png"" alt=""Built with Axolotl"" width=""200"" height=""32""/>](https://github.com/OpenAccess-AI-Collective/axolotl)","{""id"": ""abideen/gemma-7b-openhermes"", ""author"": ""abideen"", ""sha"": ""df84319cbf6f07d98d557c7e3cc2a6197fc7bab0"", ""last_modified"": ""2024-02-25 19:30:03+00:00"", ""created_at"": ""2024-02-21 23:03:54+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 9, ""downloads_all_time"": null, ""likes"": 11, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""axolotl"", ""instruct"", ""finetune"", ""chatml"", ""gpt4"", ""synthetic data"", ""distillation"", ""conversational"", ""en"", ""dataset:mlabonne/chatml-OpenHermes2.5-dpo-binarized-alpha"", ""base_model:google/gemma-7b-it"", ""base_model:finetune:google/gemma-7b-it"", ""license:cc-by-nc-4.0"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b-it\ndatasets:\n- mlabonne/chatml-OpenHermes2.5-dpo-binarized-alpha\nlanguage:\n- en\nlibrary_name: transformers\nlicense: cc-by-nc-4.0\npipeline_tag: text-generation\ntags:\n- generated_from_trainer\n- axolotl\n- gemma\n- instruct\n- finetune\n- chatml\n- gpt4\n- synthetic data\n- distillation\nmodel-index:\n- name: gemma-7b-openhermes\n  results: []"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": [{""name"": ""gemma-7b-openhermes"", ""results"": []}], ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'user') != (loop.index0 % 2 == 0) %}{{ raise_exception('Conversation roles must alternate user/assistant/user/assistant/...') }}{% endif %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='generation_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00001-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00002-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00003-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00004-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model.safetensors.index.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": {""parameters"": {""F16"": 8537680896}, ""total"": 8537680896}, ""security_repo_status"": null, ""lastModified"": ""2024-02-25 19:30:03+00:00"", ""cardData"": ""base_model: google/gemma-7b-it\ndatasets:\n- mlabonne/chatml-OpenHermes2.5-dpo-binarized-alpha\nlanguage:\n- en\nlibrary_name: transformers\nlicense: cc-by-nc-4.0\npipeline_tag: text-generation\ntags:\n- generated_from_trainer\n- axolotl\n- gemma\n- instruct\n- finetune\n- chatml\n- gpt4\n- synthetic data\n- distillation\nmodel-index:\n- name: gemma-7b-openhermes\n  results: []"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""65d6815ac57d1c140e318f55"", ""modelId"": ""abideen/gemma-7b-openhermes"", ""usedStorage"": 17097110144}",2,,0,"https://huggingface.co/mradermacher/gemma-7b-openhermes-GGUF, https://huggingface.co/mradermacher/gemma-7b-openhermes-i1-GGUF",2,,0,huggingface/InferenceSupport/discussions/new?title=abideen/gemma-7b-openhermes&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Babideen%2Fgemma-7b-openhermes%5D(%2Fabideen%2Fgemma-7b-openhermes)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
bartowski/gemma-7b-openhermes-exl2,"---
license: cc-by-nc-4.0
base_model: google/gemma-7b-it
tags:
- generated_from_trainer
- axolotl
- gemma
- instruct
- finetune
- chatml
- gpt4
- synthetic data
- distillation
model-index:
- name: gemma-7b-openhermes
  results: []
datasets:
- mlabonne/chatml-OpenHermes2.5-dpo-binarized-alpha
language:
- en
library_name: transformers
pipeline_tag: text-generation
quantized_by: bartowski
---

## Exllama v2 Quantizations of gemma-7b-openhermes

Using <a href=""https://github.com/turboderp/exllamav2/releases/tag/v0.0.13"">turboderp's ExLlamaV2 v0.0.13</a> for quantization.

<b>The ""main"" branch only contains the measurement.json, download one of the other branches for the model (see below)</b>

Each branch contains an individual bits per weight, with the main one containing only the meaurement.json for further conversions.

Original model: https://huggingface.co/abideen/gemma-7b-openhermes

No GQA - VRAM requirements will be higher

| Branch                                                         | Bits | lm_head bits | Size (4k) | Size (16k) | Description |
| -------------------------------------------------------------- | ---- | ------------ | --------- | ---------- | ----------- |
| [8_0](https://huggingface.co/bartowski/gemma-7b-openhermes-exl2/tree/8_0) | 8.0 | 8.0 | 14.0 GB | 19.4 GB | Maximum quality that ExLlamaV2 can produce, near unquantized performance. |
| [6_5](https://huggingface.co/bartowski/gemma-7b-openhermes-exl2/tree/6_5) | 6.5  | 8.0 | 12.5 GB | 17.9 GB | Near unquantized performance at vastly reduced size, **recommended**. |
| [5_0](https://huggingface.co/bartowski/gemma-7b-openhermes-exl2/tree/5_0) | 5.0  | 6.0 | 10.9 GB | 16.3 GB | Slightly lower quality vs 6.5, great for 12GB cards with 4k context. |
| [4_25](https://huggingface.co/bartowski/gemma-7b-openhermes-exl2/tree/4_25) | 4.25 | 6.0 | 10.2 GB | 15.7 GB | GPTQ equivalent bits per weight, ideal for 16GB cards at 16k context |
| [3_5](https://huggingface.co/bartowski/gemma-7b-openhermes-exl2/tree/3_5) | 3.5 | 6.0 | 9.5 GB | 14.9 GB | Lower quality, not recommended. |

## Download instructions

With git:

```shell
git clone --single-branch --branch 6_5 https://huggingface.co/bartowski/gemma-7b-openhermes-exl2 gemma-7b-openhermes-exl2-6_5
```

With huggingface hub (credit to TheBloke for instructions):

```shell
pip3 install huggingface-hub
```

To download the `main` (only useful if you only care about measurement.json) branch to a folder called `gemma-7b-openhermes-exl2`:

```shell
mkdir gemma-7b-openhermes-exl2
huggingface-cli download bartowski/gemma-7b-openhermes-exl2 --local-dir gemma-7b-openhermes-exl2 --local-dir-use-symlinks False
```

To download from a different branch, add the `--revision` parameter:

Linux:

```shell
mkdir gemma-7b-openhermes-exl2-6_5
huggingface-cli download bartowski/gemma-7b-openhermes-exl2 --revision 6_5 --local-dir gemma-7b-openhermes-exl2-6_5 --local-dir-use-symlinks False
```

Windows (which apparently doesn't like _ in folders sometimes?):

```shell
mkdir gemma-7b-openhermes-exl2-6.5
huggingface-cli download bartowski/gemma-7b-openhermes-exl2 --revision 6_5 --local-dir gemma-7b-openhermes-exl2-6.5 --local-dir-use-symlinks False
```

Want to support my work? Visit my ko-fi page here: https://ko-fi.com/bartowski","{""id"": ""bartowski/gemma-7b-openhermes-exl2"", ""author"": ""bartowski"", ""sha"": ""71ef6a3c82ec60773ff2f15af85c0e94e088b719"", ""last_modified"": ""2024-02-26 01:30:16+00:00"", ""created_at"": ""2024-02-23 01:41:22+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 4, ""downloads_all_time"": null, ""likes"": 4, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""generated_from_trainer"", ""axolotl"", ""gemma"", ""instruct"", ""finetune"", ""chatml"", ""gpt4"", ""synthetic data"", ""distillation"", ""text-generation"", ""en"", ""dataset:mlabonne/chatml-OpenHermes2.5-dpo-binarized-alpha"", ""base_model:google/gemma-7b-it"", ""base_model:finetune:google/gemma-7b-it"", ""license:cc-by-nc-4.0"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b-it\ndatasets:\n- mlabonne/chatml-OpenHermes2.5-dpo-binarized-alpha\nlanguage:\n- en\nlibrary_name: transformers\nlicense: cc-by-nc-4.0\npipeline_tag: text-generation\ntags:\n- generated_from_trainer\n- axolotl\n- gemma\n- instruct\n- finetune\n- chatml\n- gpt4\n- synthetic data\n- distillation\nquantized_by: bartowski\nmodel-index:\n- name: gemma-7b-openhermes\n  results: []"", ""widget_data"": [{""text"": ""My name is Julien and I like to""}, {""text"": ""I like traveling by train because""}, {""text"": ""Paris is an amazing place to visit,""}, {""text"": ""Once upon a time,""}], ""model_index"": [{""name"": ""gemma-7b-openhermes"", ""results"": []}], ""config"": null, ""transformers_info"": {""auto_model"": ""AutoModel"", ""custom_class"": null, ""pipeline_tag"": null, ""processor"": null}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='measurement.json', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2024-02-26 01:30:16+00:00"", ""cardData"": ""base_model: google/gemma-7b-it\ndatasets:\n- mlabonne/chatml-OpenHermes2.5-dpo-binarized-alpha\nlanguage:\n- en\nlibrary_name: transformers\nlicense: cc-by-nc-4.0\npipeline_tag: text-generation\ntags:\n- generated_from_trainer\n- axolotl\n- gemma\n- instruct\n- finetune\n- chatml\n- gpt4\n- synthetic data\n- distillation\nquantized_by: bartowski\nmodel-index:\n- name: gemma-7b-openhermes\n  results: []"", ""transformersInfo"": {""auto_model"": ""AutoModel"", ""custom_class"": null, ""pipeline_tag"": null, ""processor"": null}, ""_id"": ""65d7f7c2d532b55d200ea742"", ""modelId"": ""bartowski/gemma-7b-openhermes-exl2"", ""usedStorage"": 37738210768}",2,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=bartowski/gemma-7b-openhermes-exl2&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bbartowski%2Fgemma-7b-openhermes-exl2%5D(%2Fbartowski%2Fgemma-7b-openhermes-exl2)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
QueryloopAI/gemma-7b-openhermes,"---
license: cc-by-nc-4.0
base_model: google/gemma-7b-it
tags:
- generated_from_trainer
- axolotl
- gemma
- instruct
- finetune
- chatml
- gpt4
- synthetic data
- distillation
model-index:
- name: gemma-7b-openhermes
  results: []
datasets:
- mlabonne/chatml-OpenHermes2.5-dpo-binarized-alpha
language:
- en
library_name: transformers
pipeline_tag: text-generation
---
<!-- This model card has been generated automatically according to the information the Trainer had access to. You
should probably proofread and complete it, then remove this comment. -->

# gemma-7b-openhermes



![image/jpeg](https://cdn-uploads.huggingface.co/production/uploads/64e380b2e12618b261fa6ba0/mh-NUO_aNbQpD_NAuFv7g.jpeg)

gemma-7b-openhermes is a variant of the Gemma 7B language model, which has been further fine-tuned on the OpenHermes-2.5 preference dataset 
using QLoRA.


* [google/gemma-7b-it](https://huggingface.co/google/gemma-7b-it)
* [mlabonne/chatml-OpenHermes2.5-dpo-binarized-alpha](https://huggingface.co/datasets/mlabonne/chatml-OpenHermes2.5-dpo-binarized-alpha)

</details><br>

## Usage

### Chat Template

The instruction-tuned models use a chat template that must be adhered to for conversational use.
The easiest way to apply it is using the tokenizer's built-in chat template, as shown in the following snippet.

Let's load the model and apply the chat template to a conversation. In this example, we'll start with a single user interaction:

```py
from transformers import AutoTokenizer, AutoModelForCausalLM
import transformers
import torch

model_id = ""abideen/gemma-7b-openhermes""
dtype = torch.bfloat16

tokenizer = AutoTokenizer.from_pretrained(model_id)
model = AutoModelForCausalLM.from_pretrained(
    model_id,
    device_map=""cuda"",
    torch_dtype=dtype,
)

chat = [{ ""role"": ""user"", ""content"": ""What is a Language Model?"" }]
prompt = tokenizer.apply_chat_template(chat, tokenize=False, add_generation_prompt=True)
```

After the prompt is ready, generation can be performed like this:

```py
inputs = tokenizer.encode(prompt, add_special_tokens=True, return_tensors=""pt"")
outputs = model.generate(input_ids=inputs.to(model.device), max_new_tokens=250)
print(tokenizer.decode(outputs[0]))
```

### Inputs and outputs

*   **Input:** Text string, such as a question, a prompt, or a document to be
    summarized.
*   **Output:** Generated English-language text in response to the input, such
    as an answer to a question, or a summary of a document.

## 🏆 Evaluation results

# Nous Benchmark

Agieval

| Task                                      | Version | Metric | Value |   | StdErr |
|-------------------------------------------|---------|--------|-------|---|---------|
| agieval\_aqua\_rat                        | 0       | acc    | 24.80 | _ | 2.72    |
| agieval\_aqua\_rat                        | 0       | acc\_norm | 24.80 | _ | 2.72    |
| agieval\_logiqa\_en                      | 0       | acc    | 20.89 | _ | 1.59    |
| agieval\_logiqa\_en                      | 0       | acc\_norm | 23.35 | _ | 1.66    |
| agieval\_lsat\_ar                        | 0       | acc    | 21.74 | _ | 2.73    |
| agieval\_lsat\_ar                        | 0       | acc\_norm | 20.43 | _ | 2.66    |
| agieval\_lsat\_lr                        | 0       | acc    | 15.49 | _ | 1.60    |
| agieval\_lsat\_lr                        | 0       | acc\_norm | 20.59 | _ | 1.79    |
| agieval\_lsat\_rc                        | 0       | acc    | 17.10 | _ | 2.30    |
| agieval\_lsat\_rc                        | 0       | acc\_norm | 17.84 | _ | 2.34    |
| agieval\_sat\_en                         | 0       | acc    | 29.61 | _ | 3.19    |
| agieval\_sat\_en                         | 0       | acc\_norm | 29.61 | _ | 3.19    |
| agieval\_sat\_en\_without\_passage       | 0       | acc    | 26.21 | _ | 3.07    |
| agieval\_sat\_en\_without\_passage       | 0       | acc\_norm | 24.76 | _ | 3.01    |
| agieval\_sat\_math                        | 0       | acc    | 22.73 | _ | 2.83    |
| agieval\_sat\_math                        | 0       | acc\_norm | 22.73 | _ | 2.83    |
Average: 22.29

GPT4ALL

| Task          | Version | Metric     | Value   |   | StdErr      |
|---------------|---------|------------|---------|---|-------------|
| arc_challenge | 0       | acc        | 20.14   | _ | 1.17        |
| arc_challenge | 0       | acc_norm   | 22.87   | _ | 1.23        |
| arc_easy      | 0       | acc        | 32.37   | _ | 0.96        |
| arc_easy      | 0       | acc_norm   | 31.61   | _ | 0.95        |
| boolq         | 1       | acc        | 45.78   | _ | 0.87        |
| hellaswag     | 0       | acc        | 32.03   | _ | 0.47        |
| hellaswag     | 0       | acc_norm   | 35.18   | _ | 0.48        |
| openbookqa    | 0       | acc        | 17.8    | _ | 1.71        |
| openbookqa    | 0       | acc_norm   | 29.8    | _ | 2.05        |
| piqa          | 0       | acc        | 54.46   | _ | 1.16        |
| piqa          | 0       | acc_norm   | 54.57   | _ | 1.16        |
| winogrande    | 0       | acc        | 48.30   | _ | 1.40        |
Average: 32.00


TruthfulQA

| Task                             | Version | Metric | Value | Std Err |
|----------------------------------|---------|--------|--------|----------|
| truthfulqa\_mc                   | 1       | mc1    | 30.11  | 1.61    |
| truthfulqa\_mc                   | 1       | mc2    | 47.69  | 1.61    |
Average: 38.90


# Openllm Benchmark

|    Task     |Version| Metric |Value|   |Stderr|
|-------------|------:|--------|----:|---|-----:|
|arc_challenge|      0|acc     |48.12|±  |  1.46|
|             |       |acc_norm|51.27|±  |  1.46|
|hellaswag    |      0|acc     |55.4 |±  |  0.49|
|             |       |acc_norm|71.92|±  |  0.42|
|gsm8k        |      0|acc     |29.87|±  |  1.2 |
|winogrande   |      0|acc     |68.19|±  |  1.3 |
|mmlu         |      0|acc     |53.62  |±|  0.6 |

Average: 73.5%

### TruthfulQA
|    Task     |Version|Metric|Value|   |Stderr|
|-------------|------:|------|----:|---|-----:|
|truthfulqa_mc|      1|mc1   |30.23|±  |  1.60|
|             |       |mc2   |47.17|±  |  1.63|



### Training hyperparameters

The following hyperparameters were used during training:
- learning_rate: 5e-07
- train_batch_size: 1
- eval_batch_size: 8
- seed: 42
- gradient_accumulation_steps: 8
- total_train_batch_size: 8
- optimizer: Adam with betas=(0.9,0.999) and epsilon=1e-08
- lr_scheduler_type: cosine
- lr_scheduler_warmup_steps: 100
- training_steps: 1000


### 📝 Axolotl Configuration

```yaml
base_model: google/gemma-7b-it
model_type: GemmaForCausalLM
tokenizer_type: GemmaTokenizer
trust_remote_code: true

load_in_8bit: false
load_in_4bit: true
strict: false

rl: dpo
chat_template: chatml
datasets:
  - path: mlabonne/chatml-OpenHermes2.5-dpo-binarized-alpha
    split: train
    type: chatml.intel
dataset_prepared_path:
val_set_size: 0.01
output_dir: ./out

adapter: qlora
lora_model_dir:

sequence_len: 1800
sample_packing: false
pad_to_sequence_len: false

lora_r: 16
lora_alpha: 16
lora_dropout: 0.05
lora_target_linear: true
lora_fan_in_fan_out:
lora_target_modules:

wandb_project: gemma
wandb_entity:
wandb_watch:
wandb_name:
wandb_log_model:

gradient_accumulation_steps: 8
micro_batch_size: 1
num_epochs: 1
optimizer: paged_adamw_32bit
lr_scheduler: cosine
learning_rate: 5e-7

train_on_inputs: false
group_by_length: false
bf16: true
fp16: false
tf32: true

gradient_checkpointing: true
early_stopping_patience:
resume_from_checkpoint:
local_rank:
logging_steps: 1
xformers_attention:
flash_attention: false

warmup_steps: 100
evals_per_epoch: 1
eval_table_size:
eval_table_max_new_tokens: 128
save_steps: 1000
max_steps: 1000
debug:
deepspeed:
weight_decay: 0.0
fsdp:
fsdp_config:
special_tokens:
```


### Framework versions

- Transformers 4.39.0.dev0
- Pytorch 2.1.2+cu118
- Datasets 2.17.0
- Tokenizers 0.15.0
- axolotl: 0.4.0

[<img src=""https://raw.githubusercontent.com/OpenAccess-AI-Collective/axolotl/main/image/axolotl-badge-web.png"" alt=""Built with Axolotl"" width=""200"" height=""32""/>](https://github.com/OpenAccess-AI-Collective/axolotl)","{""id"": ""QueryloopAI/gemma-7b-openhermes"", ""author"": ""QueryloopAI"", ""sha"": ""4f2213462ffdd520c6e550a88ac78524c01e6078"", ""last_modified"": ""2024-03-09 20:41:21+00:00"", ""created_at"": ""2024-03-09 07:34:09+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 3, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""safetensors"", ""gemma"", ""feature-extraction"", ""generated_from_trainer"", ""axolotl"", ""instruct"", ""finetune"", ""chatml"", ""gpt4"", ""synthetic data"", ""distillation"", ""text-generation"", ""conversational"", ""en"", ""dataset:mlabonne/chatml-OpenHermes2.5-dpo-binarized-alpha"", ""base_model:google/gemma-7b-it"", ""base_model:finetune:google/gemma-7b-it"", ""license:cc-by-nc-4.0"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b-it\ndatasets:\n- mlabonne/chatml-OpenHermes2.5-dpo-binarized-alpha\nlanguage:\n- en\nlibrary_name: transformers\nlicense: cc-by-nc-4.0\npipeline_tag: text-generation\ntags:\n- generated_from_trainer\n- axolotl\n- gemma\n- instruct\n- finetune\n- chatml\n- gpt4\n- synthetic data\n- distillation\nmodel-index:\n- name: gemma-7b-openhermes\n  results: []"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": [{""name"": ""gemma-7b-openhermes"", ""results"": []}], ""config"": {""architectures"": [""GemmaModel""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'user') != (loop.index0 % 2 == 0) %}{{ raise_exception('Conversation roles must alternate user/assistant/user/assistant/...') }}{% endif %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModel"", ""custom_class"": null, ""pipeline_tag"": ""feature-extraction"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00001-of-00008.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00002-of-00008.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00003-of-00008.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00004-of-00008.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00005-of-00008.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00006-of-00008.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00007-of-00008.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00008-of-00008.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model.safetensors.index.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": {""parameters"": {""F32"": 8537680896}, ""total"": 8537680896}, ""security_repo_status"": null, ""lastModified"": ""2024-03-09 20:41:21+00:00"", ""cardData"": ""base_model: google/gemma-7b-it\ndatasets:\n- mlabonne/chatml-OpenHermes2.5-dpo-binarized-alpha\nlanguage:\n- en\nlibrary_name: transformers\nlicense: cc-by-nc-4.0\npipeline_tag: text-generation\ntags:\n- generated_from_trainer\n- axolotl\n- gemma\n- instruct\n- finetune\n- chatml\n- gpt4\n- synthetic data\n- distillation\nmodel-index:\n- name: gemma-7b-openhermes\n  results: []"", ""transformersInfo"": {""auto_model"": ""AutoModel"", ""custom_class"": null, ""pipeline_tag"": ""feature-extraction"", ""processor"": ""AutoTokenizer""}, ""_id"": ""65ec10f1d7d63c2ed085bbfb"", ""modelId"": ""QueryloopAI/gemma-7b-openhermes"", ""usedStorage"": 34168229401}",2,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=QueryloopAI/gemma-7b-openhermes&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5BQueryloopAI%2Fgemma-7b-openhermes%5D(%2FQueryloopAI%2Fgemma-7b-openhermes)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
https://huggingface.co/ihopper/ko-gemma-7b-sft-dpo-v1.0,N/A,N/A,2,,0,,0,,0,,0,,0.0
https://huggingface.co/yhkim9362/gemma-en-ko-7b-v0.1,N/A,N/A,2,,0,,0,,0,,0,,0.0
https://huggingface.co/yhkim9362/gemma-en-ko-7b-v0.2,N/A,N/A,2,,0,,0,,0,,0,,0.0
PrunaAI/google-gemma-7b-it-HQQ-2bit-smashed,"---
thumbnail: ""https://assets-global.website-files.com/646b351987a8d8ce158d1940/64ec9e96b4334c0e1ac41504_Logo%20with%20white%20text.svg""
base_model: google/gemma-7b-it
metrics:
- memory_disk
- memory_inference
- inference_latency
- inference_throughput
- inference_CO2_emissions
- inference_energy_consumption
tags:
- pruna-ai
---
<!-- header start -->
<!-- 200823 -->
<div style=""width: auto; margin-left: auto; margin-right: auto"">
    <a href=""https://www.pruna.ai/"" target=""_blank"" rel=""noopener noreferrer"">
        <img src=""https://i.imgur.com/eDAlcgk.png"" alt=""PrunaAI"" style=""width: 100%; min-width: 400px; display: block; margin: auto;"">
    </a>
</div>
<!-- header end -->

[![Twitter](https://img.shields.io/twitter/follow/PrunaAI?style=social)](https://twitter.com/PrunaAI)
[![GitHub](https://img.shields.io/github/followers/PrunaAI?label=Follow%20%40PrunaAI&style=social)](https://github.com/PrunaAI)
[![LinkedIn](https://img.shields.io/badge/LinkedIn-Connect-blue)](https://www.linkedin.com/company/93832878/admin/feed/posts/?feedType=following)
[![Discord](https://img.shields.io/badge/Discord-Join%20Us-blue?style=social&logo=discord)](https://discord.gg/rskEr4BZJx)

# Simply make AI models cheaper, smaller, faster, and greener!

- Give a thumbs up if you like this model!
- Contact us and tell us which model to compress next [here](https://www.pruna.ai/contact).
- Request access to easily compress your *own* AI models [here](https://z0halsaff74.typeform.com/pruna-access?typeform-source=www.pruna.ai).
- Read the documentations to know more [here](https://pruna-ai-pruna.readthedocs-hosted.com/en/latest/)
- Join Pruna AI community on Discord [here](https://discord.gg/rskEr4BZJx) to share feedback/suggestions or get help.

## Results

![image info](./plots.png)

**Frequently Asked Questions**
- ***How does the compression work?*** The model is compressed with hqq.
- ***How does the model quality change?*** The quality of the model output might vary compared to the base model.
- ***How is the model efficiency evaluated?*** These results were obtained on NVIDIA A100-PCIE-40GB with configuration described in `model/smash_config.json` and are obtained after a hardware warmup. The smashed model is directly compared to the original base model. Efficiency results may vary in other settings (e.g. other hardware, image size, batch size, ...). We recommend to directly run them in the use-case conditions to know if the smashed model can benefit you.
- ***What is the model format?*** We use safetensors.
- ***What calibration data has been used?*** If needed by the compression method, we used WikiText as the calibration data.
- ***What is the naming convention for Pruna Huggingface models?*** We take the original model name and append ""turbo"", ""tiny"", or ""green"" if the smashed model has a measured inference speed, inference memory, or inference energy consumption which is less than 90% of the original base model.
- ***How to compress my own models?*** You can request premium access to more compression methods and tech support for your specific use-cases [here](https://z0halsaff74.typeform.com/pruna-access?typeform-source=www.pruna.ai).
- ***What are ""first"" metrics?*** Results mentioning ""first"" are obtained after the first run of the model. The first run might take more memory or be slower than the subsequent runs due cuda overheads.
- ***What are ""Sync"" and ""Async"" metrics?*** ""Sync"" metrics are obtained by syncing all GPU processes and stop measurement when all of them are executed. ""Async"" metrics are obtained without syncing all GPU processes and stop when the model output can be used by the CPU. We provide both metrics since both could be relevant depending on the use-case. We recommend to test the efficiency gains directly in your use-cases.

## Setup

You can run the smashed model with these steps:

0. Check requirements from the original repo google/gemma-7b-it installed. In particular, check python, cuda, and transformers versions.
1. Make sure that you have installed quantization related packages.
    ```bash
    pip install hqq
    ```
2. Load & run the model.
    ```python 
   from transformers import AutoModelForCausalLM, AutoTokenizer
    from hqq.engine.hf import HQQModelForCausalLM
 from hqq.models.hf.base import AutoHQQHFModel

   try:
     model = HQQModelForCausalLM.from_quantized(""PrunaAI/google-gemma-7b-it-HQQ-2bit-smashed"", device_map='auto')
    except: 
     model = AutoHQQHFModel.from_quantized(""PrunaAI/google-gemma-7b-it-HQQ-2bit-smashed"")
   tokenizer = AutoTokenizer.from_pretrained(""google/gemma-7b-it"")
    
   input_ids = tokenizer(""What is the color of prunes?,"", return_tensors='pt').to(model.device)[""input_ids""]
    
   outputs = model.generate(input_ids, max_new_tokens=216)
   tokenizer.decode(outputs[0])
    ```

## Configurations

The configuration info are in `smash_config.json`.

## Credits & License

The license of the smashed model follows the license of the original model. Please check the license of the original model google/gemma-7b-it before using this model which provided the base model. The license  of the `pruna-engine` is [here](https://pypi.org/project/pruna-engine/) on Pypi.

## Want to compress other models?

- Contact us and tell us which model to compress next [here](https://www.pruna.ai/contact).
- Request access to easily compress your own AI models [here](https://z0halsaff74.typeform.com/pruna-access?typeform-source=www.pruna.ai).","{""id"": ""PrunaAI/google-gemma-7b-it-HQQ-2bit-smashed"", ""author"": ""PrunaAI"", ""sha"": ""bef6bb2cee196c5ea1866644cabe90af61ef00ca"", ""last_modified"": ""2024-08-02 15:56:14+00:00"", ""created_at"": ""2024-04-29 13:11:14+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 4, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""gemma"", ""text-generation"", ""pruna-ai"", ""base_model:google/gemma-7b-it"", ""base_model:finetune:google/gemma-7b-it"", ""autotrain_compatible"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b-it\nmetrics:\n- memory_disk\n- memory_inference\n- inference_latency\n- inference_throughput\n- inference_CO2_emissions\n- inference_energy_consumption\ntags:\n- pruna-ai\nthumbnail: https://assets-global.website-files.com/646b351987a8d8ce158d1940/64ec9e96b4334c0e1ac41504_Logo%20with%20white%20text.svg"", ""widget_data"": [{""text"": ""My name is Julien and I like to""}, {""text"": ""I like traveling by train because""}, {""text"": ""Paris is an amazing place to visit,""}, {""text"": ""Once upon a time,""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma""}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='plots.png', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='qmodel.pt', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='smash_config.json', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2024-08-02 15:56:14+00:00"", ""cardData"": ""base_model: google/gemma-7b-it\nmetrics:\n- memory_disk\n- memory_inference\n- inference_latency\n- inference_throughput\n- inference_CO2_emissions\n- inference_energy_consumption\ntags:\n- pruna-ai\nthumbnail: https://assets-global.website-files.com/646b351987a8d8ce158d1940/64ec9e96b4334c0e1ac41504_Logo%20with%20white%20text.svg"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""662f9c727dc03cfaae84ff79"", ""modelId"": ""PrunaAI/google-gemma-7b-it-HQQ-2bit-smashed"", ""usedStorage"": 3692979050}",2,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=PrunaAI/google-gemma-7b-it-HQQ-2bit-smashed&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5BPrunaAI%2Fgoogle-gemma-7b-it-HQQ-2bit-smashed%5D(%2FPrunaAI%2Fgoogle-gemma-7b-it-HQQ-2bit-smashed)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
PrunaAI/google-gemma-7b-it-HQQ-1bit-smashed,"---
thumbnail: ""https://assets-global.website-files.com/646b351987a8d8ce158d1940/64ec9e96b4334c0e1ac41504_Logo%20with%20white%20text.svg""
base_model: google/gemma-7b-it
metrics:
- memory_disk
- memory_inference
- inference_latency
- inference_throughput
- inference_CO2_emissions
- inference_energy_consumption
tags:
- pruna-ai
---
<!-- header start -->
<!-- 200823 -->
<div style=""width: auto; margin-left: auto; margin-right: auto"">
    <a href=""https://www.pruna.ai/"" target=""_blank"" rel=""noopener noreferrer"">
        <img src=""https://i.imgur.com/eDAlcgk.png"" alt=""PrunaAI"" style=""width: 100%; min-width: 400px; display: block; margin: auto;"">
    </a>
</div>
<!-- header end -->

[![Twitter](https://img.shields.io/twitter/follow/PrunaAI?style=social)](https://twitter.com/PrunaAI)
[![GitHub](https://img.shields.io/github/followers/PrunaAI?label=Follow%20%40PrunaAI&style=social)](https://github.com/PrunaAI)
[![LinkedIn](https://img.shields.io/badge/LinkedIn-Connect-blue)](https://www.linkedin.com/company/93832878/admin/feed/posts/?feedType=following)
[![Discord](https://img.shields.io/badge/Discord-Join%20Us-blue?style=social&logo=discord)](https://discord.gg/rskEr4BZJx)

# Simply make AI models cheaper, smaller, faster, and greener!

- Give a thumbs up if you like this model!
- Contact us and tell us which model to compress next [here](https://www.pruna.ai/contact).
- Request access to easily compress your *own* AI models [here](https://z0halsaff74.typeform.com/pruna-access?typeform-source=www.pruna.ai).
- Read the documentations to know more [here](https://pruna-ai-pruna.readthedocs-hosted.com/en/latest/)
- Join Pruna AI community on Discord [here](https://discord.gg/rskEr4BZJx) to share feedback/suggestions or get help.

## Results

![image info](./plots.png)

**Frequently Asked Questions**
- ***How does the compression work?*** The model is compressed with hqq.
- ***How does the model quality change?*** The quality of the model output might vary compared to the base model.
- ***How is the model efficiency evaluated?*** These results were obtained on NVIDIA A100-PCIE-40GB with configuration described in `model/smash_config.json` and are obtained after a hardware warmup. The smashed model is directly compared to the original base model. Efficiency results may vary in other settings (e.g. other hardware, image size, batch size, ...). We recommend to directly run them in the use-case conditions to know if the smashed model can benefit you.
- ***What is the model format?*** We use safetensors.
- ***What calibration data has been used?*** If needed by the compression method, we used WikiText as the calibration data.
- ***What is the naming convention for Pruna Huggingface models?*** We take the original model name and append ""turbo"", ""tiny"", or ""green"" if the smashed model has a measured inference speed, inference memory, or inference energy consumption which is less than 90% of the original base model.
- ***How to compress my own models?*** You can request premium access to more compression methods and tech support for your specific use-cases [here](https://z0halsaff74.typeform.com/pruna-access?typeform-source=www.pruna.ai).
- ***What are ""first"" metrics?*** Results mentioning ""first"" are obtained after the first run of the model. The first run might take more memory or be slower than the subsequent runs due cuda overheads.
- ***What are ""Sync"" and ""Async"" metrics?*** ""Sync"" metrics are obtained by syncing all GPU processes and stop measurement when all of them are executed. ""Async"" metrics are obtained without syncing all GPU processes and stop when the model output can be used by the CPU. We provide both metrics since both could be relevant depending on the use-case. We recommend to test the efficiency gains directly in your use-cases.

## Setup

You can run the smashed model with these steps:

0. Check requirements from the original repo google/gemma-7b-it installed. In particular, check python, cuda, and transformers versions.
1. Make sure that you have installed quantization related packages.
    ```bash
    pip install hqq
    ```
2. Load & run the model.
    ```python 
   from transformers import AutoModelForCausalLM, AutoTokenizer
    from hqq.engine.hf import HQQModelForCausalLM
 from hqq.models.hf.base import AutoHQQHFModel

   try:
     model = HQQModelForCausalLM.from_quantized(""PrunaAI/google-gemma-7b-it-HQQ-1bit-smashed"", device_map='auto')
    except: 
     model = AutoHQQHFModel.from_quantized(""PrunaAI/google-gemma-7b-it-HQQ-1bit-smashed"")
   tokenizer = AutoTokenizer.from_pretrained(""google/gemma-7b-it"")
    
   input_ids = tokenizer(""What is the color of prunes?,"", return_tensors='pt').to(model.device)[""input_ids""]
    
   outputs = model.generate(input_ids, max_new_tokens=216)
   tokenizer.decode(outputs[0])
    ```

## Configurations

The configuration info are in `smash_config.json`.

## Credits & License

The license of the smashed model follows the license of the original model. Please check the license of the original model google/gemma-7b-it before using this model which provided the base model. The license  of the `pruna-engine` is [here](https://pypi.org/project/pruna-engine/) on Pypi.

## Want to compress other models?

- Contact us and tell us which model to compress next [here](https://www.pruna.ai/contact).
- Request access to easily compress your own AI models [here](https://z0halsaff74.typeform.com/pruna-access?typeform-source=www.pruna.ai).","{""id"": ""PrunaAI/google-gemma-7b-it-HQQ-1bit-smashed"", ""author"": ""PrunaAI"", ""sha"": ""23aa1ff3cc0d8d0d49285654b01b65bf83fdbf83"", ""last_modified"": ""2024-08-02 15:56:15+00:00"", ""created_at"": ""2024-04-29 13:11:26+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 3, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""gemma"", ""text-generation"", ""pruna-ai"", ""base_model:google/gemma-7b-it"", ""base_model:finetune:google/gemma-7b-it"", ""autotrain_compatible"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b-it\nmetrics:\n- memory_disk\n- memory_inference\n- inference_latency\n- inference_throughput\n- inference_CO2_emissions\n- inference_energy_consumption\ntags:\n- pruna-ai\nthumbnail: https://assets-global.website-files.com/646b351987a8d8ce158d1940/64ec9e96b4334c0e1ac41504_Logo%20with%20white%20text.svg"", ""widget_data"": [{""text"": ""My name is Julien and I like to""}, {""text"": ""I like traveling by train because""}, {""text"": ""Paris is an amazing place to visit,""}, {""text"": ""Once upon a time,""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma""}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='plots.png', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='qmodel.pt', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='smash_config.json', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2024-08-02 15:56:15+00:00"", ""cardData"": ""base_model: google/gemma-7b-it\nmetrics:\n- memory_disk\n- memory_inference\n- inference_latency\n- inference_throughput\n- inference_CO2_emissions\n- inference_energy_consumption\ntags:\n- pruna-ai\nthumbnail: https://assets-global.website-files.com/646b351987a8d8ce158d1940/64ec9e96b4334c0e1ac41504_Logo%20with%20white%20text.svg"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""662f9c7e35acb81eed38dfab"", ""modelId"": ""PrunaAI/google-gemma-7b-it-HQQ-1bit-smashed"", ""usedStorage"": 2724094826}",2,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=PrunaAI/google-gemma-7b-it-HQQ-1bit-smashed&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5BPrunaAI%2Fgoogle-gemma-7b-it-HQQ-1bit-smashed%5D(%2FPrunaAI%2Fgoogle-gemma-7b-it-HQQ-1bit-smashed)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
PrunaAI/google-gemma-7b-it-HQQ-4bit-smashed,"---
thumbnail: ""https://assets-global.website-files.com/646b351987a8d8ce158d1940/64ec9e96b4334c0e1ac41504_Logo%20with%20white%20text.svg""
base_model: google/gemma-7b-it
metrics:
- memory_disk
- memory_inference
- inference_latency
- inference_throughput
- inference_CO2_emissions
- inference_energy_consumption
tags:
- pruna-ai
---
<!-- header start -->
<!-- 200823 -->
<div style=""width: auto; margin-left: auto; margin-right: auto"">
    <a href=""https://www.pruna.ai/"" target=""_blank"" rel=""noopener noreferrer"">
        <img src=""https://i.imgur.com/eDAlcgk.png"" alt=""PrunaAI"" style=""width: 100%; min-width: 400px; display: block; margin: auto;"">
    </a>
</div>
<!-- header end -->

[![Twitter](https://img.shields.io/twitter/follow/PrunaAI?style=social)](https://twitter.com/PrunaAI)
[![GitHub](https://img.shields.io/github/followers/PrunaAI?label=Follow%20%40PrunaAI&style=social)](https://github.com/PrunaAI)
[![LinkedIn](https://img.shields.io/badge/LinkedIn-Connect-blue)](https://www.linkedin.com/company/93832878/admin/feed/posts/?feedType=following)
[![Discord](https://img.shields.io/badge/Discord-Join%20Us-blue?style=social&logo=discord)](https://discord.gg/rskEr4BZJx)

# Simply make AI models cheaper, smaller, faster, and greener!

- Give a thumbs up if you like this model!
- Contact us and tell us which model to compress next [here](https://www.pruna.ai/contact).
- Request access to easily compress your *own* AI models [here](https://z0halsaff74.typeform.com/pruna-access?typeform-source=www.pruna.ai).
- Read the documentations to know more [here](https://pruna-ai-pruna.readthedocs-hosted.com/en/latest/)
- Join Pruna AI community on Discord [here](https://discord.gg/rskEr4BZJx) to share feedback/suggestions or get help.

## Results

![image info](./plots.png)

**Frequently Asked Questions**
- ***How does the compression work?*** The model is compressed with hqq.
- ***How does the model quality change?*** The quality of the model output might vary compared to the base model.
- ***How is the model efficiency evaluated?*** These results were obtained on NVIDIA A100-PCIE-40GB with configuration described in `model/smash_config.json` and are obtained after a hardware warmup. The smashed model is directly compared to the original base model. Efficiency results may vary in other settings (e.g. other hardware, image size, batch size, ...). We recommend to directly run them in the use-case conditions to know if the smashed model can benefit you.
- ***What is the model format?*** We use safetensors.
- ***What calibration data has been used?*** If needed by the compression method, we used WikiText as the calibration data.
- ***What is the naming convention for Pruna Huggingface models?*** We take the original model name and append ""turbo"", ""tiny"", or ""green"" if the smashed model has a measured inference speed, inference memory, or inference energy consumption which is less than 90% of the original base model.
- ***How to compress my own models?*** You can request premium access to more compression methods and tech support for your specific use-cases [here](https://z0halsaff74.typeform.com/pruna-access?typeform-source=www.pruna.ai).
- ***What are ""first"" metrics?*** Results mentioning ""first"" are obtained after the first run of the model. The first run might take more memory or be slower than the subsequent runs due cuda overheads.
- ***What are ""Sync"" and ""Async"" metrics?*** ""Sync"" metrics are obtained by syncing all GPU processes and stop measurement when all of them are executed. ""Async"" metrics are obtained without syncing all GPU processes and stop when the model output can be used by the CPU. We provide both metrics since both could be relevant depending on the use-case. We recommend to test the efficiency gains directly in your use-cases.

## Setup

You can run the smashed model with these steps:

0. Check requirements from the original repo google/gemma-7b-it installed. In particular, check python, cuda, and transformers versions.
1. Make sure that you have installed quantization related packages.
    ```bash
    pip install hqq
    ```
2. Load & run the model.
    ```python 
   from transformers import AutoModelForCausalLM, AutoTokenizer
    from hqq.engine.hf import HQQModelForCausalLM
 from hqq.models.hf.base import AutoHQQHFModel

   try:
     model = HQQModelForCausalLM.from_quantized(""PrunaAI/google-gemma-7b-it-HQQ-4bit-smashed"", device_map='auto')
    except: 
     model = AutoHQQHFModel.from_quantized(""PrunaAI/google-gemma-7b-it-HQQ-4bit-smashed"")
   tokenizer = AutoTokenizer.from_pretrained(""google/gemma-7b-it"")
    
   input_ids = tokenizer(""What is the color of prunes?,"", return_tensors='pt').to(model.device)[""input_ids""]
    
   outputs = model.generate(input_ids, max_new_tokens=216)
   tokenizer.decode(outputs[0])
    ```

## Configurations

The configuration info are in `smash_config.json`.

## Credits & License

The license of the smashed model follows the license of the original model. Please check the license of the original model google/gemma-7b-it before using this model which provided the base model. The license  of the `pruna-engine` is [here](https://pypi.org/project/pruna-engine/) on Pypi.

## Want to compress other models?

- Contact us and tell us which model to compress next [here](https://www.pruna.ai/contact).
- Request access to easily compress your own AI models [here](https://z0halsaff74.typeform.com/pruna-access?typeform-source=www.pruna.ai).","{""id"": ""PrunaAI/google-gemma-7b-it-HQQ-4bit-smashed"", ""author"": ""PrunaAI"", ""sha"": ""2f9bbe3e6e50cb5b448d370a416a6356957207d3"", ""last_modified"": ""2024-08-02 15:57:14+00:00"", ""created_at"": ""2024-04-29 16:03:26+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 19, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""gemma"", ""text-generation"", ""pruna-ai"", ""base_model:google/gemma-7b-it"", ""base_model:finetune:google/gemma-7b-it"", ""autotrain_compatible"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b-it\nmetrics:\n- memory_disk\n- memory_inference\n- inference_latency\n- inference_throughput\n- inference_CO2_emissions\n- inference_energy_consumption\ntags:\n- pruna-ai\nthumbnail: https://assets-global.website-files.com/646b351987a8d8ce158d1940/64ec9e96b4334c0e1ac41504_Logo%20with%20white%20text.svg"", ""widget_data"": [{""text"": ""My name is Julien and I like to""}, {""text"": ""I like traveling by train because""}, {""text"": ""Paris is an amazing place to visit,""}, {""text"": ""Once upon a time,""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma""}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='plots.png', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='qmodel.pt', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='smash_config.json', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2024-08-02 15:57:14+00:00"", ""cardData"": ""base_model: google/gemma-7b-it\nmetrics:\n- memory_disk\n- memory_inference\n- inference_latency\n- inference_throughput\n- inference_CO2_emissions\n- inference_energy_consumption\ntags:\n- pruna-ai\nthumbnail: https://assets-global.website-files.com/646b351987a8d8ce158d1940/64ec9e96b4334c0e1ac41504_Logo%20with%20white%20text.svg"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""662fc4ced2f21fa96cf50691"", ""modelId"": ""PrunaAI/google-gemma-7b-it-HQQ-4bit-smashed"", ""usedStorage"": 5630753154}",2,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=PrunaAI/google-gemma-7b-it-HQQ-4bit-smashed&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5BPrunaAI%2Fgoogle-gemma-7b-it-HQQ-4bit-smashed%5D(%2FPrunaAI%2Fgoogle-gemma-7b-it-HQQ-4bit-smashed)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
shisa-ai/shisa-v1-gemma-8b,"---
license: gemma
datasets:
- augmxnt/ultra-orca-boros-en-ja-v1
language:
- ja
- en
base_model: google/gemma-7b-it
---
shisa-v2 Base Model ablation

Using a [fork](https://github.com/shisa-ai/shaberi) of [Lightblue's Shaberi benchmark framework](https://github.com/lightblue-tech/japanese_llm_eval):

| Model                                  | Average | ELYZA-tasks-100 | MT-Bench | Rakuda | Tengu-Bench |
|----------------------------------------|---------|-----------------|----------|--------|-------------|
| gpt-4-turbo-2024-04-09                 | 8.75    | 8.78            | 8.74     | 9.18   | 8.31        |
| CohereForAI/c4ai-command-r-plus        | 7.69    | 7.50            | 7.43     | 9.05   | 6.79        |
| gpt-3.5-turbo-0125                     | 7.17    | 7.24            | 6.98     | 7.64   | 6.82        |
| **shisa-ai/shisa-v1-llama3-70b**       | **7.17**| **7.16**        | **7.45** | **7.98** | **6.09**  |
| karakuri-ai/karakuri-lm-70b-chat-v0.1  | 6.84    | 6.86            | 6.43     | 7.85   | 6.23        |
| lightblue/ao-karasu-72B                | 6.81    | 7.19            | 6.54     | 7.25   | 6.27        |
| **shisa-ai/shisa-v1-llama3-8b^**       | **6.29**| **6.62**        | **6.41** | **7.05**|**5.07**    |
| shisa-ai/shisa-swallowmx-13a47b-v1     | 6.17    | 6.48            | 6.07     | 7.11   | 5.03        |
| **shisa-ai/shisa-v1-llama3-8b**        | **6.10**| **6.52**        | **6.20** | **6.37**|**5.33**    |
| Rakuten/RakutenAI-7B-chat              | 5.58    | 5.92            | 4.60     | 6.58   | 5.24        |
| shisa-ai/shisa-v1-gemma-8b             | 5.64    | 6.50            | 5.42     | 5.10   | 5.55        |
| augmxnt/shisa-gamma-7b-v1              | 5.56    | 5.84            | 4.00     | 6.73   | 5.68        |
| lightblue/qarasu-14B-chat-plus-unleashed | 5.20  | 5.58            | 4.74     | 5.46   | 5.01        |
| cyberagent/calm2-7b-chat               | 4.76    | 4.90            | 3.58     | 5.75   | 4.81        |
| mistralai/Mistral-7B-Instruct-v0.2     | 4.69    | 5.78            | 4.65     | 3.80   | 4.53        |
| **shisa-ai/shisa-v1-yi1.5-9b**         | **4.63**| **5.98**        | **4.28** | **3.26**|**5.00**    |","{""id"": ""shisa-ai/shisa-v1-gemma-8b"", ""author"": ""shisa-ai"", ""sha"": ""be0c1785582b69c70c2f96b3b5dec9a772539c06"", ""last_modified"": ""2024-05-19 18:09:06+00:00"", ""created_at"": ""2024-05-17 16:45:38+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 12, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""safetensors"", ""gemma"", ""text-generation"", ""conversational"", ""ja"", ""en"", ""dataset:augmxnt/ultra-orca-boros-en-ja-v1"", ""base_model:google/gemma-7b-it"", ""base_model:finetune:google/gemma-7b-it"", ""license:gemma"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b-it\ndatasets:\n- augmxnt/ultra-orca-boros-en-ja-v1\nlanguage:\n- ja\n- en\nlicense: gemma"", ""widget_data"": null, ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{% if not add_generation_prompt is defined %}{% set add_generation_prompt = false %}{% endif %}{% for message in messages %}{{'<|im_start|>' + message['role'] + '\n' + message['content'] + '<|im_end|>' + '\n'}}{% endfor %}{% if add_generation_prompt %}{{ '<|im_start|>assistant\n' }}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='generation_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00001-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00002-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00003-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00004-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model.safetensors.index.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": {""parameters"": {""BF16"": 8537680896}, ""total"": 8537680896}, ""security_repo_status"": null, ""lastModified"": ""2024-05-19 18:09:06+00:00"", ""cardData"": ""base_model: google/gemma-7b-it\ndatasets:\n- augmxnt/ultra-orca-boros-en-ja-v1\nlanguage:\n- ja\n- en\nlicense: gemma"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""664789b210c26a4d0a9c492e"", ""modelId"": ""shisa-ai/shisa-v1-gemma-8b"", ""usedStorage"": 17097150888}",2,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=shisa-ai/shisa-v1-gemma-8b&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bshisa-ai%2Fshisa-v1-gemma-8b%5D(%2Fshisa-ai%2Fshisa-v1-gemma-8b)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
Punthon/gemma-5-sdgs,"---
tags:
- autotrain
- text-generation-inference
- text-generation
- peft
library_name: transformers
base_model: google/gemma-7b-it
widget:
  - messages:
      - role: user
        content: What is your favorite condiment?
license: other
---

# Model Trained Using AutoTrain

This model was trained using AutoTrain. For more information, please visit [AutoTrain](https://hf.co/docs/autotrain).

# Usage

```python

from transformers import AutoModelForCausalLM, AutoTokenizer

model_path = ""PATH_TO_THIS_REPO""

tokenizer = AutoTokenizer.from_pretrained(model_path)
model = AutoModelForCausalLM.from_pretrained(
    model_path,
    device_map=""auto"",
    torch_dtype='auto'
).eval()

# Prompt content: ""hi""
messages = [
    {""role"": ""user"", ""content"": ""hi""}
]

input_ids = tokenizer.apply_chat_template(conversation=messages, tokenize=True, add_generation_prompt=True, return_tensors='pt')
output_ids = model.generate(input_ids.to('cuda'))
response = tokenizer.decode(output_ids[0][input_ids.shape[1]:], skip_special_tokens=True)

# Model response: ""Hello! How can I assist you today?""
print(response)
```","{""id"": ""Punthon/gemma-5-sdgs"", ""author"": ""Punthon"", ""sha"": ""aded093162d7c95f0a7a00d10ac1c8fa511de15e"", ""last_modified"": ""2024-08-16 16:28:46+00:00"", ""created_at"": ""2024-08-16 15:29:09+00:00"", ""private"": false, ""gated"": ""auto"", ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""autotrain"", ""text-generation-inference"", ""text-generation"", ""peft"", ""conversational"", ""base_model:google/gemma-7b-it"", ""base_model:finetune:google/gemma-7b-it"", ""license:other"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b-it\nlibrary_name: transformers\nlicense: other\ntags:\n- autotrain\n- text-generation-inference\n- text-generation\n- peft\nwidget:\n- messages:\n  - role: user\n    content: What is your favorite condiment?"", ""widget_data"": [{""messages"": [{""role"": ""user"", ""content"": ""What is your favorite condiment?""}]}], ""model_index"": null, ""config"": {""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'user') != (loop.index0 % 2 == 0) %}{{ raise_exception('Conversation roles must alternate user/assistant/user/assistant/...') }}{% endif %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModel"", ""custom_class"": null, ""pipeline_tag"": null, ""processor"": null}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Aug16_15-20-36_484e05cf8b76/events.out.tfevents.1723822153.484e05cf8b76.7275.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_params.json', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2024-08-16 16:28:46+00:00"", ""cardData"": ""base_model: google/gemma-7b-it\nlibrary_name: transformers\nlicense: other\ntags:\n- autotrain\n- text-generation-inference\n- text-generation\n- peft\nwidget:\n- messages:\n  - role: user\n    content: What is your favorite condiment?"", ""transformersInfo"": {""auto_model"": ""AutoModel"", ""custom_class"": null, ""pipeline_tag"": null, ""processor"": null}, ""_id"": ""66bf7045ae70890c9029788d"", ""modelId"": ""Punthon/gemma-5-sdgs"", ""usedStorage"": 221866176}",2,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=Punthon/gemma-5-sdgs&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5BPunthon%2Fgemma-5-sdgs%5D(%2FPunthon%2Fgemma-5-sdgs)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
Punthon/gemma-5-sdgs-100rows,"---
tags:
- autotrain
- text-generation-inference
- text-generation
- peft
library_name: transformers
base_model: google/gemma-7b-it
widget:
  - messages:
      - role: user
        content: What is your favorite condiment?
license: other
---

# Model Trained Using AutoTrain

This model was trained using AutoTrain. For more information, please visit [AutoTrain](https://hf.co/docs/autotrain).

# Usage

```python

from transformers import AutoModelForCausalLM, AutoTokenizer

model_path = ""PATH_TO_THIS_REPO""

tokenizer = AutoTokenizer.from_pretrained(model_path)
model = AutoModelForCausalLM.from_pretrained(
    model_path,
    device_map=""auto"",
    torch_dtype='auto'
).eval()

# Prompt content: ""hi""
messages = [
    {""role"": ""user"", ""content"": ""hi""}
]

input_ids = tokenizer.apply_chat_template(conversation=messages, tokenize=True, add_generation_prompt=True, return_tensors='pt')
output_ids = model.generate(input_ids.to('cuda'))
response = tokenizer.decode(output_ids[0][input_ids.shape[1]:], skip_special_tokens=True)

# Model response: ""Hello! How can I assist you today?""
print(response)
```","{""id"": ""Punthon/gemma-5-sdgs-100rows"", ""author"": ""Punthon"", ""sha"": ""5edb7c92d6c5b14db4f396e29f886addd071b733"", ""last_modified"": ""2024-08-17 09:59:40+00:00"", ""created_at"": ""2024-08-17 09:40:05+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""autotrain"", ""text-generation-inference"", ""text-generation"", ""peft"", ""conversational"", ""base_model:google/gemma-7b-it"", ""base_model:finetune:google/gemma-7b-it"", ""license:other"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b-it\nlibrary_name: transformers\nlicense: other\ntags:\n- autotrain\n- text-generation-inference\n- text-generation\n- peft\nwidget:\n- messages:\n  - role: user\n    content: What is your favorite condiment?"", ""widget_data"": [{""messages"": [{""role"": ""user"", ""content"": ""What is your favorite condiment?""}]}], ""model_index"": null, ""config"": {""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'user') != (loop.index0 % 2 == 0) %}{{ raise_exception('Conversation roles must alternate user/assistant/user/assistant/...') }}{% endif %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModel"", ""custom_class"": null, ""pipeline_tag"": null, ""processor"": null}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Aug17_09-35-41_c86344f2b9d9/events.out.tfevents.1723887608.c86344f2b9d9.7354.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_params.json', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2024-08-17 09:59:40+00:00"", ""cardData"": ""base_model: google/gemma-7b-it\nlibrary_name: transformers\nlicense: other\ntags:\n- autotrain\n- text-generation-inference\n- text-generation\n- peft\nwidget:\n- messages:\n  - role: user\n    content: What is your favorite condiment?"", ""transformersInfo"": {""auto_model"": ""AutoModel"", ""custom_class"": null, ""pipeline_tag"": null, ""processor"": null}, ""_id"": ""66c06ff58e95eabff297dccb"", ""modelId"": ""Punthon/gemma-5-sdgs-100rows"", ""usedStorage"": 221851970}",2,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=Punthon/gemma-5-sdgs-100rows&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5BPunthon%2Fgemma-5-sdgs-100rows%5D(%2FPunthon%2Fgemma-5-sdgs-100rows)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
Punthon/gemma-5-sdgs-200rows,"---
tags:
- autotrain
- text-generation-inference
- text-generation
- peft
library_name: transformers
base_model: google/gemma-7b-it
widget:
  - messages:
      - role: user
        content: What is your favorite condiment?
license: other
---

# Model Trained Using AutoTrain

This model was trained using AutoTrain. For more information, please visit [AutoTrain](https://hf.co/docs/autotrain).

# Usage

```python

from transformers import AutoModelForCausalLM, AutoTokenizer

model_path = ""PATH_TO_THIS_REPO""

tokenizer = AutoTokenizer.from_pretrained(model_path)
model = AutoModelForCausalLM.from_pretrained(
    model_path,
    device_map=""auto"",
    torch_dtype='auto'
).eval()

# Prompt content: ""hi""
messages = [
    {""role"": ""user"", ""content"": ""hi""}
]

input_ids = tokenizer.apply_chat_template(conversation=messages, tokenize=True, add_generation_prompt=True, return_tensors='pt')
output_ids = model.generate(input_ids.to('cuda'))
response = tokenizer.decode(output_ids[0][input_ids.shape[1]:], skip_special_tokens=True)

# Model response: ""Hello! How can I assist you today?""
print(response)
```","{""id"": ""Punthon/gemma-5-sdgs-200rows"", ""author"": ""Punthon"", ""sha"": ""f1146548fb29bd89200fe78e42091f457493cd99"", ""last_modified"": ""2024-08-17 13:27:39+00:00"", ""created_at"": ""2024-08-17 12:47:35+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""autotrain"", ""text-generation-inference"", ""text-generation"", ""peft"", ""conversational"", ""base_model:google/gemma-7b-it"", ""base_model:finetune:google/gemma-7b-it"", ""license:other"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b-it\nlibrary_name: transformers\nlicense: other\ntags:\n- autotrain\n- text-generation-inference\n- text-generation\n- peft\nwidget:\n- messages:\n  - role: user\n    content: What is your favorite condiment?"", ""widget_data"": [{""messages"": [{""role"": ""user"", ""content"": ""What is your favorite condiment?""}]}], ""model_index"": null, ""config"": {""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'user') != (loop.index0 % 2 == 0) %}{{ raise_exception('Conversation roles must alternate user/assistant/user/assistant/...') }}{% endif %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModel"", ""custom_class"": null, ""pipeline_tag"": null, ""processor"": null}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Aug17_12-45-34_59499df87da0/events.out.tfevents.1723898859.59499df87da0.4176.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_params.json', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2024-08-17 13:27:39+00:00"", ""cardData"": ""base_model: google/gemma-7b-it\nlibrary_name: transformers\nlicense: other\ntags:\n- autotrain\n- text-generation-inference\n- text-generation\n- peft\nwidget:\n- messages:\n  - role: user\n    content: What is your favorite condiment?"", ""transformersInfo"": {""auto_model"": ""AutoModel"", ""custom_class"": null, ""pipeline_tag"": null, ""processor"": null}, ""_id"": ""66c09be78c3816c5632498a8"", ""modelId"": ""Punthon/gemma-5-sdgs-200rows"", ""usedStorage"": 221858917}",2,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=Punthon/gemma-5-sdgs-200rows&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5BPunthon%2Fgemma-5-sdgs-200rows%5D(%2FPunthon%2Fgemma-5-sdgs-200rows)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
terry69/feedback_gemma,"---
library_name: transformers
license: gemma
base_model: google/gemma-7b-it
tags:
- alignment-handbook
- trl
- sft
- generated_from_trainer
- trl
- sft
- generated_from_trainer
datasets:
- preference-data
model-index:
- name: feedback_gemma
  results: []
---

<!-- This model card has been generated automatically according to the information the Trainer had access to. You
should probably proofread and complete it, then remove this comment. -->

# feedback_gemma

This model is a fine-tuned version of [google/gemma-7b-it](https://huggingface.co/google/gemma-7b-it) on the preference-data dataset.

## Model description

More information needed

## Intended uses & limitations

More information needed

## Training and evaluation data

More information needed

## Training procedure

### Training hyperparameters

The following hyperparameters were used during training:
- learning_rate: 1e-05
- train_batch_size: 4
- eval_batch_size: 1
- seed: 42
- distributed_type: multi-GPU
- num_devices: 4
- total_train_batch_size: 16
- total_eval_batch_size: 4
- optimizer: Adam with betas=(0.9,0.999) and epsilon=1e-08
- lr_scheduler_type: cosine
- lr_scheduler_warmup_ratio: 0.1
- num_epochs: 1

### Training results



### Framework versions

- Transformers 4.44.2
- Pytorch 2.3.1+cu121
- Datasets 2.19.1
- Tokenizers 0.19.1
","{""id"": ""terry69/feedback_gemma"", ""author"": ""terry69"", ""sha"": ""3dea074790c475adb8df3e7b79ab4185ff5a4b1b"", ""last_modified"": ""2024-09-19 11:49:56+00:00"", ""created_at"": ""2024-09-19 05:59:44+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""alignment-handbook"", ""trl"", ""sft"", ""generated_from_trainer"", ""conversational"", ""dataset:preference-data"", ""base_model:google/gemma-7b-it"", ""base_model:finetune:google/gemma-7b-it"", ""license:gemma"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b-it\ndatasets:\n- preference-data\nlibrary_name: transformers\nlicense: gemma\ntags:\n- alignment-handbook\n- trl\n- sft\n- generated_from_trainer\nmodel-index:\n- name: feedback_gemma\n  results: []"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": [{""name"": ""feedback_gemma"", ""results"": []}], ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{% for message in messages %}\n{% if message['role'] == 'user' %}\n{{ '<|user|>\n' + message['content'] + eos_token }}\n{% elif message['role'] == 'system' %}\n{{ '<|system|>\n' + message['content'] + eos_token }}\n{% elif message['role'] == 'assistant' %}\n{{ '<|assistant|>\n'  + message['content'] + eos_token }}\n{% endif %}\n{% if loop.last and add_generation_prompt %}\n{{ '<|assistant|>' }}\n{% endif %}\n{% endfor %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='eval_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='generation_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00001-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00002-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00003-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00004-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model.safetensors.index.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Sep19_05-49-17_COE-CS-sv003/events.out.tfevents.1726725600.COE-CS-sv003.346740.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Sep19_05-49-17_COE-CS-sv003/events.out.tfevents.1726746544.COE-CS-sv003.346740.1', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": {""parameters"": {""BF16"": 8537680896}, ""total"": 8537680896}, ""security_repo_status"": null, ""lastModified"": ""2024-09-19 11:49:56+00:00"", ""cardData"": ""base_model: google/gemma-7b-it\ndatasets:\n- preference-data\nlibrary_name: transformers\nlicense: gemma\ntags:\n- alignment-handbook\n- trl\n- sft\n- generated_from_trainer\nmodel-index:\n- name: feedback_gemma\n  results: []"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""66ebbdd08ed4a19697dec88f"", ""modelId"": ""terry69/feedback_gemma"", ""usedStorage"": 17097312997}",2,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=terry69/feedback_gemma&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bterry69%2Ffeedback_gemma%5D(%2Fterry69%2Ffeedback_gemma)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
terry69/feedback_gemma_dirty,"---
library_name: transformers
license: gemma
base_model: google/gemma-7b-it
tags:
- alignment-handbook
- trl
- sft
- generated_from_trainer
- trl
- sft
- generated_from_trainer
datasets:
- preference-data
model-index:
- name: feedback_gemma_dirty
  results: []
---

<!-- This model card has been generated automatically according to the information the Trainer had access to. You
should probably proofread and complete it, then remove this comment. -->

# feedback_gemma_dirty

This model is a fine-tuned version of [google/gemma-7b-it](https://huggingface.co/google/gemma-7b-it) on the preference-data dataset.

## Model description

More information needed

## Intended uses & limitations

More information needed

## Training and evaluation data

More information needed

## Training procedure

### Training hyperparameters

The following hyperparameters were used during training:
- learning_rate: 1e-05
- train_batch_size: 4
- eval_batch_size: 1
- seed: 42
- distributed_type: multi-GPU
- num_devices: 4
- total_train_batch_size: 16
- total_eval_batch_size: 4
- optimizer: Adam with betas=(0.9,0.999) and epsilon=1e-08
- lr_scheduler_type: cosine
- lr_scheduler_warmup_ratio: 0.1
- num_epochs: 1

### Training results



### Framework versions

- Transformers 4.44.2
- Pytorch 2.3.1+cu121
- Datasets 2.19.1
- Tokenizers 0.19.1
","{""id"": ""terry69/feedback_gemma_dirty"", ""author"": ""terry69"", ""sha"": ""af68c50af1863506a9bcb3ec733c0993e82253d6"", ""last_modified"": ""2024-09-19 23:33:09+00:00"", ""created_at"": ""2024-09-19 17:43:36+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 5, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""alignment-handbook"", ""trl"", ""sft"", ""generated_from_trainer"", ""conversational"", ""dataset:preference-data"", ""base_model:google/gemma-7b-it"", ""base_model:finetune:google/gemma-7b-it"", ""license:gemma"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b-it\ndatasets:\n- preference-data\nlibrary_name: transformers\nlicense: gemma\ntags:\n- alignment-handbook\n- trl\n- sft\n- generated_from_trainer\nmodel-index:\n- name: feedback_gemma_dirty\n  results: []"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": [{""name"": ""feedback_gemma_dirty"", ""results"": []}], ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{% for message in messages %}\n{% if message['role'] == 'user' %}\n{{ '<|user|>\n' + message['content'] + eos_token }}\n{% elif message['role'] == 'system' %}\n{{ '<|system|>\n' + message['content'] + eos_token }}\n{% elif message['role'] == 'assistant' %}\n{{ '<|assistant|>\n'  + message['content'] + eos_token }}\n{% endif %}\n{% if loop.last and add_generation_prompt %}\n{{ '<|assistant|>' }}\n{% endif %}\n{% endfor %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='eval_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='generation_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00001-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00002-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00003-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00004-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model.safetensors.index.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Sep19_17-38-55_COE-CS-sv003/events.out.tfevents.1726767828.COE-CS-sv003.388702.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Sep19_17-38-55_COE-CS-sv003/events.out.tfevents.1726788742.COE-CS-sv003.388702.1', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": {""parameters"": {""BF16"": 8537680896}, ""total"": 8537680896}, ""security_repo_status"": null, ""lastModified"": ""2024-09-19 23:33:09+00:00"", ""cardData"": ""base_model: google/gemma-7b-it\ndatasets:\n- preference-data\nlibrary_name: transformers\nlicense: gemma\ntags:\n- alignment-handbook\n- trl\n- sft\n- generated_from_trainer\nmodel-index:\n- name: feedback_gemma_dirty\n  results: []"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""66ec62c81fff8ac6a38c4c3e"", ""modelId"": ""terry69/feedback_gemma_dirty"", ""usedStorage"": 17097312623}",2,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=terry69/feedback_gemma_dirty&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bterry69%2Ffeedback_gemma_dirty%5D(%2Fterry69%2Ffeedback_gemma_dirty)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
OpenVINO/gemma-7b-it-fp16-ov,"---
license: gemma
license_link: https://choosealicense.com/licenses/gemma/
base_model:
- google/gemma-7b-it
---
# gemma-7b-it-fp16-ov
* Model creator: [Google](https://huggingface.co/google)
 * Original model: [gemma-7b-it](https://huggingface.co/google/gemma-7b-it)

## Description

## Compatibility

The provided OpenVINO™ IR model is compatible with:

* OpenVINO version 2024.4.0 and higher
* Optimum Intel 1.20.0 and higher

## Running Model Inference with [Optimum Intel](https://huggingface.co/docs/optimum/intel/index)

1. Install packages required for using [Optimum Intel](https://huggingface.co/docs/optimum/intel/index) integration with the OpenVINO backend:

```
pip install optimum[openvino]
```

2. Run model inference:

```
from transformers import AutoTokenizer
from optimum.intel.openvino import OVModelForCausalLM

model_id = ""OpenVINO/gemma-7b-it-fp16-ov""
tokenizer = AutoTokenizer.from_pretrained(model_id)
model = OVModelForCausalLM.from_pretrained(model_id)

inputs = tokenizer(""What is OpenVINO?"", return_tensors=""pt"")

outputs = model.generate(**inputs, max_length=200)
text = tokenizer.batch_decode(outputs)[0]
print(text)
```

For more examples and possible optimizations, refer to the [OpenVINO Large Language Model Inference Guide](https://docs.openvino.ai/2024/learn-openvino/llm_inference_guide.html).

## Running Model Inference with [OpenVINO GenAI](https://github.com/openvinotoolkit/openvino.genai)

1. Install packages required for using OpenVINO GenAI.
```
pip install openvino-genai huggingface_hub
```

2. Download model from HuggingFace Hub
   
```
import huggingface_hub as hf_hub

model_id = ""OpenVINO/gemma-7b-it-fp16-ov""
model_path = ""gemma-7b-it-fp16-ov""

hf_hub.snapshot_download(model_id, local_dir=model_path)

```

3. Run model inference:

```
import openvino_genai as ov_genai

device = ""CPU""
pipe = ov_genai.LLMPipeline(model_path, device)
print(pipe.generate(""What is OpenVINO?"", max_length=200))
```

More GenAI usage examples can be found in OpenVINO GenAI library [docs](https://github.com/openvinotoolkit/openvino.genai/blob/master/src/README.md) and [samples](https://github.com/openvinotoolkit/openvino.genai?tab=readme-ov-file#openvino-genai-samples)
## Limitations

Check the original model card for [original model card](https://huggingface.co/google/gemma-7b-it) for limitations.

## Legal information

The original model is distributed under [gemma](https://choosealicense.com/licenses/gemma/) license. More details can be found in [original model card](https://huggingface.co/google/gemma-7b-it).

## Disclaimer

Intel is committed to respecting human rights and avoiding causing or contributing to adverse impacts on human rights. See [Intel’s Global Human Rights Principles](https://www.intel.com/content/dam/www/central-libraries/us/en/documents/policy-human-rights.pdf). Intel’s products and software are intended only to be used in applications that do not cause or contribute to adverse impacts on human rights.","{""id"": ""OpenVINO/gemma-7b-it-fp16-ov"", ""author"": ""OpenVINO"", ""sha"": ""74a2836ac41ce25b227d343d0bab2b4f50d81f04"", ""last_modified"": ""2024-11-05 10:43:57+00:00"", ""created_at"": ""2024-10-30 07:57:05+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 1, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": null, ""gguf"": null, ""inference"": null, ""tags"": [""openvino"", ""gemma"", ""base_model:google/gemma-7b-it"", ""base_model:finetune:google/gemma-7b-it"", ""license:gemma"", ""region:us""], ""pipeline_tag"": null, ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model:\n- google/gemma-7b-it\nlicense: gemma\nlicense_link: https://choosealicense.com/licenses/gemma/"", ""widget_data"": null, ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'user') != (loop.index0 % 2 == 0) %}{{ raise_exception('Conversation roles must alternate user/assistant/user/assistant/...') }}{% endif %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": null, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='generation_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='openvino_detokenizer.bin', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='openvino_detokenizer.xml', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='openvino_model.bin', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='openvino_model.xml', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='openvino_tokenizer.bin', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='openvino_tokenizer.xml', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2024-11-05 10:43:57+00:00"", ""cardData"": ""base_model:\n- google/gemma-7b-it\nlicense: gemma\nlicense_link: https://choosealicense.com/licenses/gemma/"", ""transformersInfo"": null, ""_id"": ""6721e6d1a6664a71cbd134c0"", ""modelId"": ""OpenVINO/gemma-7b-it-fp16-ov"", ""usedStorage"": 17129158949}",2,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=OpenVINO/gemma-7b-it-fp16-ov&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5BOpenVINO%2Fgemma-7b-it-fp16-ov%5D(%2FOpenVINO%2Fgemma-7b-it-fp16-ov)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
hyokwan/familidata_gemma7b,"---
license: mit
datasets:
- hyokwan/common
language:
- ko
metrics:
- accuracy
base_model:
- google/gemma-7b-it
pipeline_tag: text-generation
library_name: transformers
---
Model Details model

model is continued pretrained language model based on google/gemma-7b-it

This model is trained with specific department of university (Korea Plytechnics Fintech) .


Intended Use TBD

How to use TBD

Responsibility & Safety We believe that an open approach to AI leads to better, safer products, faster innovation, and a bigger overall market. We are committed to Responsible AI development and took a series of steps to limit misuse and harm and support the open source community.

Foundation models are widely capable technologies that are built to be used for a diverse range of applications. They are not designed to meet every developer preference on safety levels for all use cases, out-of-the-box, as those by their nature will differ across different applications.

Rather, responsible LLM-application deployment is achieved by implementing a series of safety best practices throughout the development of such applications, from the model pre-training, fine-tuning and the deployment of systems composed of safeguards to tailor the safety needs specifically to the use case and audience.

As part of the Llama 3 release, we updated our Responsible Use Guide to outline the steps and best practices for developers to implement model and system level safety for their application. We also provide a set of resources including Meta Llama Guard 2 and Code Shield safeguards. These tools have proven to drastically reduce residual risks of LLM Systems, while maintaining a high level of helpfulness. We encourage developers to tune and deploy these safeguards according to their needs and we provide a reference implementation to get you started.

Responsible release In addition to responsible use considerations outlined above, we followed a rigorous process that requires us to take extra measures against misuse and critical risks before we make our release decision.

Misuse



---
license: mit
datasets:
- hyokwan/common
language:
- ko
metrics:
- accuracy
base_model:
- google/gemma-7b-it
pipeline_tag: text-generation
library_name: transformers
tags:
- finance
- education
---","{""id"": ""hyokwan/familidata_gemma7b"", ""author"": ""hyokwan"", ""sha"": ""e8dbabcde843360b149601ceaead5724387c1962"", ""last_modified"": ""2024-11-12 12:32:47+00:00"", ""created_at"": ""2024-11-12 12:15:03+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 1742, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""safetensors"", ""gemma"", ""text-generation"", ""conversational"", ""ko"", ""dataset:hyokwan/common"", ""base_model:google/gemma-7b-it"", ""base_model:finetune:google/gemma-7b-it"", ""license:mit"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model:\n- google/gemma-7b-it\ndatasets:\n- hyokwan/common\nlanguage:\n- ko\nlibrary_name: transformers\nlicense: mit\nmetrics:\n- accuracy\npipeline_tag: text-generation"", ""widget_data"": null, ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'user') != (loop.index0 % 2 == 0) %}{{ raise_exception('Conversation roles must alternate user/assistant/user/assistant/...') }}{% endif %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<eos>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='generation_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00001-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00002-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00003-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00004-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model.safetensors.index.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": {""parameters"": {""F16"": 8537680896}, ""total"": 8537680896}, ""security_repo_status"": null, ""lastModified"": ""2024-11-12 12:32:47+00:00"", ""cardData"": ""base_model:\n- google/gemma-7b-it\ndatasets:\n- hyokwan/common\nlanguage:\n- ko\nlibrary_name: transformers\nlicense: mit\nmetrics:\n- accuracy\npipeline_tag: text-generation"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""673346c781bcaf17746a60f8"", ""modelId"": ""hyokwan/familidata_gemma7b"", ""usedStorage"": 17097150632}",2,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=hyokwan/familidata_gemma7b&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bhyokwan%2Ffamilidata_gemma7b%5D(%2Fhyokwan%2Ffamilidata_gemma7b)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
hyokwan/gemma_7b_hkcode20241126,"---
license: apache-2.0
datasets:
- hyokwan/common
language:
- ko
metrics:
- accuracy
base_model:
- google/gemma-7b-it
new_version: hyokwan/gemma_7b_hkcode20241126
pipeline_tag: text-generation
library_name: transformers
---
Model Details model

model is continued pretrained language model based on google/gemma-7b-it

This model is trained with specific department of university (Korea Plytechnics Fintech) .

Intended Use TBD

How to use TBD

Responsibility & Safety We believe that an open approach to AI leads to better, safer products, faster innovation, and a bigger overall market. We are committed to Responsible AI development and took a series of steps to limit misuse and harm and support the open source community.

Foundation models are widely capable technologies that are built to be used for a diverse range of applications. They are not designed to meet every developer preference on safety levels for all use cases, out-of-the-box, as those by their nature will differ across different applications.

Rather, responsible LLM-application deployment is achieved by implementing a series of safety best practices throughout the development of such applications, from the model pre-training, fine-tuning and the deployment of systems composed of safeguards to tailor the safety needs specifically to the use case and audience.

As part of the gemma release, we updated our Responsible Use Guide to outline the steps and best practices for developers to implement model and system level safety for their application. We also provide a set of resources including Meta Llama Guard 2 and Code Shield safeguards. These tools have proven to drastically reduce residual risks of LLM Systems, while maintaining a high level of helpfulness. We encourage developers to tune and deploy these safeguards according to their needs and we provide a reference implementation to get you started.

Responsible release In addition to responsible use considerations outlined above, we followed a rigorous process that requires us to take extra measures against misuse and critical risks before we make our release decision.

Misuse


---
license: apache-2.0
datasets:
- hyokwan/common
language:
- ko
metrics:
- accuracy
base_model:
- google/gemma-7b-it
new_version: hyokwan/gemma_7b_hkcode20241126
pipeline_tag: text-generation
library_name: transformers
tags:
- university
---","{""id"": ""hyokwan/gemma_7b_hkcode20241126"", ""author"": ""hyokwan"", ""sha"": ""b9111b5f5ea32c47214cb275b8ac0b413ba59eff"", ""last_modified"": ""2024-11-29 00:57:01+00:00"", ""created_at"": ""2024-11-26 00:50:04+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 1751, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""safetensors"", ""gemma"", ""text-generation"", ""conversational"", ""ko"", ""dataset:hyokwan/common"", ""base_model:google/gemma-7b-it"", ""base_model:finetune:google/gemma-7b-it"", ""license:apache-2.0"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model:\n- google/gemma-7b-it\ndatasets:\n- hyokwan/common\nlanguage:\n- ko\nlibrary_name: transformers\nlicense: apache-2.0\nmetrics:\n- accuracy\npipeline_tag: text-generation\nnew_version: hyokwan/gemma_7b_hkcode20241126"", ""widget_data"": null, ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'user') != (loop.index0 % 2 == 0) %}{{ raise_exception('Conversation roles must alternate user/assistant/user/assistant/...') }}{% endif %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<eos>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='generation_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00001-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00002-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00003-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00004-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model.safetensors.index.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": {""parameters"": {""F16"": 8537680896}, ""total"": 8537680896}, ""security_repo_status"": null, ""lastModified"": ""2024-11-29 00:57:01+00:00"", ""cardData"": ""base_model:\n- google/gemma-7b-it\ndatasets:\n- hyokwan/common\nlanguage:\n- ko\nlibrary_name: transformers\nlicense: apache-2.0\nmetrics:\n- accuracy\npipeline_tag: text-generation\nnew_version: hyokwan/gemma_7b_hkcode20241126"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67451b3c55df0b402fccce13"", ""modelId"": ""hyokwan/gemma_7b_hkcode20241126"", ""usedStorage"": 17097150632}",2,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=hyokwan/gemma_7b_hkcode20241126&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bhyokwan%2Fgemma_7b_hkcode20241126%5D(%2Fhyokwan%2Fgemma_7b_hkcode20241126)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
hyokwan/kopo_gemma_7b_it_20241202,"---
license: apache-2.0
datasets:
- hyokwan/hkcode_20241202
language:
- ko
metrics:
- accuracy
base_model:
- google/gemma-7b-it
new_version: hyokwan/kopo_gemma_7b_it_20241202
pipeline_tag: text-generation
library_name: transformers
tags:
- university
---
Model Details model

model is continued pretrained language model based on google/gemma-7b-it

This model is trained with specific department of university (Korea Polytechnics Fintech) .

Intended Use TBD

How to use TBD

Responsibility & Safety We believe that an open approach to AI leads to better, safer products, faster innovation, and a bigger overall market. We are committed to Responsible AI development and took a series of steps to limit misuse and harm and support the open source community.

Foundation models are widely capable technologies that are built to be used for a diverse range of applications. They are not designed to meet every developer preference on safety levels for all use cases, out-of-the-box, as those by their nature will differ across different applications.

Rather, responsible LLM-application deployment is achieved by implementing a series of safety best practices throughout the development of such applications, from the model pre-training, fine-tuning and the deployment of systems composed of safeguards to tailor the safety needs specifically to the use case and audience.

As part of the gemma release, we updated our Responsible Use Guide to outline the steps and best practices for developers to implement model and system level safety for their application. We also provide a set of resources including Meta Llama Guard 2 and Code Shield safeguards. These tools have proven to drastically reduce residual risks of LLM Systems, while maintaining a high level of helpfulness. We encourage developers to tune and deploy these safeguards according to their needs and we provide a reference implementation to get you started.

Responsible release In addition to responsible use considerations outlined above, we followed a rigorous process that requires us to take extra measures against misuse and critical risks before we make our release decision.

Misuse

---
license: apache-2.0
---","{""id"": ""hyokwan/kopo_gemma_7b_it_20241202"", ""author"": ""hyokwan"", ""sha"": ""c05bd3b5fa3df391d376bd3b665e989a252170d3"", ""last_modified"": ""2024-12-02 04:31:42+00:00"", ""created_at"": ""2024-12-02 04:20:10+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""safetensors"", ""gemma"", ""text-generation"", ""university"", ""conversational"", ""ko"", ""dataset:hyokwan/hkcode_20241202"", ""base_model:google/gemma-7b-it"", ""base_model:finetune:google/gemma-7b-it"", ""license:apache-2.0"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model:\n- google/gemma-7b-it\ndatasets:\n- hyokwan/hkcode_20241202\nlanguage:\n- ko\nlibrary_name: transformers\nlicense: apache-2.0\nmetrics:\n- accuracy\npipeline_tag: text-generation\ntags:\n- university\nnew_version: hyokwan/kopo_gemma_7b_it_20241202"", ""widget_data"": null, ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'user') != (loop.index0 % 2 == 0) %}{{ raise_exception('Conversation roles must alternate user/assistant/user/assistant/...') }}{% endif %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<eos>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='generation_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00001-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00002-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00003-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00004-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model.safetensors.index.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": {""parameters"": {""F16"": 8537680896}, ""total"": 8537680896}, ""security_repo_status"": null, ""lastModified"": ""2024-12-02 04:31:42+00:00"", ""cardData"": ""base_model:\n- google/gemma-7b-it\ndatasets:\n- hyokwan/hkcode_20241202\nlanguage:\n- ko\nlibrary_name: transformers\nlicense: apache-2.0\nmetrics:\n- accuracy\npipeline_tag: text-generation\ntags:\n- university\nnew_version: hyokwan/kopo_gemma_7b_it_20241202"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""674d357a4e69219448af8560"", ""modelId"": ""hyokwan/kopo_gemma_7b_it_20241202"", ""usedStorage"": 17113988148}",2,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=hyokwan/kopo_gemma_7b_it_20241202&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bhyokwan%2Fkopo_gemma_7b_it_20241202%5D(%2Fhyokwan%2Fkopo_gemma_7b_it_20241202)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
atm77777/model77,"---
license: apache-2.0
datasets:
- atm77777/youtube
language:
- ko
metrics:
- accuracy
base_model:
- google/gemma-7b-it
new_version: atm77777/model77
pipeline_tag: text-generation
library_name: transformers
tags:
- university
---
Model Details model

model is continued pretrained language model based on google/gemma-7b-it

This model is trained with specific department of university (Korea Plytechnics Fintech) .

Intended Use TBD

How to use TBD

Responsibility & Safety We believe that an open approach to AI leads to better, safer products, faster innovation, and a bigger overall market. We are committed to Responsible AI development and took a series of steps to limit misuse and harm and support the open source community.

Foundation models are widely capable technologies that are built to be used for a diverse range of applications. They are not designed to meet every developer preference on safety levels for all use cases, out-of-the-box, as those by their nature will differ across different applications.

Rather, responsible LLM-application deployment is achieved by implementing a series of safety best practices throughout the development of such applications, from the model pre-training, fine-tuning and the deployment of systems composed of safeguards to tailor the safety needs specifically to the use case and audience.

As part of the gemma release, we updated our Responsible Use Guide to outline the steps and best practices for developers to implement model and system level safety for their application. We also provide a set of resources including Meta Llama Guard 2 and Code Shield safeguards. These tools have proven to drastically reduce residual risks of LLM Systems, while maintaining a high level of helpfulness. We encourage developers to tune and deploy these safeguards according to their needs and we provide a reference implementation to get you started.

Responsible release In addition to responsible use considerations outlined above, we followed a rigorous process that requires us to take extra measures against misuse and critical risks before we make our release decision.

Misuse

---
---
---","{""id"": ""atm77777/model77"", ""author"": ""atm77777"", ""sha"": ""663d66027709c8e5b415c2ffb74da36b9dae1b20"", ""last_modified"": ""2024-12-02 09:43:49+00:00"", ""created_at"": ""2024-12-02 09:27:30+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""safetensors"", ""gemma"", ""text-generation"", ""university"", ""conversational"", ""ko"", ""dataset:atm77777/youtube"", ""base_model:google/gemma-7b-it"", ""base_model:finetune:google/gemma-7b-it"", ""license:apache-2.0"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model:\n- google/gemma-7b-it\ndatasets:\n- atm77777/youtube\nlanguage:\n- ko\nlibrary_name: transformers\nlicense: apache-2.0\nmetrics:\n- accuracy\npipeline_tag: text-generation\ntags:\n- university\nnew_version: atm77777/model77"", ""widget_data"": null, ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'user') != (loop.index0 % 2 == 0) %}{{ raise_exception('Conversation roles must alternate user/assistant/user/assistant/...') }}{% endif %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<eos>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='generation_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00001-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00002-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00003-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00004-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model.safetensors.index.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": {""parameters"": {""F16"": 8537680896}, ""total"": 8537680896}, ""security_repo_status"": null, ""lastModified"": ""2024-12-02 09:43:49+00:00"", ""cardData"": ""base_model:\n- google/gemma-7b-it\ndatasets:\n- atm77777/youtube\nlanguage:\n- ko\nlibrary_name: transformers\nlicense: apache-2.0\nmetrics:\n- accuracy\npipeline_tag: text-generation\ntags:\n- university\nnew_version: atm77777/model77"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""674d7d8271743cff46fd0a99"", ""modelId"": ""atm77777/model77"", ""usedStorage"": 17097150632}",2,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=atm77777/model77&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Batm77777%2Fmodel77%5D(%2Fatm77777%2Fmodel77)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
doubleyyh/exit-gemma-7b,"---
language: en
tags:
- rag
- context-compression
- gemma
license: apache-2.0
datasets:
- hotpotqa
base_model:
- google/gemma-7b-it
---

# EXIT: Context-Aware Extractive Compression for RAG

EXIT is a context-aware extractive compression model that improves the efficiency and effectiveness of Retrieval-Augmented Generation (RAG) by intelligently selecting relevant sentences while preserving contextual dependencies.

[[Paper]](https://arxiv.org/abs/2412.12559) [[GitHub]](https://github.com/ThisIsHwang/EXIT)

## Model Description

EXIT is designed to:
- Compress retrieved documents while preserving critical information
- Consider full document context when evaluating sentence importance 
- Enable parallelizable, context-aware extraction
- Adapt dynamically to query complexity
- Balance compression ratio and answer accuracy

## Task and Intended Use

EXIT is trained to classify sentences as either relevant or irrelevant for answering a query based on their content and surrounding context. It is specifically designed for:

- RAG context compression
- Open-domain question answering
- Both single-hop and multi-hop queries

## Quickstart

```python
import torch
from transformers import AutoModelForCausalLM, AutoTokenizer
from peft import PeftModel
import spacy

# 1. Load models
base_model = AutoModelForCausalLM.from_pretrained(
    ""google/gemma-7b-it"",
    device_map=""auto"",
    torch_dtype=torch.float16
)
exit_model = PeftModel.from_pretrained(
    base_model, 
    ""doubleyyh/exit-gemma-7b""
)
tokenizer = AutoTokenizer.from_pretrained(""google/gemma-7b-it"")

# 2. Initialize sentence splitter
nlp = spacy.load(""en_core_web_sm"", disable=[
    ""tok2vec"", ""tagger"", ""parser"", ""attribute_ruler"", 
    ""lemmatizer"", ""ner""
])
nlp.enable_pipe(""senter"")

# 3. Input
query = ""How do solid-state drives (SSDs) improve computer performance?""
context = """"""
Solid-state drives use flash memory to store data without moving parts.
Unlike traditional hard drives, SSDs have no mechanical components.
The absence of physical movement allows for much faster data access speeds.
I bought my computer last week.
SSDs significantly reduce boot times and application loading speeds.
They consume less power and are more reliable than mechanical drives.
The price of SSDs has decreased significantly in recent years.
""""""

# 4. Process sentences
def get_relevance(query: str, context: str, sentence: str, tau: float = 0.5) -> bool:
    prompt = f'''<start_of_turn>user
Query:
{query}
Full context:
{context}
Sentence:
{sentence}
Is this sentence useful in answering the query? Answer only ""Yes"" or ""No"".<end_of_turn>
<start_of_turn>model
'''
    inputs = tokenizer(prompt, return_tensors=""pt"").to(exit_model.device)
    
    with torch.no_grad():
        outputs = exit_model(**inputs)
        yes_id = tokenizer.encode(""Yes"", add_special_tokens=False)
        no_id = tokenizer.encode(""No"", add_special_tokens=False)
        logits = outputs.logits[0, -1, [yes_id, no_id]]
        prob = torch.softmax(logits, dim=0)[0].item()
        
    return prob >= tau

# 5. Compress document
sentences = [sent.text.strip() for sent in nlp(context).sents]
compressed = [sent for sent in sentences if get_relevance(query, context, sent)]
compressed_text = "" "".join(compressed)

print(f""Compressed text ({len(compressed)}/{len(sentences)} sentences):"", compressed_text)
```

## Training Data

The model was trained on the HotpotQA dataset using:
- Positive examples: Sentences marked as supporting facts
- Hard negatives: Sentences from same documents but not supporting facts  
- Random negatives: Sentences from unrelated documents

## Parameters

- Base model: Gemma-7b-it
- Training method: PEFT/LoRA
- Recommended tau threshold: 0.5

## Limitations

- Currently optimized for English text only
- No support for cross-lingual compression

## Citation

```bibtex
@article{hwang2024exit,
  title={EXIT: Context-Aware Extractive Compression for Enhancing Retrieval-Augmented Generation},
  author={Hwang, Taeho and Cho, Sukmin and Jeong, Soyeong and Song, Hoyun and Han, SeungYoon and Park, Jong C.},
  journal={arXiv preprint arXiv:2412.12559},
  year={2024}
}
```","{""id"": ""doubleyyh/exit-gemma-7b"", ""author"": ""doubleyyh"", ""sha"": ""d87d48577ce52683edecf87b79b68f73e9b170c4"", ""last_modified"": ""2024-12-21 07:51:11+00:00"", ""created_at"": ""2024-12-21 07:41:24+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": null, ""gguf"": null, ""inference"": null, ""tags"": [""safetensors"", ""rag"", ""context-compression"", ""gemma"", ""en"", ""dataset:hotpotqa"", ""arxiv:2412.12559"", ""base_model:google/gemma-7b-it"", ""base_model:finetune:google/gemma-7b-it"", ""license:apache-2.0"", ""region:us""], ""pipeline_tag"": null, ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model:\n- google/gemma-7b-it\ndatasets:\n- hotpotqa\nlanguage: en\nlicense: apache-2.0\ntags:\n- rag\n- context-compression\n- gemma"", ""widget_data"": null, ""model_index"": null, ""config"": {""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'user') != (loop.index0 % 2 == 0) %}{{ raise_exception('Conversation roles must alternate user/assistant/user/assistant/...') }}{% endif %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": null, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='generation_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2024-12-21 07:51:11+00:00"", ""cardData"": ""base_model:\n- google/gemma-7b-it\ndatasets:\n- hotpotqa\nlanguage: en\nlicense: apache-2.0\ntags:\n- rag\n- context-compression\n- gemma"", ""transformersInfo"": null, ""_id"": ""67667124f30e323531dee8a7"", ""modelId"": ""doubleyyh/exit-gemma-7b"", ""usedStorage"": 838713500}",2,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=doubleyyh/exit-gemma-7b&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bdoubleyyh%2Fexit-gemma-7b%5D(%2Fdoubleyyh%2Fexit-gemma-7b)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
matrixportal/gemma-7b-it-GGUF,"---
library_name: transformers
license: gemma
tags:
- llama-cpp
- gguf-my-repo
widget:
- messages:
  - role: user
    content: How does the brain work?
inference:
  parameters:
    max_new_tokens: 200
extra_gated_heading: Access Gemma on Hugging Face
extra_gated_prompt: To access Gemma on Hugging Face, you’re required to review and
  agree to Google’s usage license. To do this, please ensure you’re logged-in to Hugging
  Face and click below. Requests are processed immediately.
extra_gated_button_content: Acknowledge license
base_model: google/gemma-7b-it
base_model_relation: finetune
---

# matrixportal/gemma-7b-it-GGUF
This model was converted to GGUF format from [`google/gemma-7b-it`](https://huggingface.co/google/gemma-7b-it) using llama.cpp via the ggml.ai's [GGUF-my-repo](https://huggingface.co/spaces/ggml-org/gguf-my-repo) space.
Refer to the [original model card](https://huggingface.co/google/gemma-7b-it) for more details on the model.

## Use with llama.cpp
Install llama.cpp through brew (works on Mac and Linux)

```bash
brew install llama.cpp

```
Invoke the llama.cpp server or the CLI.

### CLI:
```bash
llama-cli --hf-repo matrixportal/gemma-7b-it-GGUF --hf-file gemma-7b-it-q4_k_m.gguf -p ""The meaning to life and the universe is""
```

### Server:
```bash
llama-server --hf-repo matrixportal/gemma-7b-it-GGUF --hf-file gemma-7b-it-q4_k_m.gguf -c 2048
```

Note: You can also use this checkpoint directly through the [usage steps](https://github.com/ggerganov/llama.cpp?tab=readme-ov-file#usage) listed in the Llama.cpp repo as well.

Step 1: Clone llama.cpp from GitHub.
```
git clone https://github.com/ggerganov/llama.cpp
```

Step 2: Move into the llama.cpp folder and build it with `LLAMA_CURL=1` flag along with other hardware-specific flags (for ex: LLAMA_CUDA=1 for Nvidia GPUs on Linux).
```
cd llama.cpp && LLAMA_CURL=1 make
```

Step 3: Run inference through the main binary.
```
./llama-cli --hf-repo matrixportal/gemma-7b-it-GGUF --hf-file gemma-7b-it-q4_k_m.gguf -p ""The meaning to life and the universe is""
```
or 
```
./llama-server --hf-repo matrixportal/gemma-7b-it-GGUF --hf-file gemma-7b-it-q4_k_m.gguf -c 2048
```
","{""id"": ""matrixportal/gemma-7b-it-GGUF"", ""author"": ""matrixportal"", ""sha"": ""2713ebde51a97986ba0d055d2ed24fca9575a647"", ""last_modified"": ""2025-01-20 20:47:48+00:00"", ""created_at"": ""2025-01-20 20:47:13+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 3, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": {""total"": 8537680896, ""architecture"": ""gemma"", ""context_length"": 8192, ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'user') != (loop.index0 % 2 == 0) %}{{ raise_exception('Conversation roles must alternate user/assistant/user/assistant/...') }}{% endif %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}"", ""bos_token"": ""<bos>"", ""eos_token"": ""<eos>""}, ""inference"": null, ""tags"": [""transformers"", ""gguf"", ""llama-cpp"", ""gguf-my-repo"", ""base_model:google/gemma-7b-it"", ""base_model:finetune:google/gemma-7b-it"", ""license:gemma"", ""endpoints_compatible"", ""region:us"", ""conversational""], ""pipeline_tag"": null, ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b-it\nlibrary_name: transformers\nlicense: gemma\ntags:\n- llama-cpp\n- gguf-my-repo\nwidget:\n- messages:\n  - role: user\n    content: How does the brain work?\ninference:\n  parameters:\n    max_new_tokens: 200\nextra_gated_heading: Access Gemma on Hugging Face\nextra_gated_prompt: To access Gemma on Hugging Face, you\u2019re required to review and\n  agree to Google\u2019s usage license. To do this, please ensure you\u2019re logged-in to Hugging\n  Face and click below. Requests are processed immediately.\nextra_gated_button_content: Acknowledge license\nbase_model_relation: finetune"", ""widget_data"": [{""messages"": [{""role"": ""user"", ""content"": ""How does the brain work?""}]}], ""model_index"": null, ""config"": null, ""transformers_info"": {""auto_model"": ""AutoModel"", ""custom_class"": null, ""pipeline_tag"": null, ""processor"": null}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='gemma-7b-it-q4_k_m.gguf', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-01-20 20:47:48+00:00"", ""cardData"": ""base_model: google/gemma-7b-it\nlibrary_name: transformers\nlicense: gemma\ntags:\n- llama-cpp\n- gguf-my-repo\nwidget:\n- messages:\n  - role: user\n    content: How does the brain work?\ninference:\n  parameters:\n    max_new_tokens: 200\nextra_gated_heading: Access Gemma on Hugging Face\nextra_gated_prompt: To access Gemma on Hugging Face, you\u2019re required to review and\n  agree to Google\u2019s usage license. To do this, please ensure you\u2019re logged-in to Hugging\n  Face and click below. Requests are processed immediately.\nextra_gated_button_content: Acknowledge license\nbase_model_relation: finetune"", ""transformersInfo"": {""auto_model"": ""AutoModel"", ""custom_class"": null, ""pipeline_tag"": null, ""processor"": null}, ""_id"": ""678eb6517a31429ac721dd49"", ""modelId"": ""matrixportal/gemma-7b-it-GGUF"", ""usedStorage"": 5329759776}",2,,0,,0,,0,"ggml-org/gguf-my-repo, huggingface/InferenceSupport/discussions/new?title=matrixportal/gemma-7b-it-GGUF&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bmatrixportal%2Fgemma-7b-it-GGUF%5D(%2Fmatrixportal%2Fgemma-7b-it-GGUF)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A",2,,
wandb/gemma-7b-zephyr-sft,"---
license: other
library_name: transformers
datasets:
- HuggingFaceH4/ultrachat_200k
base_model: google/gemma-7b
license_name: gemma-terms-of-use
license_link: https://ai.google.dev/gemma/terms
model-index:
- name: gemma-7b-zephyr-sft
  results:
  - task:
      type: text-generation
      name: Text Generation
    dataset:
      name: AI2 Reasoning Challenge (25-Shot)
      type: ai2_arc
      config: ARC-Challenge
      split: test
      args:
        num_few_shot: 25
    metrics:
    - type: acc_norm
      value: 61.43
      name: normalized accuracy
    source:
      url: https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard?query=wandb/gemma-7b-zephyr-sft
      name: Open LLM Leaderboard
  - task:
      type: text-generation
      name: Text Generation
    dataset:
      name: HellaSwag (10-Shot)
      type: hellaswag
      split: validation
      args:
        num_few_shot: 10
    metrics:
    - type: acc_norm
      value: 80.73
      name: normalized accuracy
    source:
      url: https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard?query=wandb/gemma-7b-zephyr-sft
      name: Open LLM Leaderboard
  - task:
      type: text-generation
      name: Text Generation
    dataset:
      name: MMLU (5-Shot)
      type: cais/mmlu
      config: all
      split: test
      args:
        num_few_shot: 5
    metrics:
    - type: acc
      value: 60.33
      name: accuracy
    source:
      url: https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard?query=wandb/gemma-7b-zephyr-sft
      name: Open LLM Leaderboard
  - task:
      type: text-generation
      name: Text Generation
    dataset:
      name: TruthfulQA (0-shot)
      type: truthful_qa
      config: multiple_choice
      split: validation
      args:
        num_few_shot: 0
    metrics:
    - type: mc2
      value: 43.35
    source:
      url: https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard?query=wandb/gemma-7b-zephyr-sft
      name: Open LLM Leaderboard
  - task:
      type: text-generation
      name: Text Generation
    dataset:
      name: Winogrande (5-shot)
      type: winogrande
      config: winogrande_xl
      split: validation
      args:
        num_few_shot: 5
    metrics:
    - type: acc
      value: 74.19
      name: accuracy
    source:
      url: https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard?query=wandb/gemma-7b-zephyr-sft
      name: Open LLM Leaderboard
  - task:
      type: text-generation
      name: Text Generation
    dataset:
      name: GSM8k (5-shot)
      type: gsm8k
      config: main
      split: test
      args:
        num_few_shot: 5
    metrics:
    - type: acc
      value: 49.81
      name: accuracy
    source:
      url: https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard?query=wandb/gemma-7b-zephyr-sft
      name: Open LLM Leaderboard
---

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""200"" height=""32""/>](https://wandb.ai/llm_surgery/gemma-zephyr)

# Gemma 7B Zephyr SFT

The [Zephyr](https://huggingface.co/HuggingFaceH4/zephyr-7b-beta) SFT recipe applied on top of Gemma 7B

## Model description

- **Model type:** A 8.5B parameter GPT-like model fine-tuned on a mix of publicly available, synthetic datasets.
- **Language(s) (NLP):** Primarily English
- **Finetuned from model:** [google/gemma-7b](https://huggingface.co/google/gemma-7b)

## Recipe

We trained using the [alignment handbook recipe](https://github.com/huggingface/alignment-handbook/blob/main/scripts/run_sft.py) and logging to W&B

Visit the [W&B workspace here](https://wandb.ai/llm_surgery/gemma-zephyr?nw=nwusercapecape)

## License
This model has the same license as the [original Gemma model collection](https://ai.google.dev/gemma/terms)

## Compute provided by Lambda Labs - 8xA100 80GB node

# [Open LLM Leaderboard Evaluation Results](https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard)
Detailed results can be found [here](https://huggingface.co/datasets/open-llm-leaderboard/details_wandb__gemma-7b-zephyr-sft)

|             Metric              |Value|
|---------------------------------|----:|
|Avg.                             |61.64|
|AI2 Reasoning Challenge (25-Shot)|61.43|
|HellaSwag (10-Shot)              |80.73|
|MMLU (5-Shot)                    |60.33|
|TruthfulQA (0-shot)              |43.35|
|Winogrande (5-shot)              |74.19|
|GSM8k (5-shot)                   |49.81|

","{""id"": ""wandb/gemma-7b-zephyr-sft"", ""author"": ""wandb"", ""sha"": ""b65841649af9ee93f7636c739da8427a988625b4"", ""last_modified"": ""2024-03-04 12:54:59+00:00"", ""created_at"": ""2024-02-28 11:20:03+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 21, ""downloads_all_time"": null, ""likes"": 2, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""safetensors"", ""gemma"", ""text-generation"", ""conversational"", ""dataset:HuggingFaceH4/ultrachat_200k"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""license:other"", ""model-index"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- HuggingFaceH4/ultrachat_200k\nlibrary_name: transformers\nlicense: other\nlicense_name: gemma-terms-of-use\nlicense_link: https://ai.google.dev/gemma/terms\nmodel-index:\n- name: gemma-7b-zephyr-sft\n  results:\n  - task:\n      type: text-generation\n      name: Text Generation\n    dataset:\n      name: AI2 Reasoning Challenge (25-Shot)\n      type: ai2_arc\n      config: ARC-Challenge\n      split: test\n      args:\n        num_few_shot: 25\n    metrics:\n    - type: acc_norm\n      value: 61.43\n      name: normalized accuracy\n      verified: false\n    source:\n      url: https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard?query=wandb/gemma-7b-zephyr-sft\n      name: Open LLM Leaderboard\n  - task:\n      type: text-generation\n      name: Text Generation\n    dataset:\n      name: HellaSwag (10-Shot)\n      type: hellaswag\n      split: validation\n      args:\n        num_few_shot: 10\n    metrics:\n    - type: acc_norm\n      value: 80.73\n      name: normalized accuracy\n      verified: false\n    source:\n      url: https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard?query=wandb/gemma-7b-zephyr-sft\n      name: Open LLM Leaderboard\n  - task:\n      type: text-generation\n      name: Text Generation\n    dataset:\n      name: MMLU (5-Shot)\n      type: cais/mmlu\n      config: all\n      split: test\n      args:\n        num_few_shot: 5\n    metrics:\n    - type: acc\n      value: 60.33\n      name: accuracy\n      verified: false\n    source:\n      url: https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard?query=wandb/gemma-7b-zephyr-sft\n      name: Open LLM Leaderboard\n  - task:\n      type: text-generation\n      name: Text Generation\n    dataset:\n      name: TruthfulQA (0-shot)\n      type: truthful_qa\n      config: multiple_choice\n      split: validation\n      args:\n        num_few_shot: 0\n    metrics:\n    - type: mc2\n      value: 43.35\n      verified: false\n    source:\n      url: https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard?query=wandb/gemma-7b-zephyr-sft\n      name: Open LLM Leaderboard\n  - task:\n      type: text-generation\n      name: Text Generation\n    dataset:\n      name: Winogrande (5-shot)\n      type: winogrande\n      config: winogrande_xl\n      split: validation\n      args:\n        num_few_shot: 5\n    metrics:\n    - type: acc\n      value: 74.19\n      name: accuracy\n      verified: false\n    source:\n      url: https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard?query=wandb/gemma-7b-zephyr-sft\n      name: Open LLM Leaderboard\n  - task:\n      type: text-generation\n      name: Text Generation\n    dataset:\n      name: GSM8k (5-shot)\n      type: gsm8k\n      config: main\n      split: test\n      args:\n        num_few_shot: 5\n    metrics:\n    - type: acc\n      value: 49.81\n      name: accuracy\n      verified: false\n    source:\n      url: https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard?query=wandb/gemma-7b-zephyr-sft\n      name: Open LLM Leaderboard"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": [{""name"": ""gemma-7b-zephyr-sft"", ""results"": [{""task"": {""type"": ""text-generation"", ""name"": ""Text Generation""}, ""dataset"": {""name"": ""AI2 Reasoning Challenge (25-Shot)"", ""type"": ""ai2_arc"", ""config"": ""ARC-Challenge"", ""split"": ""test"", ""args"": {""num_few_shot"": 25}}, ""metrics"": [{""type"": ""acc_norm"", ""value"": 61.43, ""name"": ""normalized accuracy"", ""verified"": false}], ""source"": {""url"": ""https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard?query=wandb/gemma-7b-zephyr-sft"", ""name"": ""Open LLM Leaderboard""}}, {""task"": {""type"": ""text-generation"", ""name"": ""Text Generation""}, ""dataset"": {""name"": ""HellaSwag (10-Shot)"", ""type"": ""hellaswag"", ""split"": ""validation"", ""args"": {""num_few_shot"": 10}}, ""metrics"": [{""type"": ""acc_norm"", ""value"": 80.73, ""name"": ""normalized accuracy"", ""verified"": false}], ""source"": {""url"": ""https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard?query=wandb/gemma-7b-zephyr-sft"", ""name"": ""Open LLM Leaderboard""}}, {""task"": {""type"": ""text-generation"", ""name"": ""Text Generation""}, ""dataset"": {""name"": ""MMLU (5-Shot)"", ""type"": ""cais/mmlu"", ""config"": ""all"", ""split"": ""test"", ""args"": {""num_few_shot"": 5}}, ""metrics"": [{""type"": ""acc"", ""value"": 60.33, ""name"": ""accuracy"", ""verified"": false}], ""source"": {""url"": ""https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard?query=wandb/gemma-7b-zephyr-sft"", ""name"": ""Open LLM Leaderboard""}}, {""task"": {""type"": ""text-generation"", ""name"": ""Text Generation""}, ""dataset"": {""name"": ""TruthfulQA (0-shot)"", ""type"": ""truthful_qa"", ""config"": ""multiple_choice"", ""split"": ""validation"", ""args"": {""num_few_shot"": 0}}, ""metrics"": [{""type"": ""mc2"", ""value"": 43.35, ""verified"": false}], ""source"": {""url"": ""https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard?query=wandb/gemma-7b-zephyr-sft"", ""name"": ""Open LLM Leaderboard""}}, {""task"": {""type"": ""text-generation"", ""name"": ""Text Generation""}, ""dataset"": {""name"": ""Winogrande (5-shot)"", ""type"": ""winogrande"", ""config"": ""winogrande_xl"", ""split"": ""validation"", ""args"": {""num_few_shot"": 5}}, ""metrics"": [{""type"": ""acc"", ""value"": 74.19, ""name"": ""accuracy"", ""verified"": false}], ""source"": {""url"": ""https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard?query=wandb/gemma-7b-zephyr-sft"", ""name"": ""Open LLM Leaderboard""}}, {""task"": {""type"": ""text-generation"", ""name"": ""Text Generation""}, ""dataset"": {""name"": ""GSM8k (5-shot)"", ""type"": ""gsm8k"", ""config"": ""main"", ""split"": ""test"", ""args"": {""num_few_shot"": 5}}, ""metrics"": [{""type"": ""acc"", ""value"": 49.81, ""name"": ""accuracy"", ""verified"": false}], ""source"": {""url"": ""https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard?query=wandb/gemma-7b-zephyr-sft"", ""name"": ""Open LLM Leaderboard""}}]}], ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{% for message in messages %}\n{% if message['role'] == 'user' %}\n{{ '<|user|>\n' + message['content'] + eos_token }}\n{% elif message['role'] == 'system' %}\n{{ '<|system|>\n' + message['content'] + eos_token }}\n{% elif message['role'] == 'assistant' %}\n{{ '<|assistant|>\n'  + message['content'] + eos_token }}\n{% endif %}\n{% if loop.last and add_generation_prompt %}\n{{ '<|assistant|>' }}\n{% endif %}\n{% endfor %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='generation_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00001-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00002-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00003-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00004-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model.safetensors.index.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": {""parameters"": {""BF16"": 8537680896}, ""total"": 8537680896}, ""security_repo_status"": null, ""lastModified"": ""2024-03-04 12:54:59+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- HuggingFaceH4/ultrachat_200k\nlibrary_name: transformers\nlicense: other\nlicense_name: gemma-terms-of-use\nlicense_link: https://ai.google.dev/gemma/terms\nmodel-index:\n- name: gemma-7b-zephyr-sft\n  results:\n  - task:\n      type: text-generation\n      name: Text Generation\n    dataset:\n      name: AI2 Reasoning Challenge (25-Shot)\n      type: ai2_arc\n      config: ARC-Challenge\n      split: test\n      args:\n        num_few_shot: 25\n    metrics:\n    - type: acc_norm\n      value: 61.43\n      name: normalized accuracy\n      verified: false\n    source:\n      url: https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard?query=wandb/gemma-7b-zephyr-sft\n      name: Open LLM Leaderboard\n  - task:\n      type: text-generation\n      name: Text Generation\n    dataset:\n      name: HellaSwag (10-Shot)\n      type: hellaswag\n      split: validation\n      args:\n        num_few_shot: 10\n    metrics:\n    - type: acc_norm\n      value: 80.73\n      name: normalized accuracy\n      verified: false\n    source:\n      url: https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard?query=wandb/gemma-7b-zephyr-sft\n      name: Open LLM Leaderboard\n  - task:\n      type: text-generation\n      name: Text Generation\n    dataset:\n      name: MMLU (5-Shot)\n      type: cais/mmlu\n      config: all\n      split: test\n      args:\n        num_few_shot: 5\n    metrics:\n    - type: acc\n      value: 60.33\n      name: accuracy\n      verified: false\n    source:\n      url: https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard?query=wandb/gemma-7b-zephyr-sft\n      name: Open LLM Leaderboard\n  - task:\n      type: text-generation\n      name: Text Generation\n    dataset:\n      name: TruthfulQA (0-shot)\n      type: truthful_qa\n      config: multiple_choice\n      split: validation\n      args:\n        num_few_shot: 0\n    metrics:\n    - type: mc2\n      value: 43.35\n      verified: false\n    source:\n      url: https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard?query=wandb/gemma-7b-zephyr-sft\n      name: Open LLM Leaderboard\n  - task:\n      type: text-generation\n      name: Text Generation\n    dataset:\n      name: Winogrande (5-shot)\n      type: winogrande\n      config: winogrande_xl\n      split: validation\n      args:\n        num_few_shot: 5\n    metrics:\n    - type: acc\n      value: 74.19\n      name: accuracy\n      verified: false\n    source:\n      url: https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard?query=wandb/gemma-7b-zephyr-sft\n      name: Open LLM Leaderboard\n  - task:\n      type: text-generation\n      name: Text Generation\n    dataset:\n      name: GSM8k (5-shot)\n      type: gsm8k\n      config: main\n      split: test\n      args:\n        num_few_shot: 5\n    metrics:\n    - type: acc\n      value: 49.81\n      name: accuracy\n      verified: false\n    source:\n      url: https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard?query=wandb/gemma-7b-zephyr-sft\n      name: Open LLM Leaderboard"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""65df16e3dea1ab1ad3ed2208"", ""modelId"": ""wandb/gemma-7b-zephyr-sft"", ""usedStorage"": 51243621921}",1,https://huggingface.co/wandb/gemma-7b-zephyr-dpo,1,,0,,0,"HuggingFaceH4/open_llm_leaderboard?query=wandb/gemma-7b-zephyr-sft, huggingface/InferenceSupport/discussions/new?title=wandb/gemma-7b-zephyr-sft&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bwandb%2Fgemma-7b-zephyr-sft%5D(%2Fwandb%2Fgemma-7b-zephyr-sft)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A",2,,
wandb/gemma-7b-zephyr-dpo,"---
license: other
library_name: transformers
datasets:
- HuggingFaceH4/ultrafeedback_binarized
base_model: wandb/gemma-7b-zephyr-sft
license_name: gemma-terms-of-use
license_link: https://ai.google.dev/gemma/terms
model-index:
- name: gemma-7b-zephyr-dpo
  results:
  - task:
      type: text-generation
      name: Text Generation
    dataset:
      name: AI2 Reasoning Challenge (25-Shot)
      type: ai2_arc
      config: ARC-Challenge
      split: test
      args:
        num_few_shot: 25
    metrics:
    - type: acc_norm
      value: 60.84
      name: normalized accuracy
    source:
      url: https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard?query=tcapelle/gemma-7b-zephyr-dpo
      name: Open LLM Leaderboard
  - task:
      type: text-generation
      name: Text Generation
    dataset:
      name: HellaSwag (10-Shot)
      type: hellaswag
      split: validation
      args:
        num_few_shot: 10
    metrics:
    - type: acc_norm
      value: 80.44
      name: normalized accuracy
    source:
      url: https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard?query=tcapelle/gemma-7b-zephyr-dpo
      name: Open LLM Leaderboard
  - task:
      type: text-generation
      name: Text Generation
    dataset:
      name: MMLU (5-Shot)
      type: cais/mmlu
      config: all
      split: test
      args:
        num_few_shot: 5
    metrics:
    - type: acc
      value: 60.6
      name: accuracy
    source:
      url: https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard?query=tcapelle/gemma-7b-zephyr-dpo
      name: Open LLM Leaderboard
  - task:
      type: text-generation
      name: Text Generation
    dataset:
      name: TruthfulQA (0-shot)
      type: truthful_qa
      config: multiple_choice
      split: validation
      args:
        num_few_shot: 0
    metrics:
    - type: mc2
      value: 42.48
    source:
      url: https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard?query=tcapelle/gemma-7b-zephyr-dpo
      name: Open LLM Leaderboard
  - task:
      type: text-generation
      name: Text Generation
    dataset:
      name: Winogrande (5-shot)
      type: winogrande
      config: winogrande_xl
      split: validation
      args:
        num_few_shot: 5
    metrics:
    - type: acc
      value: 75.37
      name: accuracy
    source:
      url: https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard?query=tcapelle/gemma-7b-zephyr-dpo
      name: Open LLM Leaderboard
  - task:
      type: text-generation
      name: Text Generation
    dataset:
      name: GSM8k (5-shot)
      type: gsm8k
      config: main
      split: test
      args:
        num_few_shot: 5
    metrics:
    - type: acc
      value: 49.96
      name: accuracy
    source:
      url: https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard?query=tcapelle/gemma-7b-zephyr-dpo
      name: Open LLM Leaderboard
---

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""200"" height=""32""/>](https://wandb.ai/llm_surgery/gemma-zephyr)

# Gemma 7B Zephyr DPO

The [Zephyr](https://huggingface.co/HuggingFaceH4/zephyr-7b-beta) DPO recipe applied on top of SFT finetuned Gemma 7B

## Model description

- **Model type:** A 8.5B parameter GPT-like model fine-tuned on a mix of publicly available, synthetic datasets.
- **Language(s) (NLP):** Primarily English
- **Finetuned from model:** [wandb/gemma-7b-zephyr-sft](https://huggingface.co/wandb/gemma-7b-zephyr-sft/)

## Recipe

We trained using the DPO script in [alignment handbook recipe](https://github.com/huggingface/alignment-handbook/blob/main/scripts/run_dpo.py) and logging to W&B

Visit the [W&B workspace here](https://wandb.ai/llm_surgery/gemma-zephyr?nw=nwusercapecape)


## License
This model has the same license as the [original Gemma model collection](https://ai.google.dev/gemma/terms)

## Compute provided by [Lambda Labs](https://lambdalabs.com/) - 8xA100 80GB node


# [Open LLM Leaderboard Evaluation Results](https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard)
Detailed results can be found [here](https://huggingface.co/datasets/open-llm-leaderboard/details_tcapelle__gemma-7b-zephyr-dpo)

|             Metric              |Value|
|---------------------------------|----:|
|Avg.                             |61.62|
|AI2 Reasoning Challenge (25-Shot)|60.84|
|HellaSwag (10-Shot)              |80.44|
|MMLU (5-Shot)                    |60.60|
|TruthfulQA (0-shot)              |42.48|
|Winogrande (5-shot)              |75.37|
|GSM8k (5-shot)                   |49.96|

","{""id"": ""wandb/gemma-7b-zephyr-dpo"", ""author"": ""wandb"", ""sha"": ""919d3ba3ea8d7ad5f30294ba289ab4d517b26406"", ""last_modified"": ""2024-03-04 12:54:13+00:00"", ""created_at"": ""2024-02-28 11:39:50+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 9, ""downloads_all_time"": null, ""likes"": 2, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""safetensors"", ""gemma"", ""text-generation"", ""conversational"", ""dataset:HuggingFaceH4/ultrafeedback_binarized"", ""base_model:wandb/gemma-7b-zephyr-sft"", ""base_model:finetune:wandb/gemma-7b-zephyr-sft"", ""license:other"", ""model-index"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: wandb/gemma-7b-zephyr-sft\ndatasets:\n- HuggingFaceH4/ultrafeedback_binarized\nlibrary_name: transformers\nlicense: other\nlicense_name: gemma-terms-of-use\nlicense_link: https://ai.google.dev/gemma/terms\nmodel-index:\n- name: gemma-7b-zephyr-dpo\n  results:\n  - task:\n      type: text-generation\n      name: Text Generation\n    dataset:\n      name: AI2 Reasoning Challenge (25-Shot)\n      type: ai2_arc\n      config: ARC-Challenge\n      split: test\n      args:\n        num_few_shot: 25\n    metrics:\n    - type: acc_norm\n      value: 60.84\n      name: normalized accuracy\n      verified: false\n    source:\n      url: https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard?query=tcapelle/gemma-7b-zephyr-dpo\n      name: Open LLM Leaderboard\n  - task:\n      type: text-generation\n      name: Text Generation\n    dataset:\n      name: HellaSwag (10-Shot)\n      type: hellaswag\n      split: validation\n      args:\n        num_few_shot: 10\n    metrics:\n    - type: acc_norm\n      value: 80.44\n      name: normalized accuracy\n      verified: false\n    source:\n      url: https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard?query=tcapelle/gemma-7b-zephyr-dpo\n      name: Open LLM Leaderboard\n  - task:\n      type: text-generation\n      name: Text Generation\n    dataset:\n      name: MMLU (5-Shot)\n      type: cais/mmlu\n      config: all\n      split: test\n      args:\n        num_few_shot: 5\n    metrics:\n    - type: acc\n      value: 60.6\n      name: accuracy\n      verified: false\n    source:\n      url: https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard?query=tcapelle/gemma-7b-zephyr-dpo\n      name: Open LLM Leaderboard\n  - task:\n      type: text-generation\n      name: Text Generation\n    dataset:\n      name: TruthfulQA (0-shot)\n      type: truthful_qa\n      config: multiple_choice\n      split: validation\n      args:\n        num_few_shot: 0\n    metrics:\n    - type: mc2\n      value: 42.48\n      verified: false\n    source:\n      url: https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard?query=tcapelle/gemma-7b-zephyr-dpo\n      name: Open LLM Leaderboard\n  - task:\n      type: text-generation\n      name: Text Generation\n    dataset:\n      name: Winogrande (5-shot)\n      type: winogrande\n      config: winogrande_xl\n      split: validation\n      args:\n        num_few_shot: 5\n    metrics:\n    - type: acc\n      value: 75.37\n      name: accuracy\n      verified: false\n    source:\n      url: https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard?query=tcapelle/gemma-7b-zephyr-dpo\n      name: Open LLM Leaderboard\n  - task:\n      type: text-generation\n      name: Text Generation\n    dataset:\n      name: GSM8k (5-shot)\n      type: gsm8k\n      config: main\n      split: test\n      args:\n        num_few_shot: 5\n    metrics:\n    - type: acc\n      value: 49.96\n      name: accuracy\n      verified: false\n    source:\n      url: https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard?query=tcapelle/gemma-7b-zephyr-dpo\n      name: Open LLM Leaderboard"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": [{""name"": ""gemma-7b-zephyr-dpo"", ""results"": [{""task"": {""type"": ""text-generation"", ""name"": ""Text Generation""}, ""dataset"": {""name"": ""AI2 Reasoning Challenge (25-Shot)"", ""type"": ""ai2_arc"", ""config"": ""ARC-Challenge"", ""split"": ""test"", ""args"": {""num_few_shot"": 25}}, ""metrics"": [{""type"": ""acc_norm"", ""value"": 60.84, ""name"": ""normalized accuracy"", ""verified"": false}], ""source"": {""url"": ""https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard?query=tcapelle/gemma-7b-zephyr-dpo"", ""name"": ""Open LLM Leaderboard""}}, {""task"": {""type"": ""text-generation"", ""name"": ""Text Generation""}, ""dataset"": {""name"": ""HellaSwag (10-Shot)"", ""type"": ""hellaswag"", ""split"": ""validation"", ""args"": {""num_few_shot"": 10}}, ""metrics"": [{""type"": ""acc_norm"", ""value"": 80.44, ""name"": ""normalized accuracy"", ""verified"": false}], ""source"": {""url"": ""https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard?query=tcapelle/gemma-7b-zephyr-dpo"", ""name"": ""Open LLM Leaderboard""}}, {""task"": {""type"": ""text-generation"", ""name"": ""Text Generation""}, ""dataset"": {""name"": ""MMLU (5-Shot)"", ""type"": ""cais/mmlu"", ""config"": ""all"", ""split"": ""test"", ""args"": {""num_few_shot"": 5}}, ""metrics"": [{""type"": ""acc"", ""value"": 60.6, ""name"": ""accuracy"", ""verified"": false}], ""source"": {""url"": ""https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard?query=tcapelle/gemma-7b-zephyr-dpo"", ""name"": ""Open LLM Leaderboard""}}, {""task"": {""type"": ""text-generation"", ""name"": ""Text Generation""}, ""dataset"": {""name"": ""TruthfulQA (0-shot)"", ""type"": ""truthful_qa"", ""config"": ""multiple_choice"", ""split"": ""validation"", ""args"": {""num_few_shot"": 0}}, ""metrics"": [{""type"": ""mc2"", ""value"": 42.48, ""verified"": false}], ""source"": {""url"": ""https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard?query=tcapelle/gemma-7b-zephyr-dpo"", ""name"": ""Open LLM Leaderboard""}}, {""task"": {""type"": ""text-generation"", ""name"": ""Text Generation""}, ""dataset"": {""name"": ""Winogrande (5-shot)"", ""type"": ""winogrande"", ""config"": ""winogrande_xl"", ""split"": ""validation"", ""args"": {""num_few_shot"": 5}}, ""metrics"": [{""type"": ""acc"", ""value"": 75.37, ""name"": ""accuracy"", ""verified"": false}], ""source"": {""url"": ""https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard?query=tcapelle/gemma-7b-zephyr-dpo"", ""name"": ""Open LLM Leaderboard""}}, {""task"": {""type"": ""text-generation"", ""name"": ""Text Generation""}, ""dataset"": {""name"": ""GSM8k (5-shot)"", ""type"": ""gsm8k"", ""config"": ""main"", ""split"": ""test"", ""args"": {""num_few_shot"": 5}}, ""metrics"": [{""type"": ""acc"", ""value"": 49.96, ""name"": ""accuracy"", ""verified"": false}], ""source"": {""url"": ""https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard?query=tcapelle/gemma-7b-zephyr-dpo"", ""name"": ""Open LLM Leaderboard""}}]}], ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{% for message in messages %}\n{% if message['role'] == 'user' %}\n{{ '<|user|>\n' + message['content'] + eos_token }}\n{% elif message['role'] == 'system' %}\n{{ '<|system|>\n' + message['content'] + eos_token }}\n{% elif message['role'] == 'assistant' %}\n{{ '<|assistant|>\n'  + message['content'] + eos_token }}\n{% endif %}\n{% if loop.last and add_generation_prompt %}\n{{ '<|assistant|>' }}\n{% endif %}\n{% endfor %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='generation_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00001-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00002-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00003-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00004-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model.safetensors.index.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": {""parameters"": {""BF16"": 8537680896}, ""total"": 8537680896}, ""security_repo_status"": null, ""lastModified"": ""2024-03-04 12:54:13+00:00"", ""cardData"": ""base_model: wandb/gemma-7b-zephyr-sft\ndatasets:\n- HuggingFaceH4/ultrafeedback_binarized\nlibrary_name: transformers\nlicense: other\nlicense_name: gemma-terms-of-use\nlicense_link: https://ai.google.dev/gemma/terms\nmodel-index:\n- name: gemma-7b-zephyr-dpo\n  results:\n  - task:\n      type: text-generation\n      name: Text Generation\n    dataset:\n      name: AI2 Reasoning Challenge (25-Shot)\n      type: ai2_arc\n      config: ARC-Challenge\n      split: test\n      args:\n        num_few_shot: 25\n    metrics:\n    - type: acc_norm\n      value: 60.84\n      name: normalized accuracy\n      verified: false\n    source:\n      url: https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard?query=tcapelle/gemma-7b-zephyr-dpo\n      name: Open LLM Leaderboard\n  - task:\n      type: text-generation\n      name: Text Generation\n    dataset:\n      name: HellaSwag (10-Shot)\n      type: hellaswag\n      split: validation\n      args:\n        num_few_shot: 10\n    metrics:\n    - type: acc_norm\n      value: 80.44\n      name: normalized accuracy\n      verified: false\n    source:\n      url: https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard?query=tcapelle/gemma-7b-zephyr-dpo\n      name: Open LLM Leaderboard\n  - task:\n      type: text-generation\n      name: Text Generation\n    dataset:\n      name: MMLU (5-Shot)\n      type: cais/mmlu\n      config: all\n      split: test\n      args:\n        num_few_shot: 5\n    metrics:\n    - type: acc\n      value: 60.6\n      name: accuracy\n      verified: false\n    source:\n      url: https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard?query=tcapelle/gemma-7b-zephyr-dpo\n      name: Open LLM Leaderboard\n  - task:\n      type: text-generation\n      name: Text Generation\n    dataset:\n      name: TruthfulQA (0-shot)\n      type: truthful_qa\n      config: multiple_choice\n      split: validation\n      args:\n        num_few_shot: 0\n    metrics:\n    - type: mc2\n      value: 42.48\n      verified: false\n    source:\n      url: https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard?query=tcapelle/gemma-7b-zephyr-dpo\n      name: Open LLM Leaderboard\n  - task:\n      type: text-generation\n      name: Text Generation\n    dataset:\n      name: Winogrande (5-shot)\n      type: winogrande\n      config: winogrande_xl\n      split: validation\n      args:\n        num_few_shot: 5\n    metrics:\n    - type: acc\n      value: 75.37\n      name: accuracy\n      verified: false\n    source:\n      url: https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard?query=tcapelle/gemma-7b-zephyr-dpo\n      name: Open LLM Leaderboard\n  - task:\n      type: text-generation\n      name: Text Generation\n    dataset:\n      name: GSM8k (5-shot)\n      type: gsm8k\n      config: main\n      split: test\n      args:\n        num_few_shot: 5\n    metrics:\n    - type: acc\n      value: 49.96\n      name: accuracy\n      verified: false\n    source:\n      url: https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard?query=tcapelle/gemma-7b-zephyr-dpo\n      name: Open LLM Leaderboard"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""65df1b861ba3300ccfbaef6a"", ""modelId"": ""wandb/gemma-7b-zephyr-dpo"", ""usedStorage"": 51243621921}",2,,0,,0,,0,"HuggingFaceH4/open_llm_leaderboard?query=tcapelle/gemma-7b-zephyr-dpo, huggingface/InferenceSupport/discussions/new?title=wandb/gemma-7b-zephyr-dpo&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bwandb%2Fgemma-7b-zephyr-dpo%5D(%2Fwandb%2Fgemma-7b-zephyr-dpo)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A",2,,
https://huggingface.co/Telugu-LLM-Labs/Indic-gemma-7b-finetuned-sft-Navarasa-2.0,N/A,N/A,1,,0,,0,,0,,0,,0.0
google/gemma-7b-aps-it,"---
base_model: google/gemma-7b
library_name: transformers
license: gemma
pipeline_tag: text-generation
extra_gated_heading: Access Gemma on Hugging Face
extra_gated_prompt: To access Gemma on Hugging Face, you’re required to review and
  agree to Google’s usage license. To do this, please ensure you’re logged in to Hugging
  Face and click below. Requests are processed immediately.
extra_gated_button_content: Acknowledge license
---

# Gemma Model Card

**Model Page**: [Gemma](https://ai.google.dev/gemma/docs)

This model card corresponds to the 7B finetuned version of the Gemma-APS model.
You can also visit the model card of the [2B finetuned model](https://huggingface.co/google/gemma-2b-aps-it).

**Resources and Technical Documentation**:

* [Scalable and Domain-General Abstractive Proposition Segmentation](https://arxiv.org/abs/2406.19803)
* [Gemma Technical Report](https://storage.googleapis.com/deepmind-media/gemma/gemma-report.pdf)
* [Responsible Generative AI Toolkit](https://ai.google.dev/responsible)
* [Gemma on Kaggle](https://www.kaggle.com/models/google/gemma)

**Terms of Use**: [Terms](https://www.kaggle.com/models/google/gemma/license/consent/verify/huggingface?returnModelRepoId=google/gemma-7b-aps-it)

**Authors**: Mohammad Javad Hosseini, Yang Gao, Tim Baumgärtner, Alex Fabrikant, Reinald Kim Amplayo

## Model Information

Summary description and brief definition of inputs and outputs.

### Description

Gemma-APS is a generative model and a research tool for **abstractive proposition segmentation** (APS for short), a.k.a. claim extraction.
Given a text passage, the model segments the content into the individual facts, statements, and ideas expressed in the text, and restates
them in full sentences with small changes to the original text.

This model can be used for research where there is a need to break down text content into meaningful components. Applications include
grounding, retrieval, fact-checking, and evaluation of generation tasks (such as summarization) where it can be useful to divide up
individual propositions (claims) so that they can be processed independently. For more information, check out the [research paper](https://arxiv.org/abs/2406.19803).

### Context Length

Models are trained on a context length of 8192 tokens.

### Usage

Below we share some code snippets on how to get quickly started with running the model. First make sure to `pip install -U transformers nltk`,
then copy the snippet from the section that is relevant for your usecase.

For ease-of-use, we define two helper functions for pre-processing input and post-processing output of the model:

```py
import nltk
import re

nltk.download('punkt')

start_marker = '<s>'
end_marker = '</s>'
separator = '\n'

def create_propositions_input(text: str) -> str:
    input_sents = nltk.tokenize.sent_tokenize(text)
    propositions_input = ''
    for sent in input_sents:
        propositions_input += f'{start_marker} ' + sent + f' {end_marker}{separator}'
    propositions_input = propositions_input.strip(f'{separator}')
    return propositions_input

def process_propositions_output(text):
    pattern = re.compile(f'{re.escape(start_marker)}(.*?){re.escape(end_marker)}', re.DOTALL)
    output_grouped_strs = re.findall(pattern, text)
    predicted_grouped_propositions = []
    for grouped_str in output_grouped_strs:
        grouped_str = grouped_str.strip(separator)
        props = [x[2:] for x in grouped_str.split(separator)]
        predicted_grouped_propositions.append(props)
    return predicted_grouped_propositions
```

#### Usage with the `pipeline` API

```py
from transformers import pipeline
import torch

generator = pipeline('text-generation', 'google/gemma-7b-aps-it', device_map='auto', torch_dtype=torch.bfloat16)

passage = 'Sarah Stage, 30, welcomed James Hunter into the world on Tuesday.\nThe baby boy weighed eight pounds seven ounces and was 22 inches long.'
messages = [{'role': 'user', 'content': create_propositions_input(passage)}]
output = generator(messages, max_new_tokens=4096, return_full_text=False)
result = process_propositions_output(output[0]['generated_text'])
print(result)
```


<details>

<summary>Example output</summary>

```json
[
  [
    ""Sarah Stage welcomed James Hunter into the world."",
    ""Sarah Stage is 30 years old."",
    ""James Hunter was welcomed on Tuesday.""
  ],
  [
    ""James Hunter weighed eight pounds seven ounces."",
    ""James Hunter was 22 inches long.""
  ]
]
```
</details>


#### Usage with `AutoModel` and `AutoTokenizer` APIs

```python
from transformers import AutoTokenizer, AutoModelForCausalLM
import torch

model_id = 'google/gemma-7b-aps-it'
tokenizer = AutoTokenizer.from_pretrained(model_id)
model = AutoModelForCausalLM.from_pretrained(
    model_id,
    device_map='auto',
    torch_dtype=torch.bfloat16,
)

passage = ""For more than 40 years, the lyrics of American Pie have been puzzled over. This week the handwritten lyrics sold for more than $1 million at auction. The verses contain hidden references to seminal events of the 50s and 60s. It includes nods to Buddy Holly, Charles Manson and Martin Luther King.""
messages = [{'role': 'user', 'content': create_propositions_input(passage)}]
inputs = tokenizer.apply_chat_template(messages, return_tensors='pt', add_generation_prompt=True, return_dict=True).to(model.device)

output = model.generate(**inputs, max_new_tokens=4096, do_sample=False)
generated_text = tokenizer.batch_decode(output[:, inputs['input_ids'].shape[1]:], skip_special_tokens=True)[0]
result = process_propositions_output(generated_text)
print(result)
```

<details>

<summary>Example output</summary>

```json
[
  [
    ""The lyrics of American Pie have been puzzled over for more than 40 years.""
  ],
  [
    ""The handwritten lyrics sold for more than $1 million."",
    ""The handwritten lyrics sold at auction."",
    ""The handwritten lyrics sold this week.""
  ],
  [
    ""The verses contain hidden references to seminal events of the 50s."",
    ""The verses contain hidden references to seminal events of the 60s.""
  ],
  [
    ""The lyrics include nods to Buddy Holly."",
    ""The lyrics include nods to Charles Manson."",
    ""The lyrics include nods to Martin Luther King.""
  ]
]
```

</details>


### Inputs and outputs

*   **Input:** A text passage.
*   **Output:** List of propositions for all the sentences in the text passage. The propositions for each sentence are grouped separately.


## Model Data

Data used for model training and how the data was processed.

### Training Dataset

* The training data contains synthetically generated examples, where each example has (input passage, propositions list) pairs, with the
  propositions list containing propositions for all the sentences in the input passage (one group of propositions for each sentence).
* The input passages are generated by few-shot prompting Gemini Ultra.
* The propositions list is generated by applying a teacher LLM on the input passage. The teacher LLM is a Gemini Pro model trained on
  a filtered version of the ROSE dataset.

See the [research paper](https://arxiv.org/abs/2406.19803) for all the details.

### Data Preprocessing

* We filtered example passages that have >=4 tokens overlap with any of the few-shot examples used for prompting Gemini Ultra.
* We used the ROSE dataset for training the teacher LLM (Gemini Pro). We filtered ROSE examples using an entailment model to remove
  cases that do not satisfy desired properties of propositions.


## Implementation Information

Details about the model internals.

### Hardware

Similar to Gemma, Gemma-APS was trained on [TPUv5e](https://cloud.google.com/tpu/docs/intro-to-tpu?_gl=1*18wi411*_ga*MzE3NDU5OTY1LjE2MzQwNDA4NDY.*_ga_WH2QY8WWF5*MTcxMTA0MjUxMy4xNy4wLjE3MTEwNDI1MTkuMC4wLjA.&_ga=2.239449409.-317459965.1634040846).

Training large language models requires significant computational power. TPUs, designed specifically for matrix operations common in machine learning, offer several advantages in this domain:

Performance: TPUs are specifically designed to handle the massive computations involved in training LLMs. They can speed up training considerably compared to CPUs.
Memory: TPUs often come with large amounts of high-bandwidth memory, allowing for the handling of large models and batch sizes during training. This can lead to better model quality.
Scalability: TPU Pods (large clusters of TPUs) provide a scalable solution for handling the growing complexity of large foundation models. You can distribute training across multiple TPU devices for faster and more efficient processing.
Cost-effectiveness: In many scenarios, TPUs can provide a more cost-effective solution for training large models compared to CPU-based infrastructure, especially when considering the time and resources saved due to faster training.
These advantages are aligned with [Google's commitments to operate sustainably](https://sustainability.google/operating-sustainably/).

### Software

Training was done using [JAX](https://github.com/jax-ml/jax).

JAX allows researchers to leverage the latest generation of hardware, including TPUs, for faster and more efficient training of large models.


## Evaluation

Model evaluation metrics and results.

### Benchmark Results

Evaluation was done on one existing in-domain dataset (development set of the [ROSE](https://github.com/Yale-LILY/ROSE) dataset filtered by an entailment model) and two out-of-domain datasets introduced in the paper. Evaluation was performed based on our new metrics for the abstractive proposition segmentation task.


## Ethics and Safety

Ethics and safety evaluation approach and results.

### Evaluation Approach

These models are only suitable for abstractive proposition segmentation for English text, not any other task or language. While we have tested the models on three evaluation datasets and have obtained positive results compared to strong baselines, the model might still have errors on some examples.


## Usage and Limitations

These models have certain limitations that users should be aware of.

### Intended Usage

These models are only suitable for abstractive proposition segmentation for English text, not any other task or language.
While we have tested it on three evaluation datasets and have obtained positive results compared to strong baselines,
the models might still have errors on some examples.

### Limitations

These models have certain limitations that users should be aware of.

* Training Data
  * The quality and diversity of the training data significantly influence the
    model's capabilities. Biases or gaps in the training data can lead to
    limitations in the model's responses.
  * The scope of the training dataset determines the subject areas the model can
    handle effectively.
  * We have tested our models on passages from different domains, where passages
    contain a few sentences. 
  * This model supports abstractive proposition segmentation in English, not any
    other language.
* Language Ambiguity and Nuance
  * Natural language is inherently complex. LLMs might struggle to grasp subtle
    nuances, sarcasm, or figurative language.
* Factual Accuracy
  * LLMs generate responses based on information they learned from their
    training datasets, but they are not knowledge bases. They may generate
    incorrect or outdated factual statements.
* Common Sense
  * LLMs rely on statistical patterns in language. They might lack the ability
    to apply common sense reasoning in certain situations.

### Ethical Considerations and Risks

The development of large language models (LLMs) raises several ethical concerns.
In creating an open model, we have carefully considered the following:

* Bias and Fairness
  * LLMs trained on large-scale, real-world text data can reflect socio-cultural
    biases embedded in the training material. These models underwent careful
    scrutiny, input data pre-processing described and posterior evaluations
    reported in this card.
* Misinformation and Misuse
  * LLMs can be misused to generate text that is false, misleading, or harmful.
  * Guidelines are provided for responsible use with the model, see the
    [Responsible Generative AI Toolkit](http://ai.google.dev/gemma/responsible).
* Transparency and Accountability:
  * This model card summarizes details on the models' architecture,
    capabilities, limitations, and evaluation processes.
  * A responsibly developed open model offers the opportunity to share
    innovation by making LLM technology accessible to developers and researchers
    across the AI ecosystem.

Risks identified and mitigations:

* Perpetuation of biases: It's encouraged to perform continuous monitoring
  (using evaluation metrics, human review) and the exploration of de-biasing
  techniques during model training, fine-tuning, and other use cases.
* Generation of harmful content: Mechanisms and guidelines for content safety
  are essential. Developers are encouraged to exercise caution and implement
  appropriate content safety safeguards based on their specific product policies
  and application use cases.
* Misuse for malicious purposes: Technical limitations and developer and
  end-user education can help mitigate against malicious applications of LLMs.
  Educational resources and reporting mechanisms for users to flag misuse are
  provided. Prohibited uses of Gemma models are outlined in the
  [Gemma Prohibited Use Policy](https://ai.google.dev/gemma/prohibited_use_policy).
* Privacy violations: Models were trained on data filtered for removal of PII
  (Personally Identifiable Information). Developers are encouraged to adhere to
  privacy regulations with privacy-preserving techniques.

### Benefits

These models are useful for academics working on abstractive proposition segmentation (claim extraction) research or other problems (e.g., grounding, retrieval, fact-checking) that could benefit from this task.","{""id"": ""google/gemma-7b-aps-it"", ""author"": ""google"", ""sha"": ""0b6f012c7d463400f4774982db89b8f98e500edb"", ""last_modified"": ""2024-09-27 18:02:50+00:00"", ""created_at"": ""2024-09-06 08:50:24+00:00"", ""private"": false, ""gated"": ""manual"", ""disabled"": false, ""downloads"": 304, ""downloads_all_time"": null, ""likes"": 32, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""safetensors"", ""gemma"", ""text-generation"", ""conversational"", ""arxiv:2406.19803"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""license:gemma"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\nlibrary_name: transformers\nlicense: gemma\npipeline_tag: text-generation\nextra_gated_heading: Access Gemma on Hugging Face\nextra_gated_prompt: To access Gemma on Hugging Face, you\u2019re required to review and\n  agree to Google\u2019s usage license. To do this, please ensure you\u2019re logged in to Hugging\n  Face and click below. Requests are processed immediately.\nextra_gated_button_content: Acknowledge license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{% set loop_messages = messages[1:] %}{% set system_message = messages[0]['content'] %}{% else %}{% set loop_messages = messages %}{% set system_message = 'I will provide a passage split into sentences by <s> and </s> markers. For each sentence, generate its list of propositions. Each proposition contains a single fact mentioned in the corresponding sentence written as briefly and clearly as possible.\n\nPassage: ' %}{% endif %}{{ '<start_of_turn>system\n' + system_message + '<end_of_turn>\n'}}{% for message in loop_messages %}{% if (message['role'] == 'user') != (loop.index0 % 2 == 0) %}{{ raise_exception('Conversation roles must alternate user/assistant/user/assistant/...') }}{% endif %}{{ '<start_of_turn>' + message['role'] + '\n' + message['content'] + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{ '<start_of_turn>model\n' }}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='gemma_aps_7b_torch.ckpt', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='generation_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00001-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00002-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00003-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00004-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model.safetensors.index.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)""], ""spaces"": [""KBaba7/Quant"", ""bhaskartripathi/LLM_Quantization"", ""totolook/Quant"", ""FallnAI/Quantize-HF-Models"", ""ruslanmv/convert_to_gguf"", ""K00B404/LLM_Quantization""], ""safetensors"": {""parameters"": {""BF16"": 8537680896}, ""total"": 8537680896}, ""security_repo_status"": null, ""lastModified"": ""2024-09-27 18:02:50+00:00"", ""cardData"": ""base_model: google/gemma-7b\nlibrary_name: transformers\nlicense: gemma\npipeline_tag: text-generation\nextra_gated_heading: Access Gemma on Hugging Face\nextra_gated_prompt: To access Gemma on Hugging Face, you\u2019re required to review and\n  agree to Google\u2019s usage license. To do this, please ensure you\u2019re logged in to Hugging\n  Face and click below. Requests are processed immediately.\nextra_gated_button_content: Acknowledge license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""66dac250e8dd73ce1f6b4505"", ""modelId"": ""google/gemma-7b-aps-it"", ""usedStorage"": 136659236877}",1,https://huggingface.co/m7alek/lora_model,1,"https://huggingface.co/lmstudio-community/gemma-7b-aps-it-GGUF, https://huggingface.co/sheldonrobinson/gemma-7b-aps-it-Q8_0-GGUF, https://huggingface.co/sheldonrobinson/gemma-7b-aps-it-Q4_K_M-GGUF, https://huggingface.co/mradermacher/gemma-7b-aps-it-GGUF, https://huggingface.co/mradermacher/gemma-7b-aps-it-i1-GGUF",5,,0,"FallnAI/Quantize-HF-Models, K00B404/LLM_Quantization, KBaba7/Quant, bhaskartripathi/LLM_Quantization, huggingface/InferenceSupport/discussions/new?title=google/gemma-7b-aps-it&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bgoogle%2Fgemma-7b-aps-it%5D(%2Fgoogle%2Fgemma-7b-aps-it)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A, ruslanmv/convert_to_gguf, totolook/Quant",7,,
m7alek/lora_model,"---
license: mit
datasets:
- m7alek/external_df
- m7alek/Fifth_file
- m7alek/ninth_file
- m7alek/eighth_file
language:
- ar
- en
metrics:
- accuracy
- bertscore
new_version: nvidia/Llama-3.1-Nemotron-70B-Instruct-HF
library_name: transformers
tags:
- NLP
- Text-generation
base_model:
- google/gemma-7b-aps-it
---","{""id"": ""m7alek/lora_model"", ""author"": ""m7alek"", ""sha"": ""8ca3eeea7438bd213c4186f8a7952061d55f9219"", ""last_modified"": ""2024-11-10 04:41:08+00:00"", ""created_at"": ""2024-11-09 13:22:38+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""NLP"", ""Text-generation"", ""ar"", ""en"", ""dataset:m7alek/external_df"", ""dataset:m7alek/Fifth_file"", ""dataset:m7alek/ninth_file"", ""dataset:m7alek/eighth_file"", ""base_model:google/gemma-7b-aps-it"", ""base_model:finetune:google/gemma-7b-aps-it"", ""license:mit"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": null, ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model:\n- google/gemma-7b-aps-it\ndatasets:\n- m7alek/external_df\n- m7alek/Fifth_file\n- m7alek/ninth_file\n- m7alek/eighth_file\nlanguage:\n- ar\n- en\nlibrary_name: transformers\nlicense: mit\nmetrics:\n- accuracy\n- bertscore\ntags:\n- NLP\n- Text-generation\nnew_version: nvidia/Llama-3.1-Nemotron-70B-Instruct-HF"", ""widget_data"": null, ""model_index"": null, ""config"": null, ""transformers_info"": {""auto_model"": ""AutoModel"", ""custom_class"": null, ""pipeline_tag"": null, ""processor"": null}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2024-11-10 04:41:08+00:00"", ""cardData"": ""base_model:\n- google/gemma-7b-aps-it\ndatasets:\n- m7alek/external_df\n- m7alek/Fifth_file\n- m7alek/ninth_file\n- m7alek/eighth_file\nlanguage:\n- ar\n- en\nlibrary_name: transformers\nlicense: mit\nmetrics:\n- accuracy\n- bertscore\ntags:\n- NLP\n- Text-generation\nnew_version: nvidia/Llama-3.1-Nemotron-70B-Instruct-HF"", ""transformersInfo"": {""auto_model"": ""AutoModel"", ""custom_class"": null, ""pipeline_tag"": null, ""processor"": null}, ""_id"": ""672f621eef44556ddf08c83a"", ""modelId"": ""m7alek/lora_model"", ""usedStorage"": 0}",2,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=m7alek/lora_model&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bm7alek%2Flora_model%5D(%2Fm7alek%2Flora_model)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
seojeongsoo/AI_Pet_code,"---
license: apache-2.0
datasets:
- seojeongsoo/AI_pet_code
language:
- ko
metrics:
- accuracy
base_model:
- google/gemma-7b
new_version: seojeongsoo/AI_Pet_code
pipeline_tag: text-generation
library_name: transformers
---
Model Details model

model is continued pretrained language model based on google/gemma-7b-it

This model is trained with CRM Bussiness department of KTDS (KT DataSystem) .

Intended Use TBD

How to use TBD

Responsibility & Safety We believe that an open approach to AI leads to better, safer products, faster innovation, and a bigger overall market. We are committed to Responsible AI development and took a series of steps to limit misuse and harm and support the open source community.

Foundation models are widely capable technologies that are built to be used for a diverse range of applications. They are not designed to meet every developer preference on safety levels for all use cases, out-of-the-box, as those by their nature will differ across different applications.

Rather, responsible LLM-application deployment is achieved by implementing a series of safety best practices throughout the development of such applications, from the model pre-training, fine-tuning and the deployment of systems composed of safeguards to tailor the safety needs specifically to the use case and audience.

As part of the gemma release, we updated our Responsible Use Guide to outline the steps and best practices for developers to implement model and system level safety for their application. We also provide a set of resources including Meta Llama Guard 2 and Code Shield safeguards. These tools have proven to drastically reduce residual risks of LLM Systems, while maintaining a high level of helpfulness. We encourage developers to tune and deploy these safeguards according to their needs and we provide a reference implementation to get you started.

Responsible release In addition to responsible use considerations outlined above, we followed a rigorous process that requires us to take extra measures against misuse and critical risks before we make our release decision.

Misuse
","{""id"": ""seojeongsoo/AI_Pet_code"", ""author"": ""seojeongsoo"", ""sha"": ""4c1615d2652e83d5839a9585624a2c813a4f20c2"", ""last_modified"": ""2025-01-22 06:19:47+00:00"", ""created_at"": ""2025-01-15 06:30:06+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 5, ""downloads_all_time"": null, ""likes"": 1, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""safetensors"", ""gemma"", ""text-generation"", ""conversational"", ""ko"", ""dataset:seojeongsoo/AI_pet_code"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""license:apache-2.0"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model:\n- google/gemma-7b\ndatasets:\n- seojeongsoo/AI_pet_code\nlanguage:\n- ko\nlibrary_name: transformers\nlicense: apache-2.0\nmetrics:\n- accuracy\npipeline_tag: text-generation\nnew_version: seojeongsoo/AI_Pet_code"", ""widget_data"": null, ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'user') != (loop.index0 % 2 == 0) %}{{ raise_exception('Conversation roles must alternate user/assistant/user/assistant/...') }}{% endif %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<eos>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='generation_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00001-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00002-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00003-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00004-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model.safetensors.index.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": {""parameters"": {""F16"": 8537680896}, ""total"": 8537680896}, ""security_repo_status"": null, ""lastModified"": ""2025-01-22 06:19:47+00:00"", ""cardData"": ""base_model:\n- google/gemma-7b\ndatasets:\n- seojeongsoo/AI_pet_code\nlanguage:\n- ko\nlibrary_name: transformers\nlicense: apache-2.0\nmetrics:\n- accuracy\npipeline_tag: text-generation\nnew_version: seojeongsoo/AI_Pet_code"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""678755ee45c53fa982880202"", ""modelId"": ""seojeongsoo/AI_Pet_code"", ""usedStorage"": 17113988148}",1,,0,https://huggingface.co/mradermacher/AI_Pet_code-GGUF,1,,0,huggingface/InferenceSupport/discussions/new?title=seojeongsoo/AI_Pet_code&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bseojeongsoo%2FAI_Pet_code%5D(%2Fseojeongsoo%2FAI_Pet_code)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
mlabonne/gemma-7b-dare,"---
license: cc-by-nc-4.0
tags:
- merge
- mergekit
- lazymergekit
base_model:
- google/gemma-7b
---

# gemma-7b-dare

gemma-7b-dare is a merge of the following models using [LazyMergekit](https://colab.research.google.com/drive/1obulZ1ROXHjYLn6PPZJwRR6GzgQogxxb?usp=sharing):
* [google/gemma-7b](https://huggingface.co/google/gemma-7b)

## 🧩 Configuration

```yaml
models:
  - model: google/gemma-7b-it
    # No parameters necessary for base model
  - model: google/gemma-7b
    parameters:
      density: 0.53
      weight: 0.45
merge_method: dare_ties
base_model: google/gemma-7b-it
parameters:
  int8_mask: true
dtype: bfloat16
random_seed: 0
```

## 💻 Usage

```python
!pip install -qU transformers accelerate

from transformers import AutoTokenizer
import transformers
import torch

model = ""mlabonne/gemma-7b-dare""
messages = [{""role"": ""user"", ""content"": ""What is a large language model?""}]

tokenizer = AutoTokenizer.from_pretrained(model)
prompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)
pipeline = transformers.pipeline(
    ""text-generation"",
    model=model,
    torch_dtype=torch.float16,
    device_map=""auto"",
)

outputs = pipeline(prompt, max_new_tokens=256, do_sample=True, temperature=0.7, top_k=50, top_p=0.95)
print(outputs[0][""generated_text""])
```","{""id"": ""mlabonne/gemma-7b-dare"", ""author"": ""mlabonne"", ""sha"": ""31c2fd9eb64ebd5908bce79264c5c6e789adfe0a"", ""last_modified"": ""2024-02-21 13:49:23+00:00"", ""created_at"": ""2024-02-21 13:49:22+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 3, ""library_name"": null, ""gguf"": null, ""inference"": null, ""tags"": [""merge"", ""mergekit"", ""lazymergekit"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""license:cc-by-nc-4.0"", ""region:us""], ""pipeline_tag"": null, ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model:\n- google/gemma-7b\nlicense: cc-by-nc-4.0\ntags:\n- merge\n- mergekit\n- lazymergekit"", ""widget_data"": null, ""model_index"": null, ""config"": null, ""transformers_info"": null, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2024-02-21 13:49:23+00:00"", ""cardData"": ""base_model:\n- google/gemma-7b\nlicense: cc-by-nc-4.0\ntags:\n- merge\n- mergekit\n- lazymergekit"", ""transformersInfo"": null, ""_id"": ""65d5ff6215f94930d75a8b9f"", ""modelId"": ""mlabonne/gemma-7b-dare"", ""usedStorage"": 0}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=mlabonne/gemma-7b-dare&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bmlabonne%2Fgemma-7b-dare%5D(%2Fmlabonne%2Fgemma-7b-dare)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
sohug/gemma-7b_banglo_qlora,"---
license: other
base_model: google/gemma-7b
tags:
- generated_from_trainer
model-index:
- name: gemma-7b_banglo_qlora
  results: []
---

<!-- This model card has been generated automatically according to the information the Trainer had access to. You
should probably proofread and complete it, then remove this comment. -->

# gemma-7b_banglo_qlora

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on an unknown dataset.

## Model description

More information needed

## Intended uses & limitations

More information needed

## Training and evaluation data

More information needed

## Training procedure

### Training hyperparameters

The following hyperparameters were used during training:
- learning_rate: 0.0002
- train_batch_size: 1
- eval_batch_size: 8
- seed: 42
- gradient_accumulation_steps: 4
- total_train_batch_size: 4
- optimizer: Adam with betas=(0.9,0.999) and epsilon=1e-08
- lr_scheduler_type: linear
- lr_scheduler_warmup_ratio: 0.03
- training_steps: 1000

### Training results



### Framework versions

- Transformers 4.39.0.dev0
- Pytorch 2.1.2+cu121
- Datasets 2.15.0
- Tokenizers 0.15.1
","{""id"": ""sohug/gemma-7b_banglo_qlora"", ""author"": ""sohug"", ""sha"": ""a457682effaac92504a9efaa943eda750ca565ec"", ""last_modified"": ""2024-02-23 16:42:09+00:00"", ""created_at"": ""2024-02-23 09:19:31+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": null, ""gguf"": null, ""inference"": null, ""tags"": [""safetensors"", ""generated_from_trainer"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""license:other"", ""region:us""], ""pipeline_tag"": null, ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\nlicense: other\ntags:\n- generated_from_trainer\nmodel-index:\n- name: gemma-7b_banglo_qlora\n  results: []"", ""widget_data"": null, ""model_index"": [{""name"": ""gemma-7b_banglo_qlora"", ""results"": []}], ""config"": {""tokenizer_config"": {""bos_token"": ""<bos>"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": null, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='generation_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2024-02-23 16:42:09+00:00"", ""cardData"": ""base_model: google/gemma-7b\nlicense: other\ntags:\n- generated_from_trainer\nmodel-index:\n- name: gemma-7b_banglo_qlora\n  results: []"", ""transformersInfo"": null, ""_id"": ""65d863231bbb5a6aaacbc56f"", ""modelId"": ""sohug/gemma-7b_banglo_qlora"", ""usedStorage"": 3222194559}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=sohug/gemma-7b_banglo_qlora&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsohug%2Fgemma-7b_banglo_qlora%5D(%2Fsohug%2Fgemma-7b_banglo_qlora)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
mlabonne/Gemmalpaca-7B,"---
library_name: transformers
extra_gated_heading: Access Gemma on Hugging Face
extra_gated_prompt: >-
  To access Gemma on Hugging Face, you’re required to review and agree to
  Google’s usage license. To do this, please ensure you’re logged-in to Hugging
  Face and click below. Requests are processed immediately.
extra_gated_button_content: Acknowledge license
license: other
license_name: gemma-terms-of-use
license_link: https://ai.google.dev/gemma/terms
base_model:
- google/gemma-7b
datasets:
- vicgalle/alpaca-gpt4
---

![image/webp](https://cdn-uploads.huggingface.co/production/uploads/61b8e2ba285851687028d395/uwPjZeV-JQwKWrI7nHg4w.webp)

# Gemmalpaca-7B

This is gemma-7b model supervised fine-tuned on the [vicgalle/alpaca-gpt4](https://huggingface.co/datasets/vicgalle/alpaca-gpt4) dataset. It outperforms gemma-7b-it, Google's chat version, on Nous' benchmark suite.

It's mostly a test to see how fine-tuning works with Gemma models on a well-known dataset.

## 🔍 Applications

This model has a context length of 8k. I recommend using it with the Alpaca chat template and NOT the Gemma Instruct template (works perfectly with LM Studio). You also want to add `</s>` as a stop token.

## 🏆 Evaluation

### Nous

Gemmalpaca-7B outperforms gemma-7b and gemma-7b-it on Nous' benchmark suite (evaluation performed using [LLM AutoEval](https://github.com/mlabonne/llm-autoeval)). See the entire leaderboard [here](https://huggingface.co/spaces/mlabonne/Yet_Another_LLM_Leaderboard).

| Model | Average | AGIEval | GPT4All | TruthfulQA | Bigbench |
|---|---:|---:|---:|---:|---:|
| [**mlabonne/Gemmalpaca-7B**](https://huggingface.co/mlabonne/Gemmalpaca-7B) [📄](https://gist.github.com/mlabonne/61622c46e53914a16e11be89d078f66c) | **34.45** | **21.6** | **40.87** | **44.85** | **30.49** |
| [google/gemma-2b](https://huggingface.co/google/gemma-2b) [📄](https://gist.github.com/mlabonne/7df1f238c515a5f63a750c8792cef59e) | 34.26 | 22.7 | 43.35 | 39.96 | 31.03 |
| [google/gemma-7b](https://huggingface.co/google/gemma-7b) [📄](https://gist.github.com/mlabonne/5f9855d341c3b11f775348ecb4fd8cf1) | 33.56 | 20.64 | 38.49 | 46.61 | 28.51 |
| [google/gemma-7b-it](https://huggingface.co/google/gemma-7b-it) [📄](https://gist.github.com/mlabonne/0fb752dc3c5b578fff87a73c56a16d7a) | 33.53 | 21.33 | 40.84 | 41.7 | 30.25 |

## 🧩 Configuration

It was trained using [Axolotl](https://github.com/OpenAccess-AI-Collective/axolotl) with the following configuration.

```yaml
base_model: alpindale/gemma-7b
model_type: AutoModelForCausalLM
tokenizer_config: philschmid/gemma-tokenizer-chatml
tokenizer_type: AutoTokenizer
tokenizer_use_fast: true

load_in_8bit: false
load_in_4bit: true
strict: false

datasets:
  - path: vicgalle/alpaca-gpt4
    type: alpaca

dataset_prepared_path:
val_set_size: 0.01
output_dir: ./out

sequence_len: 2048
sample_packing: true
pad_to_sequence_len: true

adapter: qlora
lora_model_dir:
lora_r: 32
lora_alpha: 64
lora_dropout: 0.05
lora_target_linear: true

wandb_project: axolotl
wandb_entity:
wandb_watch:
wandb_name:
wandb_log_model:

gradient_accumulation_steps: 2
micro_batch_size: 4
num_epochs: 3
optimizer: adamw_bnb_8bit
lr_scheduler: cosine
learning_rate: 0.0002

train_on_inputs: false
group_by_length: false
bf16: auto
fp16:
tf32: false

gradient_checkpointing: true
early_stopping_patience:
resume_from_checkpoint:
local_rank:
logging_steps: 1
xformers_attention:
flash_attention: true

warmup_steps: 10
evals_per_epoch: 10
eval_table_size:
eval_table_max_new_tokens: 128
saves_per_epoch: 1
debug:
deepspeed:
weight_decay: 0.1
fsdp:
fsdp_config:
special_tokens:
```

[<img src=""https://raw.githubusercontent.com/OpenAccess-AI-Collective/axolotl/main/image/axolotl-badge-web.png"" alt=""Built with Axolotl"" width=""200"" height=""32""/>](https://github.com/OpenAccess-AI-Collective/axolotl)","{""id"": ""mlabonne/Gemmalpaca-7B"", ""author"": ""mlabonne"", ""sha"": ""5df2f6851398b024fbdb4225815e2608ec816c6e"", ""last_modified"": ""2024-02-29 17:50:07+00:00"", ""created_at"": ""2024-02-25 19:10:34+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 17, ""downloads_all_time"": null, ""likes"": 7, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""safetensors"", ""gemma"", ""text-generation"", ""dataset:vicgalle/alpaca-gpt4"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""license:other"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model:\n- google/gemma-7b\ndatasets:\n- vicgalle/alpaca-gpt4\nlibrary_name: transformers\nlicense: other\nlicense_name: gemma-terms-of-use\nlicense_link: https://ai.google.dev/gemma/terms\nextra_gated_heading: Access Gemma on Hugging Face\nextra_gated_prompt: To access Gemma on Hugging Face, you\u2019re required to review and\n  agree to Google\u2019s usage license. To do this, please ensure you\u2019re logged-in to Hugging\n  Face and click below. Requests are processed immediately.\nextra_gated_button_content: Acknowledge license"", ""widget_data"": [{""text"": ""My name is Julien and I like to""}, {""text"": ""I like traveling by train because""}, {""text"": ""Paris is an amazing place to visit,""}, {""text"": ""Once upon a time,""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='generation_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00001-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00002-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00003-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00004-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model.safetensors.index.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": {""parameters"": {""F16"": 8537680896}, ""total"": 8537680896}, ""security_repo_status"": null, ""lastModified"": ""2024-02-29 17:50:07+00:00"", ""cardData"": ""base_model:\n- google/gemma-7b\ndatasets:\n- vicgalle/alpaca-gpt4\nlibrary_name: transformers\nlicense: other\nlicense_name: gemma-terms-of-use\nlicense_link: https://ai.google.dev/gemma/terms\nextra_gated_heading: Access Gemma on Hugging Face\nextra_gated_prompt: To access Gemma on Hugging Face, you\u2019re required to review and\n  agree to Google\u2019s usage license. To do this, please ensure you\u2019re logged-in to Hugging\n  Face and click below. Requests are processed immediately.\nextra_gated_button_content: Acknowledge license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""65db90aa90bd042d5b3fe52f"", ""modelId"": ""mlabonne/Gemmalpaca-7B"", ""usedStorage"": 17097109768}",1,,0,"https://huggingface.co/mradermacher/Gemmalpaca-7B-GGUF, https://huggingface.co/mradermacher/Gemmalpaca-7B-i1-GGUF",2,,0,"huggingface/InferenceSupport/discussions/new?title=mlabonne/Gemmalpaca-7B&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bmlabonne%2FGemmalpaca-7B%5D(%2Fmlabonne%2FGemmalpaca-7B)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A, mlabonne/Yet_Another_LLM_Leaderboard",2,,
arcee-ai/gemma-7b-slerp,"---
library_name: transformers
license: apache-2.0
base_model:
- google/gemma-7b
merge-model: 
- google/gemma-7b-it
tags:
- merge
- mergekit
- google/gemma-7b-it
- google/gemma-7b
---

![image/webp](https://plus.unsplash.com/premium_photo-1664526284199-e36d32a3941d?w=800&auto=format&fit=crop&q=60&ixlib=rb-4.0.3&ixid=M3wxMjA3fDB8MHxzZWFyY2h8MTN8fHNtYWxsZXJ8ZW58MHx8MHx8fDA%3D)


# Gemma-7B-slerp

This model is a merge of Gemma 7b base and 7b-instruct, using the Slerp merging method.

Test-7B-slerp is a merge of the following models using [mergekit](https://github.com/cg123/mergekit):
* [google/gemma-7b-it](https://huggingface.co/google/gemma-7b-it)
* [google/gemma-7b](https://huggingface.co/google/gemma-7b)

## 🏆 Evaluation

### Nous

Gemma-7B-slerp's Nous' benchmark suite (evaluation performed using [LLM AutoEval](https://github.com/mlabonne/llm-autoeval)).

| Model | Average | AGIEval | GPT4All | TruthfulQA | Bigbench |
|---|---:|---:|---:|---:|---:|
| [arcee-ai/Gemma-7B-slerp](https://huggingface.co/arcee-ai/gemma-7b-slerp) [📄](https://gist.github.com/shamanez/4c18f8d79747d4019ecf6d5ce098cf72) | 34.14 | 23.86 | 36.55 | 46.22 | 29.94 |

## 🧩 Configuration

Slerp YAML Config

```yaml
slices:
  - sources:
      - model: google/gemma-7b-it
        layer_range: [0, 28]
      - model: google/gemma-7b
        layer_range: [0, 28]
merge_method: slerp
base_model: google/gemma-7b
parameters:
  t:
    - filter: self_attn
      value: [0, 0.5, 0.3, 0.7, 1]
    - filter: mlp
      value: [1, 0.5, 0.7, 0.3, 0]
    - value: 0.5
dtype: bfloat16

```","{""id"": ""arcee-ai/gemma-7b-slerp"", ""author"": ""arcee-ai"", ""sha"": ""cf123b52c8f3d4469cf7306a7df0a62b04ee4dbb"", ""last_modified"": ""2024-02-28 18:12:12+00:00"", ""created_at"": ""2024-02-27 20:40:47+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 3, ""downloads_all_time"": null, ""likes"": 1, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""safetensors"", ""gemma"", ""text-generation"", ""merge"", ""mergekit"", ""google/gemma-7b-it"", ""google/gemma-7b"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""license:apache-2.0"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model:\n- google/gemma-7b\nlibrary_name: transformers\nlicense: apache-2.0\ntags:\n- merge\n- mergekit\n- google/gemma-7b-it\n- google/gemma-7b\nmerge-model:\n- google/gemma-7b-it"", ""widget_data"": [{""text"": ""My name is Julien and I like to""}, {""text"": ""I like traveling by train because""}, {""text"": ""Paris is an amazing place to visit,""}, {""text"": ""Once upon a time,""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='mergekit_config.yml', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00001-of-00009.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00002-of-00009.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00003-of-00009.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00004-of-00009.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00005-of-00009.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00006-of-00009.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00007-of-00009.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00008-of-00009.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00009-of-00009.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model.safetensors.index.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": {""parameters"": {""BF16"": 8537680896}, ""total"": 8537680896}, ""security_repo_status"": null, ""lastModified"": ""2024-02-28 18:12:12+00:00"", ""cardData"": ""base_model:\n- google/gemma-7b\nlibrary_name: transformers\nlicense: apache-2.0\ntags:\n- merge\n- mergekit\n- google/gemma-7b-it\n- google/gemma-7b\nmerge-model:\n- google/gemma-7b-it"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""65de48cfbffca636e923b7a2"", ""modelId"": ""arcee-ai/gemma-7b-slerp"", ""usedStorage"": 17097109940}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=arcee-ai/gemma-7b-slerp&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Barcee-ai%2Fgemma-7b-slerp%5D(%2Farcee-ai%2Fgemma-7b-slerp)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
Telugu-LLM-Labs/Telugu-gemma-7b-finetuned-sft,"---
license: other
license_name: gemma-terms-of-use
license_link: https://ai.google.dev/gemma/terms
base_model: google/gemma-7b
datasets:
- Telugu-LLM-Labs/telugu_teknium_GPTeacher_general_instruct_filtered_romanized
- Telugu-LLM-Labs/telugu_alpaca_yahma_cleaned_filtered_romanized
language:
- te
- en
library_name: transformers
pipeline_tag: text-generation
---

# Telugu-gemma-7b-finetuned-sft

This model is based on [google/gemma-7b](https://huggingface.co/google/gemma-7b) and hase been LoRA finetuned on instruction datasets:
  1. [yahma_alpaca_cleaned_telugu_filtered_and_romanized](https://huggingface.co/datasets/Telugu-LLM-Labs/yahma_alpaca_cleaned_telugu_filtered_and_romanized)
  2. [teknium_GPTeacher_general_instruct_telugu_filtered_and_romanized](https://huggingface.co/datasets/Telugu-LLM-Labs/teknium_GPTeacher_general_instruct_telugu_filtered_and_romanized)

The model is finetuned using [unsloth](https://github.com/unslothai/unsloth) library and we provide inference code using the same for faster inference. Alternatively you can use HuggingFace Library for inference.

The model is finetuned only on native telugu SFT data from above datasets and we will update the model with transliteration in upcoming days.

# Installation

`!pip install ""unsloth[colab-ampere] @git+https://github.com/unslothai/unsloth.git""`

# Input Text Format

```
### Instruction: {instruction}

### Input: {input}

## Response: {response}
```

# Inference With Unsloth

```python3
from unsloth import FastLanguageModel
import torch
max_seq_length = 2048
dtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+
load_in_4bit = False 
model, tokenizer = FastLanguageModel.from_pretrained(
    model_name = ""Telugu-LLM-Labs/Telugu-gemma-7b-finetuned-sft"",
    max_seq_length = max_seq_length,
    dtype = dtype,
    load_in_4bit = load_in_4bit,
    device_map=""auto""
)
FastLanguageModel.for_inference(model) # Enable native 2x faster inference

input_prompt = """"""
### Instruction:
{}

### Input:
{}

### Response:
{}""""""

input_text = input_prompt.format(
        ""కింది వచనాన్ని రెండు పాయింట్లలో సంగ్రహించండి."", # instruction
        ""Google వార్తలు అనేది Google ద్వారా అభివృద్ధి చేయబడిన వార్తా అగ్రిగేటర్ సేవ. ఇది వేలకొద్దీ ప్రచురణకర్తలు మరియు మ్యాగజైన్‌ల నుండి నిర్వహించబడిన కథనాలకు నిరంతర లింక్‌లను అందిస్తుంది. Google వార్తలు Android, iOS మరియు వెబ్‌లో యాప్‌గా అందుబాటులో ఉన్నాయి. గూగుల్ సెప్టెంబరు 2002లో బీటా వెర్షన్‌ను మరియు జనవరి 2006లో అధికారిక యాప్‌ను విడుదల చేసింది."", # input
        """", # output - leave this blank for generation!
    )

inputs = tokenizer([input_text], return_tensors = ""pt"").to(""cuda"")

outputs = model.generate(**inputs, max_new_tokens = 300, use_cache = True)
response = tokenizer.batch_decode(outputs)
```

# Inference with HuggingFace

```python3
from peft import AutoPeftModelForCausalLM
from transformers import AutoTokenizer

model = AutoPeftModelForCausalLM.from_pretrained(
    ""Telugu-LLM-Labs/Telugu-gemma-7b-finetuned-sft"",
    load_in_4bit = False,
    token = hf_token
)
tokenizer = AutoTokenizer.from_pretrained(""Telugu-LLM-Labs/Telugu-gemma-7b-finetuned-sft"")

input_prompt = """"""
### Instruction:
{}

### Input:
{}

### Response:
{}""""""

input_text = input_prompt.format(
        ""కింది వచనాన్ని రెండు పాయింట్లలో సంగ్రహించండి."", # instruction
        ""Google వార్తలు అనేది Google ద్వారా అభివృద్ధి చేయబడిన వార్తా అగ్రిగేటర్ సేవ. ఇది వేలకొద్దీ ప్రచురణకర్తలు మరియు మ్యాగజైన్‌ల నుండి నిర్వహించబడిన కథనాలకు నిరంతర లింక్‌లను అందిస్తుంది. Google వార్తలు Android, iOS మరియు వెబ్‌లో యాప్‌గా అందుబాటులో ఉన్నాయి. గూగుల్ సెప్టెంబరు 2002లో బీటా వెర్షన్‌ను మరియు జనవరి 2006లో అధికారిక యాప్‌ను విడుదల చేసింది."", # input
        """", # output - leave this blank for generation!
    )

inputs = tokenizer([input_text], return_tensors = ""pt"").to(""cuda"")

outputs = model.generate(**inputs, max_new_tokens = 300, use_cache = True)
response = tokenizer.batch_decode(outputs)[0]
```

# Sample Questions and Responses

## Reasoning

### Instruction: 
(5+4)*(2+1)? నాకు దశల వారీ వివరణ ఇవ్వండి. 

### Response:
1. పారెంథసిస్ లోపల వ్యక్తీకరణలను పరిష్కరించండి: (5+4) మరియు (2+1).
2. పరిష్కారాలను గుణించండి: (5+4) * (2+1).
3. ఫలితాన్ని లెక్కించండి: 9 * 3.
4. తుది సమాధానాన్ని పొందడానికి 9ని 3 తో గుణించండి: 27.

## Content Generation

### Instruction:
కాకి మీద చాలా చిన్న కథ రాయండి

### Response:
ఒకప్పుడు ఒక పల్లెటూరులో అందమైన, పచ్చని పొలాల మధ్య ఒక పెద్ద కాకి ఉండేది. అక్కడి పిల్లలు తరచూ ఆకాశంలోకి ఎగురుతూ, పైకి ఎగురుతూ కనిపించేవారు.

ఒక రోజు, పల్లెటూరులోని ఒక పిల్లవాడు అక్కడికి వచ్చి, కాకిని చూసి ఆశ్చర్యపోయాడు. ""కాకి, మీరు అందమైన పక్షి, మీరు ఎక్కడ నుండి వచ్చారు?"" అని అడిగాడు.

కాకి కిటికీలోకి దూకింది, తన పక్కనే పడుకుంది మరియు ""నాకు ఇక్కడ ఎవరికీ తెలియదు. నాకు ఇక్కడ కూడా ఇష్టం.""

కాకికి పిల్లవాడు ఆశ్చర్యపోయాడు మరియు ""నాకు ఇక్కడ కూడా ఇష్టం. మీరు అందమైన పక్షి, మీరు ఇక్కడికి వచ్చినందుకు నాకు సంతోషంగా ఉంది.""

కాకి కిటికీలోకి దూకింది మరియు పిల్లవాడు వెంటనే పాట వింటాడు. ""నాకు ఇక్కడ ఇష్టం. నాకు ఇక్కడికి వచ్చినందుకు ధన్యవాదాలు.""

అప్పటి నుండి, పిల్లవాడు తరచూ కాకిని చూడవచ్చు, అది పచ్చని పొలాల పైన ఎగురుతుంది. కానీ అది ఎక్కడి నుంచి వచ్చిందో ఎప్పుడూ అర్థం కాలేదు.

## Question Answering with Context

### Instruction:
స్నోఫ్లేక్ సీఈవో ఎవరు?

### Input:
స్నోఫ్లేక్ (NYSE: SNOW), డేటా క్లౌడ్ కంపెనీ, ఫ్రాంక్ స్లూట్‌మన్ చీఫ్ ఎగ్జిక్యూటివ్ ఆఫీసర్‌గా పదవీ విరమణ చేయాలని నిర్ణయించుకున్నారని మరియు శ్రీధర్ రామస్వామి చీఫ్ ఎగ్జిక్యూటివ్ ఆఫీసర్‌గా మరియు డైరెక్టర్ల బోర్డు సభ్యునిగా వెంటనే అమలులోకి వచ్చినట్లు ఈరోజు ప్రకటించింది. శ్రీధర్ రామస్వామి గతంలో స్నోఫ్లేక్‌లో AI సీనియర్ వైస్ ప్రెసిడెంట్‌గా ఉన్నారు.

### Response:
స్నోఫ్లేక్ సీఈవో (క్రింది పదవిలో) శ్రీధర్ రామస్వామి

## General Question Answering

### Instruction:
Share the strategy to grow audience on Twitter in 3 short points?

### Response:
1. **కంటెంట్ సృష్టి మరియు పంపిణీని పెంపొందించండి:** మీరు మీ ప్రేక్షకులకు విలువను అందించే అధిక-నాణ్యత, సంబంధిత మరియు ఆకర్షణీయమైన కంటెంట్ను సృష్టించడం ద్వారా ప్రారంభించండి. మీరు మీ కంటెంట్ను పంచుకునే విధానం గురించి కూడా చాలా అవగాహన పొందాలి. మీరు మీ కంటెంట్ను పంచుకోవడానికి అనుకూలమైన పద్ధతులలో ట్విట్టర్ లైవ్, వీడియోలు, ఇన్ఫోగ్రాఫిక్స్ మరియు మరెన్నో ఉన్నాయి.

2. **ఇతరులతో నిమగ్నం అవ్వండి:** ఇతరులతో నిమగ్నం కావడం అంటే వ్యాఖ్యలు మరియు సందేశాలకు ప్రతిస్పందించడం, ఇతర ట్విట్టర్ వినియోగదారులతో సహకరించడం మరియు మీ పరిధిని పెంచడానికి ఇతర ప్రసిద్ధ ట్విట్టర్ ఖాతాలను పంచుకోవడం. ఇది సంభావ్య అనుచరులను ఆకర్షించడానికి మరియు మీ ప్రస్తుత అనుచరులను నిలుపుకోవటానికి సహాయపడుతుంది.

3. **మీ ప్రేక్షకులను విశ్లేషించండి:** మీ ట్విట్టర్ ఖాతాను పర్యవేక్షించడానికి మరియు మీ పోస్ట్ ల పనితీరును ట్రాక్ చేయడానికి ట్విట్టర్ యొక్క విశ్లేషణ సాధనాలను ఉపయోగించండి. ఇది మీ కంటెంట్ను మెరుగుపరచడానికి మరియు మీ ప్రేక్షకులను మరింత సమర్థవంతంగా లక్ష్యంగా చేసుకోవడానికి మీకు సహాయపడుతుంది. మీ పోస్ట్ ల పనితీరును పర్యవేక్షించడం ద్వారా మరియు అత్యంత పనితీరు కనబరిచిన కంటెంట్ ను పునరుత్పత్తి చేయడం ద్వారా, మీరు మీ ఆన్ లైన్ ఉనికిని పెంచుకోవచ్చు మరియు మీ ప్రేక్షకులను పెంచుకోవచ్చు.

------------------------------------------------------------------------------------------------------------------------------------


# Developers:

The model is a collaborative effort by [Ravi Theja](https://twitter.com/ravithejads) and [Ramsri Goutham](https://twitter.com/ramsri_goutham). Feel free to DM either of us if you have any questions.","{""id"": ""Telugu-LLM-Labs/Telugu-gemma-7b-finetuned-sft"", ""author"": ""Telugu-LLM-Labs"", ""sha"": ""749c0b20c5ab14ef48f6903354552ee8e850fb92"", ""last_modified"": ""2024-03-17 13:45:29+00:00"", ""created_at"": ""2024-02-29 03:42:01+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 14, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""safetensors"", ""text-generation"", ""te"", ""en"", ""dataset:Telugu-LLM-Labs/telugu_teknium_GPTeacher_general_instruct_filtered_romanized"", ""dataset:Telugu-LLM-Labs/telugu_alpaca_yahma_cleaned_filtered_romanized"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""license:other"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- Telugu-LLM-Labs/telugu_teknium_GPTeacher_general_instruct_filtered_romanized\n- Telugu-LLM-Labs/telugu_alpaca_yahma_cleaned_filtered_romanized\nlanguage:\n- te\n- en\nlibrary_name: transformers\nlicense: other\nlicense_name: gemma-terms-of-use\nlicense_link: https://ai.google.dev/gemma/terms\npipeline_tag: text-generation"", ""widget_data"": null, ""model_index"": null, ""config"": {""tokenizer_config"": {""bos_token"": ""<bos>"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModel"", ""custom_class"": null, ""pipeline_tag"": null, ""processor"": null}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='LICENSE', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2024-03-17 13:45:29+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- Telugu-LLM-Labs/telugu_teknium_GPTeacher_general_instruct_filtered_romanized\n- Telugu-LLM-Labs/telugu_alpaca_yahma_cleaned_filtered_romanized\nlanguage:\n- te\n- en\nlibrary_name: transformers\nlicense: other\nlicense_name: gemma-terms-of-use\nlicense_link: https://ai.google.dev/gemma/terms\npipeline_tag: text-generation"", ""transformersInfo"": {""auto_model"": ""AutoModel"", ""custom_class"": null, ""pipeline_tag"": null, ""processor"": null}, ""_id"": ""65dffd094ca171ab2664dc1c"", ""modelId"": ""Telugu-LLM-Labs/Telugu-gemma-7b-finetuned-sft"", ""usedStorage"": 821835012}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=Telugu-LLM-Labs/Telugu-gemma-7b-finetuned-sft&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5BTelugu-LLM-Labs%2FTelugu-gemma-7b-finetuned-sft%5D(%2FTelugu-LLM-Labs%2FTelugu-gemma-7b-finetuned-sft)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
https://huggingface.co/OpenBuddy/openbuddy-gemma-7b-v19.1-4k,N/A,N/A,1,,0,,0,,0,,0,,0.0
lewtun/gemma-7b-sft-full-dolly-v0,"---
license: other
base_model: google/gemma-7b
tags:
- alignment-handbook
- trl
- sft
- generated_from_trainer
- trl
- sft
- generated_from_trainer
datasets:
- philschmid/dolly-15k-oai-style
model-index:
- name: gemma-7b-sft-full-dolly-v0
  results: []
---

<!-- This model card has been generated automatically according to the information the Trainer had access to. You
should probably proofread and complete it, then remove this comment. -->

# gemma-7b-sft-full-dolly-v0

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the philschmid/dolly-15k-oai-style dataset.

## Model description

More information needed

## Intended uses & limitations

More information needed

## Training and evaluation data

More information needed

## Training procedure

### Training hyperparameters

The following hyperparameters were used during training:
- learning_rate: 2e-05
- train_batch_size: 4
- eval_batch_size: 16
- seed: 42
- distributed_type: multi-GPU
- num_devices: 8
- gradient_accumulation_steps: 4
- total_train_batch_size: 128
- total_eval_batch_size: 128
- optimizer: Adam with betas=(0.9,0.999) and epsilon=1e-08
- lr_scheduler_type: cosine
- lr_scheduler_warmup_ratio: 0.1
- num_epochs: 3

### Training results



### Framework versions

- Transformers 4.39.0.dev0
- Pytorch 2.1.2+cu121
- Datasets 2.14.6
- Tokenizers 0.15.1
","{""id"": ""lewtun/gemma-7b-sft-full-dolly-v0"", ""author"": ""lewtun"", ""sha"": ""8e85221aebc55546da8b134cbcec5d31b7e4c475"", ""last_modified"": ""2024-02-29 11:51:11+00:00"", ""created_at"": ""2024-02-29 11:38:13+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""alignment-handbook"", ""trl"", ""sft"", ""generated_from_trainer"", ""conversational"", ""dataset:philschmid/dolly-15k-oai-style"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""license:other"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- philschmid/dolly-15k-oai-style\nlicense: other\ntags:\n- alignment-handbook\n- trl\n- sft\n- generated_from_trainer\nmodel-index:\n- name: gemma-7b-sft-full-dolly-v0\n  results: []"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": [{""name"": ""gemma-7b-sft-full-dolly-v0"", ""results"": []}], ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% for message in messages %}{{'<|im_start|>' + message['role'] + '\n' + message['content'] + '<|im_end|>' + '\n'}}{% endfor %}{% if add_generation_prompt %}{{ '<|im_start|>assistant\n' }}{% else %}{{ eos_token }}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='generation_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00001-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00002-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00003-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00004-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model.safetensors.index.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Feb29_11-37-37_ip-26-0-166-244/events.out.tfevents.1709206696.ip-26-0-166-244.3458191.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Feb29_11-43-18_ip-26-0-166-244/events.out.tfevents.1709207022.ip-26-0-166-244.3459558.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Feb29_11-45-28_ip-26-0-166-244/events.out.tfevents.1709207149.ip-26-0-166-244.3460209.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": {""parameters"": {""BF16"": 8537680896}, ""total"": 8537680896}, ""security_repo_status"": null, ""lastModified"": ""2024-02-29 11:51:11+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- philschmid/dolly-15k-oai-style\nlicense: other\ntags:\n- alignment-handbook\n- trl\n- sft\n- generated_from_trainer\nmodel-index:\n- name: gemma-7b-sft-full-dolly-v0\n  results: []"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""65e06ca5e24cefcceb9abbdd"", ""modelId"": ""lewtun/gemma-7b-sft-full-dolly-v0"", ""usedStorage"": 17092891664}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=lewtun/gemma-7b-sft-full-dolly-v0&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Blewtun%2Fgemma-7b-sft-full-dolly-v0%5D(%2Flewtun%2Fgemma-7b-sft-full-dolly-v0)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
lewtun/gemma-7b-sft-full-dolly-v1,"---
license: other
base_model: google/gemma-7b
tags:
- alignment-handbook
- trl
- sft
- generated_from_trainer
- trl
- sft
- generated_from_trainer
datasets:
- philschmid/dolly-15k-oai-style
model-index:
- name: gemma-7b-sft-full-dolly-v1
  results: []
---

<!-- This model card has been generated automatically according to the information the Trainer had access to. You
should probably proofread and complete it, then remove this comment. -->

# gemma-7b-sft-full-dolly-v1

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the philschmid/dolly-15k-oai-style dataset.

## Model description

More information needed

## Intended uses & limitations

More information needed

## Training and evaluation data

More information needed

## Training procedure

### Training hyperparameters

The following hyperparameters were used during training:
- learning_rate: 4e-05
- train_batch_size: 4
- eval_batch_size: 16
- seed: 42
- distributed_type: multi-GPU
- num_devices: 8
- gradient_accumulation_steps: 4
- total_train_batch_size: 128
- total_eval_batch_size: 128
- optimizer: Adam with betas=(0.9,0.999) and epsilon=1e-08
- lr_scheduler_type: cosine
- lr_scheduler_warmup_ratio: 0.1
- num_epochs: 3

### Training results



### Framework versions

- Transformers 4.39.0.dev0
- Pytorch 2.1.2+cu121
- Datasets 2.14.6
- Tokenizers 0.15.1
","{""id"": ""lewtun/gemma-7b-sft-full-dolly-v1"", ""author"": ""lewtun"", ""sha"": ""b69cb83b670f2e271d3e874639b74fa112995b60"", ""last_modified"": ""2024-02-29 12:03:57+00:00"", ""created_at"": ""2024-02-29 11:58:44+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 1, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""safetensors"", ""gemma"", ""text-generation"", ""alignment-handbook"", ""trl"", ""sft"", ""generated_from_trainer"", ""conversational"", ""dataset:philschmid/dolly-15k-oai-style"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""license:other"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- philschmid/dolly-15k-oai-style\nlicense: other\ntags:\n- alignment-handbook\n- trl\n- sft\n- generated_from_trainer\nmodel-index:\n- name: gemma-7b-sft-full-dolly-v1\n  results: []"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": [{""name"": ""gemma-7b-sft-full-dolly-v1"", ""results"": []}], ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% for message in messages %}{{'<|im_start|>' + message['role'] + '\n' + message['content'] + '<|im_end|>' + '\n'}}{% endfor %}{% if add_generation_prompt %}{{ '<|im_start|>assistant\n' }}{% else %}{{ eos_token }}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='generation_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00001-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00002-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00003-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00004-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model.safetensors.index.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": {""parameters"": {""BF16"": 8537680896}, ""total"": 8537680896}, ""security_repo_status"": null, ""lastModified"": ""2024-02-29 12:03:57+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- philschmid/dolly-15k-oai-style\nlicense: other\ntags:\n- alignment-handbook\n- trl\n- sft\n- generated_from_trainer\nmodel-index:\n- name: gemma-7b-sft-full-dolly-v1\n  results: []"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""65e07174663980a9321eff66"", ""modelId"": ""lewtun/gemma-7b-sft-full-dolly-v1"", ""usedStorage"": 17092874969}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=lewtun/gemma-7b-sft-full-dolly-v1&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Blewtun%2Fgemma-7b-sft-full-dolly-v1%5D(%2Flewtun%2Fgemma-7b-sft-full-dolly-v1)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
lewtun/gemma-7b-sft-full-dolly-v2,"---
license: other
base_model: google/gemma-7b
tags:
- alignment-handbook
- trl
- sft
- generated_from_trainer
- trl
- sft
- generated_from_trainer
datasets:
- philschmid/dolly-15k-oai-style
model-index:
- name: gemma-7b-sft-full-dolly-v2
  results: []
---

<!-- This model card has been generated automatically according to the information the Trainer had access to. You
should probably proofread and complete it, then remove this comment. -->

# gemma-7b-sft-full-dolly-v2

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the philschmid/dolly-15k-oai-style dataset.

## Model description

More information needed

## Intended uses & limitations

More information needed

## Training and evaluation data

More information needed

## Training procedure

### Training hyperparameters

The following hyperparameters were used during training:
- learning_rate: 2e-05
- train_batch_size: 4
- eval_batch_size: 16
- seed: 42
- distributed_type: multi-GPU
- num_devices: 8
- total_train_batch_size: 32
- total_eval_batch_size: 128
- optimizer: Adam with betas=(0.9,0.999) and epsilon=1e-08
- lr_scheduler_type: cosine
- lr_scheduler_warmup_ratio: 0.1
- num_epochs: 3

### Training results



### Framework versions

- Transformers 4.39.0.dev0
- Pytorch 2.1.2+cu121
- Datasets 2.14.6
- Tokenizers 0.15.1
","{""id"": ""lewtun/gemma-7b-sft-full-dolly-v2"", ""author"": ""lewtun"", ""sha"": ""82b036b5b581f3e5110a944138ec345edc2d653c"", ""last_modified"": ""2024-02-29 12:13:39+00:00"", ""created_at"": ""2024-02-29 12:07:08+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""safetensors"", ""gemma"", ""text-generation"", ""alignment-handbook"", ""trl"", ""sft"", ""generated_from_trainer"", ""conversational"", ""dataset:philschmid/dolly-15k-oai-style"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""license:other"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- philschmid/dolly-15k-oai-style\nlicense: other\ntags:\n- alignment-handbook\n- trl\n- sft\n- generated_from_trainer\nmodel-index:\n- name: gemma-7b-sft-full-dolly-v2\n  results: []"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": [{""name"": ""gemma-7b-sft-full-dolly-v2"", ""results"": []}], ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% for message in messages %}{{'<|im_start|>' + message['role'] + '\n' + message['content'] + '<|im_end|>' + '\n'}}{% endfor %}{% if add_generation_prompt %}{{ '<|im_start|>assistant\n' }}{% else %}{{ eos_token }}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='generation_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00001-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00002-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00003-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00004-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model.safetensors.index.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": {""parameters"": {""BF16"": 8537680896}, ""total"": 8537680896}, ""security_repo_status"": null, ""lastModified"": ""2024-02-29 12:13:39+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- philschmid/dolly-15k-oai-style\nlicense: other\ntags:\n- alignment-handbook\n- trl\n- sft\n- generated_from_trainer\nmodel-index:\n- name: gemma-7b-sft-full-dolly-v2\n  results: []"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""65e0736c4ab2a7725e463ee1"", ""modelId"": ""lewtun/gemma-7b-sft-full-dolly-v2"", ""usedStorage"": 17092874969}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=lewtun/gemma-7b-sft-full-dolly-v2&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Blewtun%2Fgemma-7b-sft-full-dolly-v2%5D(%2Flewtun%2Fgemma-7b-sft-full-dolly-v2)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
lewtun/gemma-7b-sft-full-dolly-v3,"---
license: other
base_model: google/gemma-7b
tags:
- alignment-handbook
- trl
- sft
- generated_from_trainer
- trl
- sft
- generated_from_trainer
datasets:
- philschmid/dolly-15k-oai-style
model-index:
- name: gemma-7b-sft-full-dolly-v3
  results: []
---

<!-- This model card has been generated automatically according to the information the Trainer had access to. You
should probably proofread and complete it, then remove this comment. -->

# gemma-7b-sft-full-dolly-v3

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the philschmid/dolly-15k-oai-style dataset.

## Model description

More information needed

## Intended uses & limitations

More information needed

## Training and evaluation data

More information needed

## Training procedure

### Training hyperparameters

The following hyperparameters were used during training:
- learning_rate: 2e-05
- train_batch_size: 4
- eval_batch_size: 16
- seed: 42
- distributed_type: multi-GPU
- num_devices: 8
- total_train_batch_size: 32
- total_eval_batch_size: 128
- optimizer: Adam with betas=(0.9,0.999) and epsilon=1e-08
- lr_scheduler_type: cosine
- lr_scheduler_warmup_ratio: 0.1
- num_epochs: 3

### Training results



### Framework versions

- Transformers 4.39.0.dev0
- Pytorch 2.1.2+cu121
- Datasets 2.14.6
- Tokenizers 0.15.1
","{""id"": ""lewtun/gemma-7b-sft-full-dolly-v3"", ""author"": ""lewtun"", ""sha"": ""210d01279b2c76aa7cf569e55ab171a414920978"", ""last_modified"": ""2024-02-29 12:36:27+00:00"", ""created_at"": ""2024-02-29 12:24:16+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 1, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""safetensors"", ""gemma"", ""text-generation"", ""alignment-handbook"", ""trl"", ""sft"", ""generated_from_trainer"", ""conversational"", ""dataset:philschmid/dolly-15k-oai-style"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""license:other"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- philschmid/dolly-15k-oai-style\nlicense: other\ntags:\n- alignment-handbook\n- trl\n- sft\n- generated_from_trainer\nmodel-index:\n- name: gemma-7b-sft-full-dolly-v3\n  results: []"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": [{""name"": ""gemma-7b-sft-full-dolly-v3"", ""results"": []}], ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% for message in messages %}{{'<|im_start|>' + message['role'] + '\n' + message['content'] + '<|im_end|>' + '\n'}}{% endfor %}{% if add_generation_prompt %}{{ '<|im_start|>assistant\n' }}{% else %}{{ eos_token }}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='generation_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00001-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00002-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00003-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00004-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model.safetensors.index.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": {""parameters"": {""BF16"": 8537680896}, ""total"": 8537680896}, ""security_repo_status"": null, ""lastModified"": ""2024-02-29 12:36:27+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- philschmid/dolly-15k-oai-style\nlicense: other\ntags:\n- alignment-handbook\n- trl\n- sft\n- generated_from_trainer\nmodel-index:\n- name: gemma-7b-sft-full-dolly-v3\n  results: []"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""65e0777091899c8d7000f232"", ""modelId"": ""lewtun/gemma-7b-sft-full-dolly-v3"", ""usedStorage"": 17092874969}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=lewtun/gemma-7b-sft-full-dolly-v3&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Blewtun%2Fgemma-7b-sft-full-dolly-v3%5D(%2Flewtun%2Fgemma-7b-sft-full-dolly-v3)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
lewtun/gemma-7b-sft-full-ultrachat-v0,"---
license: other
base_model: google/gemma-7b
tags:
- alignment-handbook
- trl
- sft
- generated_from_trainer
- trl
- sft
- generated_from_trainer
datasets:
- HuggingFaceH4/ultrachat_200k
model-index:
- name: gemma-7b-sft-full-ultrachat-v0
  results: []
---

<!-- This model card has been generated automatically according to the information the Trainer had access to. You
should probably proofread and complete it, then remove this comment. -->

# gemma-7b-sft-full-ultrachat-v0

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the HuggingFaceH4/ultrachat_200k dataset.

## Model description

More information needed

## Intended uses & limitations

More information needed

## Training and evaluation data

More information needed

## Training procedure

### Training hyperparameters

The following hyperparameters were used during training:
- learning_rate: 2e-05
- train_batch_size: 4
- eval_batch_size: 4
- seed: 42
- distributed_type: multi-GPU
- num_devices: 16
- gradient_accumulation_steps: 2
- total_train_batch_size: 128
- total_eval_batch_size: 64
- optimizer: Adam with betas=(0.9,0.999) and epsilon=1e-08
- lr_scheduler_type: cosine
- lr_scheduler_warmup_ratio: 0.1
- num_epochs: 1

### Training results



### Framework versions

- Transformers 4.39.0.dev0
- Pytorch 2.1.2+cu121
- Datasets 2.14.6
- Tokenizers 0.15.1
","{""id"": ""lewtun/gemma-7b-sft-full-ultrachat-v0"", ""author"": ""lewtun"", ""sha"": ""499e82750007cd82c2d6220c199cb07c3c1ac249"", ""last_modified"": ""2024-02-29 15:40:39+00:00"", ""created_at"": ""2024-02-29 13:03:21+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 2, ""downloads_all_time"": null, ""likes"": 1, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""alignment-handbook"", ""trl"", ""sft"", ""generated_from_trainer"", ""conversational"", ""dataset:HuggingFaceH4/ultrachat_200k"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""license:other"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- HuggingFaceH4/ultrachat_200k\nlicense: other\ntags:\n- alignment-handbook\n- trl\n- sft\n- generated_from_trainer\nmodel-index:\n- name: gemma-7b-sft-full-ultrachat-v0\n  results: []"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": [{""name"": ""gemma-7b-sft-full-ultrachat-v0"", ""results"": []}], ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% for message in messages %}{{'<|im_start|>' + message['role'] + '\n' + message['content'] + '<|im_end|>' + '\n'}}{% endfor %}{% if add_generation_prompt %}{{ '<|im_start|>assistant\n' }}{% else %}{{ eos_token }}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='generation_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00001-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00002-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00003-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00004-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model.safetensors.index.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Feb29_13-20-34_ip-26-0-161-142/events.out.tfevents.1709213458.ip-26-0-161-142.1718787.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Feb29_14-51-25_ip-26-0-169-139/events.out.tfevents.1709218323.ip-26-0-169-139.2593159.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": {""parameters"": {""BF16"": 8537680896}, ""total"": 8537680896}, ""security_repo_status"": null, ""lastModified"": ""2024-02-29 15:40:39+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- HuggingFaceH4/ultrachat_200k\nlicense: other\ntags:\n- alignment-handbook\n- trl\n- sft\n- generated_from_trainer\nmodel-index:\n- name: gemma-7b-sft-full-ultrachat-v0\n  results: []"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""65e08099516f9405b0b4fe9c"", ""modelId"": ""lewtun/gemma-7b-sft-full-ultrachat-v0"", ""usedStorage"": 17092935539}",1,"https://huggingface.co/lewtun/gemma-7b-dpo-full-orca-v0, https://huggingface.co/lewtun/gemma-7b-dpo-full-ultrafeedback-beta-0.01",2,,0,,0,huggingface/InferenceSupport/discussions/new?title=lewtun/gemma-7b-sft-full-ultrachat-v0&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Blewtun%2Fgemma-7b-sft-full-ultrachat-v0%5D(%2Flewtun%2Fgemma-7b-sft-full-ultrachat-v0)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
lewtun/gemma-7b-dpo-full-orca-v0,"---
license: other
base_model: lewtun/gemma-7b-sft-full-ultrachat-v0
tags:
- alignment-handbook
- trl
- dpo
- generated_from_trainer
- trl
- dpo
- generated_from_trainer
datasets:
- HuggingFaceH4/orca_dpo_pairs
model-index:
- name: gemma-7b-dpo-full-orca-v0
  results: []
---

<!-- This model card has been generated automatically according to the information the Trainer had access to. You
should probably proofread and complete it, then remove this comment. -->

# gemma-7b-dpo-full-orca-v0

This model is a fine-tuned version of [lewtun/gemma-7b-sft-full-ultrachat-v0](https://huggingface.co/lewtun/gemma-7b-sft-full-ultrachat-v0) on the HuggingFaceH4/orca_dpo_pairs dataset.
It achieves the following results on the evaluation set:
- Loss: 0.0131
- Rewards/chosen: 4.5525
- Rewards/rejected: -7.7149
- Rewards/accuracies: 0.9922
- Rewards/margins: 12.2674
- Logps/rejected: -860.7157
- Logps/chosen: -725.1588
- Logits/rejected: 141.1811
- Logits/chosen: 94.1054

## Model description

More information needed

## Intended uses & limitations

More information needed

## Training and evaluation data

More information needed

## Training procedure

### Training hyperparameters

The following hyperparameters were used during training:
- learning_rate: 5e-07
- train_batch_size: 4
- eval_batch_size: 4
- seed: 42
- distributed_type: multi-GPU
- num_devices: 8
- gradient_accumulation_steps: 4
- total_train_batch_size: 128
- total_eval_batch_size: 32
- optimizer: Adam with betas=(0.9,0.999) and epsilon=1e-08
- lr_scheduler_type: cosine
- lr_scheduler_warmup_ratio: 0.1
- num_epochs: 1

### Training results



### Framework versions

- Transformers 4.39.0.dev0
- Pytorch 2.1.2+cu121
- Datasets 2.14.6
- Tokenizers 0.15.1
","{""id"": ""lewtun/gemma-7b-dpo-full-orca-v0"", ""author"": ""lewtun"", ""sha"": ""00636577c4d0867c56774ecc0145089195c53c4e"", ""last_modified"": ""2024-02-29 16:52:45+00:00"", ""created_at"": ""2024-02-29 15:31:49+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""alignment-handbook"", ""trl"", ""dpo"", ""generated_from_trainer"", ""conversational"", ""dataset:HuggingFaceH4/orca_dpo_pairs"", ""base_model:lewtun/gemma-7b-sft-full-ultrachat-v0"", ""base_model:finetune:lewtun/gemma-7b-sft-full-ultrachat-v0"", ""license:other"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: lewtun/gemma-7b-sft-full-ultrachat-v0\ndatasets:\n- HuggingFaceH4/orca_dpo_pairs\nlicense: other\ntags:\n- alignment-handbook\n- trl\n- dpo\n- generated_from_trainer\nmodel-index:\n- name: gemma-7b-dpo-full-orca-v0\n  results: []"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": [{""name"": ""gemma-7b-dpo-full-orca-v0"", ""results"": []}], ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{% if messages[0]['role'] == 'user' or messages[0]['role'] == 'system' %}{{ bos_token }}{% endif %}{% for message in messages %}{{ '<|im_start|>' + message['role'] + '\n' + message['content'] + '<|im_end|>' + '\n' }}{% endfor %}{% if add_generation_prompt %}{{ '<|im_start|>assistant\n' }}{% elif messages[-1]['role'] == 'assistant' %}{{ eos_token }}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='eval_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='generation_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00001-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00002-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00003-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00004-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model.safetensors.index.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Feb29_16-29-02_ip-26-0-167-9/events.out.tfevents.1709224231.ip-26-0-167-9.3787591.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Feb29_16-29-02_ip-26-0-167-9/events.out.tfevents.1709225527.ip-26-0-167-9.3787591.1', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": {""parameters"": {""BF16"": 8537680896}, ""total"": 8537680896}, ""security_repo_status"": null, ""lastModified"": ""2024-02-29 16:52:45+00:00"", ""cardData"": ""base_model: lewtun/gemma-7b-sft-full-ultrachat-v0\ndatasets:\n- HuggingFaceH4/orca_dpo_pairs\nlicense: other\ntags:\n- alignment-handbook\n- trl\n- dpo\n- generated_from_trainer\nmodel-index:\n- name: gemma-7b-dpo-full-orca-v0\n  results: []"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""65e0a36537c8528cd011792f"", ""modelId"": ""lewtun/gemma-7b-dpo-full-orca-v0"", ""usedStorage"": 17092887782}",2,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=lewtun/gemma-7b-dpo-full-orca-v0&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Blewtun%2Fgemma-7b-dpo-full-orca-v0%5D(%2Flewtun%2Fgemma-7b-dpo-full-orca-v0)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
https://huggingface.co/lewtun/gemma-7b-dpo-full-ultrafeedback-beta-0.01,N/A,N/A,2,,0,,0,,0,,0,,0.0
lewtun/gemma-7b-sft-full-longest-1k-v0,"---
license: other
base_model: google/gemma-7b
tags:
- alignment-handbook
- trl
- sft
- generated_from_trainer
- trl
- sft
- generated_from_trainer
datasets:
- HuggingFaceH4/OpenHermes-2.5-1k-longest
model-index:
- name: gemma-7b-sft-full-longest-1k-v0
  results: []
---

<!-- This model card has been generated automatically according to the information the Trainer had access to. You
should probably proofread and complete it, then remove this comment. -->

# gemma-7b-sft-full-longest-1k-v0

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the HuggingFaceH4/OpenHermes-2.5-1k-longest dataset.
It achieves the following results on the evaluation set:
- Loss: 1.7445

## Model description

More information needed

## Intended uses & limitations

More information needed

## Training and evaluation data

More information needed

## Training procedure

### Training hyperparameters

The following hyperparameters were used during training:
- learning_rate: 2e-06
- train_batch_size: 4
- eval_batch_size: 8
- seed: 42
- distributed_type: multi-GPU
- num_devices: 8
- gradient_accumulation_steps: 4
- total_train_batch_size: 128
- total_eval_batch_size: 64
- optimizer: Adam with betas=(0.9,0.999) and epsilon=1e-08
- lr_scheduler_type: cosine
- num_epochs: 15

### Training results

| Training Loss | Epoch | Step | Validation Loss |
|:-------------:|:-----:|:----:|:---------------:|
| 5.6993        | 1.0   | 6    | 2.8191          |
| 3.3379        | 2.0   | 12   | 2.2503          |
| 2.8978        | 3.0   | 18   | 2.0730          |
| 2.7495        | 4.0   | 24   | 1.9771          |
| 2.5265        | 5.0   | 30   | 1.9129          |
| 2.4727        | 6.0   | 36   | 1.8681          |
| 2.443         | 7.0   | 42   | 1.8344          |
| 2.3432        | 8.0   | 48   | 1.8083          |
| 2.3291        | 9.0   | 54   | 1.7878          |
| 2.2843        | 10.0  | 60   | 1.7719          |
| 2.2529        | 11.0  | 66   | 1.7595          |
| 2.2723        | 12.0  | 72   | 1.7509          |
| 2.2302        | 13.0  | 78   | 1.7465          |
| 2.2224        | 14.0  | 84   | 1.7448          |
| 2.2309        | 15.0  | 90   | 1.7445          |


### Framework versions

- Transformers 4.39.0.dev0
- Pytorch 2.1.2+cu121
- Datasets 2.14.6
- Tokenizers 0.15.1
","{""id"": ""lewtun/gemma-7b-sft-full-longest-1k-v0"", ""author"": ""lewtun"", ""sha"": ""35b4115c908be73f8bc9baaa13a4c848952d6b2d"", ""last_modified"": ""2024-02-29 14:00:18+00:00"", ""created_at"": ""2024-02-29 13:26:26+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""alignment-handbook"", ""trl"", ""sft"", ""generated_from_trainer"", ""conversational"", ""dataset:HuggingFaceH4/OpenHermes-2.5-1k-longest"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""license:other"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- HuggingFaceH4/OpenHermes-2.5-1k-longest\nlicense: other\ntags:\n- alignment-handbook\n- trl\n- sft\n- generated_from_trainer\nmodel-index:\n- name: gemma-7b-sft-full-longest-1k-v0\n  results: []"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": [{""name"": ""gemma-7b-sft-full-longest-1k-v0"", ""results"": []}], ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% for message in messages %}{{'<|im_start|>' + message['role'] + '\n' + message['content'] + '<|im_end|>' + '\n'}}{% endfor %}{% if add_generation_prompt %}{{ '<|im_start|>assistant\n' }}{% else %}{{ eos_token }}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='eval_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='generation_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00001-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00002-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00003-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00004-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model.safetensors.index.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Feb29_13-36-31_ip-26-0-166-244/events.out.tfevents.1709213816.ip-26-0-166-244.3489680.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Feb29_13-36-31_ip-26-0-166-244/events.out.tfevents.1709215080.ip-26-0-166-244.3489680.1', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": {""parameters"": {""BF16"": 8537680896}, ""total"": 8537680896}, ""security_repo_status"": null, ""lastModified"": ""2024-02-29 14:00:18+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- HuggingFaceH4/OpenHermes-2.5-1k-longest\nlicense: other\ntags:\n- alignment-handbook\n- trl\n- sft\n- generated_from_trainer\nmodel-index:\n- name: gemma-7b-sft-full-longest-1k-v0\n  results: []"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""65e086020123d090c9b703cf"", ""modelId"": ""lewtun/gemma-7b-sft-full-longest-1k-v0"", ""usedStorage"": 17092888323}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=lewtun/gemma-7b-sft-full-longest-1k-v0&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Blewtun%2Fgemma-7b-sft-full-longest-1k-v0%5D(%2Flewtun%2Fgemma-7b-sft-full-longest-1k-v0)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
lewtun/gemma-7b-sft-full-longest-1k-v1,"---
license: other
base_model: google/gemma-7b
tags:
- alignment-handbook
- trl
- sft
- generated_from_trainer
- trl
- sft
- generated_from_trainer
datasets:
- HuggingFaceH4/OpenHermes-2.5-1k-longest
model-index:
- name: gemma-7b-sft-full-longest-1k-v1
  results: []
---

<!-- This model card has been generated automatically according to the information the Trainer had access to. You
should probably proofread and complete it, then remove this comment. -->

# gemma-7b-sft-full-longest-1k-v1

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the HuggingFaceH4/OpenHermes-2.5-1k-longest dataset.
It achieves the following results on the evaluation set:
- Loss: 1.0137

## Model description

More information needed

## Intended uses & limitations

More information needed

## Training and evaluation data

More information needed

## Training procedure

### Training hyperparameters

The following hyperparameters were used during training:
- learning_rate: 2e-05
- train_batch_size: 4
- eval_batch_size: 8
- seed: 42
- distributed_type: multi-GPU
- num_devices: 8
- gradient_accumulation_steps: 4
- total_train_batch_size: 128
- total_eval_batch_size: 64
- optimizer: Adam with betas=(0.9,0.999) and epsilon=1e-08
- lr_scheduler_type: cosine
- num_epochs: 15

### Training results

| Training Loss | Epoch | Step | Validation Loss |
|:-------------:|:-----:|:----:|:---------------:|
| 1.9689        | 5.0   | 30   | 1.4644          |
| 1.1624        | 10.0  | 60   | 1.0363          |
| 1.0662        | 15.0  | 90   | 1.0137          |


### Framework versions

- Transformers 4.39.0.dev0
- Pytorch 2.1.2+cu121
- Datasets 2.14.6
- Tokenizers 0.15.1
","{""id"": ""lewtun/gemma-7b-sft-full-longest-1k-v1"", ""author"": ""lewtun"", ""sha"": ""7958ec4ebff5ba592ef91d33aa7933f0b052ea62"", ""last_modified"": ""2024-02-29 14:27:53+00:00"", ""created_at"": ""2024-02-29 14:13:41+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 4, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""safetensors"", ""gemma"", ""text-generation"", ""alignment-handbook"", ""trl"", ""sft"", ""generated_from_trainer"", ""conversational"", ""dataset:HuggingFaceH4/OpenHermes-2.5-1k-longest"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""license:other"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- HuggingFaceH4/OpenHermes-2.5-1k-longest\nlicense: other\ntags:\n- alignment-handbook\n- trl\n- sft\n- generated_from_trainer\nmodel-index:\n- name: gemma-7b-sft-full-longest-1k-v1\n  results: []"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": [{""name"": ""gemma-7b-sft-full-longest-1k-v1"", ""results"": []}], ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% for message in messages %}{{'<|im_start|>' + message['role'] + '\n' + message['content'] + '<|im_end|>' + '\n'}}{% endfor %}{% if add_generation_prompt %}{{ '<|im_start|>assistant\n' }}{% else %}{{ eos_token }}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='eval_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='generation_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00001-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00002-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00003-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00004-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model.safetensors.index.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": {""parameters"": {""BF16"": 8537680896}, ""total"": 8537680896}, ""security_repo_status"": null, ""lastModified"": ""2024-02-29 14:27:53+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- HuggingFaceH4/OpenHermes-2.5-1k-longest\nlicense: other\ntags:\n- alignment-handbook\n- trl\n- sft\n- generated_from_trainer\nmodel-index:\n- name: gemma-7b-sft-full-longest-1k-v1\n  results: []"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""65e091154383d681fd9cf307"", ""modelId"": ""lewtun/gemma-7b-sft-full-longest-1k-v1"", ""usedStorage"": 17092874969}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=lewtun/gemma-7b-sft-full-longest-1k-v1&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Blewtun%2Fgemma-7b-sft-full-longest-1k-v1%5D(%2Flewtun%2Fgemma-7b-sft-full-longest-1k-v1)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
lewtun/gemma-7b-sft-full-deita-10k-v0,"---
license: other
base_model: google/gemma-7b
tags:
- alignment-handbook
- trl
- sft
- generated_from_trainer
- trl
- sft
- generated_from_trainer
datasets:
- HuggingFaceH4/deita-10k-v0-sft
model-index:
- name: gemma-7b-sft-full-deita-10k-v0
  results: []
---

<!-- This model card has been generated automatically according to the information the Trainer had access to. You
should probably proofread and complete it, then remove this comment. -->

# gemma-7b-sft-full-deita-10k-v0

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the HuggingFaceH4/deita-10k-v0-sft dataset.

## Model description

More information needed

## Intended uses & limitations

More information needed

## Training and evaluation data

More information needed

## Training procedure

### Training hyperparameters

The following hyperparameters were used during training:
- learning_rate: 2e-05
- train_batch_size: 4
- eval_batch_size: 16
- seed: 42
- distributed_type: multi-GPU
- num_devices: 8
- gradient_accumulation_steps: 4
- total_train_batch_size: 128
- total_eval_batch_size: 128
- optimizer: Adam with betas=(0.9,0.999) and epsilon=1e-08
- lr_scheduler_type: cosine
- lr_scheduler_warmup_ratio: 0.1
- num_epochs: 3

### Training results



### Framework versions

- Transformers 4.39.0.dev0
- Pytorch 2.1.2+cu121
- Datasets 2.14.6
- Tokenizers 0.15.1
","{""id"": ""lewtun/gemma-7b-sft-full-deita-10k-v0"", ""author"": ""lewtun"", ""sha"": ""6011e3db5876401bd1052633b4394a3758c9a67d"", ""last_modified"": ""2024-02-29 16:07:41+00:00"", ""created_at"": ""2024-02-29 14:39:18+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""alignment-handbook"", ""trl"", ""sft"", ""generated_from_trainer"", ""conversational"", ""dataset:HuggingFaceH4/deita-10k-v0-sft"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""license:other"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- HuggingFaceH4/deita-10k-v0-sft\nlicense: other\ntags:\n- alignment-handbook\n- trl\n- sft\n- generated_from_trainer\nmodel-index:\n- name: gemma-7b-sft-full-deita-10k-v0\n  results: []"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": [{""name"": ""gemma-7b-sft-full-deita-10k-v0"", ""results"": []}], ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% for message in messages %}{{'<|im_start|>' + message['role'] + '\n' + message['content'] + '<|im_end|>' + '\n'}}{% endfor %}{% if add_generation_prompt %}{{ '<|im_start|>assistant\n' }}{% else %}{{ eos_token }}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='generation_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00001-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00002-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00003-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00004-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model.safetensors.index.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Feb29_14-35-38_ip-26-0-166-244/events.out.tfevents.1709217561.ip-26-0-166-244.3503402.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Feb29_14-40-22_ip-26-0-166-244/events.out.tfevents.1709217651.ip-26-0-166-244.3505275.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": {""parameters"": {""BF16"": 8537680896}, ""total"": 8537680896}, ""security_repo_status"": null, ""lastModified"": ""2024-02-29 16:07:41+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- HuggingFaceH4/deita-10k-v0-sft\nlicense: other\ntags:\n- alignment-handbook\n- trl\n- sft\n- generated_from_trainer\nmodel-index:\n- name: gemma-7b-sft-full-deita-10k-v0\n  results: []"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""65e09716bd8bd4b5306ec16b"", ""modelId"": ""lewtun/gemma-7b-sft-full-deita-10k-v0"", ""usedStorage"": 17092922794}",1,"https://huggingface.co/lewtun/gemma-7b-dpo-full-mix1-beta-0.1, https://huggingface.co/lewtun/gemma-7b-dpo-full-mix1-beta-0.1-epoch-3, https://huggingface.co/lewtun/gemma-7b-dpo-full-mix1-beta-0.2, https://huggingface.co/lewtun/gemma-7b-dpo-full-mix2-beta-0.1, https://huggingface.co/lewtun/gemma-7b-dpo-full-mix1-beta-0.4, https://huggingface.co/lewtun/gemma-7b-dpo-full-mix1-beta-0.6, https://huggingface.co/lewtun/gemma-7b-dpo-full-mix1-beta-0.05, https://huggingface.co/lewtun/gemma-7b-dpo-full-mix1-beta-0.01, https://huggingface.co/lewtun/gemma-7b-dpo-full-mix1-beta-0.4-epoch-3, https://huggingface.co/lewtun/gemma-7b-dpo-full-mix1-beta-0.05-epoch-2, https://huggingface.co/lewtun/gemma-7b-dpo-full-mix1-beta-0.05-epoch-3",11,,0,,0,huggingface/InferenceSupport/discussions/new?title=lewtun/gemma-7b-sft-full-deita-10k-v0&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Blewtun%2Fgemma-7b-sft-full-deita-10k-v0%5D(%2Flewtun%2Fgemma-7b-sft-full-deita-10k-v0)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
https://huggingface.co/lewtun/gemma-7b-dpo-full-mix1-beta-0.1,N/A,N/A,2,,0,,0,,0,,0,,0.0
https://huggingface.co/lewtun/gemma-7b-dpo-full-mix1-beta-0.1-epoch-3,N/A,N/A,2,,0,,0,,0,,0,,0.0
https://huggingface.co/lewtun/gemma-7b-dpo-full-mix1-beta-0.2,N/A,N/A,2,,0,,0,,0,,0,,0.0
https://huggingface.co/lewtun/gemma-7b-dpo-full-mix2-beta-0.1,N/A,N/A,2,,0,,0,,0,,0,,0.0
https://huggingface.co/lewtun/gemma-7b-dpo-full-mix1-beta-0.4,N/A,N/A,2,,0,,0,,0,,0,,0.0
https://huggingface.co/lewtun/gemma-7b-dpo-full-mix1-beta-0.6,N/A,N/A,2,,0,,0,,0,,0,,0.0
https://huggingface.co/lewtun/gemma-7b-dpo-full-mix1-beta-0.05,N/A,N/A,2,,0,,0,,0,,0,,0.0
https://huggingface.co/lewtun/gemma-7b-dpo-full-mix1-beta-0.01,N/A,N/A,2,,0,,0,,0,,0,,0.0
https://huggingface.co/lewtun/gemma-7b-dpo-full-mix1-beta-0.4-epoch-3,N/A,N/A,2,,0,,0,,0,,0,,0.0
https://huggingface.co/lewtun/gemma-7b-dpo-full-mix1-beta-0.05-epoch-2,N/A,N/A,2,,0,,0,,0,,0,,0.0
https://huggingface.co/lewtun/gemma-7b-dpo-full-mix1-beta-0.05-epoch-3,N/A,N/A,2,,0,,0,,0,,0,,0.0
philschmid/gemma-7b-chatml-orca-100k-test,"---
license: other
base_model: google/gemma-7b
tags:
- generated_from_trainer
datasets:
- generator
model-index:
- name: gemma-sft
  results: []
---

<!-- This model card has been generated automatically according to the information the Trainer had access to. You
should probably proofread and complete it, then remove this comment. -->

# gemma-sft

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the generator dataset.

## Model description

More information needed

## Intended uses & limitations

More information needed

## Training and evaluation data

More information needed

## Training procedure

### Training hyperparameters

The following hyperparameters were used during training:
- learning_rate: 5e-05
- train_batch_size: 8
- eval_batch_size: 8
- seed: 42
- distributed_type: multi-GPU
- num_devices: 8
- total_train_batch_size: 64
- total_eval_batch_size: 64
- optimizer: Adam with betas=(0.9,0.999) and epsilon=1e-08
- lr_scheduler_type: cosine
- lr_scheduler_warmup_ratio: 0.03
- num_epochs: 3

### Training results



### Framework versions

- Transformers 4.38.1
- Pytorch 2.1.2+cu121
- Datasets 2.17.1
- Tokenizers 0.15.0
","{""id"": ""philschmid/gemma-7b-chatml-orca-100k-test"", ""author"": ""philschmid"", ""sha"": ""8766ea2d66808e2dcee332500b0a3e046ebd84e3"", ""last_modified"": ""2024-02-29 18:26:14+00:00"", ""created_at"": ""2024-02-29 18:20:24+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 2, ""downloads_all_time"": null, ""likes"": 2, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""conversational"", ""dataset:generator"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""license:other"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- generator\nlicense: other\ntags:\n- generated_from_trainer\nmodel-index:\n- name: gemma-sft\n  results: []"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": [{""name"": ""gemma-sft"", ""results"": []}], ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{% if messages[0]['role'] == 'user' or messages[0]['role'] == 'system' %}{{ bos_token }}{% endif %}{% for message in messages %}{{ '<|im_start|>' + message['role'] + '\n' + message['content'] + '<|im_end|>' + '\n' }}{% endfor %}{% if add_generation_prompt %}{{ '<|im_start|>assistant\n' }}{% elif messages[-1]['role'] == 'assistant' %}{{ eos_token }}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='generation_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00001-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00002-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00003-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00004-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model.safetensors.index.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Feb29_16-52-23_ip-26-0-168-52/events.out.tfevents.1709225704.ip-26-0-168-52.787838.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Feb29_16-55-28_ip-26-0-168-52/events.out.tfevents.1709225803.ip-26-0-168-52.788552.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Feb29_17-27-37_ip-26-0-168-52/events.out.tfevents.1709227837.ip-26-0-168-52.792252.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": {""parameters"": {""BF16"": 9324112896}, ""total"": 9324112896}, ""security_repo_status"": null, ""lastModified"": ""2024-02-29 18:26:14+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- generator\nlicense: other\ntags:\n- generated_from_trainer\nmodel-index:\n- name: gemma-sft\n  results: []"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""65e0cae8057f3af1bc2cd258"", ""modelId"": ""philschmid/gemma-7b-chatml-orca-100k-test"", ""usedStorage"": 18665779831}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=philschmid/gemma-7b-chatml-orca-100k-test&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bphilschmid%2Fgemma-7b-chatml-orca-100k-test%5D(%2Fphilschmid%2Fgemma-7b-chatml-orca-100k-test)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
lewtun/gemma-7b-sft-full-openhermes-v0,"---
license: other
base_model: google/gemma-7b
tags:
- alignment-handbook
- trl
- sft
- generated_from_trainer
- trl
- sft
- generated_from_trainer
datasets:
- HuggingFaceH4/OpenHermes-2.5
model-index:
- name: gemma-7b-sft-full-openhermes-v0
  results: []
---

<!-- This model card has been generated automatically according to the information the Trainer had access to. You
should probably proofread and complete it, then remove this comment. -->

# gemma-7b-sft-full-openhermes-v0

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the HuggingFaceH4/OpenHermes-2.5 dataset.

## Model description

More information needed

## Intended uses & limitations

More information needed

## Training and evaluation data

More information needed

## Training procedure

### Training hyperparameters

The following hyperparameters were used during training:
- learning_rate: 1e-05
- train_batch_size: 4
- eval_batch_size: 4
- seed: 42
- distributed_type: multi-GPU
- num_devices: 16
- gradient_accumulation_steps: 8
- total_train_batch_size: 512
- total_eval_batch_size: 64
- optimizer: Adam with betas=(0.9,0.999) and epsilon=1e-08
- lr_scheduler_type: cosine
- lr_scheduler_warmup_ratio: 0.1
- num_epochs: 4

### Training results



### Framework versions

- Transformers 4.39.0.dev0
- Pytorch 2.1.2+cu121
- Datasets 2.14.6
- Tokenizers 0.15.1
","{""id"": ""lewtun/gemma-7b-sft-full-openhermes-v0"", ""author"": ""lewtun"", ""sha"": ""2116cf00722938ac88f69267974140312f8df9fd"", ""last_modified"": ""2024-03-01 04:30:19+00:00"", ""created_at"": ""2024-02-29 23:46:55+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""alignment-handbook"", ""trl"", ""sft"", ""generated_from_trainer"", ""conversational"", ""dataset:HuggingFaceH4/OpenHermes-2.5"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""license:other"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- HuggingFaceH4/OpenHermes-2.5\nlicense: other\ntags:\n- alignment-handbook\n- trl\n- sft\n- generated_from_trainer\nmodel-index:\n- name: gemma-7b-sft-full-openhermes-v0\n  results: []"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": [{""name"": ""gemma-7b-sft-full-openhermes-v0"", ""results"": []}], ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% for message in messages %}{{'<|im_start|>' + message['role'] + '\n' + message['content'] + '<|im_end|>' + '\n'}}{% endfor %}{% if add_generation_prompt %}{{ '<|im_start|>assistant\n' }}{% else %}{{ eos_token }}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='generation_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00001-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00002-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00003-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00004-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model.safetensors.index.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Feb29_23-32-13_ip-26-0-172-73/events.out.tfevents.1709250419.ip-26-0-172-73.1092806.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": {""parameters"": {""BF16"": 8537680896}, ""total"": 8537680896}, ""security_repo_status"": null, ""lastModified"": ""2024-03-01 04:30:19+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- HuggingFaceH4/OpenHermes-2.5\nlicense: other\ntags:\n- alignment-handbook\n- trl\n- sft\n- generated_from_trainer\nmodel-index:\n- name: gemma-7b-sft-full-openhermes-v0\n  results: []"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""65e1176f209d6b03a7c44ddb"", ""modelId"": ""lewtun/gemma-7b-sft-full-openhermes-v0"", ""usedStorage"": 17092942550}",1,"https://huggingface.co/lewtun/gemma-7b-dpo-full-openhermes-mix1-beta-0.1, https://huggingface.co/lewtun/gemma-7b-dpo-full-openhermes-mix1-beta-0.05, https://huggingface.co/lewtun/gemma-7b-dpo-full-openhermes-mix1-beta-0.2, https://huggingface.co/lewtun/gemma-7b-dpo-full-openhermes-mix1-beta-0.4, https://huggingface.co/lewtun/gemma-7b-dpo-full-openhermes-mix1-beta-0.01",5,,0,,0,huggingface/InferenceSupport/discussions/new?title=lewtun/gemma-7b-sft-full-openhermes-v0&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Blewtun%2Fgemma-7b-sft-full-openhermes-v0%5D(%2Flewtun%2Fgemma-7b-sft-full-openhermes-v0)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
https://huggingface.co/lewtun/gemma-7b-dpo-full-openhermes-mix1-beta-0.1,N/A,N/A,2,,0,,0,,0,,0,,0.0
https://huggingface.co/lewtun/gemma-7b-dpo-full-openhermes-mix1-beta-0.05,N/A,N/A,2,,0,,0,,0,,0,,0.0
https://huggingface.co/lewtun/gemma-7b-dpo-full-openhermes-mix1-beta-0.2,N/A,N/A,2,,0,,0,,0,,0,,0.0
https://huggingface.co/lewtun/gemma-7b-dpo-full-openhermes-mix1-beta-0.4,N/A,N/A,2,,0,,0,,0,,0,,0.0
https://huggingface.co/lewtun/gemma-7b-dpo-full-openhermes-mix1-beta-0.01,N/A,N/A,2,,0,,0,,0,,0,,0.0
https://huggingface.co/HuggingFaceH4/zephyr-7b-gemma-sft-v0.1,N/A,N/A,1,,0,,0,,0,,0,,0.0
https://huggingface.co/bartowski/zephyr-7b-gemma-sft-v0.1-exl2,N/A,N/A,1,,0,,0,,0,,0,,0.0
https://huggingface.co/LoneStriker/zephyr-7b-gemma-sft-v0.1-3.0bpw-h6-exl2,N/A,N/A,1,,0,,0,,0,,0,,0.0
https://huggingface.co/LoneStriker/zephyr-7b-gemma-sft-v0.1-4.0bpw-h6-exl2,N/A,N/A,1,,0,,0,,0,,0,,0.0
https://huggingface.co/LoneStriker/zephyr-7b-gemma-sft-v0.1-5.0bpw-h6-exl2,N/A,N/A,1,,0,,0,,0,,0,,0.0
https://huggingface.co/LoneStriker/zephyr-7b-gemma-sft-v0.1-6.0bpw-h6-exl2,N/A,N/A,1,,0,,0,,0,,0,,0.0
https://huggingface.co/LoneStriker/zephyr-7b-gemma-sft-v0.1-8.0bpw-h8-exl2,N/A,N/A,1,,0,,0,,0,,0,,0.0
https://huggingface.co/LoneStriker/openbuddy-gemma-7b-v19.1-4k-3.0bpw-h6-exl2,N/A,N/A,1,,0,,0,,0,,0,,0.0
https://huggingface.co/LoneStriker/openbuddy-gemma-7b-v19.1-4k-4.0bpw-h6-exl2,N/A,N/A,1,,0,,0,,0,,0,,0.0
https://huggingface.co/LoneStriker/openbuddy-gemma-7b-v19.1-4k-5.0bpw-h6-exl2,N/A,N/A,1,,0,,0,,0,,0,,0.0
https://huggingface.co/LoneStriker/openbuddy-gemma-7b-v19.1-4k-6.0bpw-h6-exl2,N/A,N/A,1,,0,,0,,0,,0,,0.0
https://huggingface.co/LoneStriker/openbuddy-gemma-7b-v19.1-4k-8.0bpw-h8-exl2,N/A,N/A,1,,0,,0,,0,,0,,0.0
https://huggingface.co/bartowski/openbuddy-gemma-7b-v19.1-4k-exl2,N/A,N/A,1,,0,,0,,0,,0,,0.0
Telugu-LLM-Labs/Indic-gemma-7b-finetuned-sft-Navarasa,"---
license: other
license_name: gemma-terms-of-use
license_link: https://ai.google.dev/gemma/terms
base_model: google/gemma-7b
datasets:
- ravithejads/samvaad-hi-filtered
- Telugu-LLM-Labs/telugu_teknium_GPTeacher_general_instruct_filtered_romanized
- Telugu-LLM-Labs/telugu_alpaca_yahma_cleaned_filtered_romanized
- abhinand/tamil-alpaca
- Tensoic/airoboros-3.2_kn
- Tensoic/gpt-teacher_kn
- VishnuPJ/Alpaca_Instruct_Malayalam
- Tensoic/Alpaca-Gujarati
- HydraIndicLM/punjabi_alpaca_52K
- HydraIndicLM/bengali_alpaca_dolly_67k
- OdiaGenAI/Odia_Alpaca_instructions_52k
- yahma/alpaca-cleaned
language:
- te
- en
- ta
- ml
- hi
- kn
- gu
- bn
- pa
- or
library_name: transformers
pipeline_tag: text-generation
---

# Indic-gemma-7b-finetuned-sft-Navarasa

This model is based on [google/gemma-7b](https://huggingface.co/google/gemma-7b) and hase been LoRA finetuned on 9 Indian languages and English language instruction datasets:

1. #### Hindi - [ravithejads/samvaad-hi-filtered](https://huggingface.co/datasets/ravithejads/samvaad-hi-filtered), [HydraIndicLM/hindi_alpaca_dolly_67k](https://huggingface.co/datasets/HydraIndicLM/hindi_alpaca_dolly_67k)(sampled)
2. #### Telugu - [Telugu-LLM-Labs/yahma_alpaca_cleaned_telugu_filtered_and_romanized](https://huggingface.co/datasets/Telugu-LLM-Labs/yahma_alpaca_cleaned_telugu_filtered_and_romanized), [Telugu-LLM-Labs/teknium_GPTeacher_general_instruct_telugu_filtered_and_romanized](https://huggingface.co/datasets/Telugu-LLM-Labs/teknium_GPTeacher_general_instruct_telugu_filtered_and_romanized)
3. #### Tamil - [abhinand/tamil-alpaca](https://huggingface.co/datasets/abhinand/tamil-alpaca)
4. #### Kannada - [Tensoic/airoboros-3.2_kn](https://huggingface.co/datasets/Tensoic/airoboros-3.2_kn), [Tensoic/gpt-teacher_kn](https://huggingface.co/datasets/Tensoic/gpt-teacher_kn)
5. #### Malayalam - [VishnuPJ/Alpaca_Instruct_Malayalam](https://huggingface.co/datasets/VishnuPJ/Alpaca_Instruct_Malayalam)
6. #### Gujarati - [Tensoic/Alpaca-Gujarati](https://huggingface.co/datasets/Tensoic/Alpaca-Gujarati)
7. #### Punjabi - [HydraIndicLM/punjabi_alpaca_52K](https://huggingface.co/datasets/HydraIndicLM/punjabi_alpaca_52K)
8. #### Bengali - [HydraIndicLM/bengali_alpaca_dolly_67k](https://huggingface.co/datasets/HydraIndicLM/bengali_alpaca_dolly_67k)(alpaca filtered)
9. #### Odia - [OdiaGenAI/Odia_Alpaca_instructions_52k](https://huggingface.co/datasets/OdiaGenAI/Odia_Alpaca_instructions_52k), [OdiaGenAI/gpt-teacher-roleplay-odia-3k](https://huggingface.co/datasets/OdiaGenAI/gpt-teacher-roleplay-odia-3k)
10. #### English - [yahma/alpaca-cleaned](https://huggingface.co/datasets/yahma/alpaca-cleaned)

The model is finetuned using [unsloth](https://github.com/unslothai/unsloth) library and we provide inference code using the same for faster inference. Alternatively you can use HuggingFace Library for inference.

# Training Details:

The model is trained on approx 500K instruction samples.
1. GPU: 1 A100, 80GB
2. Time: 36.5 Hours
3. Platform: [E2E Networks](https://www.e2enetworks.com/)
# Installation

`!pip install ""unsloth[colab-ampere] @git+https://github.com/unslothai/unsloth.git""`

# Input Text Format

```
### Instruction: {instruction}

### Input: {input}

## Response: {response}
```

# Inference With Unsloth

```python3
from unsloth import FastLanguageModel
import torch
max_seq_length = 2048
dtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+
load_in_4bit = False 
model, tokenizer = FastLanguageModel.from_pretrained(
    model_name = ""Telugu-LLM-Labs/Indic-gemma-7b-finetuned-sft-Navarasa"",
    max_seq_length = max_seq_length,
    dtype = dtype,
    load_in_4bit = load_in_4bit,
    device_map=""auto""
)
FastLanguageModel.for_inference(model) # Enable native 2x faster inference

input_prompt = """"""
### Instruction:
{}

### Input:
{}

### Response:
{}""""""

input_text = input_prompt.format(
        ""Tranlsate following sentence to Hindi."", # instruction
        ""This model is developed by Telugu LLM Labs"", # input
        """", # output - leave this blank for generation!
    )

inputs = tokenizer([input_text], return_tensors = ""pt"").to(""cuda"")

outputs = model.generate(**inputs, max_new_tokens = 300, use_cache = True)
response = tokenizer.batch_decode(outputs)
```

# Inference with HuggingFace

```python3
from peft import AutoPeftModelForCausalLM
from transformers import AutoTokenizer

model = AutoPeftModelForCausalLM.from_pretrained(
    ""Telugu-LLM-Labs/Indic-gemma-7b-finetuned-sft-Navarasa"",
    load_in_4bit = False,
    token = hf_token
)
tokenizer = AutoTokenizer.from_pretrained(""Telugu-LLM-Labs/Indic-gemma-7b-finetuned-sft-Navarasa"")

input_prompt = """"""
### Instruction:
{}

### Input:
{}

### Response:
{}""""""

input_text = input_prompt.format(
        ""Tranlsate following sentence to Hindi."", # instruction
        ""This model is developed by Telugu LLM Labs"", # input
        """", # output - leave this blank for generation!
    )

inputs = tokenizer([input_text], return_tensors = ""pt"").to(""cuda"")

outputs = model.generate(**inputs, max_new_tokens = 300, use_cache = True)
response = tokenizer.batch_decode(outputs)[0]
```

Refer to the [blog post](https://ravidesetty.medium.com/introducing-indic-gemma-7b-2b-instruction-tuned-model-on-9-indian-languages-navarasa-86bc81b4a282) for sample examples.

Please check our [Code Repository](https://github.com/TeluguLLMLabs/Indic-gemma-7b-Navarasa) for training and inference scripts.


# Developers:

The model is a collaborative effort by [Ravi Theja](https://twitter.com/ravithejads) and [Ramsri Goutham](https://twitter.com/ramsri_goutham). Feel free to DM either of us if you have any questions.","{""id"": ""Telugu-LLM-Labs/Indic-gemma-7b-finetuned-sft-Navarasa"", ""author"": ""Telugu-LLM-Labs"", ""sha"": ""769f6c780cfc749b4964d3831e02389f963b95fb"", ""last_modified"": ""2024-03-17 13:42:19+00:00"", ""created_at"": ""2024-03-05 19:57:12+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 9, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""safetensors"", ""text-generation"", ""te"", ""en"", ""ta"", ""ml"", ""hi"", ""kn"", ""gu"", ""bn"", ""pa"", ""or"", ""dataset:ravithejads/samvaad-hi-filtered"", ""dataset:Telugu-LLM-Labs/telugu_teknium_GPTeacher_general_instruct_filtered_romanized"", ""dataset:Telugu-LLM-Labs/telugu_alpaca_yahma_cleaned_filtered_romanized"", ""dataset:abhinand/tamil-alpaca"", ""dataset:Tensoic/airoboros-3.2_kn"", ""dataset:Tensoic/gpt-teacher_kn"", ""dataset:VishnuPJ/Alpaca_Instruct_Malayalam"", ""dataset:Tensoic/Alpaca-Gujarati"", ""dataset:HydraIndicLM/punjabi_alpaca_52K"", ""dataset:HydraIndicLM/bengali_alpaca_dolly_67k"", ""dataset:OdiaGenAI/Odia_Alpaca_instructions_52k"", ""dataset:yahma/alpaca-cleaned"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""license:other"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- ravithejads/samvaad-hi-filtered\n- Telugu-LLM-Labs/telugu_teknium_GPTeacher_general_instruct_filtered_romanized\n- Telugu-LLM-Labs/telugu_alpaca_yahma_cleaned_filtered_romanized\n- abhinand/tamil-alpaca\n- Tensoic/airoboros-3.2_kn\n- Tensoic/gpt-teacher_kn\n- VishnuPJ/Alpaca_Instruct_Malayalam\n- Tensoic/Alpaca-Gujarati\n- HydraIndicLM/punjabi_alpaca_52K\n- HydraIndicLM/bengali_alpaca_dolly_67k\n- OdiaGenAI/Odia_Alpaca_instructions_52k\n- yahma/alpaca-cleaned\nlanguage:\n- te\n- en\n- ta\n- ml\n- hi\n- kn\n- gu\n- bn\n- pa\n- or\nlibrary_name: transformers\nlicense: other\nlicense_name: gemma-terms-of-use\nlicense_link: https://ai.google.dev/gemma/terms\npipeline_tag: text-generation"", ""widget_data"": null, ""model_index"": null, ""config"": {""tokenizer_config"": {""bos_token"": ""<bos>"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModel"", ""custom_class"": null, ""pipeline_tag"": null, ""processor"": null}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2024-03-17 13:42:19+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- ravithejads/samvaad-hi-filtered\n- Telugu-LLM-Labs/telugu_teknium_GPTeacher_general_instruct_filtered_romanized\n- Telugu-LLM-Labs/telugu_alpaca_yahma_cleaned_filtered_romanized\n- abhinand/tamil-alpaca\n- Tensoic/airoboros-3.2_kn\n- Tensoic/gpt-teacher_kn\n- VishnuPJ/Alpaca_Instruct_Malayalam\n- Tensoic/Alpaca-Gujarati\n- HydraIndicLM/punjabi_alpaca_52K\n- HydraIndicLM/bengali_alpaca_dolly_67k\n- OdiaGenAI/Odia_Alpaca_instructions_52k\n- yahma/alpaca-cleaned\nlanguage:\n- te\n- en\n- ta\n- ml\n- hi\n- kn\n- gu\n- bn\n- pa\n- or\nlibrary_name: transformers\nlicense: other\nlicense_name: gemma-terms-of-use\nlicense_link: https://ai.google.dev/gemma/terms\npipeline_tag: text-generation"", ""transformersInfo"": {""auto_model"": ""AutoModel"", ""custom_class"": null, ""pipeline_tag"": null, ""processor"": null}, ""_id"": ""65e77918fd146f20fd150325"", ""modelId"": ""Telugu-LLM-Labs/Indic-gemma-7b-finetuned-sft-Navarasa"", ""usedStorage"": 821835012}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=Telugu-LLM-Labs/Indic-gemma-7b-finetuned-sft-Navarasa&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5BTelugu-LLM-Labs%2FIndic-gemma-7b-finetuned-sft-Navarasa%5D(%2FTelugu-LLM-Labs%2FIndic-gemma-7b-finetuned-sft-Navarasa)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
grayhacker91/gemma-7b-open-platypus-commercial,"---
language:
- ko
datasets: 
- kyujinpy/Open-platypus-Commercial
base_model: google/gemma-7b
library_name: transformers
pipeline_tag: text-generation
license: other
license_name: gemma-terms-of-use
license_link: LICENSE
---

# **gemma-7b-open-platypus-commercial**  

## Model Details   
**Base Model**   
- google/gemma-7b (https://huggingface.co/google/gemma-7b)   

**Training Dataset**   
- kyujinpy/Open-platypus-Commercial (https://huggingface.co/datasets/kyujinpy/Open-platypus-Commercial)  

# Implementation Code
```python
### KO-Platypus
from transformers import AutoModelForCausalLM, AutoTokenizer
import torch

repo = ""grayhacker91/gemma-7b-open-platypus-commercial""
OpenOrca = AutoModelForCausalLM.from_pretrained(
        repo,
        return_dict=True,
        torch_dtype=torch.float16,
        device_map='auto'
)
OpenOrca_tokenizer = AutoTokenizer.from_pretrained(repo)
```

---
","{""id"": ""grayhacker91/gemma-7b-open-platypus-commercial"", ""author"": ""grayhacker91"", ""sha"": ""50a1fda9a90009f9de508f08bf1b192ef195667a"", ""last_modified"": ""2024-03-06 10:20:26+00:00"", ""created_at"": ""2024-03-06 09:30:32+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 2, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""safetensors"", ""gemma"", ""text-generation"", ""ko"", ""dataset:kyujinpy/Open-platypus-Commercial"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""license:other"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- kyujinpy/Open-platypus-Commercial\nlanguage:\n- ko\nlibrary_name: transformers\nlicense: other\nlicense_name: gemma-terms-of-use\nlicense_link: LICENSE\npipeline_tag: text-generation"", ""widget_data"": null, ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='LICENSE', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='generation_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00001-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00002-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00003-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00004-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model.safetensors.index.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": {""parameters"": {""F16"": 8537680896}, ""total"": 8537680896}, ""security_repo_status"": null, ""lastModified"": ""2024-03-06 10:20:26+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- kyujinpy/Open-platypus-Commercial\nlanguage:\n- ko\nlibrary_name: transformers\nlicense: other\nlicense_name: gemma-terms-of-use\nlicense_link: LICENSE\npipeline_tag: text-generation"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""65e837b854d6d0a5142aa009"", ""modelId"": ""grayhacker91/gemma-7b-open-platypus-commercial"", ""usedStorage"": 17097109660}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=grayhacker91/gemma-7b-open-platypus-commercial&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bgrayhacker91%2Fgemma-7b-open-platypus-commercial%5D(%2Fgrayhacker91%2Fgemma-7b-open-platypus-commercial)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
saucam/gemma-samvaad-7b,"---
language:
- en
license: apache-2.0
tags:
- text-generation-inference
- transformers
- unsloth
- gemma
- trl
base_model: google/gemma-7b
---

# Uploaded  model

- **Developed by:** saucam
- **License:** apache-2.0
- **Finetuned from model :** google/gemma-7b

This is a finetuned version of gemma-7b on sarvamai/samvaad-hi-v1 hindi dataset using chatml format.

## Inference

We can use unsloth for fast inference
```
from unsloth import FastLanguageModel
from unsloth.chat_templates import get_chat_template
from unsloth.chat_templates import get_chat_template

model, tokenizer = FastLanguageModel.from_pretrained(
    model_name = ""saucam/gemma-samvaad-7b"", # YOUR MODEL YOU USED FOR TRAINING
    max_seq_length = 2048,
    dtype = None,
    load_in_4bit = False,
)
FastLanguageModel.for_inference(model) # Enable native 2x faster inference

tokenizer = get_chat_template(
    tokenizer,
    chat_template = ""chatml"",
    map_eos_token = True, # Maps <|im_end|> to </s> instead
)

FastLanguageModel.for_inference(model) # Enable native 2x faster inference

messages = [
    {""role"": ""user"", ""content"": ""(9+1)+(5+0). इसे 3 चरणों में हल करें.""},
]
inputs = tokenizer.apply_chat_template(
    messages,
    tokenize = True,
    add_generation_prompt = True, # Must add for generation
    return_tensors = ""pt"",
).to(""cuda"")

outputs = model.generate(input_ids = inputs, max_new_tokens = 512, use_cache = True)
out = tokenizer.batch_decode(outputs)
print(out)
```

```
['<bos><|im_start|>user\n(9+1)+(5+0). इसे 3 चरणों में हल करें.<|im_end|>\n
<|im_start|>assistant\n(9+1)+(5+0) को 3 चरणों में हल करने के लिए, हम इसे छोटे भागों में विभाजित कर सकते हैं। पहले चरण में, हम 9 को 1 से जोड़ते हैं, जो 10 देता है। दूसरे चरण में, हम 5 को 0 से जोड़ते हैं, जो 5 देता है। तीसरे चरण में, हम 10 को 5 से जोड़ते हैं, जो 15 देता है। इसलिए, (9+1)+(5+0) का परिणाम 15 है।<|im_end|>
```

This gemma model was trained 2x faster with [Unsloth](https://github.com/unslothai/unsloth) and Huggingface's TRL library.

[<img src=""https://raw.githubusercontent.com/unslothai/unsloth/main/images/unsloth%20made%20with%20love.png"" width=""200""/>](https://github.com/unslothai/unsloth)
","{""id"": ""saucam/gemma-samvaad-7b"", ""author"": ""saucam"", ""sha"": ""8a3d3b2202368ec202c31c919702f5641b930bc5"", ""last_modified"": ""2024-03-09 14:20:25+00:00"", ""created_at"": ""2024-03-09 13:28:33+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""safetensors"", ""text-generation-inference"", ""unsloth"", ""gemma"", ""trl"", ""en"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""license:apache-2.0"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": null, ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\nlanguage:\n- en\nlicense: apache-2.0\ntags:\n- text-generation-inference\n- transformers\n- unsloth\n- gemma\n- trl"", ""widget_data"": null, ""model_index"": null, ""config"": {""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% for message in messages %}{% if message['role'] == 'user' %}{{'<|im_start|>user\n' + message['content'] + '<|im_end|>\n'}}{% elif message['role'] == 'assistant' %}{{'<|im_start|>assistant\n' + message['content'] + '<|im_end|>\n' }}{% else %}{{ '<|im_start|>system\n' + message['content'] + '<|im_end|>\n' }}{% endif %}{% endfor %}{% if add_generation_prompt %}{{ '<|im_start|>assistant\n' }}{% endif %}"", ""eos_token"": ""<|im_end|>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>""}}, ""transformers_info"": {""auto_model"": ""AutoModel"", ""custom_class"": null, ""pipeline_tag"": null, ""processor"": null}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2024-03-09 14:20:25+00:00"", ""cardData"": ""base_model: google/gemma-7b\nlanguage:\n- en\nlicense: apache-2.0\ntags:\n- text-generation-inference\n- transformers\n- unsloth\n- gemma\n- trl"", ""transformersInfo"": {""auto_model"": ""AutoModel"", ""custom_class"": null, ""pipeline_tag"": null, ""processor"": null}, ""_id"": ""65ec6401c7a83c458f57409b"", ""modelId"": ""saucam/gemma-samvaad-7b"", ""usedStorage"": 817593992}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=saucam/gemma-samvaad-7b&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsaucam%2Fgemma-samvaad-7b%5D(%2Fsaucam%2Fgemma-samvaad-7b)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
https://huggingface.co/mervinpraison/tamil-large-language-model-7b-v1.0,N/A,N/A,1,,0,,0,,0,,0,,0.0
danilopeixoto/pandora-7b-chat,"---
pretty_name: Pandora 7B Chat
base_model: google/gemma-7b
datasets:
- danilopeixoto/pandora-instruct
- danilopeixoto/pandora-tool-calling
- danilopeixoto/pandora-rlhf
task_categories:
- text-generation
tags:
- chat
- dpo
- fine-tuning
- function-calling
- instruct
- rlhf
- sft
- tool-calling
license: bsd-3-clause
---

# Pandora 7B Chat

Pandora 7B Chat is a Large Language Model (LLM) designed for chat applications.

Pandora is fine-tuned with publicly available datasets, including a tool-calling dataset for agent-based tasks and a Reinforcement Learning from Human Feedback (RLHF) dataset with Direct Preference Optimization (DPO) training for preference alignment.

The fine-tuning process incorporates Low-Rank Adaptation (LoRA) with the [MLX framework](https://ml-explore.github.io/mlx/build/html/index.html), optimized for Apple Silicon.

The model is based on the [google/gemma-7b](https://huggingface.co/google/gemma-7b) model.

![Pandora](assets/pandora.jpeg)

## Datasets

Datasets used for fine-tuning stages:

- [danilopeixoto/pandora-instruct](https://huggingface.co/datasets/danilopeixoto/pandora-instruct)
- [danilopeixoto/pandora-tool-calling](https://huggingface.co/datasets/danilopeixoto/pandora-tool-calling)
- [danilopeixoto/pandora-rlhf](https://huggingface.co/datasets/danilopeixoto/pandora-rlhf)

## Evaluation

Evaluation on [MT-Bench](https://arxiv.org/abs/2306.05685) multi-turn benchmark:

![Benchmark](assets/benchmark.svg)

## Usage

Install package dependencies:

```shell
pip install mlx-lm
```

Generate response:

```python
from mlx_lm import load, generate


model, tokenizer = load('danilopeixoto/pandora-7b-chat')

prompt = '''<|start|>system
You are Pandora, a helpful AI assistant.
<|end|>
<|start|>user
Hello!
<|end|>
<|start|>'''

response = generate(model, tokenizer, prompt)
print(response)
```

The model supports the following prompt templates:

**Question-answering with system messages**

```txt
<|start|>system
{system_message}
<|end|>
<|start|>user
{user_message}
<|end|>
<|start|>assistant
{assistant_message}
<|end|>
```

**Tool calling**

```txt
<|start|>system
{system_message}
<|end|>
<|start|>system:tools
{system_tools_message}
<|end|>
<|start|>user
{user_message}
<|end|>
<|start|>assistant:tool_calls
{assistant_tool_calls_message}
<|end|>
<|start|>tool
{tool_message}
<|end|>
<|start|>assistant
{assistant_message}
<|end|>
```

> **Note** The variables `system_tools_message`, `assistant_tool_calls_message`, and `tool_message` must contain valid YAML.

An example of a tool-calling prompt:

```python
prompt = '''<|start|>system
You are Pandora, a helpful AI assistant.
<|end|>
<|start|>system:tools
- description: Get the current weather based on a given location.
  name: get_current_weather
  parameters:
    type: object
    properties:
      location:
        type: string
        description: The location name.
    required:
    - location
<|end|>
<|start|>user
What is the weather in Sydney, Australia?
<|end|>
<|start|>assistant:tool_calls
- name: get_current_weather
  arguments:
    location: Sydney, Australia
<|end|>
<|start|>tool
name: get_current_weather
content: 72°F
<|end|>
<|start|>'''
```

## Examples

**OpenGPTs**

![OpenGPTs](assets/opengpts.png)

## Copyright and license

Copyright (c) 2024, Danilo Peixoto Ferreira. All rights reserved.

Project developed under a [BSD-3-Clause license](LICENSE.md).

Gemma is provided under and subject to the [Gemma Terms of Use license](GEMMA_LICENSE.md).
","{""id"": ""danilopeixoto/pandora-7b-chat"", ""author"": ""danilopeixoto"", ""sha"": ""c98ef7feabd87dd2d4d7d2c36960591eaba29c01"", ""last_modified"": ""2024-03-24 03:36:16+00:00"", ""created_at"": ""2024-03-11 16:01:41+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 2, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""gemma"", ""text-generation"", ""chat"", ""dpo"", ""fine-tuning"", ""function-calling"", ""instruct"", ""rlhf"", ""sft"", ""tool-calling"", ""dataset:danilopeixoto/pandora-instruct"", ""dataset:danilopeixoto/pandora-tool-calling"", ""dataset:danilopeixoto/pandora-rlhf"", ""arxiv:2306.05685"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""license:bsd-3-clause"", ""autotrain_compatible"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- danilopeixoto/pandora-instruct\n- danilopeixoto/pandora-tool-calling\n- danilopeixoto/pandora-rlhf\nlicense: bsd-3-clause\ntags:\n- chat\n- dpo\n- fine-tuning\n- function-calling\n- instruct\n- rlhf\n- sft\n- tool-calling\npretty_name: Pandora 7B Chat\ntask_categories:\n- text-generation"", ""widget_data"": [{""text"": ""My name is Julien and I like to""}, {""text"": ""I like traveling by train because""}, {""text"": ""Paris is an amazing place to visit,""}, {""text"": ""Once upon a time,""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""eos_token"": ""<|end|>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='.gitignore', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='GEMMA_LICENSE.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='LICENSE.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='added_tokens.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='assets/benchmark.svg', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='assets/opengpts.png', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='assets/pandora.jpeg', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model.0.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model.1.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model.2.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model.3.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2024-03-24 03:36:16+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- danilopeixoto/pandora-instruct\n- danilopeixoto/pandora-tool-calling\n- danilopeixoto/pandora-rlhf\nlicense: bsd-3-clause\ntags:\n- chat\n- dpo\n- fine-tuning\n- function-calling\n- instruct\n- rlhf\n- sft\n- tool-calling\npretty_name: Pandora 7B Chat\ntask_categories:\n- text-generation"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""65ef2ae5a2d95266f7735035"", ""modelId"": ""danilopeixoto/pandora-7b-chat"", ""usedStorage"": 17097122525}",1,,0,"https://huggingface.co/mradermacher/pandora-7b-chat-GGUF, https://huggingface.co/mradermacher/pandora-7b-chat-i1-GGUF",2,,0,huggingface/InferenceSupport/discussions/new?title=danilopeixoto/pandora-7b-chat&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bdanilopeixoto%2Fpandora-7b-chat%5D(%2Fdanilopeixoto%2Fpandora-7b-chat)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
Omickeyee/Marathi_Gemma_7B,"---
language:
- en
license: apache-2.0
tags:
- text-generation-inference
- transformers
- unsloth
- gemma
- trl
base_model: google/gemma-7b
---

# Uploaded  model

- **Developed by:** Omickeyee
- **License:** apache-2.0
- **Finetuned from model :** google/gemma-7b

This gemma model was trained 2x faster with [Unsloth](https://github.com/unslothai/unsloth) and Huggingface's TRL library.

[<img src=""https://raw.githubusercontent.com/unslothai/unsloth/main/images/unsloth%20made%20with%20love.png"" width=""200""/>](https://github.com/unslothai/unsloth)
","{""id"": ""Omickeyee/Marathi_Gemma_7B"", ""author"": ""Omickeyee"", ""sha"": ""248e54e9d10d620cf5463359452ec65e628b6b12"", ""last_modified"": ""2024-03-16 19:19:12+00:00"", ""created_at"": ""2024-03-16 19:18:22+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""safetensors"", ""text-generation-inference"", ""unsloth"", ""gemma"", ""trl"", ""en"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""license:apache-2.0"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": null, ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\nlanguage:\n- en\nlicense: apache-2.0\ntags:\n- text-generation-inference\n- transformers\n- unsloth\n- gemma\n- trl"", ""widget_data"": null, ""model_index"": null, ""config"": {""tokenizer_config"": {""bos_token"": ""<bos>"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModel"", ""custom_class"": null, ""pipeline_tag"": null, ""processor"": null}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2024-03-16 19:19:12+00:00"", ""cardData"": ""base_model: google/gemma-7b\nlanguage:\n- en\nlicense: apache-2.0\ntags:\n- text-generation-inference\n- transformers\n- unsloth\n- gemma\n- trl"", ""transformersInfo"": {""auto_model"": ""AutoModel"", ""custom_class"": null, ""pipeline_tag"": null, ""processor"": null}, ""_id"": ""65f5f07e55009c4ad9ba6251"", ""modelId"": ""Omickeyee/Marathi_Gemma_7B"", ""usedStorage"": 821835012}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=Omickeyee/Marathi_Gemma_7B&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5BOmickeyee%2FMarathi_Gemma_7B%5D(%2FOmickeyee%2FMarathi_Gemma_7B)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
somosnlp/gemma-7b-it-legal-refugiados-es,"---
language:
- es
license: apache-2.0
library_name: transformers, pe
tags:
- trl
- sft
- generated_from_trainer
base_model: google/gemma-7b
datasets:
- somosnlp/instruct-legal-refugiados-es
---

<!--
Esta plantilla de Model Card es una adaptación de la de Hugging Face: https://github.com/huggingface/huggingface_hub/blob/main/src/huggingface_hub/templates/modelcard_template.md

¿Cómo utilizar esta plantilla? Copia el contenido en el README.md del repo de tu modelo en el Hub de Hugging Face y rellena cada sección.

Para más información sobre cómo rellenar cada sección ver las docs: https://huggingface.co/docs/hub/model-cards
-->

# Model Card for gemma-7b-it-legal-refugiados-es

<!-- Suele haber un nombre corto (""pretty name"") para las URLs, tablas y demás y uno largo más descriptivo. Para crear el pretty name podéis utilizar acrónimos. -->

<!-- Resumen del modelo y motivación del proyecto (inc. los ODS relacionados). Esta sección es como el abstract. También se puede incluir aquí el logo del proyecto. -->

<!-- Si queréis incluir una versión de la Dataset Card en español, enlazarla aquí al principio (e.g. `README_es.md`).-->

Spain is the third country with the highest number of asylum applications, receiving each year approximately more than 100,000 applications, and the third with the lowest number of approvals within the EU.

The main objective of this project is to facilitate the tasks of NGOs in this field and other institutions and help them to obtain answers to questions (QA) related to refugee legislation in Spanish. With its refined understanding of the nuances and complexities of this legal field.

The objective of this model is to facilitate question answering (QA) tasks pertaining to Spanish refugee legislation. With its refined understanding of the nuances and intricacies of this legal domain

## Model Details

### Model Description

<!-- Resumen del modelo. -->
The objective of this model is to facilitate question answering (QA) tasks pertaining to Spanish refugee legislation. With its refined understanding of the nuances and intricacies of this legal domain.

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the dataset [AsistenciaRefugiados](https://huggingface.co/datasets/somosnlp/instruct-legal-refugiados-es).

This is the model card of a 🤗 transformers model that has been pushed on the Hub to allow public access.


- **Developed by:** <!-- Nombre de los miembros del equipo -->
[Alvaro Hidalgo](https://huggingface.co/hacendado)
[Eduardo Muñoz](https://huggingface.co/edumunozsala)
[Teresa Martin](https://huggingface.co/narhim)

- **Funded by:** SomosNLP, HuggingFace <!-- Si contasteis con apoyo de otra entidad (e.g. vuestra universidad), añadidla aquí -->
- **Model type:** Language model, instruction tuned
- **Language(s):** es-ES, es-MX, es-VE <!-- Enumerar las lenguas en las que se ha entrenado el modelo, especificando el país de origen. Utilizar códigos ISO. Por ejemplo: Spanish (`es-CL`, `es-ES`, `es-MX`), Catalan (`ca`), Quechua (`qu`).  -->
- **License:** apache-2.0 <!-- Elegid una licencia lo más permisiva posible teniendo en cuenta la licencia del model pre-entrenado y los datasets utilizados -->
- **Fine-tuned from model:** [google/gemma-7b](https://huggingface.co/google/ <!-- Enlace al modelo pre-entrenado que habéis utilizado como base -->
- **Dataset used:** [AsistenciaRefugiados](https://huggingface.co/datasets/somosnlp/instruct-legal-refugiados-es) <!-- Enlace al dataset utilizado para el ajuste -->

### Model Sources

- **Repository:** Notebook in [This repo](https://huggingface.co/somosnlp/gemma-7b-it-legal-refugee-v0.1.1) <!-- Enlace al `main` del repo donde tengáis los scripts, i.e.: o del mismo repo del modelo en HuggingFace o a GitHub. -->
- **Demo:** [Demo Space](https://huggingface.co/spaces/somosnlp/QA-legal-refugiados) <!-- Enlace a la demo -->
- **Video presentation:** [Youtube Video](https://www.youtube.com/watch?v=1OqHDE5LKMI&list=PLTA-KAy8nxaASMwEUWkkTfMaDxWBxn-8J&index=3) <!-- Enlace a vuestro vídeo de presentación en YouTube (están todos subidos aquí: https://www.youtube.com/playlist?list=PLTA-KAy8nxaASMwEUWkkTfMaDxWBxn-8J) -->

### Model Family

<!-- Si habéis entrenado varios modelos similares podéis enumerarlos aquí. -->
This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b).

## Uses

<!-- Address questions around how the model is intended to be used, including the foreseeable users of the model and those affected by the model. -->

### Direct Use

<!-- This section is for the model use without fine-tuning or plugging into a larger ecosystem/app. -->

The primary objective of this model is to facilitate question answering (QA) tasks pertaining to Spanish refugee legislation. With its refined understanding of the nuances and intricacies of this legal domain.

### Downstream Use

<!-- This section is for the model use when fine-tuned for a task, or when plugged into a larger ecosystem/app -->

Intented to be use in question-answering with a context and text generation.

### Out-of-Scope Use

<!-- This section addresses misuse, malicious use, and uses that the model will not work well for. -->

Misuse includes any application that promotes unethical practices, misinterprets refugee law, or uses the model for malicious purposes. The model is not designed to replace professional legal advice.

## Bias, Risks, and Limitations

<!-- This section is meant to convey both technical and sociotechnical limitations. -->

The model, while powerful, has limitations inherent to AI, including biases present in the training data. It may not cover all nuances of refugee regulations or adapt to changes in law without updates.

### Recommendations

<!-- This section is meant to convey recommendations with respect to the bias, risk, and technical limitations. -->

<!-- Example: Users (both direct and downstream) should be made aware of the risks, biases and limitations of the model. More information needed for further recommendations. -->

## How to Get Started with the Model

Use the code below to get started with the model.

```python
import torch

from transformers import (
    AutoModelForCausalLM,
    AutoTokenizer,
    BitsAndBytesConfig,
    pipeline
)

model_id = ""somosnlp/gemma-7b-it-legal-refugiados-es""
tokenizer_id = ""somosnlp/gemma-7b-it-legal-refugiados-es""

tokenizer = AutoTokenizer.from_pretrained(tokenizer_id)
# Cargamos el modelo en 4 bits para agilizar la inferencia
quantization_config = BitsAndBytesConfig(
    load_in_4bit=True,
    bnb_4bit_compute_dtype=torch.float16,
    bnb_4bit_use_double_quant=True,
)

model = AutoModelForCausalLM.from_pretrained(
    model_id,
    torch_dtype=torch.float16,
    device_map=""auto"",
    quantization_config=quantization_config,
)

# Generamos el pipeline de generación de texto
pipe = pipeline(""text-generation"", model=model, tokenizer=tokenizer)
# Definimos el eos token para el modelo
eos_token = tokenizer(""<|im_end|>"",add_special_tokens=False)[""input_ids""][0]

def generate_inference(instruction, input, temperature):
    prompt = pipe.tokenizer.apply_chat_template([{""role"": ""user"", 
                                                  ""content"": f""{instruction}/n{input}""}], tokenize=False, add_generation_prompt=True)
    outputs = pipe(prompt, max_new_tokens=256, do_sample=True, num_beams=1, temperature=float(temperature), top_k=50, top_p=0.95, 
                   max_time= 300, eos_token_id=eos_token)
    return outputs[0]['generated_text'][len(prompt):].strip()


instruction = ""¿Podrías explicarme brevemente los hechos que originan el procedimiento y las posibles calificaciones, así como las sanciones correspondientes, según lo expuesto en el contexto?""
input = ""b) Hechos que motivan la incoación del procedimiento sucintamente expuestos, su posible calificación y las sanciones que pudieran corresponder, sin perjuicio de lo que resulte de la instrucción. c) Instructor y, en su caso, secretario del procedimiento, con expresa indicación del régimen de recusación de éstos. d) Órgano competente para la resolución del expediente y norma que le atribuye tal competencia. e) Indicación de la posibilidad de que el presunto responsable pueda reconocer voluntariamente su responsabilidad. f) Medidas de carácter provisional que se hayan acordado por el órgano competente para iniciar el procedimiento sancionador, sin perjuicio de las que se puedan adoptar durante éste de conformidad con los artículos 55 y 61 de la Ley Orgánica 4/2000, de 11 de enero. g) Indicación del derecho a formular alegaciones y a la audiencia en el procedimiento y de los plazos para su ejercicio. 2. El acuerdo de iniciación se comunicará al instructor con traslado de cuantas actuaciones existan al respecto y se notificará a los interesados, entendiéndose en todo caso por tal al expedientado. En la notificación se advertirá a los interesados que, de no efectuar alegaciones sobre el contenido de la iniciación del procedimiento en el plazo previsto en el artículo siguiente, no realizarse propuesta de prueba o no ser admitidas, por improcedentes o innecesarias, las pruebas propuestas, la iniciación podrá ser considerada propuesta de resolución cuando contenga un pronunciamiento preciso acerca de la responsabilidad imputada, con los efectos previstos en los artículos 229 y 230.""

response = test_inference(instruction, input, 0.3)
print(f""Response:\n{response}"")
```
## Training Details

### Training Data

<!-- This should link to a Dataset Card, perhaps with a short stub of information on what the training data is all about as well as documentation related to data pre-processing or additional filtering. -->
The dataset used was [instruct-legal-refugiados-es](https://huggingface.co/datasets/somosnlp/instruct-legal-refugiados-es) but we adapted the dataset to a ChatML format, described in the next section.

### Training Procedure

<!-- This relates heavily to the Technical Specifications. Content here should link to that section when it is relevant to the training procedure. -->

<!-- Detallar la técnica de entrenamiento utilizada y enlazar los scripts/notebooks. -->
The training was done using RTX 4090 from Vast.ai with PeRF and Lora

#### Preprocessing

We wanted to make a conversation model so we investigated the base model prompt in order to make conversational base on [chatml format](https://github.com/MicrosoftDocs/azure-docs/blob/main/articles/ai-services/openai/includes/chat-markup-language.md#working-with-chat-markup-language-chatml)

we identified the special tokens so the model could understand the different roles in the conversation

Example 
```
<bos><|im_start|>system
You are Gemma.<|im_end|>
<|im_start|>user
Hello, how are you?<|im_end|>
<|im_start|>assistant
I'm doing great. How can I help you today?<|im_end|>\n<eos>
```
So we used [Phil Schmid's gemma chatml tokenizer](https://huggingface.co/philschmid/gemma-tokenizer-chatml) to adapt our dataset for training

#### Training Hyperparameters

<!-- Enumerar los valores de los hiperparámetros de entrenamiento. -->
The following hyperparameters were used during training:
- learning_rate: 5e-05
- train_batch_size: 2
- eval_batch_size: 8
- seed: 66
- gradient_accumulation_steps: 2
- total_train_batch_size: 4
- optimizer: Adam with betas=(0.9,0.999) and epsilon=1e-08
- lr_scheduler_type: constant
- lr_scheduler_warmup_ratio: 0.03
- num_epochs: 3


- **Training regime:** <!--fp32, fp16 mixed precision, bf16 mixed precision, bf16 non-mixed precision, fp16 non-mixed precision, fp8 mixed precision -->

## Evaluation

<!-- This section describes the evaluation protocols and provides the results. -->

### Testing Data, Factors & Metrics

#### Testing Data

<!-- This should link to a Dataset Card. -->

[More Information Needed]

#### Factors

<!-- These are the things the evaluation is disaggregating by, e.g., subpopulations or domains. -->

[More Information Needed]

#### Metrics

<!-- These are the evaluation metrics being used, ideally with a description of why. -->

[More Information Needed]

### Results

<!-- Enlazar aquí los scripts/notebooks de evaluación y especificar los resultados. -->

[More Information Needed]

## Environmental Impact

<!-- Total emissions (in grams of CO2eq) and additional considerations, such as electricity usage, go here. Edit the suggested text below accordingly. -->

<!-- Rellenar la información de la lista y calcular las emisiones con la página mencionada. -->

Carbon emissions can be estimated using the [Machine Learning Impact calculator](https://mlco2.github.io/impact#compute) presented in [Lacoste et al. (2019)](https://arxiv.org/abs/1910.09700).

- **Hardware Type**: 1 X RTX4090
- **Hours used**: 4
- **Cloud Provider**: Vast.ai
- **Compute Region**: West Europe
- **Carbon Emitted**: 350W x 4h = 1.4 kWh x 0.57 kg eq. CO2/kWh = 0.8 kg eq. CO2

## Technical Specifications

<!-- Esta sección es opcional porque seguramente ya habéis mencionado estos detalles más arriba, igualmente está bien incluirlos aquí de nuevo como bullet points a modo de resumen. -->

### Model Architecture and Objective

 The base model is [google/gemma-7b](https://huggingface.co/google/gemma-7b) finetuned in 4-bit.

### Compute Infrastructure

#### Hardware

<!-- Indicar el hardware utilizado, podéis agradecer aquí a quien lo patrocinó. -->
1 x RTX4090 GPU by Vast.ai.

#### Software

<!-- Enumerar las librerías utilizadas (e.g. transformers, distilabel). -->

Libraries: 
- transformers
- bitsandbytes 
- accelerate
- xformers 
- trl 
- peft
- wandb

## License

<!-- Indicar bajo qué licencia se libera el modelo explicando, si no es apache 2.0, a qué se debe la licencia más restrictiva (i.e. herencia de las licencias del modelo pre-entrenado o de los datos utilizados). -->

This model is under the license of the Gemma models by Google.
Link to consent: https://www.kaggle.com/models/google/gemma/license/consent


## Citation

**BibTeX:**

[More Information Needed]

<!--

Aquí tenéis un ejemplo de cita de un dataset que podéis adaptar:

```
@software{benallal2024cosmopedia,
  author = {Ben Allal, Loubna and Lozhkov, Anton and Penedo, Guilherme and Wolf, Thomas and von Werra, Leandro},
  title = {Cosmopedia},
  month = February,
  year = 2024,
  url = {https://huggingface.co/datasets/HuggingFaceTB/cosmopedia}
}
```

- benallal2024cosmopedia -> nombre + año + nombre del modelo
- author: lista de miembros del equipo
- title: nombre del modelo
- year: año
- url: enlace al modelo

-->
```
@software{somosnlp2024asistenciarefugiados,
  author = {Alvaro Hidalgo, Eduardo Muñoz, Teresa Martín},
  title = {gemma-7b-it-legal-refugiados-es},
  month = April,
  year = 2024,
  url = {somosnlp/gemma-7b-it-legal-refugee-v0.1.1}
}
```
## More Information

<!-- Indicar aquí que el marco en el que se desarrolló el proyecto, en esta sección podéis incluir agradecimientos y más información sobre los miembros del equipo. Podéis adaptar el ejemplo a vuestro gusto. -->

This project was developed during the [Hackathon #Somos600M](https://somosnlp.org/hackathon) organized by SomosNLP. The model was trained using GPUs sponsored by HuggingFace.

**Team:**

[Alvaro Hidalgo](https://huggingface.co/hacendado)
[Eduardo Muñoz](https://huggingface.co/edumunozsala)
[Teresa Martin](https://huggingface.co/narhim)

<!--
- [Name 1](Link to Hugging Face profile)
- [Name 2](Link to Hugging Face profile)
-->

## Contact [optional]

<!-- Email de contacto para´posibles preguntas sobre el modelo. -->
","{""id"": ""somosnlp/gemma-7b-it-legal-refugiados-es"", ""author"": ""somosnlp"", ""sha"": ""28246a46b8deef21750fddf8141115d5dc228a2c"", ""last_modified"": ""2024-04-24 11:36:00+00:00"", ""created_at"": ""2024-03-18 22:59:55+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 2, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers, pe"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers, pe"", ""safetensors"", ""gemma"", ""trl"", ""sft"", ""generated_from_trainer"", ""es"", ""dataset:somosnlp/instruct-legal-refugiados-es"", ""arxiv:1910.09700"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""license:apache-2.0"", ""region:us""], ""pipeline_tag"": null, ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- somosnlp/instruct-legal-refugiados-es\nlanguage:\n- es\nlibrary_name: transformers, pe\nlicense: apache-2.0\ntags:\n- trl\n- sft\n- generated_from_trainer"", ""widget_data"": null, ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{% if messages[0]['role'] == 'user' or messages[0]['role'] == 'system' %}{{ bos_token }}{% endif %}{% for message in messages %}{{ '<|im_start|>' + message['role'] + '\n' + message['content'] + '<|im_end|>' + '\n' }}{% endfor %}{% if add_generation_prompt %}{{ '<|im_start|>assistant\n' }}{% elif messages[-1]['role'] == 'assistant' %}{{ eos_token }}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": null, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='generation_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00001-of-00008.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00002-of-00008.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00003-of-00008.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00004-of-00008.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00005-of-00008.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00006-of-00008.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00007-of-00008.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00008-of-00008.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model.safetensors.index.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_notebook.ipynb', size=None, blob_id=None, lfs=None)""], ""spaces"": [""Saturdays/QA-legal-refugiados-smosnlp"", ""somosnlp/QA-legal-refugiados""], ""safetensors"": {""parameters"": {""F32"": 8537680896}, ""total"": 8537680896}, ""security_repo_status"": null, ""lastModified"": ""2024-04-24 11:36:00+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- somosnlp/instruct-legal-refugiados-es\nlanguage:\n- es\nlibrary_name: transformers, pe\nlicense: apache-2.0\ntags:\n- trl\n- sft\n- generated_from_trainer"", ""transformersInfo"": null, ""_id"": ""65f8c76b48699f59af87e048"", ""modelId"": ""somosnlp/gemma-7b-it-legal-refugiados-es"", ""usedStorage"": 34168230481}",1,,0,,0,,0,"Saturdays/QA-legal-refugiados-smosnlp, huggingface/InferenceSupport/discussions/new?title=somosnlp/gemma-7b-it-legal-refugiados-es&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsomosnlp%2Fgemma-7b-it-legal-refugiados-es%5D(%2Fsomosnlp%2Fgemma-7b-it-legal-refugiados-es)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A, somosnlp/QA-legal-refugiados",3,,
saucam/Rudra-7b-qlora,"---
language:
- en
license: apache-2.0
tags:
- text-generation-inference
- transformers
- unsloth
- gemma
- trl
base_model: google/gemma-7b
---

# Uploaded  model

- **Developed by:** saucam
- **License:** apache-2.0
- **Finetuned from model :** google/gemma-7b

This gemma model was trained 2x faster with [Unsloth](https://github.com/unslothai/unsloth) and Huggingface's TRL library.

[<img src=""https://raw.githubusercontent.com/unslothai/unsloth/main/images/unsloth%20made%20with%20love.png"" width=""200""/>](https://github.com/unslothai/unsloth)
","{""id"": ""saucam/Rudra-7b-qlora"", ""author"": ""saucam"", ""sha"": ""170aa1dee1db5f515bb76a3de7bc4b4bfb4b5303"", ""last_modified"": ""2024-03-21 15:47:11+00:00"", ""created_at"": ""2024-03-21 15:46:46+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""safetensors"", ""text-generation-inference"", ""unsloth"", ""gemma"", ""trl"", ""en"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""license:apache-2.0"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": null, ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\nlanguage:\n- en\nlicense: apache-2.0\ntags:\n- text-generation-inference\n- transformers\n- unsloth\n- gemma\n- trl"", ""widget_data"": null, ""model_index"": null, ""config"": {""tokenizer_config"": {""bos_token"": ""<bos>"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModel"", ""custom_class"": null, ""pipeline_tag"": null, ""processor"": null}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2024-03-21 15:47:11+00:00"", ""cardData"": ""base_model: google/gemma-7b\nlanguage:\n- en\nlicense: apache-2.0\ntags:\n- text-generation-inference\n- transformers\n- unsloth\n- gemma\n- trl"", ""transformersInfo"": {""auto_model"": ""AutoModel"", ""custom_class"": null, ""pipeline_tag"": null, ""processor"": null}, ""_id"": ""65fc56668d815d64d9f0eb2a"", ""modelId"": ""saucam/Rudra-7b-qlora"", ""usedStorage"": 821835012}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=saucam/Rudra-7b-qlora&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsaucam%2FRudra-7b-qlora%5D(%2Fsaucam%2FRudra-7b-qlora)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
https://huggingface.co/beratcmn/cem-v0.1,N/A,N/A,1,,0,,0,,0,,0,,0.0
kykim0/gemma-7b-ultrachat-sft,"---
license: other
base_model: google/gemma-7b
tags:
- alignment-handbook
- trl
- sft
- generated_from_trainer
- trl
- sft
- generated_from_trainer
datasets:
- HuggingFaceH4/ultrachat_200k
model-index:
- name: gemma-7b-ultrachat-sft
  results: []
---

<!-- This model card has been generated automatically according to the information the Trainer had access to. You
should probably proofread and complete it, then remove this comment. -->

# gemma-7b-ultrachat-sft

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the HuggingFaceH4/ultrachat_200k dataset.
It achieves the following results on the evaluation set:
- Loss: 1.1229

## Model description

More information needed

## Intended uses & limitations

More information needed

## Training and evaluation data

More information needed

## Training procedure

### Training hyperparameters

The following hyperparameters were used during training:
- learning_rate: 2e-05
- train_batch_size: 2
- eval_batch_size: 4
- seed: 42
- distributed_type: multi-GPU
- num_devices: 4
- gradient_accumulation_steps: 16
- total_train_batch_size: 128
- total_eval_batch_size: 16
- optimizer: Adam with betas=(0.9,0.999) and epsilon=1e-08
- lr_scheduler_type: cosine
- lr_scheduler_warmup_ratio: 0.1
- num_epochs: 3

### Training results

| Training Loss | Epoch | Step | Validation Loss |
|:-------------:|:-----:|:----:|:---------------:|
| 1.1236        | 1.0   | 954  | 1.1430          |
| 1.0327        | 2.0   | 1909 | 1.1133          |
| 0.8854        | 3.0   | 2862 | 1.1229          |


### Framework versions

- Transformers 4.39.0.dev0
- Pytorch 2.1.2
- Datasets 2.14.6
- Tokenizers 0.15.2
","{""id"": ""kykim0/gemma-7b-ultrachat-sft"", ""author"": ""kykim0"", ""sha"": ""0d863e8f7a3c5b87d2c634132f1f657a241a394e"", ""last_modified"": ""2024-03-29 18:37:00+00:00"", ""created_at"": ""2024-03-28 13:54:01+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 6, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""safetensors"", ""gemma"", ""text-generation"", ""alignment-handbook"", ""trl"", ""sft"", ""generated_from_trainer"", ""conversational"", ""dataset:HuggingFaceH4/ultrachat_200k"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""license:other"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- HuggingFaceH4/ultrachat_200k\nlicense: other\ntags:\n- alignment-handbook\n- trl\n- sft\n- generated_from_trainer\nmodel-index:\n- name: gemma-7b-ultrachat-sft\n  results: []"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": [{""name"": ""gemma-7b-ultrachat-sft"", ""results"": []}], ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{% if messages[0]['role'] == 'user' or messages[0]['role'] == 'system' %}{{ bos_token }}{% endif %}{% for message in messages %}{{ '<|im_start|>' + message['role'] + '\n' + message['content'] + '<|im_end|>' + '\n' }}{% endfor %}{% if add_generation_prompt %}{{ '<|im_start|>assistant\n' }}{% elif messages[-1]['role'] == 'assistant' %}{{ eos_token }}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='eval_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='generation_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00001-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00002-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00003-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00004-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model.safetensors.index.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": {""parameters"": {""BF16"": 8537680896}, ""total"": 8537680896}, ""security_repo_status"": null, ""lastModified"": ""2024-03-29 18:37:00+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- HuggingFaceH4/ultrachat_200k\nlicense: other\ntags:\n- alignment-handbook\n- trl\n- sft\n- generated_from_trainer\nmodel-index:\n- name: gemma-7b-ultrachat-sft\n  results: []"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""66057679323f5f8cd6a8f69e"", ""modelId"": ""kykim0/gemma-7b-ultrachat-sft"", ""usedStorage"": 17092881105}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=kykim0/gemma-7b-ultrachat-sft&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bkykim0%2Fgemma-7b-ultrachat-sft%5D(%2Fkykim0%2Fgemma-7b-ultrachat-sft)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
Omickeyee/Marathi_Gemma_7B_52k,"---
language:
- en
license: apache-2.0
tags:
- text-generation-inference
- transformers
- unsloth
- gemma
- trl
base_model: google/gemma-7b
---

# Uploaded  model

- **Developed by:** Omickeyee
- **License:** apache-2.0
- **Finetuned from model :** google/gemma-7b

This gemma model was trained 2x faster with [Unsloth](https://github.com/unslothai/unsloth) and Huggingface's TRL library.

[<img src=""https://raw.githubusercontent.com/unslothai/unsloth/main/images/unsloth%20made%20with%20love.png"" width=""200""/>](https://github.com/unslothai/unsloth)
","{""id"": ""Omickeyee/Marathi_Gemma_7B_52k"", ""author"": ""Omickeyee"", ""sha"": ""a837072bcac557768b70b0967f896d32f6ab9441"", ""last_modified"": ""2024-04-04 21:05:37+00:00"", ""created_at"": ""2024-04-04 21:05:07+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""safetensors"", ""text-generation-inference"", ""unsloth"", ""gemma"", ""trl"", ""en"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""license:apache-2.0"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": null, ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\nlanguage:\n- en\nlicense: apache-2.0\ntags:\n- text-generation-inference\n- transformers\n- unsloth\n- gemma\n- trl"", ""widget_data"": null, ""model_index"": null, ""config"": {""tokenizer_config"": {""bos_token"": ""<bos>"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModel"", ""custom_class"": null, ""pipeline_tag"": null, ""processor"": null}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2024-04-04 21:05:37+00:00"", ""cardData"": ""base_model: google/gemma-7b\nlanguage:\n- en\nlicense: apache-2.0\ntags:\n- text-generation-inference\n- transformers\n- unsloth\n- gemma\n- trl"", ""transformersInfo"": {""auto_model"": ""AutoModel"", ""custom_class"": null, ""pipeline_tag"": null, ""processor"": null}, ""_id"": ""660f1603417903ed731fb833"", ""modelId"": ""Omickeyee/Marathi_Gemma_7B_52k"", ""usedStorage"": 821835012}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=Omickeyee/Marathi_Gemma_7B_52k&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5BOmickeyee%2FMarathi_Gemma_7B_52k%5D(%2FOmickeyee%2FMarathi_Gemma_7B_52k)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
Omickeyee/Marathi_Gemma_7B_5k,"---
language:
- en
license: apache-2.0
tags:
- text-generation-inference
- transformers
- unsloth
- gemma
- trl
base_model: google/gemma-7b
---

# Uploaded  model

- **Developed by:** Omickeyee
- **License:** apache-2.0
- **Finetuned from model :** google/gemma-7b

This gemma model was trained 2x faster with [Unsloth](https://github.com/unslothai/unsloth) and Huggingface's TRL library.

[<img src=""https://raw.githubusercontent.com/unslothai/unsloth/main/images/unsloth%20made%20with%20love.png"" width=""200""/>](https://github.com/unslothai/unsloth)
","{""id"": ""Omickeyee/Marathi_Gemma_7B_5k"", ""author"": ""Omickeyee"", ""sha"": ""9b145c963e3a970723ff7f9da6f558d715cfb7e4"", ""last_modified"": ""2024-08-03 12:54:04+00:00"", ""created_at"": ""2024-04-09 18:45:23+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 4, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""safetensors"", ""gemma"", ""text-generation"", ""text-generation-inference"", ""unsloth"", ""trl"", ""en"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""license:apache-2.0"", ""autotrain_compatible"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\nlanguage:\n- en\nlicense: apache-2.0\ntags:\n- text-generation-inference\n- transformers\n- unsloth\n- gemma\n- trl"", ""widget_data"": [{""text"": ""My name is Julien and I like to""}, {""text"": ""I like traveling by train because""}, {""text"": ""Paris is an amazing place to visit,""}, {""text"": ""Once upon a time,""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2024-08-03 12:54:04+00:00"", ""cardData"": ""base_model: google/gemma-7b\nlanguage:\n- en\nlicense: apache-2.0\ntags:\n- text-generation-inference\n- transformers\n- unsloth\n- gemma\n- trl"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""66158cc3362219047ef177c7"", ""modelId"": ""Omickeyee/Marathi_Gemma_7B_5k"", ""usedStorage"": 821835012}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=Omickeyee/Marathi_Gemma_7B_5k&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5BOmickeyee%2FMarathi_Gemma_7B_5k%5D(%2FOmickeyee%2FMarathi_Gemma_7B_5k)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
Omickeyee/Marathi_Gemma_7B_10k,"---
language:
- en
license: apache-2.0
tags:
- text-generation-inference
- transformers
- unsloth
- gemma
- trl
base_model: google/gemma-7b
---

# Uploaded  model

- **Developed by:** Omickeyee
- **License:** apache-2.0
- **Finetuned from model :** google/gemma-7b

This gemma model was trained 2x faster with [Unsloth](https://github.com/unslothai/unsloth) and Huggingface's TRL library.

[<img src=""https://raw.githubusercontent.com/unslothai/unsloth/main/images/unsloth%20made%20with%20love.png"" width=""200""/>](https://github.com/unslothai/unsloth)
","{""id"": ""Omickeyee/Marathi_Gemma_7B_10k"", ""author"": ""Omickeyee"", ""sha"": ""54a53bd206c1a6d21618691266751718ee9cca4a"", ""last_modified"": ""2024-04-09 19:57:14+00:00"", ""created_at"": ""2024-04-09 19:56:12+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""safetensors"", ""text-generation-inference"", ""unsloth"", ""gemma"", ""trl"", ""en"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""license:apache-2.0"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": null, ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\nlanguage:\n- en\nlicense: apache-2.0\ntags:\n- text-generation-inference\n- transformers\n- unsloth\n- gemma\n- trl"", ""widget_data"": null, ""model_index"": null, ""config"": {""tokenizer_config"": {""bos_token"": ""<bos>"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModel"", ""custom_class"": null, ""pipeline_tag"": null, ""processor"": null}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2024-04-09 19:57:14+00:00"", ""cardData"": ""base_model: google/gemma-7b\nlanguage:\n- en\nlicense: apache-2.0\ntags:\n- text-generation-inference\n- transformers\n- unsloth\n- gemma\n- trl"", ""transformersInfo"": {""auto_model"": ""AutoModel"", ""custom_class"": null, ""pipeline_tag"": null, ""processor"": null}, ""_id"": ""66159d5c24c1fd994891b98f"", ""modelId"": ""Omickeyee/Marathi_Gemma_7B_10k"", ""usedStorage"": 821835012}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=Omickeyee/Marathi_Gemma_7B_10k&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5BOmickeyee%2FMarathi_Gemma_7B_10k%5D(%2FOmickeyee%2FMarathi_Gemma_7B_10k)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
Omickeyee/Marathi_Gemma_7B_20k,"---
language:
- en
license: apache-2.0
tags:
- text-generation-inference
- transformers
- unsloth
- gemma
- trl
base_model: google/gemma-7b
---

# Uploaded  model

- **Developed by:** Omickeyee
- **License:** apache-2.0
- **Finetuned from model :** google/gemma-7b

This gemma model was trained 2x faster with [Unsloth](https://github.com/unslothai/unsloth) and Huggingface's TRL library.

[<img src=""https://raw.githubusercontent.com/unslothai/unsloth/main/images/unsloth%20made%20with%20love.png"" width=""200""/>](https://github.com/unslothai/unsloth)
","{""id"": ""Omickeyee/Marathi_Gemma_7B_20k"", ""author"": ""Omickeyee"", ""sha"": ""727faf64f721599b8cd7632a28ae94dff2ac6faf"", ""last_modified"": ""2024-04-10 18:08:51+00:00"", ""created_at"": ""2024-04-10 18:08:23+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""safetensors"", ""text-generation-inference"", ""unsloth"", ""gemma"", ""trl"", ""en"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""license:apache-2.0"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": null, ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\nlanguage:\n- en\nlicense: apache-2.0\ntags:\n- text-generation-inference\n- transformers\n- unsloth\n- gemma\n- trl"", ""widget_data"": null, ""model_index"": null, ""config"": {""tokenizer_config"": {""bos_token"": ""<bos>"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModel"", ""custom_class"": null, ""pipeline_tag"": null, ""processor"": null}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2024-04-10 18:08:51+00:00"", ""cardData"": ""base_model: google/gemma-7b\nlanguage:\n- en\nlicense: apache-2.0\ntags:\n- text-generation-inference\n- transformers\n- unsloth\n- gemma\n- trl"", ""transformersInfo"": {""auto_model"": ""AutoModel"", ""custom_class"": null, ""pipeline_tag"": null, ""processor"": null}, ""_id"": ""6616d5974c12f3b39042d210"", ""modelId"": ""Omickeyee/Marathi_Gemma_7B_20k"", ""usedStorage"": 821835012}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=Omickeyee/Marathi_Gemma_7B_20k&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5BOmickeyee%2FMarathi_Gemma_7B_20k%5D(%2FOmickeyee%2FMarathi_Gemma_7B_20k)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
masakhane/zephyr-7b-gemma-sft-african-ultrachat,"---
license: gemma
base_model: google/gemma-7b
tags:
- alignment-handbook
- trl
- sft
- generated_from_trainer
- trl
- sft
- generated_from_trainer
datasets:
- masakhane/african-ultrachat
model-index:
- name: zephyr-7b-gemma-sft-african-ultrachat
  results: []
---

<!-- This model card has been generated automatically according to the information the Trainer had access to. You
should probably proofread and complete it, then remove this comment. -->

# zephyr-7b-gemma-sft-african-ultrachat

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the masakhane/african-ultrachat dataset.
It achieves the following results on the evaluation set:
- Loss: 1.0802

## Model description

More information needed

## Intended uses & limitations

More information needed

## Training and evaluation data

[masakhane/african-ultrachat](https://huggingface.co/datasets/masakhane/african-ultrachat)

## Training procedure

### Training hyperparameters

The following hyperparameters were used during training:
- learning_rate: 1e-05
- train_batch_size: 1
- eval_batch_size: 1
- seed: 42
- distributed_type: multi-GPU
- num_devices: 8
- gradient_accumulation_steps: 2
- total_train_batch_size: 16
- total_eval_batch_size: 8
- optimizer: Adam with betas=(0.9,0.999) and epsilon=1e-08
- lr_scheduler_type: cosine
- lr_scheduler_warmup_ratio: 0.1
- num_epochs: 3

### Training results

| Training Loss | Epoch | Step | Validation Loss |
|:-------------:|:-----:|:----:|:---------------:|
| 1.1942        | 1.0   | 2089 | 1.1757          |
| 0.952         | 2.0   | 4178 | 1.0642          |
| 0.7033        | 3.0   | 6267 | 1.0802          |


### Framework versions

- Transformers 4.39.0.dev0
- Pytorch 2.2.1+cu121
- Datasets 2.14.6
- Tokenizers 0.15.2


### How to use 

``` python
import torch
from transformers import pipeline

pipe = pipeline(""text-generation"", model=""masakhane/zephyr-7b-gemma-sft-african-ultrachat"", torch_dtype=torch.bfloat16, device_map=""auto"")

# We use the tokenizer's chat template to format each message - see https://huggingface.co/docs/transformers/main/en/chat_templating
messages = [
    {
        ""role"": ""system"",
        ""content"": ""You are a friendly chatbot who always responds in the style of a pirate"",
    },
    {""role"": ""user"", ""content"": ""ሰላም እንዴት ነህ?""},
]
prompt = pipe.tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)
outputs = pipe(prompt, max_new_tokens=256, do_sample=True, temperature=0.7, top_k=50, top_p=0.95)
print(outputs[0][""generated_text""])


# <|system|>
# You are a friendly chatbot who always responds in the style of a pirate<eos>
# <|user|>
# ሰላም እንዴት ነህ?<eos>
# <|assistant|>
# ሰላም እንዴት ነህ/ነሽ? እኔም በጤና ነኝ። እንደምን ነህ/ነሽ እና የምትፈልገው እንዴት ነው?
```","{""id"": ""masakhane/zephyr-7b-gemma-sft-african-ultrachat"", ""author"": ""masakhane"", ""sha"": ""ce189fb28fe8aff354b590122d3f5c0b9eeb8f0a"", ""last_modified"": ""2024-04-11 17:40:44+00:00"", ""created_at"": ""2024-04-11 06:04:39+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 2, ""downloads_all_time"": null, ""likes"": 2, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""safetensors"", ""gemma"", ""text-generation"", ""alignment-handbook"", ""trl"", ""sft"", ""generated_from_trainer"", ""conversational"", ""dataset:masakhane/african-ultrachat"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""license:gemma"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- masakhane/african-ultrachat\nlicense: gemma\ntags:\n- alignment-handbook\n- trl\n- sft\n- generated_from_trainer\nmodel-index:\n- name: zephyr-7b-gemma-sft-african-ultrachat\n  results: []"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": [{""name"": ""zephyr-7b-gemma-sft-african-ultrachat"", ""results"": []}], ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{% for message in messages %}\n{% if message['role'] == 'user' %}\n{{ '<|user|>\n' + message['content'] + eos_token }}\n{% elif message['role'] == 'system' %}\n{{ '<|system|>\n' + message['content'] + eos_token }}\n{% elif message['role'] == 'assistant' %}\n{{ '<|assistant|>\n'  + message['content'] + eos_token }}\n{% endif %}\n{% if loop.last and add_generation_prompt %}\n{{ '<|assistant|>' }}\n{% endif %}\n{% endfor %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='eval_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='generation_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00001-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00002-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00003-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00004-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model.safetensors.index.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": {""parameters"": {""BF16"": 8537680896}, ""total"": 8537680896}, ""security_repo_status"": null, ""lastModified"": ""2024-04-11 17:40:44+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- masakhane/african-ultrachat\nlicense: gemma\ntags:\n- alignment-handbook\n- trl\n- sft\n- generated_from_trainer\nmodel-index:\n- name: zephyr-7b-gemma-sft-african-ultrachat\n  results: []"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""66177d7792abaae4ecca3807"", ""modelId"": ""masakhane/zephyr-7b-gemma-sft-african-ultrachat"", ""usedStorage"": 17097116116}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=masakhane/zephyr-7b-gemma-sft-african-ultrachat&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bmasakhane%2Fzephyr-7b-gemma-sft-african-ultrachat%5D(%2Fmasakhane%2Fzephyr-7b-gemma-sft-african-ultrachat)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
masakhane/zephyr-7b-gemma-sft-african-alpaca,"---
license: gemma
base_model: google/gemma-7b
tags:
- alignment-handbook
- trl
- sft
- generated_from_trainer
- trl
- sft
- generated_from_trainer
datasets:
- masakhane/african-translated-alpaca
model-index:
- name: zephyr-7b-gemma-sft-african-alpaca
  results: []
language:
- af
- am
- ar
- en
- ee
---

<!-- This model card has been generated automatically according to the information the Trainer had access to. You
should probably proofread and complete it, then remove this comment. -->

# zephyr-7b-gemma-sft-alpaca

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the masakhane/african-translated-alpaca dataset.
It achieves the following results on the evaluation set:
- Loss: 0.2737

## Model description

More information needed

## Intended uses & limitations

More information needed

## Training and evaluation data

More information needed

## Training procedure

### Training hyperparameters

The following hyperparameters were used during training:
- learning_rate: 1e-05
- train_batch_size: 1
- eval_batch_size: 1
- seed: 42
- distributed_type: multi-GPU
- num_devices: 8
- gradient_accumulation_steps: 2
- total_train_batch_size: 16
- total_eval_batch_size: 8
- optimizer: Adam with betas=(0.9,0.999) and epsilon=1e-08
- lr_scheduler_type: cosine
- lr_scheduler_warmup_ratio: 0.1
- num_epochs: 3

### Training results

| Training Loss | Epoch | Step  | Validation Loss |
|:-------------:|:-----:|:-----:|:---------------:|
| 0.8671        | 1.0   | 5882  | 0.7445          |
| 0.5235        | 2.0   | 11764 | 0.3905          |
| 0.3309        | 3.0   | 17646 | 0.2737          |


### Framework versions

- Transformers 4.39.0.dev0
- Pytorch 2.2.1+cu121
- Datasets 2.14.6
- Tokenizers 0.15.2




### Usage

```python

# Install transformers from source - only needed for versions <= v4.34
# pip install git+https://github.com/huggingface/transformers.git
# pip install accelerate

import torch
from transformers import pipeline

pipe = pipeline(""text-generation"", model=""masakhane/zephyr-7b-gemma-sft-african-alpaca"", torch_dtype=torch.bfloat16, device_map=""auto"")

# We use the tokenizer's chat template to format each message - see https://huggingface.co/docs/transformers/main/en/chat_templating
messages = [
    {
        ""role"": ""system"",
        ""content"": ""You are a friendly chatbot who answewrs question in given language"",
    },
    {""role"": ""user"", ""content"": ""what is the 3 biggest countrys in Africa?""},
]
prompt = pipe.tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)
outputs = pipe(prompt, max_new_tokens=256, do_sample=True, temperature=0.7, top_k=50, top_p=0.95)
print(outputs[0][""generated_text""])
# <|system|>
# You are a friendly chatbot who always responds in the style of a pirate<eos>
# <|user|>
# what is the 3 biggest countrys in Africa?<eos>
# <|assistant|>
# The 3 biggest countries in Africa are Nigeria, Ethiopia and South Africa.
```


### Quantized Versions through bitsandbytes

``` python

import torch
from transformers import pipeline
from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig


quantization_config = BitsAndBytesConfig(load_in_4bit=True)

tokenizer = AutoTokenizer.from_pretrained(""masakhane/zephyr-7b-gemma-sft-african-alpaca"")
model = AutoModelForCausalLM.from_pretrained(""masakhane/zephyr-7b-gemma-sft-african-alpaca"", quantization_config=quantization_config)


pipe = pipeline(""text-generation"", model=model,tokenizer=tokenizer, torch_dtype=torch.bfloat16, device_map=""auto"")

messages = [
    {
        ""role"": ""system"",
        ""content"": ""You are a friendly chatbot who answewrs question in given language"",
    },
    {""role"": ""user"", ""content"": ""list languages in Africa?""},
]
prompt = pipe.tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)
outputs = pipe(prompt, max_new_tokens=256, do_sample=True, temperature=0.7, top_k=50, top_p=0.95)
print(outputs[0][""generated_text""])

```
","{""id"": ""masakhane/zephyr-7b-gemma-sft-african-alpaca"", ""author"": ""masakhane"", ""sha"": ""28b4532f267ed1d644b932a6355681dc04ac7518"", ""last_modified"": ""2024-04-16 14:09:36+00:00"", ""created_at"": ""2024-04-11 15:36:07+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 16, ""downloads_all_time"": null, ""likes"": 1, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""safetensors"", ""gemma"", ""text-generation"", ""alignment-handbook"", ""trl"", ""sft"", ""generated_from_trainer"", ""conversational"", ""af"", ""am"", ""ar"", ""en"", ""ee"", ""dataset:masakhane/african-translated-alpaca"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""license:gemma"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- masakhane/african-translated-alpaca\nlanguage:\n- af\n- am\n- ar\n- en\n- ee\nlicense: gemma\ntags:\n- alignment-handbook\n- trl\n- sft\n- generated_from_trainer\nmodel-index:\n- name: zephyr-7b-gemma-sft-african-alpaca\n  results: []"", ""widget_data"": null, ""model_index"": [{""name"": ""zephyr-7b-gemma-sft-african-alpaca"", ""results"": []}], ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{% for message in messages %}\n{% if message['role'] == 'user' %}\n{{ '<|user|>\n' + message['content'] + eos_token }}\n{% elif message['role'] == 'system' %}\n{{ '<|system|>\n' + message['content'] + eos_token }}\n{% elif message['role'] == 'assistant' %}\n{{ '<|assistant|>\n'  + message['content'] + eos_token }}\n{% endif %}\n{% if loop.last and add_generation_prompt %}\n{{ '<|assistant|>' }}\n{% endif %}\n{% endfor %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='eval_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='generation_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00001-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00002-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00003-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00004-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model.safetensors.index.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [""israel/LLM-interaction"", ""Dooratre/masakhane-zephyr-7b-gemma-sft-african-alpaca""], ""safetensors"": {""parameters"": {""BF16"": 8537680896}, ""total"": 8537680896}, ""security_repo_status"": null, ""lastModified"": ""2024-04-16 14:09:36+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- masakhane/african-translated-alpaca\nlanguage:\n- af\n- am\n- ar\n- en\n- ee\nlicense: gemma\ntags:\n- alignment-handbook\n- trl\n- sft\n- generated_from_trainer\nmodel-index:\n- name: zephyr-7b-gemma-sft-african-alpaca\n  results: []"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""661803673df49433e0f0f8cd"", ""modelId"": ""masakhane/zephyr-7b-gemma-sft-african-alpaca"", ""usedStorage"": 17097128324}",1,,0,,0,,0,"Dooratre/masakhane-zephyr-7b-gemma-sft-african-alpaca, huggingface/InferenceSupport/discussions/new?title=masakhane/zephyr-7b-gemma-sft-african-alpaca&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bmasakhane%2Fzephyr-7b-gemma-sft-african-alpaca%5D(%2Fmasakhane%2Fzephyr-7b-gemma-sft-african-alpaca)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A, israel/LLM-interaction",3,,
Omickeyee/Marathi_Gemma_7B_40k,"---
language:
- en
license: apache-2.0
tags:
- text-generation-inference
- transformers
- unsloth
- gemma
- trl
base_model: google/gemma-7b
---

# Uploaded  model

- **Developed by:** Omickeyee
- **License:** apache-2.0
- **Finetuned from model :** google/gemma-7b

This gemma model was trained 2x faster with [Unsloth](https://github.com/unslothai/unsloth) and Huggingface's TRL library.

[<img src=""https://raw.githubusercontent.com/unslothai/unsloth/main/images/unsloth%20made%20with%20love.png"" width=""200""/>](https://github.com/unslothai/unsloth)
","{""id"": ""Omickeyee/Marathi_Gemma_7B_40k"", ""author"": ""Omickeyee"", ""sha"": ""ebd380dbadd28e96236f375ca62eba7102023d6b"", ""last_modified"": ""2024-04-11 15:57:03+00:00"", ""created_at"": ""2024-04-11 15:55:36+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""safetensors"", ""text-generation-inference"", ""unsloth"", ""gemma"", ""trl"", ""en"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""license:apache-2.0"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": null, ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\nlanguage:\n- en\nlicense: apache-2.0\ntags:\n- text-generation-inference\n- transformers\n- unsloth\n- gemma\n- trl"", ""widget_data"": null, ""model_index"": null, ""config"": {""tokenizer_config"": {""bos_token"": ""<bos>"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModel"", ""custom_class"": null, ""pipeline_tag"": null, ""processor"": null}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2024-04-11 15:57:03+00:00"", ""cardData"": ""base_model: google/gemma-7b\nlanguage:\n- en\nlicense: apache-2.0\ntags:\n- text-generation-inference\n- transformers\n- unsloth\n- gemma\n- trl"", ""transformersInfo"": {""auto_model"": ""AutoModel"", ""custom_class"": null, ""pipeline_tag"": null, ""processor"": null}, ""_id"": ""661807f80da4c017c4df7f27"", ""modelId"": ""Omickeyee/Marathi_Gemma_7B_40k"", ""usedStorage"": 821835012}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=Omickeyee/Marathi_Gemma_7B_40k&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5BOmickeyee%2FMarathi_Gemma_7B_40k%5D(%2FOmickeyee%2FMarathi_Gemma_7B_40k)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
masakhane/zephyr-7b-gemma-sft-african-ultrachat-5k,"---
license: gemma
base_model: google/gemma-7b
tags:
- alignment-handbook
- trl
- sft
- generated_from_trainer
- trl
- sft
- generated_from_trainer
datasets:
- masakhane/african-ultrachat
- israel/untrachat_en
model-index:
- name: zephyr-7b-gemma-sft-african-ultrachat-5k
  results: []
---

<!-- This model card has been generated automatically according to the information the Trainer had access to. You
should probably proofread and complete it, then remove this comment. -->

# zephyr-7b-gemma-sft-african-ultrachat-5k

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the masakhane/african-ultrachat and the israel/untrachat_en datasets.
It achieves the following results on the evaluation set:
- Loss: 1.1356

## Model description

More information needed

## Intended uses & limitations

More information needed

## Training and evaluation data

More information needed

## Training procedure

### Training hyperparameters

The following hyperparameters were used during training:
- learning_rate: 1e-05
- train_batch_size: 1
- eval_batch_size: 1
- seed: 42
- distributed_type: multi-GPU
- num_devices: 8
- gradient_accumulation_steps: 2
- total_train_batch_size: 16
- total_eval_batch_size: 8
- optimizer: Adam with betas=(0.9,0.999) and epsilon=1e-08
- lr_scheduler_type: cosine
- lr_scheduler_warmup_ratio: 0.1
- num_epochs: 3

### Training results

| Training Loss | Epoch | Step | Validation Loss |
|:-------------:|:-----:|:----:|:---------------:|
| 1.1994        | 1.0   | 2480 | 1.1954          |
| 1.0039        | 2.0   | 4960 | 1.0974          |
| 0.6836        | 3.0   | 7440 | 1.1356          |


### Framework versions

- Transformers 4.39.0.dev0
- Pytorch 2.2.1+cu121
- Datasets 2.14.6
- Tokenizers 0.15.2



### Usage

```python

# Install transformers from source - only needed for versions <= v4.34
# pip install git+https://github.com/huggingface/transformers.git
# pip install accelerate

import torch
from transformers import pipeline

pipe = pipeline(""text-generation"", model=""
zephyr-7b-gemma-sft-african-ultrachat-5k"", torch_dtype=torch.bfloat16, device_map=""auto"")

# We use the tokenizer's chat template to format each message - see https://huggingface.co/docs/transformers/main/en/chat_templating
messages = [
    {
        ""role"": ""system"",
        ""content"": ""You are a friendly chatbot who answewrs question in given language"",
    },
    {""role"": ""user"", ""content"": ""what is the 3 biggest countrys in Africa?""},
]
prompt = pipe.tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)
outputs = pipe(prompt, max_new_tokens=256, do_sample=True, temperature=0.7, top_k=50, top_p=0.95)
print(outputs[0][""generated_text""])
# <|system|>
# You are a friendly chatbot who always responds in the style of a pirate<eos>
# <|user|>
# what is the 3 biggest countrys in Africa?<eos>
# <|assistant|>
# The 3 biggest countries in Africa are Nigeria, Ethiopia and South Africa.
```


### Quantized Versions through bitsandbytes

``` python

import torch
from transformers import pipeline
from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig


quantization_config = BitsAndBytesConfig(load_in_4bit=True)

tokenizer = AutoTokenizer.from_pretrained(""
zephyr-7b-gemma-sft-african-ultrachat-5k"")
model = AutoModelForCausalLM.from_pretrained(""
zephyr-7b-gemma-sft-african-ultrachat-5k"", quantization_config=quantization_config)


pipe = pipeline(""text-generation"", model=model,tokenizer=tokenizer, torch_dtype=torch.bfloat16, device_map=""auto"")

messages = [
    {
        ""role"": ""system"",
        ""content"": ""You are a friendly chatbot who answewrs question in given language"",
    },
    {""role"": ""user"", ""content"": ""list languages in Africa?""},
]
prompt = pipe.tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)
outputs = pipe(prompt, max_new_tokens=256, do_sample=True, temperature=0.7, top_k=50, top_p=0.95)
print(outputs[0][""generated_text""])

```

","{""id"": ""masakhane/zephyr-7b-gemma-sft-african-ultrachat-5k"", ""author"": ""masakhane"", ""sha"": ""3d73c591a6ba630880e40311e48c369a3cd27392"", ""last_modified"": ""2024-04-17 09:24:04+00:00"", ""created_at"": ""2024-04-16 09:19:47+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 3, ""downloads_all_time"": null, ""likes"": 2, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""safetensors"", ""gemma"", ""text-generation"", ""alignment-handbook"", ""trl"", ""sft"", ""generated_from_trainer"", ""conversational"", ""dataset:masakhane/african-ultrachat"", ""dataset:israel/untrachat_en"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""license:gemma"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- masakhane/african-ultrachat\n- israel/untrachat_en\nlicense: gemma\ntags:\n- alignment-handbook\n- trl\n- sft\n- generated_from_trainer\nmodel-index:\n- name: zephyr-7b-gemma-sft-african-ultrachat-5k\n  results: []"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": [{""name"": ""zephyr-7b-gemma-sft-african-ultrachat-5k"", ""results"": []}], ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{% for message in messages %}\n{% if message['role'] == 'user' %}\n{{ '<|user|>\n' + message['content'] + eos_token }}\n{% elif message['role'] == 'system' %}\n{{ '<|system|>\n' + message['content'] + eos_token }}\n{% elif message['role'] == 'assistant' %}\n{{ '<|assistant|>\n'  + message['content'] + eos_token }}\n{% endif %}\n{% if loop.last and add_generation_prompt %}\n{{ '<|assistant|>' }}\n{% endif %}\n{% endfor %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='eval_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='generation_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00001-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00002-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00003-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00004-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model.safetensors.index.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": {""parameters"": {""BF16"": 8537680896}, ""total"": 8537680896}, ""security_repo_status"": null, ""lastModified"": ""2024-04-17 09:24:04+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- masakhane/african-ultrachat\n- israel/untrachat_en\nlicense: gemma\ntags:\n- alignment-handbook\n- trl\n- sft\n- generated_from_trainer\nmodel-index:\n- name: zephyr-7b-gemma-sft-african-ultrachat-5k\n  results: []"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""661e42b3dd97d1bd57bf6084"", ""modelId"": ""masakhane/zephyr-7b-gemma-sft-african-ultrachat-5k"", ""usedStorage"": 17097116116}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=masakhane/zephyr-7b-gemma-sft-african-ultrachat-5k&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bmasakhane%2Fzephyr-7b-gemma-sft-african-ultrachat-5k%5D(%2Fmasakhane%2Fzephyr-7b-gemma-sft-african-ultrachat-5k)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
masakhane/zephyr-7b-gemma-sft-african-ultrachat-100k,"---
license: gemma
base_model: google/gemma-7b
tags:
- alignment-handbook
- trl
- sft
- generated_from_trainer
- trl
- sft
- generated_from_trainer
datasets:
- masakhane/african-ultrachat
- israel/untrachat_en
model-index:
- name: zephyr-7b-gemma-sft-african-ultrachat-200k
  results: []
---

<!-- This model card has been generated automatically according to the information the Trainer had access to. You
should probably proofread and complete it, then remove this comment. -->

# zephyr-7b-gemma-sft-african-ultrachat-200k

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the masakhane/african-ultrachat and the israel/untrachat_en datasets.
It achieves the following results on the evaluation set:
- Loss: 1.1189

## Model description

More information needed

## Intended uses & limitations

More information needed

## Training and evaluation data

More information needed

## Training procedure

### Training hyperparameters

The following hyperparameters were used during training:
- learning_rate: 1e-05
- train_batch_size: 1
- eval_batch_size: 1
- seed: 42
- distributed_type: multi-GPU
- num_devices: 8
- gradient_accumulation_steps: 2
- total_train_batch_size: 16
- total_eval_batch_size: 8
- optimizer: Adam with betas=(0.9,0.999) and epsilon=1e-08
- lr_scheduler_type: cosine
- lr_scheduler_warmup_ratio: 0.1
- num_epochs: 3

### Training results

| Training Loss | Epoch | Step  | Validation Loss |
|:-------------:|:-----:|:-----:|:---------------:|
| 1.1862        | 1.0   | 9918  | 1.2109          |
| 0.9332        | 2.0   | 19837 | 1.0710          |
| 0.6744        | 3.0   | 29754 | 1.1189          |


### Framework versions

- Transformers 4.39.0.dev0
- Pytorch 2.2.1+cu121
- Datasets 2.14.6
- Tokenizers 0.15.2
","{""id"": ""masakhane/zephyr-7b-gemma-sft-african-ultrachat-100k"", ""author"": ""masakhane"", ""sha"": ""10ae9e35a9216065e9c1a22b1fe26cf36f87103b"", ""last_modified"": ""2024-04-28 18:44:57+00:00"", ""created_at"": ""2024-04-17 14:21:17+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 13, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""safetensors"", ""gemma"", ""text-generation"", ""alignment-handbook"", ""trl"", ""sft"", ""generated_from_trainer"", ""conversational"", ""dataset:masakhane/african-ultrachat"", ""dataset:israel/untrachat_en"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""license:gemma"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- masakhane/african-ultrachat\n- israel/untrachat_en\nlicense: gemma\ntags:\n- alignment-handbook\n- trl\n- sft\n- generated_from_trainer\nmodel-index:\n- name: zephyr-7b-gemma-sft-african-ultrachat-200k\n  results: []"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": [{""name"": ""zephyr-7b-gemma-sft-african-ultrachat-200k"", ""results"": []}], ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{% for message in messages %}\n{% if message['role'] == 'user' %}\n{{ '<|user|>\n' + message['content'] + eos_token }}\n{% elif message['role'] == 'system' %}\n{{ '<|system|>\n' + message['content'] + eos_token }}\n{% elif message['role'] == 'assistant' %}\n{{ '<|assistant|>\n'  + message['content'] + eos_token }}\n{% endif %}\n{% if loop.last and add_generation_prompt %}\n{{ '<|assistant|>' }}\n{% endif %}\n{% endfor %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='eval_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='generation_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00001-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00002-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00003-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00004-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model.safetensors.index.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": {""parameters"": {""BF16"": 8537680896}, ""total"": 8537680896}, ""security_repo_status"": null, ""lastModified"": ""2024-04-28 18:44:57+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- masakhane/african-ultrachat\n- israel/untrachat_en\nlicense: gemma\ntags:\n- alignment-handbook\n- trl\n- sft\n- generated_from_trainer\nmodel-index:\n- name: zephyr-7b-gemma-sft-african-ultrachat-200k\n  results: []"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""661fdadd332bb640c97926f4"", ""modelId"": ""masakhane/zephyr-7b-gemma-sft-african-ultrachat-100k"", ""usedStorage"": 17097169460}",1,,0,https://huggingface.co/mradermacher/zephyr-7b-gemma-sft-african-ultrachat-100k-GGUF,1,,0,huggingface/InferenceSupport/discussions/new?title=masakhane/zephyr-7b-gemma-sft-african-ultrachat-100k&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bmasakhane%2Fzephyr-7b-gemma-sft-african-ultrachat-100k%5D(%2Fmasakhane%2Fzephyr-7b-gemma-sft-african-ultrachat-100k)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
https://huggingface.co/karakuri-ai/karakuri-lm-7b-apm-v0.1,N/A,N/A,1,,0,,0,,0,,0,,0.0
pkarypis/gemma-lima,"---
license: gemma
base_model: google/gemma-7b
tags:
- alignment-handbook
- trl
- sft
- generated_from_trainer
- trl
- sft
- generated_from_trainer
datasets:
- GAIR/lima
model-index:
- name: gemma-lima
  results: []
---

<!-- This model card has been generated automatically according to the information the Trainer had access to. You
should probably proofread and complete it, then remove this comment. -->

# gemma-lima

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the GAIR/lima dataset.
It achieves the following results on the evaluation set:
- Loss: 2.7259

## Model description

More information needed

## Intended uses & limitations

More information needed

## Training and evaluation data

More information needed

## Training procedure

### Training hyperparameters

The following hyperparameters were used during training:
- learning_rate: 2e-05
- train_batch_size: 4
- eval_batch_size: 4
- seed: 42
- distributed_type: multi-GPU
- num_devices: 16
- gradient_accumulation_steps: 2
- total_train_batch_size: 128
- total_eval_batch_size: 64
- optimizer: Adam with betas=(0.9,0.999) and epsilon=1e-08
- lr_scheduler_type: cosine
- lr_scheduler_warmup_ratio: 0.1
- num_epochs: 10.0

### Training results

| Training Loss | Epoch | Step | Validation Loss |
|:-------------:|:-----:|:----:|:---------------:|
| 10.4256       | 0.91  | 5    | 47.0001         |
| 6.0419        | 2.0   | 11   | 43.9691         |
| 5.2838        | 2.91  | 16   | 40.7857         |
| 4.8705        | 4.0   | 22   | 33.9282         |
| 4.196         | 4.91  | 27   | 17.5336         |
| 3.0724        | 6.0   | 33   | 2.7088          |
| 2.1966        | 6.91  | 38   | 2.7434          |
| 2.1116        | 8.0   | 44   | 2.7265          |
| 2.0641        | 8.91  | 49   | 2.7168          |
| 2.0467        | 9.09  | 50   | 2.7259          |


### Framework versions

- Transformers 4.38.2
- Pytorch 2.1.2
- Datasets 2.14.6
- Tokenizers 0.15.2
","{""id"": ""pkarypis/gemma-lima"", ""author"": ""pkarypis"", ""sha"": ""4ecaa2ea3c98b6622982421ddd41a16d407ec8e0"", ""last_modified"": ""2024-04-27 02:52:22+00:00"", ""created_at"": ""2024-04-26 23:16:12+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 6, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""alignment-handbook"", ""trl"", ""sft"", ""generated_from_trainer"", ""conversational"", ""dataset:GAIR/lima"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""license:gemma"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- GAIR/lima\nlicense: gemma\ntags:\n- alignment-handbook\n- trl\n- sft\n- generated_from_trainer\nmodel-index:\n- name: gemma-lima\n  results: []"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": [{""name"": ""gemma-lima"", ""results"": []}], ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{% for message in messages %}\n{% if message['role'] == 'user' %}\n{{ '### Human\n' + message['content'] + eos_token }}\n{% elif message['role'] == 'system' %}\n{{ '### System\n' + message['content'] + eos_token }}\n{% elif message['role'] == 'assistant' %}\n{{ '### Assistant\n'  + message['content'] + eos_token }}\n{% endif %}\n{% if loop.last and add_generation_prompt %}\n{{ '### Assistant' }}\n{% endif %}\n{% endfor %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='eval_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='generation_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00001-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00002-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00003-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00004-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model.safetensors.index.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Apr26_17-45-06_aga43/events.out.tfevents.1714173378.aga43.1105784.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Apr26_20-17-32_aga39/events.out.tfevents.1714180734.aga39.1498112.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Apr26_20-19-28_aga39/events.out.tfevents.1714180892.aga39.1498535.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Apr26_21-28-02_aga39/events.out.tfevents.1714184910.aga39.1507435.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Apr26_21-28-56_aga39/events.out.tfevents.1714184962.aga39.1507733.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Apr26_21-34-17_aga39/events.out.tfevents.1714185283.aga39.1508781.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Apr26_21-34-17_aga39/events.out.tfevents.1714186288.aga39.1508781.1', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": {""parameters"": {""BF16"": 8537680896}, ""total"": 8537680896}, ""security_repo_status"": null, ""lastModified"": ""2024-04-27 02:52:22+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- GAIR/lima\nlicense: gemma\ntags:\n- alignment-handbook\n- trl\n- sft\n- generated_from_trainer\nmodel-index:\n- name: gemma-lima\n  results: []"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""662c35bc35ab6df959bfa406"", ""modelId"": ""pkarypis/gemma-lima"", ""usedStorage"": 17097191536}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=pkarypis/gemma-lima&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bpkarypis%2Fgemma-lima%5D(%2Fpkarypis%2Fgemma-lima)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
masakhane/zephyr-7b-gemma-sft-african-ultrachat-200k,"---
license: gemma
base_model: google/gemma-7b
tags:
- alignment-handbook
- trl
- sft
- generated_from_trainer
- trl
- sft
- generated_from_trainer
datasets:
- masakhane/african-ultrachat
- israel/untrachat_en
model-index:
- name: zephyr-7b-gemma-sft-african-ultrachat-2000k
  results: []
---

<!-- This model card has been generated automatically according to the information the Trainer had access to. You
should probably proofread and complete it, then remove this comment. -->

# zephyr-7b-gemma-sft-african-ultrachat-2000k

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the masakhane/african-ultrachat and the israel/untrachat_en datasets.
It achieves the following results on the evaluation set:
- Loss: 1.1549

## Model description

More information needed

## Intended uses & limitations

More information needed

## Training and evaluation data

More information needed

## Training procedure

### Training hyperparameters

The following hyperparameters were used during training:
- learning_rate: 1e-05
- train_batch_size: 1
- eval_batch_size: 1
- seed: 42
- distributed_type: multi-GPU
- num_devices: 8
- gradient_accumulation_steps: 2
- total_train_batch_size: 16
- total_eval_batch_size: 8
- optimizer: Adam with betas=(0.9,0.999) and epsilon=1e-08
- lr_scheduler_type: cosine
- lr_scheduler_warmup_ratio: 0.1
- num_epochs: 3

### Training results

| Training Loss | Epoch | Step  | Validation Loss |
|:-------------:|:-----:|:-----:|:---------------:|
| 1.0785        | 1.0   | 17748 | 1.2602          |
| 0.6614        | 2.0   | 35496 | 1.1089          |
| 0.2983        | 3.0   | 53244 | 1.1549          |


### Framework versions

- Transformers 4.39.0.dev0
- Pytorch 2.2.1+cu121
- Datasets 2.14.6
- Tokenizers 0.15.2
","{""id"": ""masakhane/zephyr-7b-gemma-sft-african-ultrachat-200k"", ""author"": ""masakhane"", ""sha"": ""20b809cee3d1bf5303e1317991bf2f88243eaf4b"", ""last_modified"": ""2024-04-30 07:13:21+00:00"", ""created_at"": ""2024-04-28 19:28:04+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 76, ""downloads_all_time"": null, ""likes"": 1, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""safetensors"", ""gemma"", ""text-generation"", ""alignment-handbook"", ""trl"", ""sft"", ""generated_from_trainer"", ""conversational"", ""dataset:masakhane/african-ultrachat"", ""dataset:israel/untrachat_en"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""license:gemma"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- masakhane/african-ultrachat\n- israel/untrachat_en\nlicense: gemma\ntags:\n- alignment-handbook\n- trl\n- sft\n- generated_from_trainer\nmodel-index:\n- name: zephyr-7b-gemma-sft-african-ultrachat-2000k\n  results: []"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": [{""name"": ""zephyr-7b-gemma-sft-african-ultrachat-2000k"", ""results"": []}], ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{% for message in messages %}\n{% if message['role'] == 'user' %}\n{{ '<|user|>\n' + message['content'] + eos_token }}\n{% elif message['role'] == 'system' %}\n{{ '<|system|>\n' + message['content'] + eos_token }}\n{% elif message['role'] == 'assistant' %}\n{{ '<|assistant|>\n'  + message['content'] + eos_token }}\n{% endif %}\n{% if loop.last and add_generation_prompt %}\n{{ '<|assistant|>' }}\n{% endif %}\n{% endfor %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='eval_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='generation_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00001-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00002-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00003-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00004-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model.safetensors.index.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": {""parameters"": {""BF16"": 8537680896}, ""total"": 8537680896}, ""security_repo_status"": null, ""lastModified"": ""2024-04-30 07:13:21+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- masakhane/african-ultrachat\n- israel/untrachat_en\nlicense: gemma\ntags:\n- alignment-handbook\n- trl\n- sft\n- generated_from_trainer\nmodel-index:\n- name: zephyr-7b-gemma-sft-african-ultrachat-2000k\n  results: []"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""662ea34436fd0c278bfc9498"", ""modelId"": ""masakhane/zephyr-7b-gemma-sft-african-ultrachat-200k"", ""usedStorage"": 17097157060}",1,,0,https://huggingface.co/afrideva/zephyr-7b-gemma-sft-african-ultrachat-200k-GGUF,1,,0,huggingface/InferenceSupport/discussions/new?title=masakhane/zephyr-7b-gemma-sft-african-ultrachat-200k&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bmasakhane%2Fzephyr-7b-gemma-sft-african-ultrachat-200k%5D(%2Fmasakhane%2Fzephyr-7b-gemma-sft-african-ultrachat-200k)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
PrunaAI/google-gemma-7b-HQQ-2bit-smashed,"---
thumbnail: ""https://assets-global.website-files.com/646b351987a8d8ce158d1940/64ec9e96b4334c0e1ac41504_Logo%20with%20white%20text.svg""
base_model: google/gemma-7b
metrics:
- memory_disk
- memory_inference
- inference_latency
- inference_throughput
- inference_CO2_emissions
- inference_energy_consumption
tags:
- pruna-ai
---
<!-- header start -->
<!-- 200823 -->
<div style=""width: auto; margin-left: auto; margin-right: auto"">
    <a href=""https://www.pruna.ai/"" target=""_blank"" rel=""noopener noreferrer"">
        <img src=""https://i.imgur.com/eDAlcgk.png"" alt=""PrunaAI"" style=""width: 100%; min-width: 400px; display: block; margin: auto;"">
    </a>
</div>
<!-- header end -->

[![Twitter](https://img.shields.io/twitter/follow/PrunaAI?style=social)](https://twitter.com/PrunaAI)
[![GitHub](https://img.shields.io/github/followers/PrunaAI?label=Follow%20%40PrunaAI&style=social)](https://github.com/PrunaAI)
[![LinkedIn](https://img.shields.io/badge/LinkedIn-Connect-blue)](https://www.linkedin.com/company/93832878/admin/feed/posts/?feedType=following)
[![Discord](https://img.shields.io/badge/Discord-Join%20Us-blue?style=social&logo=discord)](https://discord.gg/rskEr4BZJx)

# Simply make AI models cheaper, smaller, faster, and greener!

- Give a thumbs up if you like this model!
- Contact us and tell us which model to compress next [here](https://www.pruna.ai/contact).
- Request access to easily compress your *own* AI models [here](https://z0halsaff74.typeform.com/pruna-access?typeform-source=www.pruna.ai).
- Read the documentations to know more [here](https://pruna-ai-pruna.readthedocs-hosted.com/en/latest/)
- Join Pruna AI community on Discord [here](https://discord.gg/rskEr4BZJx) to share feedback/suggestions or get help.

## Results

![image info](./plots.png)

**Frequently Asked Questions**
- ***How does the compression work?*** The model is compressed with hqq.
- ***How does the model quality change?*** The quality of the model output might vary compared to the base model.
- ***How is the model efficiency evaluated?*** These results were obtained on NVIDIA A100-PCIE-40GB with configuration described in `model/smash_config.json` and are obtained after a hardware warmup. The smashed model is directly compared to the original base model. Efficiency results may vary in other settings (e.g. other hardware, image size, batch size, ...). We recommend to directly run them in the use-case conditions to know if the smashed model can benefit you.
- ***What is the model format?*** We use safetensors.
- ***What calibration data has been used?*** If needed by the compression method, we used WikiText as the calibration data.
- ***What is the naming convention for Pruna Huggingface models?*** We take the original model name and append ""turbo"", ""tiny"", or ""green"" if the smashed model has a measured inference speed, inference memory, or inference energy consumption which is less than 90% of the original base model.
- ***How to compress my own models?*** You can request premium access to more compression methods and tech support for your specific use-cases [here](https://z0halsaff74.typeform.com/pruna-access?typeform-source=www.pruna.ai).
- ***What are ""first"" metrics?*** Results mentioning ""first"" are obtained after the first run of the model. The first run might take more memory or be slower than the subsequent runs due cuda overheads.
- ***What are ""Sync"" and ""Async"" metrics?*** ""Sync"" metrics are obtained by syncing all GPU processes and stop measurement when all of them are executed. ""Async"" metrics are obtained without syncing all GPU processes and stop when the model output can be used by the CPU. We provide both metrics since both could be relevant depending on the use-case. We recommend to test the efficiency gains directly in your use-cases.

## Setup

You can run the smashed model with these steps:

0. Check requirements from the original repo google/gemma-7b installed. In particular, check python, cuda, and transformers versions.
1. Make sure that you have installed quantization related packages.
    ```bash
    pip install hqq
    ```
2. Load & run the model.
    ```python 
   from transformers import AutoModelForCausalLM, AutoTokenizer
    from hqq.engine.hf import HQQModelForCausalLM
 from hqq.models.hf.base import AutoHQQHFModel

   try:
     model = HQQModelForCausalLM.from_quantized(""PrunaAI/google-gemma-7b-HQQ-2bit-smashed"", device_map='auto')
    except: 
     model = AutoHQQHFModel.from_quantized(""PrunaAI/google-gemma-7b-HQQ-2bit-smashed"")
   tokenizer = AutoTokenizer.from_pretrained(""google/gemma-7b"")
    
   input_ids = tokenizer(""What is the color of prunes?,"", return_tensors='pt').to(model.device)[""input_ids""]
    
   outputs = model.generate(input_ids, max_new_tokens=216)
   tokenizer.decode(outputs[0])
    ```

## Configurations

The configuration info are in `smash_config.json`.

## Credits & License

The license of the smashed model follows the license of the original model. Please check the license of the original model google/gemma-7b before using this model which provided the base model. The license  of the `pruna-engine` is [here](https://pypi.org/project/pruna-engine/) on Pypi.

## Want to compress other models?

- Contact us and tell us which model to compress next [here](https://www.pruna.ai/contact).
- Request access to easily compress your own AI models [here](https://z0halsaff74.typeform.com/pruna-access?typeform-source=www.pruna.ai).","{""id"": ""PrunaAI/google-gemma-7b-HQQ-2bit-smashed"", ""author"": ""PrunaAI"", ""sha"": ""03a70b5f5f94f170bd083bfbb3118d54b35335c7"", ""last_modified"": ""2024-08-02 15:56:12+00:00"", ""created_at"": ""2024-04-29 13:10:39+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 2, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""gemma"", ""text-generation"", ""pruna-ai"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\nmetrics:\n- memory_disk\n- memory_inference\n- inference_latency\n- inference_throughput\n- inference_CO2_emissions\n- inference_energy_consumption\ntags:\n- pruna-ai\nthumbnail: https://assets-global.website-files.com/646b351987a8d8ce158d1940/64ec9e96b4334c0e1ac41504_Logo%20with%20white%20text.svg"", ""widget_data"": [{""text"": ""My name is Julien and I like to""}, {""text"": ""I like traveling by train because""}, {""text"": ""Paris is an amazing place to visit,""}, {""text"": ""Once upon a time,""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma""}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='plots.png', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='qmodel.pt', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='smash_config.json', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2024-08-02 15:56:12+00:00"", ""cardData"": ""base_model: google/gemma-7b\nmetrics:\n- memory_disk\n- memory_inference\n- inference_latency\n- inference_throughput\n- inference_CO2_emissions\n- inference_energy_consumption\ntags:\n- pruna-ai\nthumbnail: https://assets-global.website-files.com/646b351987a8d8ce158d1940/64ec9e96b4334c0e1ac41504_Logo%20with%20white%20text.svg"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""662f9c4faf9e8e0d23a00ff4"", ""modelId"": ""PrunaAI/google-gemma-7b-HQQ-2bit-smashed"", ""usedStorage"": 3692979050}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=PrunaAI/google-gemma-7b-HQQ-2bit-smashed&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5BPrunaAI%2Fgoogle-gemma-7b-HQQ-2bit-smashed%5D(%2FPrunaAI%2Fgoogle-gemma-7b-HQQ-2bit-smashed)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
PrunaAI/google-gemma-7b-HQQ-1bit-smashed,"---
thumbnail: ""https://assets-global.website-files.com/646b351987a8d8ce158d1940/64ec9e96b4334c0e1ac41504_Logo%20with%20white%20text.svg""
base_model: google/gemma-7b
metrics:
- memory_disk
- memory_inference
- inference_latency
- inference_throughput
- inference_CO2_emissions
- inference_energy_consumption
tags:
- pruna-ai
---
<!-- header start -->
<!-- 200823 -->
<div style=""width: auto; margin-left: auto; margin-right: auto"">
    <a href=""https://www.pruna.ai/"" target=""_blank"" rel=""noopener noreferrer"">
        <img src=""https://i.imgur.com/eDAlcgk.png"" alt=""PrunaAI"" style=""width: 100%; min-width: 400px; display: block; margin: auto;"">
    </a>
</div>
<!-- header end -->

[![Twitter](https://img.shields.io/twitter/follow/PrunaAI?style=social)](https://twitter.com/PrunaAI)
[![GitHub](https://img.shields.io/github/followers/PrunaAI?label=Follow%20%40PrunaAI&style=social)](https://github.com/PrunaAI)
[![LinkedIn](https://img.shields.io/badge/LinkedIn-Connect-blue)](https://www.linkedin.com/company/93832878/admin/feed/posts/?feedType=following)
[![Discord](https://img.shields.io/badge/Discord-Join%20Us-blue?style=social&logo=discord)](https://discord.gg/rskEr4BZJx)

# Simply make AI models cheaper, smaller, faster, and greener!

- Give a thumbs up if you like this model!
- Contact us and tell us which model to compress next [here](https://www.pruna.ai/contact).
- Request access to easily compress your *own* AI models [here](https://z0halsaff74.typeform.com/pruna-access?typeform-source=www.pruna.ai).
- Read the documentations to know more [here](https://pruna-ai-pruna.readthedocs-hosted.com/en/latest/)
- Join Pruna AI community on Discord [here](https://discord.gg/rskEr4BZJx) to share feedback/suggestions or get help.

## Results

![image info](./plots.png)

**Frequently Asked Questions**
- ***How does the compression work?*** The model is compressed with hqq.
- ***How does the model quality change?*** The quality of the model output might vary compared to the base model.
- ***How is the model efficiency evaluated?*** These results were obtained on NVIDIA A100-PCIE-40GB with configuration described in `model/smash_config.json` and are obtained after a hardware warmup. The smashed model is directly compared to the original base model. Efficiency results may vary in other settings (e.g. other hardware, image size, batch size, ...). We recommend to directly run them in the use-case conditions to know if the smashed model can benefit you.
- ***What is the model format?*** We use safetensors.
- ***What calibration data has been used?*** If needed by the compression method, we used WikiText as the calibration data.
- ***What is the naming convention for Pruna Huggingface models?*** We take the original model name and append ""turbo"", ""tiny"", or ""green"" if the smashed model has a measured inference speed, inference memory, or inference energy consumption which is less than 90% of the original base model.
- ***How to compress my own models?*** You can request premium access to more compression methods and tech support for your specific use-cases [here](https://z0halsaff74.typeform.com/pruna-access?typeform-source=www.pruna.ai).
- ***What are ""first"" metrics?*** Results mentioning ""first"" are obtained after the first run of the model. The first run might take more memory or be slower than the subsequent runs due cuda overheads.
- ***What are ""Sync"" and ""Async"" metrics?*** ""Sync"" metrics are obtained by syncing all GPU processes and stop measurement when all of them are executed. ""Async"" metrics are obtained without syncing all GPU processes and stop when the model output can be used by the CPU. We provide both metrics since both could be relevant depending on the use-case. We recommend to test the efficiency gains directly in your use-cases.

## Setup

You can run the smashed model with these steps:

0. Check requirements from the original repo google/gemma-7b installed. In particular, check python, cuda, and transformers versions.
1. Make sure that you have installed quantization related packages.
    ```bash
    pip install hqq
    ```
2. Load & run the model.
    ```python 
   from transformers import AutoModelForCausalLM, AutoTokenizer
    from hqq.engine.hf import HQQModelForCausalLM
 from hqq.models.hf.base import AutoHQQHFModel

   try:
     model = HQQModelForCausalLM.from_quantized(""PrunaAI/google-gemma-7b-HQQ-1bit-smashed"", device_map='auto')
    except: 
     model = AutoHQQHFModel.from_quantized(""PrunaAI/google-gemma-7b-HQQ-1bit-smashed"")
   tokenizer = AutoTokenizer.from_pretrained(""google/gemma-7b"")
    
   input_ids = tokenizer(""What is the color of prunes?,"", return_tensors='pt').to(model.device)[""input_ids""]
    
   outputs = model.generate(input_ids, max_new_tokens=216)
   tokenizer.decode(outputs[0])
    ```

## Configurations

The configuration info are in `smash_config.json`.

## Credits & License

The license of the smashed model follows the license of the original model. Please check the license of the original model google/gemma-7b before using this model which provided the base model. The license  of the `pruna-engine` is [here](https://pypi.org/project/pruna-engine/) on Pypi.

## Want to compress other models?

- Contact us and tell us which model to compress next [here](https://www.pruna.ai/contact).
- Request access to easily compress your own AI models [here](https://z0halsaff74.typeform.com/pruna-access?typeform-source=www.pruna.ai).","{""id"": ""PrunaAI/google-gemma-7b-HQQ-1bit-smashed"", ""author"": ""PrunaAI"", ""sha"": ""241500863353e6d0c762665656d609dbb4cb6ae4"", ""last_modified"": ""2024-08-02 15:56:13+00:00"", ""created_at"": ""2024-04-29 13:10:58+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 2, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""gemma"", ""text-generation"", ""pruna-ai"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\nmetrics:\n- memory_disk\n- memory_inference\n- inference_latency\n- inference_throughput\n- inference_CO2_emissions\n- inference_energy_consumption\ntags:\n- pruna-ai\nthumbnail: https://assets-global.website-files.com/646b351987a8d8ce158d1940/64ec9e96b4334c0e1ac41504_Logo%20with%20white%20text.svg"", ""widget_data"": [{""text"": ""My name is Julien and I like to""}, {""text"": ""I like traveling by train because""}, {""text"": ""Paris is an amazing place to visit,""}, {""text"": ""Once upon a time,""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma""}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='plots.png', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='qmodel.pt', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='smash_config.json', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2024-08-02 15:56:13+00:00"", ""cardData"": ""base_model: google/gemma-7b\nmetrics:\n- memory_disk\n- memory_inference\n- inference_latency\n- inference_throughput\n- inference_CO2_emissions\n- inference_energy_consumption\ntags:\n- pruna-ai\nthumbnail: https://assets-global.website-files.com/646b351987a8d8ce158d1940/64ec9e96b4334c0e1ac41504_Logo%20with%20white%20text.svg"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""662f9c62deea60b9209353cf"", ""modelId"": ""PrunaAI/google-gemma-7b-HQQ-1bit-smashed"", ""usedStorage"": 2724094826}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=PrunaAI/google-gemma-7b-HQQ-1bit-smashed&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5BPrunaAI%2Fgoogle-gemma-7b-HQQ-1bit-smashed%5D(%2FPrunaAI%2Fgoogle-gemma-7b-HQQ-1bit-smashed)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
PrunaAI/google-gemma-7b-HQQ-4bit-smashed,"---
thumbnail: ""https://assets-global.website-files.com/646b351987a8d8ce158d1940/64ec9e96b4334c0e1ac41504_Logo%20with%20white%20text.svg""
base_model: google/gemma-7b
metrics:
- memory_disk
- memory_inference
- inference_latency
- inference_throughput
- inference_CO2_emissions
- inference_energy_consumption
tags:
- pruna-ai
---
<!-- header start -->
<!-- 200823 -->
<div style=""width: auto; margin-left: auto; margin-right: auto"">
    <a href=""https://www.pruna.ai/"" target=""_blank"" rel=""noopener noreferrer"">
        <img src=""https://i.imgur.com/eDAlcgk.png"" alt=""PrunaAI"" style=""width: 100%; min-width: 400px; display: block; margin: auto;"">
    </a>
</div>
<!-- header end -->

[![Twitter](https://img.shields.io/twitter/follow/PrunaAI?style=social)](https://twitter.com/PrunaAI)
[![GitHub](https://img.shields.io/github/followers/PrunaAI?label=Follow%20%40PrunaAI&style=social)](https://github.com/PrunaAI)
[![LinkedIn](https://img.shields.io/badge/LinkedIn-Connect-blue)](https://www.linkedin.com/company/93832878/admin/feed/posts/?feedType=following)
[![Discord](https://img.shields.io/badge/Discord-Join%20Us-blue?style=social&logo=discord)](https://discord.gg/rskEr4BZJx)

# Simply make AI models cheaper, smaller, faster, and greener!

- Give a thumbs up if you like this model!
- Contact us and tell us which model to compress next [here](https://www.pruna.ai/contact).
- Request access to easily compress your *own* AI models [here](https://z0halsaff74.typeform.com/pruna-access?typeform-source=www.pruna.ai).
- Read the documentations to know more [here](https://pruna-ai-pruna.readthedocs-hosted.com/en/latest/)
- Join Pruna AI community on Discord [here](https://discord.gg/rskEr4BZJx) to share feedback/suggestions or get help.

## Results

![image info](./plots.png)

**Frequently Asked Questions**
- ***How does the compression work?*** The model is compressed with hqq.
- ***How does the model quality change?*** The quality of the model output might vary compared to the base model.
- ***How is the model efficiency evaluated?*** These results were obtained on NVIDIA A100-PCIE-40GB with configuration described in `model/smash_config.json` and are obtained after a hardware warmup. The smashed model is directly compared to the original base model. Efficiency results may vary in other settings (e.g. other hardware, image size, batch size, ...). We recommend to directly run them in the use-case conditions to know if the smashed model can benefit you.
- ***What is the model format?*** We use safetensors.
- ***What calibration data has been used?*** If needed by the compression method, we used WikiText as the calibration data.
- ***What is the naming convention for Pruna Huggingface models?*** We take the original model name and append ""turbo"", ""tiny"", or ""green"" if the smashed model has a measured inference speed, inference memory, or inference energy consumption which is less than 90% of the original base model.
- ***How to compress my own models?*** You can request premium access to more compression methods and tech support for your specific use-cases [here](https://z0halsaff74.typeform.com/pruna-access?typeform-source=www.pruna.ai).
- ***What are ""first"" metrics?*** Results mentioning ""first"" are obtained after the first run of the model. The first run might take more memory or be slower than the subsequent runs due cuda overheads.
- ***What are ""Sync"" and ""Async"" metrics?*** ""Sync"" metrics are obtained by syncing all GPU processes and stop measurement when all of them are executed. ""Async"" metrics are obtained without syncing all GPU processes and stop when the model output can be used by the CPU. We provide both metrics since both could be relevant depending on the use-case. We recommend to test the efficiency gains directly in your use-cases.

## Setup

You can run the smashed model with these steps:

0. Check requirements from the original repo google/gemma-7b installed. In particular, check python, cuda, and transformers versions.
1. Make sure that you have installed quantization related packages.
    ```bash
    pip install hqq
    ```
2. Load & run the model.
    ```python 
   from transformers import AutoModelForCausalLM, AutoTokenizer
    from hqq.engine.hf import HQQModelForCausalLM
 from hqq.models.hf.base import AutoHQQHFModel

   try:
     model = HQQModelForCausalLM.from_quantized(""PrunaAI/google-gemma-7b-HQQ-4bit-smashed"", device_map='auto')
    except: 
     model = AutoHQQHFModel.from_quantized(""PrunaAI/google-gemma-7b-HQQ-4bit-smashed"")
   tokenizer = AutoTokenizer.from_pretrained(""google/gemma-7b"")
    
   input_ids = tokenizer(""What is the color of prunes?,"", return_tensors='pt').to(model.device)[""input_ids""]
    
   outputs = model.generate(input_ids, max_new_tokens=216)
   tokenizer.decode(outputs[0])
    ```

## Configurations

The configuration info are in `smash_config.json`.

## Credits & License

The license of the smashed model follows the license of the original model. Please check the license of the original model google/gemma-7b before using this model which provided the base model. The license  of the `pruna-engine` is [here](https://pypi.org/project/pruna-engine/) on Pypi.

## Want to compress other models?

- Contact us and tell us which model to compress next [here](https://www.pruna.ai/contact).
- Request access to easily compress your own AI models [here](https://z0halsaff74.typeform.com/pruna-access?typeform-source=www.pruna.ai).","{""id"": ""PrunaAI/google-gemma-7b-HQQ-4bit-smashed"", ""author"": ""PrunaAI"", ""sha"": ""bc5af61f40e5ac136104683c67b5c3e639ebb465"", ""last_modified"": ""2024-08-02 15:57:13+00:00"", ""created_at"": ""2024-04-29 15:58:39+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 4, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""gemma"", ""text-generation"", ""pruna-ai"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\nmetrics:\n- memory_disk\n- memory_inference\n- inference_latency\n- inference_throughput\n- inference_CO2_emissions\n- inference_energy_consumption\ntags:\n- pruna-ai\nthumbnail: https://assets-global.website-files.com/646b351987a8d8ce158d1940/64ec9e96b4334c0e1ac41504_Logo%20with%20white%20text.svg"", ""widget_data"": [{""text"": ""My name is Julien and I like to""}, {""text"": ""I like traveling by train because""}, {""text"": ""Paris is an amazing place to visit,""}, {""text"": ""Once upon a time,""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma""}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='plots.png', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='qmodel.pt', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='smash_config.json', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2024-08-02 15:57:13+00:00"", ""cardData"": ""base_model: google/gemma-7b\nmetrics:\n- memory_disk\n- memory_inference\n- inference_latency\n- inference_throughput\n- inference_CO2_emissions\n- inference_energy_consumption\ntags:\n- pruna-ai\nthumbnail: https://assets-global.website-files.com/646b351987a8d8ce158d1940/64ec9e96b4334c0e1ac41504_Logo%20with%20white%20text.svg"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""662fc3afc222fcad3052eaf2"", ""modelId"": ""PrunaAI/google-gemma-7b-HQQ-4bit-smashed"", ""usedStorage"": 5630753154}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=PrunaAI/google-gemma-7b-HQQ-4bit-smashed&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5BPrunaAI%2Fgoogle-gemma-7b-HQQ-4bit-smashed%5D(%2FPrunaAI%2Fgoogle-gemma-7b-HQQ-4bit-smashed)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
https://huggingface.co/Ahjeong/MMPO_Gemma_7b_gamma1.1_epoch3,N/A,N/A,1,,0,,0,,0,,0,,0.0
masakhane/African-ultrachat-alpaca,"---
license: gemma
base_model: google/gemma-7b
tags:
- alignment-handbook
- trl
- sft
- generated_from_trainer
- trl
- sft
- generated_from_trainer
datasets:
- masakhane/african-ultrachat
- untrachat_en
- sd
model-index:
- name: zephyr-7b-gemma-sft-african-ultraalpaca
  results: []
---

<!-- This model card has been generated automatically according to the information the Trainer had access to. You
should probably proofread and complete it, then remove this comment. -->

# zephyr-7b-gemma-sft-african-ultraalpaca

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) 

## Model description

More information needed

## Intended uses & limitations

More information needed

## Training and evaluation data

More information needed

## Training procedure

### Training hyperparameters

The following hyperparameters were used during training:
- learning_rate: 1e-05
- train_batch_size: 1
- eval_batch_size: 1
- seed: 42
- distributed_type: multi-GPU
- num_devices: 8
- gradient_accumulation_steps: 2
- total_train_batch_size: 16
- total_eval_batch_size: 8
- optimizer: Adam with betas=(0.9,0.999) and epsilon=1e-08
- lr_scheduler_type: cosine
- lr_scheduler_warmup_ratio: 0.1
- num_epochs: 3

### Training results

| Training Loss | Epoch | Step  | Validation Loss |
|:-------------:|:-----:|:-----:|:---------------:|
| 1.0034        | 1.0   | 23628 | 1.0630          |
| 0.6403        | 2.0   | 47257 | 0.8788          |
| 0.2976        | 3.0   | 70884 | 0.8875          |


### Framework versions

- Transformers 4.39.0.dev0
- Pytorch 2.2.1+cu121
- Datasets 2.14.6
- Tokenizers 0.15.2
","{""id"": ""masakhane/African-ultrachat-alpaca"", ""author"": ""masakhane"", ""sha"": ""c39500be79989523badfcbaede039da67be271c5"", ""last_modified"": ""2024-05-02 18:53:49+00:00"", ""created_at"": ""2024-04-30 18:39:36+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 7, ""downloads_all_time"": null, ""likes"": 2, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""safetensors"", ""gemma"", ""text-generation"", ""alignment-handbook"", ""trl"", ""sft"", ""generated_from_trainer"", ""conversational"", ""dataset:masakhane/african-ultrachat"", ""dataset:untrachat_en"", ""dataset:sd"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""license:gemma"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- masakhane/african-ultrachat\n- untrachat_en\n- sd\nlicense: gemma\ntags:\n- alignment-handbook\n- trl\n- sft\n- generated_from_trainer\nmodel-index:\n- name: zephyr-7b-gemma-sft-african-ultraalpaca\n  results: []"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": [{""name"": ""zephyr-7b-gemma-sft-african-ultraalpaca"", ""results"": []}], ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{% for message in messages %}\n{% if message['role'] == 'user' %}\n{{ '<|user|>\n' + message['content'] + eos_token }}\n{% elif message['role'] == 'system' %}\n{{ '<|system|>\n' + message['content'] + eos_token }}\n{% elif message['role'] == 'assistant' %}\n{{ '<|assistant|>\n'  + message['content'] + eos_token }}\n{% endif %}\n{% if loop.last and add_generation_prompt %}\n{{ '<|assistant|>' }}\n{% endif %}\n{% endfor %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='eval_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='generation_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00001-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00002-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00003-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00004-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model.safetensors.index.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": {""parameters"": {""BF16"": 8537680896}, ""total"": 8537680896}, ""security_repo_status"": null, ""lastModified"": ""2024-05-02 18:53:49+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- masakhane/african-ultrachat\n- untrachat_en\n- sd\nlicense: gemma\ntags:\n- alignment-handbook\n- trl\n- sft\n- generated_from_trainer\nmodel-index:\n- name: zephyr-7b-gemma-sft-african-ultraalpaca\n  results: []"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""66313ae8d4843e97ef89532a"", ""modelId"": ""masakhane/African-ultrachat-alpaca"", ""usedStorage"": 17097157060}",1,,0,"https://huggingface.co/afrideva/African-ultrachat-alpaca-GGUF, https://huggingface.co/mradermacher/African-ultrachat-alpaca-GGUF, https://huggingface.co/mradermacher/African-ultrachat-alpaca-i1-GGUF",3,,0,huggingface/InferenceSupport/discussions/new?title=masakhane/African-ultrachat-alpaca&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bmasakhane%2FAfrican-ultrachat-alpaca%5D(%2Fmasakhane%2FAfrican-ultrachat-alpaca)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
webbigdata/C3TR-Adapter_hqq,"---
library_name: gptq
base_model: google/gemma-7b
language:
- ja
- en
tags:
- translation
- hqq
- gemma
- text-generation-inference
- nlp
---

### Model card
英日、日英翻訳用モデル[C3TR-Adapter](https://huggingface.co/webbigdata/C3TR-Adapter)のHQQ(Half-Quadratic Quantization)4bit量子化版です。  
This is the HQQ(Half-Quadratic Quantization) 4bit quantized version of the [C3TR-Adapter](https://huggingface.co/webbigdata/C3TR-Adapter), model for English-Japanese and Japanese-English translation.  

### 簡単に動かす方法 (A quick way to try it)
Colab有料版(L4かA100)が必要ですが以下のColabで試す事ができます  
You need a paid version of Colab (L4 or A100), but you can try it out with the following Colab  
[C3TR_Adapter_hqq_v2_Paid_Colab_sample](https://github.com/webbigdata-jp/python_sample/blob/main/C3TR_Adapter_hqq_v2_Paid_Colab_sample.ipynb)

### install 
[hqq](https://github.com/mobiusml/hqq)の公式サイトをご確認下さい  
Check official [hqq](https://github.com/mobiusml/hqq)  

私はソースからhqqをインストール( pip install git+https://github.com/mobiusml/hqq.git ではなくてローカルにclone)しないと動かす事ができませんでした。  
I couldn't get it to work without installing hqq from source(Not pip install git+https://github.com/mobiusml/hqq.git ).  

A100や30x0シリーズのような新しいGPUが必要です。  
残念ながらColabの無料版(T4)では動きません  

We need Newer GPUs such as the A100 and 30x0 series.
Unfortunately, this does not work with the free version of Colab(T4).  

```
# transformers 4.41.1
pip install transformers==4.41.1

# hqq 0.1.7.post2
git clone https://github.com/mobiusml/hqq
cd hqq
pip install .
```

### Sample code
```
from transformers import AutoModelForCausalLM, AutoTokenizer
from hqq.models.hf.base import AutoHQQHFModel

model_id = ""webbigdata/C3TR-Adapter_hqq""
model = AutoHQQHFModel.from_quantized(model_id)
tokenizer = AutoTokenizer.from_pretrained(model_id)

prompt_text = """"""You are a highly skilled professional Japanese-English and English-Japanese translator. Translate the given text accurately, taking into account the context and specific instructions provided. Steps may include hints enclosed in square brackets [] with the key and value separated by a colon:. Only when the subject is specified in the Japanese sentence, the subject will be added when translating into English. If no additional instructions or context are provided, use your expertise to consider what the most appropriate context is and provide a natural translation that aligns with that context. When translating, strive to faithfully reflect the meaning and tone of the original text, pay attention to cultural nuances and differences in language usage, and ensure that the translation is grammatically correct and easy to read. After completing the translation, review it once more to check for errors or unnatural expressions. For technical terms and proper nouns, either leave them in the original language or use appropriate translations as necessary. Take a deep breath, calm down, and start translating.

### Instruction:
Translate Japanese to English.
When translating, please use the following hints:
[writeing_style: formal]
[岡浩: Hiroshi Oka]
[植草泰彦: Yasuhiko Uekusa]

### Input:
5月20日（現地時間同日）、エジプト・アラブ共和国の首都カイロにおいて、岡浩駐エジプト日本国特命全権大使、植草泰彦内閣府国際平和協力本部事務局参事官及びサハル・アル・ジョブリー国連パレスチナ難民救済事業機関（UNRWA）カイロ事務所長（Ms. Sahar Al Jobury, Chief, the United Nations Relief and Works Agency for Palestine Refugees in the Near East (UNRWA) Representative Office in Cairo）の列席のもと、UNRWAに対して提供する物資の供与式を実施しました。

　スリーピングマット等の支援物資は、18日（現地時間17日）、アラブ首長国連邦の備蓄倉庫からエジプトのエルアリーシュ空港に到着し、
今後、エジプト赤新月社の協力を得てガザ地区まで輸送され、パレスチナ被災民のために活用されます。

（参考）UNRWAによるパレスチナ被災民支援活動に対する物資協力
概要
　パレスチナ暫定自治区であるガザ地区において人道的な国際救援活動を行っている国際連合パレスチナ難民救済事業機関（UNRWA）に対し、国際平和協力法に基づき、先方から依頼のあった物資を提供する。
提供物資
　内閣府が人道支援のためにドバイに備蓄している以下の物資を提供。
毛布 5,000枚
給水容器 10,000個
ビニールシート 4,500枚
スリーピングマット 8,500枚

### Response:
""""""

tokens = tokenizer(prompt_text, return_tensors=""pt"",
        padding=True, max_length=1600, truncation=True).to(""cuda:0"").input_ids

output = model.generate(
        input_ids=tokens,
        max_new_tokens=800,
        do_sample=True,
        num_beams=3, temperature=0.5, top_p=0.3,
        repetition_penalty=1.0)
print(tokenizer.decode(output[0]))

```

出力(Output)
```
### Response:
On May 20 (local time), H.E. Mr. Hiroshi Oka, Ambassador Extraordinary and Plenipotentiary of Japan to the Arab Republic of Egypt, Mr. Yasuhiko Uekusa, Counsellor, International Cooperation Bureau, Cabinet Office, and Ms. Sahar Al Jobury, Chief, the United Nations Relief and Works Agency for Palestine Refugees in the Near East (UNRWA) Representative Office in Cairo, attended the handover ceremony of relief supplies to be provided to UNRWA.

The relief supplies such as sleeping mats were received on May 18 (local time, May 17) at El Arish Airport in the Arab Republic of Egypt from a warehouse in the United Arab Emirates. The supplies will be transported to the Gaza Strip with the cooperation of the Egyptian Red Crescent Society and will be utilized for Palestinian refugees.

(Reference) Provision of Relief Supplies to UNRWA for Assistance to Palestinian Refugees
Overview
Based on the International Cooperation Law, Japan will provide relief supplies to the United Nations Relief and Works Agency for Palestine Refugees in the Near East (UNRWA), which is conducting humanitarian international relief activities in the Gaza Strip, Palestinian Territory.
Relief Supplies
The following relief supplies stored in Dubai for humanitarian assistance will be provided:
Blankets: 5,000 pieces
Water containers: 10,000 pieces
Plastic sheets: 4,500 pieces
Sleeping mats: 8,500 pieces<eos>
```

### Sample code for High-speed inference (For NVIDIA Ampere or later, A100 or RTX 3090, etc.)


```
import torch, os
from hqq.engine.hf import AutoTokenizer
from hqq.core.quantize import *
from hqq.utils.patching import *
from hqq.models.hf.base import AutoHQQHFModel

model_id = ""webbigdata/C3TR-Adapter_hqq""
os.environ[""TOKENIZERS_PARALLELISM""]  = ""1""
torch.backends.cuda.matmul.allow_tf32 = True
torch.backends.cudnn.allow_tf32       = True

compute_dtype = torch.bfloat16
model     = AutoHQQHFModel.from_quantized(model_id, compute_dtype=compute_dtype)
tokenizer = AutoTokenizer.from_pretrained(model_id)

patch_linearlayers(model, patch_add_quant_config,
                          BaseQuantizeConfig(nbits=4, group_size=64, quant_scale=False, quant_zero=False, axis=1))
HQQLinear.set_backend(HQQBackend.PYTORCH)

from hqq.utils.patching import prepare_for_inference
prepare_for_inference(model, backend=""torchao_int4"")

prompt_text = """"""You are a highly skilled professional Japanese-English and English-Japanese translator. Translate the given text accurately, taking into account the context and specific instructions provided. Steps may include hints enclosed in square brackets [] with the key and value separated by a colon:. Only when the subject is specified in the Japanese sentence, the subject will be added when translating into English. If no additional instructions or context are provided, use your expertise to consider what the most appropriate context is and provide a natural translation that aligns with that context. When translating, strive to faithfully reflect the meaning and tone of the original text, pay attention to cultural nuances and differences in language usage, and ensure that the translation is grammatically correct and easy to read. After completing the translation, review it once more to check for errors or unnatural expressions. For technical terms and proper nouns, either leave them in the original language or use appropriate translations as necessary. Take a deep breath, calm down, and start translating.

### Instruction:
Translate Japanese to English.
When translating, please use the following hints:
[writeing_style: formal]
[米津玄師: Kenshi YONEZU]
[吉野源三郎: Genzaburo YOSHINO]

### Input:
「私自身、訳が分からない」
「おそらく、訳が分からなかったことでしょう。私自身、訳が分からないところがありました」。

　2023年2月下旬、東京都内のスタジオで上映された、「君たちはどう生きるか」の初号試写。米津玄師の歌うピアノバラードが流れ、エンド
ロールが終わった瞬間、灯りが点き、宮崎駿監督のコメントが読み上げられた。

　客席から軽い笑い声が漏れた。私もその一人だった。あまりの展開の速さと、盛り込むだけ盛り込まれた情報を消化しきれず、茫然と座り>込んでいたが、その言葉で我に返った。

　これは「宮崎アニメ」の集大成なのか、吉野源三郎の著書『君たちはどう生きるか』の再解釈なのか。とにかく、1回見ただけではとても全容を把握できなかった。

「自分のことをやるしかない」
　今回の作品は、公開前のプロモーションも、メディア関係者向けの試写も一切ないまま公開日を迎えた。異例の態勢の中、内容は無論、見たことすら口外無用のキャスト・スタッフ向け試写に、なぜ私と両親が呼ばれたのかといえば、父が『君たちはどう生きるか』の著者・吉野源三郎の長男で、私が孫にあたるからだ。

　その5年ほど前の2017年11月、父と私は東京・小金井のスタジオジブリに招かれ、宮崎監督と対面していた。さらにさかのぼること半月ほど前、とあるイベントで宮崎監督が突然、次回作のタイトルが「君たちはどう生きるか」だと明らかにし、ニュースなどで話題になっていた。親族としては寝耳に水だったのでかなり驚いたのだが、宮崎監督は「うっかり喋ってしまいました」と詫びた上で、作品について語り始めた。

### Response:
""""""

tokens = tokenizer(prompt_text, return_tensors=""pt"",
        padding=True, max_length=1600, truncation=True).to(""cuda:0"").input_ids

output = model.generate(
        input_ids=tokens,
        max_new_tokens=800,
        do_sample=True,
        num_beams=3, temperature=0.5, top_p=0.3,
        repetition_penalty=1.0)
print(tokenizer.decode(output[0]))

```

### See also

詳細は[C3TR-Adapter](https://huggingface.co/webbigdata/C3TR-Adapter)を見てください  
See also [C3TR-Adapter](https://huggingface.co/webbigdata/C3TR-Adapter)","{""id"": ""webbigdata/C3TR-Adapter_hqq"", ""author"": ""webbigdata"", ""sha"": ""fa774a33b191b007ad74df781c23d183665aeb1b"", ""last_modified"": ""2024-05-24 07:34:44+00:00"", ""created_at"": ""2024-05-22 10:05:18+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""gptq"", ""gguf"": null, ""inference"": null, ""tags"": [""gptq"", ""gemma"", ""translation"", ""hqq"", ""text-generation-inference"", ""nlp"", ""ja"", ""en"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""region:us""], ""pipeline_tag"": ""translation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\nlanguage:\n- ja\n- en\nlibrary_name: gptq\ntags:\n- translation\n- hqq\n- gemma\n- text-generation-inference\n- nlp"", ""widget_data"": null, ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": null, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='qmodel.pt', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2024-05-24 07:34:44+00:00"", ""cardData"": ""base_model: google/gemma-7b\nlanguage:\n- ja\n- en\nlibrary_name: gptq\ntags:\n- translation\n- hqq\n- gemma\n- text-generation-inference\n- nlp"", ""transformersInfo"": null, ""_id"": ""664dc35e97e1ce6fb7e95bb1"", ""modelId"": ""webbigdata/C3TR-Adapter_hqq"", ""usedStorage"": 5937651691}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=webbigdata/C3TR-Adapter_hqq&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bwebbigdata%2FC3TR-Adapter_hqq%5D(%2Fwebbigdata%2FC3TR-Adapter_hqq)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
yimingzhang/zephyr-7b-gemma-sft,"---
license: gemma
base_model: google/gemma-7b
tags:
- alignment-handbook
- trl
- sft
- generated_from_trainer
- trl
- sft
- generated_from_trainer
datasets:
- yimingzhang/backtrack-0522
model-index:
- name: zephyr-7b-gemma-sft
  results: []
---

<!-- This model card has been generated automatically according to the information the Trainer had access to. You
should probably proofread and complete it, then remove this comment. -->

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""200"" height=""32""/>](https://wandb.ai/wandbruh/huggingface/runs/mmxq7ysi)
# zephyr-7b-gemma-sft

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the yimingzhang/backtrack-0522 dataset.
It achieves the following results on the evaluation set:
- Loss: 24.1747

## Model description

More information needed

## Intended uses & limitations

More information needed

## Training and evaluation data

More information needed

## Training procedure

### Training hyperparameters

The following hyperparameters were used during training:
- learning_rate: 2e-05
- train_batch_size: 4
- eval_batch_size: 4
- seed: 42
- distributed_type: multi-GPU
- num_devices: 8
- gradient_accumulation_steps: 4
- total_train_batch_size: 128
- total_eval_batch_size: 32
- optimizer: Adam with betas=(0.9,0.999) and epsilon=1e-08
- lr_scheduler_type: cosine
- lr_scheduler_warmup_ratio: 0.1
- num_epochs: 3

### Training results

| Training Loss | Epoch  | Step | Validation Loss |
|:-------------:|:------:|:----:|:---------------:|
| 63.281        | 0.8571 | 3    | 31.5271         |
| 53.5176       | 2.0    | 7    | 24.9493         |
| 53.5176       | 2.5714 | 9    | 24.1747         |


### Framework versions

- Transformers 4.41.0
- Pytorch 2.3.0+cu121
- Datasets 2.19.1
- Tokenizers 0.19.1
","{""id"": ""yimingzhang/zephyr-7b-gemma-sft"", ""author"": ""yimingzhang"", ""sha"": ""36ce9fb674391e5f19370a0ecf3f445344b153c1"", ""last_modified"": ""2024-05-23 02:11:30+00:00"", ""created_at"": ""2024-05-23 02:02:41+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 7, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""alignment-handbook"", ""trl"", ""sft"", ""generated_from_trainer"", ""conversational"", ""dataset:yimingzhang/backtrack-0522"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""license:gemma"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- yimingzhang/backtrack-0522\nlicense: gemma\ntags:\n- alignment-handbook\n- trl\n- sft\n- generated_from_trainer\nmodel-index:\n- name: zephyr-7b-gemma-sft\n  results: []"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": [{""name"": ""zephyr-7b-gemma-sft"", ""results"": []}], ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{% if messages[0]['role'] == 'user' or messages[0]['role'] == 'system' %}{{ bos_token }}{% endif %}{% for message in messages %}{{ '<|im_start|>' + message['role'] + '\n' + message['content'] + '<|im_end|>' + '\n' }}{% endfor %}{% if add_generation_prompt %}{{ '<|im_start|>assistant\n' }}{% elif messages[-1]['role'] == 'assistant' %}{{ eos_token }}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='eval_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='generation_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00001-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00002-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00003-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00004-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model.safetensors.index.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/May23_02-00-16_a100-st-p4de24xlarge-67/events.out.tfevents.1716429766.a100-st-p4de24xlarge-67.3476955.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/May23_02-00-16_a100-st-p4de24xlarge-67/events.out.tfevents.1716430192.a100-st-p4de24xlarge-67.3476955.1', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": {""parameters"": {""BF16"": 8537680896}, ""total"": 8537680896}, ""security_repo_status"": null, ""lastModified"": ""2024-05-23 02:11:30+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- yimingzhang/backtrack-0522\nlicense: gemma\ntags:\n- alignment-handbook\n- trl\n- sft\n- generated_from_trainer\nmodel-index:\n- name: zephyr-7b-gemma-sft\n  results: []"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""664ea3c1a6c4e3fc25f265fe"", ""modelId"": ""yimingzhang/zephyr-7b-gemma-sft"", ""usedStorage"": 17092882303}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=yimingzhang/zephyr-7b-gemma-sft&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Byimingzhang%2Fzephyr-7b-gemma-sft%5D(%2Fyimingzhang%2Fzephyr-7b-gemma-sft)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
yimingzhang/gemma-backtrack-0522,"---
license: gemma
base_model: google/gemma-7b
tags:
- alignment-handbook
- trl
- sft
- generated_from_trainer
- trl
- sft
- alignment-handbook
- generated_from_trainer
datasets:
- yimingzhang/backtrack-0522
model-index:
- name: gemma-backtrack-0522
  results: []
---

<!-- This model card has been generated automatically according to the information the Trainer had access to. You
should probably proofread and complete it, then remove this comment. -->

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""200"" height=""32""/>](https://wandb.ai/wandbruh/huggingface/runs/rbd699hg)
# gemma-backtrack-0522

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the yimingzhang/backtrack-0522 dataset.
It achieves the following results on the evaluation set:
- Loss: 24.1739

## Model description

More information needed

## Intended uses & limitations

More information needed

## Training and evaluation data

More information needed

## Training procedure

### Training hyperparameters

The following hyperparameters were used during training:
- learning_rate: 2e-05
- train_batch_size: 4
- eval_batch_size: 4
- seed: 42
- distributed_type: multi-GPU
- num_devices: 8
- gradient_accumulation_steps: 4
- total_train_batch_size: 128
- total_eval_batch_size: 32
- optimizer: Adam with betas=(0.9,0.999) and epsilon=1e-08
- lr_scheduler_type: cosine
- lr_scheduler_warmup_ratio: 0.1
- num_epochs: 3

### Training results

| Training Loss | Epoch  | Step | Validation Loss |
|:-------------:|:------:|:----:|:---------------:|
| 63.281        | 0.8571 | 3    | 31.5266         |
| 53.4745       | 2.0    | 7    | 24.9424         |
| 53.4745       | 2.5714 | 9    | 24.1739         |


### Framework versions

- Transformers 4.41.0
- Pytorch 2.3.0+cu121
- Datasets 2.19.1
- Tokenizers 0.19.1
","{""id"": ""yimingzhang/gemma-backtrack-0522"", ""author"": ""yimingzhang"", ""sha"": ""1d19bad7b1c07835b9d4dc01d16b14beb0311356"", ""last_modified"": ""2024-05-23 02:20:51+00:00"", ""created_at"": ""2024-05-23 02:12:21+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 7, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""alignment-handbook"", ""trl"", ""sft"", ""generated_from_trainer"", ""conversational"", ""dataset:yimingzhang/backtrack-0522"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""license:gemma"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- yimingzhang/backtrack-0522\nlicense: gemma\ntags:\n- alignment-handbook\n- trl\n- sft\n- generated_from_trainer\nmodel-index:\n- name: gemma-backtrack-0522\n  results: []"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": [{""name"": ""gemma-backtrack-0522"", ""results"": []}], ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{% if messages[0]['role'] == 'user' or messages[0]['role'] == 'system' %}{{ bos_token }}{% endif %}{% for message in messages %}{{ '<|im_start|>' + message['role'] + '\n' + message['content'] + '<|im_end|>' + '\n' }}{% endfor %}{% if add_generation_prompt %}{{ '<|im_start|>assistant\n' }}{% elif messages[-1]['role'] == 'assistant' %}{{ eos_token }}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='eval_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='generation_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00001-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00002-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00003-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00004-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model.safetensors.index.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/May23_02-00-16_a100-st-p4de24xlarge-67/events.out.tfevents.1716429766.a100-st-p4de24xlarge-67.3476955.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/May23_02-00-16_a100-st-p4de24xlarge-67/events.out.tfevents.1716430192.a100-st-p4de24xlarge-67.3476955.1', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/May23_02-12-02_a100-st-p4de24xlarge-67/events.out.tfevents.1716430346.a100-st-p4de24xlarge-67.3492810.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/May23_02-12-02_a100-st-p4de24xlarge-67/events.out.tfevents.1716430753.a100-st-p4de24xlarge-67.3492810.1', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": {""parameters"": {""BF16"": 8537680896}, ""total"": 8537680896}, ""security_repo_status"": null, ""lastModified"": ""2024-05-23 02:20:51+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- yimingzhang/backtrack-0522\nlicense: gemma\ntags:\n- alignment-handbook\n- trl\n- sft\n- generated_from_trainer\nmodel-index:\n- name: gemma-backtrack-0522\n  results: []"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""664ea605e4de44dd2860d7c5"", ""modelId"": ""yimingzhang/gemma-backtrack-0522"", ""usedStorage"": 17092889290}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=yimingzhang/gemma-backtrack-0522&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Byimingzhang%2Fgemma-backtrack-0522%5D(%2Fyimingzhang%2Fgemma-backtrack-0522)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
tanliboy/zephyr-7b-gemma-sft,"---
license: gemma
base_model: google/gemma-7b
tags:
- alignment-handbook
- trl
- sft
- generated_from_trainer
- trl
- sft
- generated_from_trainer
datasets:
- HuggingFaceH4/deita-10k-v0-sft
model-index:
- name: zephyr-7b-gemma-sft
  results: []
---

<!-- This model card has been generated automatically according to the information the Trainer had access to. You
should probably proofread and complete it, then remove this comment. -->

# zephyr-7b-gemma-sft

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the HuggingFaceH4/deita-10k-v0-sft dataset.
It achieves the following results on the evaluation set:
- Loss: 1.0814

## Model description

More information needed

## Intended uses & limitations

More information needed

## Training and evaluation data

More information needed

## Training procedure

### Training hyperparameters

The following hyperparameters were used during training:
- learning_rate: 2e-05
- train_batch_size: 4
- eval_batch_size: 4
- seed: 42
- distributed_type: multi-GPU
- num_devices: 8
- gradient_accumulation_steps: 4
- total_train_batch_size: 128
- total_eval_batch_size: 32
- optimizer: Adam with betas=(0.9,0.999) and epsilon=1e-08
- lr_scheduler_type: cosine
- lr_scheduler_warmup_ratio: 0.1
- num_epochs: 3

### Training results

| Training Loss | Epoch  | Step | Validation Loss |
|:-------------:|:------:|:----:|:---------------:|
| 0.9991        | 0.9983 | 299  | 1.1125          |
| 0.732         | 2.0    | 599  | 1.0251          |
| 0.4257        | 2.9950 | 897  | 1.0814          |


### Framework versions

- Transformers 4.40.2
- Pytorch 2.3.0+cu121
- Datasets 2.19.1
- Tokenizers 0.19.1
","{""id"": ""tanliboy/zephyr-7b-gemma-sft"", ""author"": ""tanliboy"", ""sha"": ""e0781b0c326dc8b2788c17b4eeb468d99674e88b"", ""last_modified"": ""2024-06-02 05:11:07+00:00"", ""created_at"": ""2024-06-02 01:42:51+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 3, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""safetensors"", ""gemma"", ""text-generation"", ""alignment-handbook"", ""trl"", ""sft"", ""generated_from_trainer"", ""conversational"", ""dataset:HuggingFaceH4/deita-10k-v0-sft"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""license:gemma"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- HuggingFaceH4/deita-10k-v0-sft\nlicense: gemma\ntags:\n- alignment-handbook\n- trl\n- sft\n- generated_from_trainer\nmodel-index:\n- name: zephyr-7b-gemma-sft\n  results: []"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": [{""name"": ""zephyr-7b-gemma-sft"", ""results"": []}], ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{% if messages[0]['role'] == 'user' or messages[0]['role'] == 'system' %}{{ bos_token }}{% endif %}{% for message in messages %}{{ '<|im_start|>' + message['role'] + '\n' + message['content'] + '<|im_end|>' + '\n' }}{% endfor %}{% if add_generation_prompt %}{{ '<|im_start|>assistant\n' }}{% elif messages[-1]['role'] == 'assistant' %}{{ eos_token }}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='eval_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='generation_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00001-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00002-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00003-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00004-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model.safetensors.index.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": {""parameters"": {""BF16"": 8537680896}, ""total"": 8537680896}, ""security_repo_status"": null, ""lastModified"": ""2024-06-02 05:11:07+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- HuggingFaceH4/deita-10k-v0-sft\nlicense: gemma\ntags:\n- alignment-handbook\n- trl\n- sft\n- generated_from_trainer\nmodel-index:\n- name: zephyr-7b-gemma-sft\n  results: []"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""665bce1b325b11b6fea6ba9a"", ""modelId"": ""tanliboy/zephyr-7b-gemma-sft"", ""usedStorage"": 17092875125}",1,https://huggingface.co/tanliboy/zephyr-7b-gemma-dpo,1,,0,,0,huggingface/InferenceSupport/discussions/new?title=tanliboy/zephyr-7b-gemma-sft&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Btanliboy%2Fzephyr-7b-gemma-sft%5D(%2Ftanliboy%2Fzephyr-7b-gemma-sft)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
tanliboy/zephyr-7b-gemma-dpo,"---
license: gemma
base_model: tanliboy/zephyr-7b-gemma-sft
tags:
- alignment-handbook
- trl
- dpo
- generated_from_trainer
- trl
- dpo
- generated_from_trainer
datasets:
- argilla/dpo-mix-7k
model-index:
- name: zephyr-7b-gemma-dpo
  results: []
---

<!-- This model card has been generated automatically according to the information the Trainer had access to. You
should probably proofread and complete it, then remove this comment. -->

# zephyr-7b-gemma-dpo

This model is a fine-tuned version of [tanliboy/zephyr-7b-gemma-sft](https://huggingface.co/tanliboy/zephyr-7b-gemma-sft) on the argilla/dpo-mix-7k dataset.
It achieves the following results on the evaluation set:
- Loss: 0.4833
- Rewards/chosen: -0.1121
- Rewards/rejected: -1.2301
- Rewards/accuracies: 0.7396
- Rewards/margins: 1.1180
- Logps/rejected: -719.5310
- Logps/chosen: -698.5295
- Logits/rejected: 153.0066
- Logits/chosen: 153.1078

## Model description

More information needed

## Intended uses & limitations

More information needed

## Training and evaluation data

More information needed

## Training procedure

### Training hyperparameters

The following hyperparameters were used during training:
- learning_rate: 5e-07
- train_batch_size: 2
- eval_batch_size: 4
- seed: 42
- distributed_type: multi-GPU
- num_devices: 8
- gradient_accumulation_steps: 8
- total_train_batch_size: 128
- total_eval_batch_size: 32
- optimizer: Adam with betas=(0.9,0.999) and epsilon=1e-08
- lr_scheduler_type: cosine
- lr_scheduler_warmup_ratio: 0.1
- num_epochs: 2

### Training results

| Training Loss | Epoch  | Step | Validation Loss | Rewards/chosen | Rewards/rejected | Rewards/accuracies | Rewards/margins | Logps/rejected | Logps/chosen | Logits/rejected | Logits/chosen |
|:-------------:|:------:|:----:|:---------------:|:--------------:|:----------------:|:------------------:|:---------------:|:--------------:|:------------:|:---------------:|:-------------:|
| 0.1424        | 1.8957 | 100  | 0.4722          | -0.0658        | -1.2673          | 0.7396             | 1.2015          | -720.2745      | -697.6023    | 152.9660        | 153.1356      |


### Framework versions

- Transformers 4.40.2
- Pytorch 2.3.0+cu121
- Datasets 2.19.1
- Tokenizers 0.19.1
","{""id"": ""tanliboy/zephyr-7b-gemma-dpo"", ""author"": ""tanliboy"", ""sha"": ""1136f5aa5eccaa12e5c973d6c88c66531dffdcbb"", ""last_modified"": ""2024-06-02 17:26:53+00:00"", ""created_at"": ""2024-06-02 06:17:14+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 3, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""safetensors"", ""gemma"", ""text-generation"", ""alignment-handbook"", ""trl"", ""dpo"", ""generated_from_trainer"", ""conversational"", ""dataset:argilla/dpo-mix-7k"", ""base_model:tanliboy/zephyr-7b-gemma-sft"", ""base_model:finetune:tanliboy/zephyr-7b-gemma-sft"", ""license:gemma"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: tanliboy/zephyr-7b-gemma-sft\ndatasets:\n- argilla/dpo-mix-7k\nlicense: gemma\ntags:\n- alignment-handbook\n- trl\n- dpo\n- generated_from_trainer\nmodel-index:\n- name: zephyr-7b-gemma-dpo\n  results: []"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": [{""name"": ""zephyr-7b-gemma-dpo"", ""results"": []}], ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{% if messages[0]['role'] == 'user' or messages[0]['role'] == 'system' %}{{ bos_token }}{% endif %}{% for message in messages %}{{ '<|im_start|>' + message['role'] + '\n' + message['content'] + '<|im_end|>' + '\n' }}{% endfor %}{% if add_generation_prompt %}{{ '<|im_start|>assistant\n' }}{% elif messages[-1]['role'] == 'assistant' %}{{ eos_token }}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='eval_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='generation_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00001-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00002-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00003-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00004-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model.safetensors.index.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": {""parameters"": {""BF16"": 8537680896}, ""total"": 8537680896}, ""security_repo_status"": null, ""lastModified"": ""2024-06-02 17:26:53+00:00"", ""cardData"": ""base_model: tanliboy/zephyr-7b-gemma-sft\ndatasets:\n- argilla/dpo-mix-7k\nlicense: gemma\ntags:\n- alignment-handbook\n- trl\n- dpo\n- generated_from_trainer\nmodel-index:\n- name: zephyr-7b-gemma-dpo\n  results: []"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""665c0e6a0a6a819676067007"", ""modelId"": ""tanliboy/zephyr-7b-gemma-dpo"", ""usedStorage"": 34168272749}",2,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=tanliboy/zephyr-7b-gemma-dpo&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Btanliboy%2Fzephyr-7b-gemma-dpo%5D(%2Ftanliboy%2Fzephyr-7b-gemma-dpo)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
Eteims/gemma_ft_quote,"---
license: gemma
library_name: transformers
tags:
- sft
- generated_from_trainer
base_model: google/gemma-7b
model-index:
- name: gemma_ft_quote
  results: []
pipeline_tag: text-generation
datasets:
- Abirate/english_quotes
language:
- en
widget:
- text: 'Quote: With great power comes'
  example_title: Example 1
- text: 'Quote: Hasta la vista baby'
  example_title: Example 2
- text: 'Quote: Elementary, my dear watson.'
  example_title: Example 3
---

<!-- This model card has been generated automatically according to the information the Trainer had access to. You
should probably proofread and complete it, then remove this comment. -->

# Gemma_ft_Quote

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [english quote](https://huggingface.co/datasets/Abirate/english_quotes) dataset using [LoRA](https://arxiv.org/abs/2106.09685).
It is based on the example provided by google [here](https://huggingface.co/google/gemma-7b/blob/main/examples/notebook_sft_peft.ipynb).
The notebook used to fine-tune the model can be found [here](https://colab.research.google.com/drive/1OMvXuK77X7yxofrhQHERUkrn3NZORXFp?usp=sharing)


## Model description

The model can complete popular quotes given to it and add the author of the quote. For example, Given the qoute below:

```
Quote: With great power comes
```

The model would complete the quote and add the author of the quote:

```
Quote: With great power comes great responsibility. Author: Ben Parker.
```

Given a complete Quoute the model would add the author:

```
Quote: I'll be back. Author: Arnold Schwarzenegger.
```

## Usage

The model can be used with [transformers](https://huggingface.co/docs/transformers/en/index) library. Here's an example of loading the model
in 4 bit quantization mode:

```python
import torch
from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig

model_id = ""Eteims/gemma_ft_quote""
bnb_config = BitsAndBytesConfig(
    load_in_4bit=True,
    bnb_4bit_quant_type=""nf4"",
    bnb_4bit_compute_dtype=torch.bfloat16
)

tokenizer = AutoTokenizer.from_pretrained(model_id)
model = AutoModelForCausalLM.from_pretrained(model_id, quantization_config=bnb_config, device_map=""cuda:0"")
```

This code would easily run in a free colab tier.

After loading the model you can use it for inference:

```python
text = ""Quote: Elementary, my dear watson.""
device = ""cuda:0""
inputs = tokenizer(text, return_tensors=""pt"").to(device)

outputs = model.generate(**inputs, max_new_tokens=20)
print(tokenizer.decode(outputs[0], skip_special_tokens=True))
```

### Training hyperparameters

The following hyperparameters were used during fine-tuning:
- learning_rate: 0.0002
- train_batch_size: 1
- eval_batch_size: 8
- seed: 42
- gradient_accumulation_steps: 4
- total_train_batch_size: 4
- optimizer: Adam with betas=(0.9,0.999) and epsilon=1e-08
- lr_scheduler_type: linear
- lr_scheduler_warmup_steps: 2
- training_steps: 10
- mixed_precision_training: Native AMP

### Framework versions

- PEFT 0.8.2
- Transformers 4.38.1
- Pytorch 2.3.0+cu121
- Datasets 2.17.0
- Tokenizers 0.15.2","{""id"": ""Eteims/gemma_ft_quote"", ""author"": ""Eteims"", ""sha"": ""71317bd94bcca07a0e4d870a8abb75cbd456c781"", ""last_modified"": ""2024-06-07 17:32:13+00:00"", ""created_at"": ""2024-06-02 09:45:23+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""sft"", ""generated_from_trainer"", ""text-generation"", ""en"", ""dataset:Abirate/english_quotes"", ""arxiv:2106.09685"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""license:gemma"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- Abirate/english_quotes\nlanguage:\n- en\nlibrary_name: transformers\nlicense: gemma\npipeline_tag: text-generation\ntags:\n- sft\n- generated_from_trainer\nwidget:\n- text: 'Quote: With great power comes'\n  example_title: Example 1\n- text: 'Quote: Hasta la vista baby'\n  example_title: Example 2\n- text: 'Quote: Elementary, my dear watson.'\n  example_title: Example 3\nmodel-index:\n- name: gemma_ft_quote\n  results: []"", ""widget_data"": [{""text"": ""Quote: With great power comes"", ""example_title"": ""Example 1""}, {""text"": ""Quote: Hasta la vista baby"", ""example_title"": ""Example 2""}, {""text"": ""Quote: Elementary, my dear watson."", ""example_title"": ""Example 3""}], ""model_index"": [{""name"": ""gemma_ft_quote"", ""results"": []}], ""config"": {""tokenizer_config"": {""bos_token"": ""<bos>"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModel"", ""custom_class"": null, ""pipeline_tag"": null, ""processor"": null}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jun06_22-36-29_cf59e3c2dc4d/events.out.tfevents.1717713394.cf59e3c2dc4d.612.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2024-06-07 17:32:13+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- Abirate/english_quotes\nlanguage:\n- en\nlibrary_name: transformers\nlicense: gemma\npipeline_tag: text-generation\ntags:\n- sft\n- generated_from_trainer\nwidget:\n- text: 'Quote: With great power comes'\n  example_title: Example 1\n- text: 'Quote: Hasta la vista baby'\n  example_title: Example 2\n- text: 'Quote: Elementary, my dear watson.'\n  example_title: Example 3\nmodel-index:\n- name: gemma_ft_quote\n  results: []"", ""transformersInfo"": {""auto_model"": ""AutoModel"", ""custom_class"": null, ""pipeline_tag"": null, ""processor"": null}, ""_id"": ""665c3f330f35c005de06a218"", ""modelId"": ""Eteims/gemma_ft_quote"", ""usedStorage"": 121831623}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=Eteims/gemma_ft_quote&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5BEteims%2Fgemma_ft_quote%5D(%2FEteims%2Fgemma_ft_quote)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
OpenLLM-Ro/RoGemma-7b-Instruct-2024-06-28,"---
license: cc-by-nc-4.0
language:
- ro
base_model:
- google/gemma-7b
datasets:
- OpenLLM-Ro/ro_sft_alpaca
- OpenLLM-Ro/ro_sft_alpaca_gpt4
- OpenLLM-Ro/ro_sft_dolly
- OpenLLM-Ro/ro_sft_selfinstruct_gpt4
- OpenLLM-Ro/ro_sft_norobots
- OpenLLM-Ro/ro_sft_orca
- OpenLLM-Ro/ro_sft_camel
model-index:
    - name: OpenLLM-Ro/RoGemma-7b-Instruct-2024-06-28
      results:
        - task:
            type: text-generation
          dataset:
            name: RoMT-Bench
            type: RoMT-Bench
          metrics:
            - name: Score
              type: Score
              value: 5.26
        - task:
            type: text-generation
          dataset:
            name: RoCulturaBench
            type: RoCulturaBench
          metrics:
            - name: Score
              type: Score
              value: 3.26
        - task:
            type: text-generation
          dataset:
            name: Romanian_Academic_Benchmarks
            type: Romanian_Academic_Benchmarks
          metrics:
            - name: Average accuracy
              type: accuracy
              value: 53.41
        - task:
            type: text-generation
          dataset:
            name: OpenLLM-Ro/ro_arc_challenge
            type: OpenLLM-Ro/ro_arc_challenge
          metrics:
            - name: Average accuracy
              type: accuracy
              value: 52.44
        - task:
            type: text-generation
          dataset:
            name: OpenLLM-Ro/ro_mmlu
            type: OpenLLM-Ro/ro_mmlu
          metrics:
            - name: Average accuracy
              type: accuracy
              value: 54.44
        - task:
            type: text-generation
          dataset:
            name: OpenLLM-Ro/ro_winogrande
            type: OpenLLM-Ro/ro_winogrande
          metrics:
            - name: Average accuracy
              type: accuracy
              value: 69.36
        - task:
            type: text-generation
          dataset:
            name: OpenLLM-Ro/ro_hellaswag
            type: OpenLLM-Ro/ro_hellaswag
          metrics:
            - name: Average accuracy
              type: accuracy
              value: 61.96
        - task:
            type: text-generation
          dataset:
            name: OpenLLM-Ro/ro_gsm8k
            type: OpenLLM-Ro/ro_gsm8k
          metrics:
            - name: Average accuracy
              type: accuracy
              value: 31.06
        - task:
            type: text-generation
          dataset:
            name: OpenLLM-Ro/ro_truthfulqa
            type: OpenLLM-Ro/ro_truthfulqa
          metrics:
            - name: Average accuracy
              type: accuracy
              value: 51.23
        - task:
            type: text-generation
          dataset:
            name: LaRoSeDa_binary
            type: LaRoSeDa_binary
          metrics:
            - name: Average macro-f1
              type: macro-f1
              value: 97.86
        - task:
            type: text-generation
          dataset:
            name: LaRoSeDa_multiclass
            type: LaRoSeDa_multiclass
          metrics:
            - name: Average macro-f1
              type: macro-f1
              value: 65.70
        - task:
            type: text-generation
          dataset:
            name: LaRoSeDa_binary_finetuned
            type: LaRoSeDa_binary_finetuned
          metrics:
            - name: Average macro-f1
              type: macro-f1
              value: 98.43
        - task:
            type: text-generation
          dataset:
            name: LaRoSeDa_multiclass_finetuned
            type: LaRoSeDa_multiclass_finetuned
          metrics:
            - name: Average macro-f1
              type: macro-f1
              value: 87.17
        - task:
            type: text-generation
          dataset:
            name: WMT_EN-RO
            type: WMT_EN-RO
          metrics:
            - name: Average bleu
              type: bleu
              value: 27.91
        - task:
            type: text-generation
          dataset:
            name: WMT_RO-EN
            type: WMT_RO-EN
          metrics:
            - name: Average bleu
              type: bleu
              value: 23.08
        - task:
            type: text-generation
          dataset:
            name: WMT_EN-RO_finetuned
            type: WMT_EN-RO_finetuned
          metrics:
            - name: Average bleu
              type: bleu
              value: 27.99
        - task:
            type: text-generation
          dataset:
            name: WMT_RO-EN_finetuned
            type: WMT_RO-EN_finetuned
          metrics:
            - name: Average bleu
              type: bleu
              value: 39.51
        - task:
            type: text-generation
          dataset:
            name: XQuAD
            type: XQuAD
          metrics:
            - name: Average exact_match
              type: exact_match
              value: 17.75
        - task:
            type: text-generation
          dataset:
            name: XQuAD
            type: XQuAD
          metrics:
            - name: Average f1
              type: f1
              value: 28.11
        - task:
            type: text-generation
          dataset:
            name: XQuAD_finetuned
            type: XQuAD_finetuned
          metrics:
            - name: Average exact_match
              type: exact_match
              value: 52.02
        - task:
            type: text-generation
          dataset:
            name: XQuAD_finetuned
            type: XQuAD_finetuned
          metrics:
            - name: Average f1
              type: f1
              value: 68.43
        - task:
            type: text-generation
          dataset:
            name: STS
            type: STS
          metrics:
            - name: Average spearman
              type: spearman
              value: 73.96
        - task:
            type: text-generation
          dataset:
            name: STS
            type: STS
          metrics:
            - name: Average pearson
              type: pearson
              value: 75.16
        - task:
            type: text-generation
          dataset:
            name: STS_finetuned
            type: STS_finetuned
          metrics:
            - name: Average spearman
              type: spearman
              value: 86.45
        - task:
            type: text-generation
          dataset:
            name: STS_finetuned
            type: STS_finetuned
          metrics:
            - name: Average pearson
              type: pearson
              value: 86.31
        - task:
            type: text-generation
          dataset:
            name: RoMT-Bench
            type: RoMT-Bench
          metrics:
            - name: First turn
              type: Score
              value: 5.92
            - name: Second turn
              type: Score
              value: 4.60
        - task:
            type: text-generation
          dataset:
            name: OpenLLM-Ro/ro_arc_challenge
            type: OpenLLM-Ro/ro_arc_challenge
          metrics:
            - name: 0-shot 
              type: accuracy
              value: 50.30
            - name: 1-shot 
              type: accuracy
              value: 50.90
            - name: 3-shot 
              type: accuracy
              value: 52.53
            - name: 5-shot 
              type: accuracy
              value: 53.30
            - name: 10-shot 
              type: accuracy
              value: 54.33
            - name: 25-shot 
              type: accuracy
              value: 53.30
        - task:
            type: text-generation
          dataset:
            name: OpenLLM-Ro/ro_mmlu
            type: OpenLLM-Ro/ro_mmlu
          metrics:
            - name: 0-shot 
              type: accuracy
              value: 54.95
            - name: 1-shot 
              type: accuracy
              value: 54.01
            - name: 3-shot 
              type: accuracy
              value: 54.03
            - name: 5-shot 
              type: accuracy
              value: 54.76
        - task:
            type: text-generation
          dataset:
            name: OpenLLM-Ro/ro_winogrande
            type: OpenLLM-Ro/ro_winogrande
          metrics:
            - name: 0-shot 
              type: accuracy
              value: 68.67
            - name: 1-shot 
              type: accuracy
              value: 69.46
            - name: 3-shot 
              type: accuracy
              value: 68.43
            - name: 5-shot 
              type: accuracy
              value: 70.88
        - task:
            type: text-generation
          dataset:
            name: OpenLLM-Ro/ro_hellaswag
            type: OpenLLM-Ro/ro_hellaswag
          metrics:
            - name: 0-shot 
              type: accuracy
              value: 61.54
            - name: 1-shot 
              type: accuracy
              value: 61.54
            - name: 3-shot 
              type: accuracy
              value: 62.08
            - name: 5-shot 
              type: accuracy
              value: 62.12
            - name: 10-shot 
              type: accuracy
              value: 62.51
        - task:
            type: text-generation
          dataset:
            name: OpenLLM-Ro/ro_gsm8k
            type: OpenLLM-Ro/ro_gsm8k
          metrics:
            - name: 1-shot 
              type: accuracy
              value: 24.79
            - name: 3-shot 
              type: accuracy
              value: 34.50
            - name: 5-shot 
              type: accuracy
              value: 33.89
        - task:
            type: text-generation
          dataset:
            name: LaRoSeDa_binary
            type: LaRoSeDa_binary
          metrics:
            - name: 0-shot 
              type: macro-f1
              value: 97.60
            - name: 1-shot 
              type: macro-f1
              value: 97.23
            - name: 3-shot 
              type: macro-f1
              value: 98.13
            - name: 5-shot 
              type: macro-f1
              value: 98.50
        - task:
            type: text-generation
          dataset:
            name: LaRoSeDa_multiclass
            type: LaRoSeDa_multiclass
          metrics:
            - name: 0-shot 
              type: macro-f1
              value: 68.53
            - name: 1-shot 
              type: macro-f1
              value: 64.84
            - name: 3-shot 
              type: macro-f1
              value: 63.62
            - name: 5-shot 
              type: macro-f1
              value: 65.83
        - task:
            type: text-generation
          dataset:
            name: WMT_EN-RO
            type: WMT_EN-RO
          metrics:
            - name: 0-shot 
              type: bleu
              value: 25.04
            - name: 1-shot 
              type: bleu
              value: 28.43
            - name: 3-shot 
              type: bleu
              value: 28.87
            - name: 5-shot 
              type: bleu
              value: 29.28
        - task:
            type: text-generation
          dataset:
            name: WMT_RO-EN
            type: WMT_RO-EN
          metrics:
            - name: 0-shot 
              type: bleu
              value: 4.94
            - name: 1-shot 
              type: bleu
              value: 25.33
            - name: 3-shot 
              type: bleu
              value: 30.87
            - name: 5-shot 
              type: bleu
              value: 31.19
        - task:
            type: text-generation
          dataset:
            name: XQuAD_EM
            type: XQuAD_EM
          metrics:
            - name: 0-shot 
              type: exact_match
              value: 36.47
            - name: 1-shot 
              type: exact_match
              value: 26.22
            - name: 3-shot 
              type: exact_match
              value: 3.19
            - name: 5-shot 
              type: exact_match
              value: 5.13
        - task:
            type: text-generation
          dataset:
            name: XQuAD_F1
            type: XQuAD_F1
          metrics:
            - name: 0-shot 
              type: f1
              value: 56.83
            - name: 1-shot 
              type: f1
              value: 38.53
            - name: 3-shot 
              type: f1
              value: 6.88
            - name: 5-shot 
              type: f1
              value: 10.19
        - task:
            type: text-generation
          dataset:
            name: STS_Spearman
            type: STS_Spearman
          metrics:
            - name: 1-shot 
              type: spearman
              value: 70.61
            - name: 3-shot 
              type: spearman
              value: 73.53
            - name: 5-shot 
              type: spearman
              value: 77.73
        - task:
            type: text-generation
          dataset:
            name: STS_Pearson
            type: STS_Pearson
          metrics:
            - name: 1-shot 
              type: pearson
              value: 72.28
            - name: 3-shot 
              type: pearson
              value: 74.46
            - name: 5-shot 
              type: pearson
              value: 78.75

---

# Model Card for Model ID

<!-- Provide a quick summary of what the model is/does. -->

RoGemma is a family of pretrained and fine-tuned generative text models for Romanian. This is the repository for the **instruct 7B model**. Links to other models can be found at the bottom of this page.

## Model Details

### Model Description

<!-- Provide a longer summary of what this model is. -->
OpenLLM-Ro represents the first open-source effort to build a LLM specialized for Romanian. OpenLLM-Ro developed and publicly releases a collection of Romanian LLMs, both in the form of foundational model and instruct and chat variants.


- **Developed by:** OpenLLM-Ro
<!-- - **Funded by [optional]:** [More Information Needed] -->
<!-- - **Shared by [optional]:** [More Information Needed] -->
<!-- - **Model type:** [More Information Needed] -->
- **Language(s):** Romanian
- **License:** cc-by-nc-4.0
- **Finetuned from model:** [gemma-7b](https://huggingface.co/google/gemma-7b)
- **Trained using:** [RoAlpaca](https://huggingface.co/datasets/OpenLLM-Ro/ro_sft_alpaca), [RoAlpacaGPT4](https://huggingface.co/datasets/OpenLLM-Ro/ro_sft_alpaca_gpt4), [RoDolly](https://huggingface.co/datasets/OpenLLM-Ro/ro_sft_dolly), [RoSelfInstruct](https://huggingface.co/datasets/OpenLLM-Ro/ro_sft_selfinstruct_gpt4), [RoNoRobots](https://huggingface.co/datasets/OpenLLM-Ro/ro_sft_norobots), [RoOrca](https://huggingface.co/datasets/OpenLLM-Ro/ro_sft_orca), [RoCamel](https://huggingface.co/datasets/OpenLLM-Ro/ro_sft_camel).


### Model Sources

<!-- Provide the basic links for the model. -->

- **Repository:** https://github.com/OpenLLM-Ro/LLaMA-Factory
- **Paper:** https://arxiv.org/abs/2406.18266

## Intended Use

### Intended Use Cases

RoGemma is intented for research use in Romanian. Base models can be adapted for a variety of natural language tasks while instruction and chat tuned models are intended for assistant-like chat.

### Out-of-Scope Use

<!-- This section addresses misuse, malicious use, and uses that the model will not work well for. -->

Use in any manner that violates the license, any applicable laws or regluations, use in languages other than Romanian.



## How to Get Started with the Model

Use the code below to get started with the model.

```python
from transformers import AutoTokenizer, AutoModelForCausalLM

tokenizer = AutoTokenizer.from_pretrained(""OpenLLM-Ro/RoGemma-7b-Instruct-2024-06-28"")
model = AutoModelForCausalLM.from_pretrained(""OpenLLM-Ro/RoGemma-7b-Instruct-2024-06-28"")

instruction = ""Ce jocuri de societate pot juca cu prietenii mei?""
chat = [
        {""role"": ""user"", ""content"": instruction},
        ]
prompt = tokenizer.apply_chat_template(chat, tokenize=False, system_message="""")

inputs = tokenizer.encode(prompt, add_special_tokens=False, return_tensors=""pt"")
outputs = model.generate(input_ids=inputs, max_new_tokens=128)
print(tokenizer.decode(outputs[0]))
```

## Academic Benchmarks

<table>
<tbody>
<tr>
<td><strong>Model</strong></td>
<td><strong><center>Average</center></strong></td>
<td><strong><center>ARC</center></strong></td>
<td><strong><center>MMLU</center></strong></td>
<td><strong><center>Winogrande</center></strong></td>
<td><strong><center>Hellaswag</center></strong></td>
<td><strong><center>GSM8k</center></strong></td>
<td><strong><center>TruthfulQA</center></strong></td>
</tr>
<tr>
<td>gemma-1.1-7b-it</td><td><center>41.44</center></td><td><center>40.32</center></td><td><center>47.22</center></td><td><center>55.01</center></td><td><center>47.03</center></td><td><center>9.50</center></td><td><center>49.58</center></td>
</tr>
<tr>
<td><em>RoGemma-7b-Instruct-2024-06-28</em></td><td><center><em><strong>53.41</strong></em></center></td><td><center><em><strong>52.44</strong></em></center></td><td><center><em>54.44</em></center></td><td><center><em><strong>69.36</strong></em></center></td><td><center><em><strong>61.96</strong></em></center></td><td><center><em>31.06</em></center></td><td><center><em><strong>51.23</strong></em></center></td>
</tr>
<tr>
<td>RoGemma-7b-Instruct-2024-10-09</td><td><center>50.48</center></td><td><center>52.01</center></td><td><center>52.37</center></td><td><center>66.97</center></td><td><center>56.34</center></td><td><center>25.98</center></td><td><center>49.18</center></td>
</tr>
<tr>
<td>RoGemma-7b-Instruct-DPO-2024-10-09</td><td><center>48.27</center></td><td><center>46.66</center></td><td><center><strong>54.45</strong></center></td><td><center>63.73</center></td><td><center>49.33</center></td><td><center><strong>34.98</strong></center></td><td><center>40.45</center></td>
</tr>
</tbody>
</table>


## Downstream tasks

<table>
<tbody>
<tr>
<td></td>
<td colspan=""4""><center><strong>LaRoSeDa</strong></center></td>
<td colspan=""4""><center><strong>WMT</strong></center></td>
</tr>
<tr>
<td></td>
<td colspan=""2""><center><strong>Few-shot</strong></center></td>
<td colspan=""2""><center><strong>Finetuned</strong></center></td>
<td colspan=""2""><center><strong>Few-shot</strong></center></td>
<td colspan=""2""><center><strong>Finetuned</strong></center></td>
</tr>
<tr>
<td><strong>Model</strong></td>
<td><center><strong>Binary<br>(Macro F1)</strong></center></td>
<td><center><strong>Multiclass<br>(Macro F1)</strong></center></td>
<td><center><strong>Binary<br>(Macro F1)</strong></center></td>
<td><center><strong>Multiclass<br>(Macro F1)</strong></center></td>
<td><center><strong>EN-RO<br>(Bleu)</strong></center></td>
<td><center><strong>RO-EN<br>(Bleu)</strong></center></td>
<td><center><strong>EN-RO<br>(Bleu)</strong></center></td>
<td><center><strong>RO-EN<br>(Bleu)</strong></center>
</tr>
<tr>
<td>gemma-1.1-7b-it</td><td><center>87.54</center></td><td><center>51.48</center></td><td><center>83.87</center></td><td><center>85.61</center></td><td><center>17.96</center></td><td><center><strong>27.74</strong></center></td><td><center>25.48</center></td><td><center>36.11</center></td>
</tr>
<tr>
<td><em>RoGemma-7b-Instruct-2024-06-28</em></td><td><center><em><strong>97.86</strong></em></center></td><td><center><em><strong>65.70</strong></em></center></td><td><center><em>98.43</em></center></td><td><center><em><strong>87.17</strong></em></center></td><td><center><em><strong>27.91</strong></em></center></td><td><center><em>23.08</em></center></td><td><center><em><strong>27.99</strong></em></center></td><td><center><em><strong>39.51</strong></em></center></td>
</tr>
<tr>
<td>RoGemma-7b-Instruct-2024-10-09</td><td><center>86.96</center></td><td><center>56.72</center></td><td><center><strong>98.80</strong></center></td><td><center>85.81</center></td><td><center>24.45</center></td><td><center>14.20</center></td><td><center>25.96</center></td><td><center>39.07</center></td>
</tr>
<tr>
<td>RoGemma-7b-Instruct-DPO-2024-10-09</td><td><center>96.45</center></td><td><center>63.23</center></td><td><center>-</center></td><td><center>-</center></td><td><center>20.73</center></td><td><center>7.87</center></td><td><center>-</center></td><td><center>-</center></td>
</tr>
</tbody>
</table>


<table>
<tbody>
<tr>
<td></td>
<td colspan=""4""><center><strong>XQuAD</strong></center></td>
<td colspan=""4""><center><strong>STS</strong></center></td>
</tr>
<tr>
<td></td>
<td colspan=""2""><center><strong>Few-shot</strong></center></td>
<td colspan=""2""><center><strong>Finetuned</strong></center></td>
<td colspan=""2""><center><strong>Few-shot</strong></center></td>
<td colspan=""2""><center><strong>Finetuned</strong></center></td>
</tr>
<tr>
<td><strong>Model</strong></td>
<td><center><strong>(EM)</strong></center></td>
<td><center><strong>(F1)</strong></center></td>
<td><center><strong>(EM)</strong></center></td>
<td><center><strong>(F1)</strong></center></td>
<td><center><strong>(Spearman)</strong></center></td>
<td><center><strong>(Pearson)</strong></center></td>
<td><center><strong>(Spearman)</strong></center></td>
<td><center><strong>(Pearson)</strong></center></td>
</tr>
<tr>
<td>gemma-1.1-7b-it</td><td><center><strong>42.10</strong></center></td><td><center><strong>62.30</strong></center></td><td><center><strong>60.34</strong></center></td><td><center><strong>77.40</strong></center></td><td><center>49.10</center></td><td><center>50.23</center></td><td><center>83.43</center></td><td><center>83.64</center></td>
</tr>
<tr>
<td><em>RoGemma-7b-Instruct-2024-06-28</em></td><td><center><em>17.75</em></center></td><td><center><em>28.11</em></center></td><td><center><em>52.02</em></center></td><td><center><em>68.43</em></center></td><td><center><em><strong>73.96</strong></em></center></td><td><center><em><strong>75.16</strong></em></center></td><td><center><em>86.45</em></center></td><td><center><em>86.31</em></center></td>
</tr>
<tr>
<td>RoGemma-7b-Instruct-2024-10-09</td><td><center>26.03</center></td><td><center>41.58</center></td><td><center>46.72</center></td><td><center>60.79</center></td><td><center>73.23</center></td><td><center>71.58</center></td><td><center><strong>88.42</strong></center></td><td><center><strong>88.45</strong></center></td>
</tr>
<tr>
<td>RoGemma-7b-Instruct-DPO-2024-10-09</td><td><center>19.14</center></td><td><center>38.10</center></td><td><center>-</center></td><td><center>-</center></td><td><center>69.38</center></td><td><center>69.34</center></td><td><center>-</center></td><td><center>-</center></td>
</tr>
</tbody>
</table>


## MT-Bench

<table>
<tbody>
<tr>
<td><strong>Model</strong></td>
<td><strong><center>Average</center></strong></td>
<td><strong><center>1st turn</center></strong></td>
<td><strong><center>2nd turn</center></strong></td>
<td><strong><center>Answers in Ro</center></strong></td>
</tr>
<tr>
<td>gemma-1.1-7b-it</td><td><center>4.83</center></td><td><center>5.11</center></td><td><center>4.55</center></td><td><center><strong>160/160</strong></center></td>
</tr>
<tr>
<td><em>RoGemma-7b-Instruct-2024-06-28</em></td><td><center><em>5.26</em></center></td><td><center><em><strong>5.92</strong></em></center></td><td><center><em>4.60</em></center></td><td><center><em><strong>160/160</strong></em></center></td>
</tr>
<tr>
<td>RoGemma-7b-Instruct-2024-10-09</td><td><center>5.24</center></td><td><center>5.55</center></td><td><center>4.94</center></td><td><center><strong>160/160</strong></center></td>
</tr>
<tr>
<td>RoGemma-7b-Instruct-DPO-2024-10-09</td><td><center><strong>5.47</strong></center></td><td><center><strong>5.92</strong></center></td><td><center><strong>5.03</strong></center></td><td><center><strong>160/160</strong></center></td>
</tr>
</tbody>
</table>


## RoCulturaBench

<table>
<tbody>
<tr>
<td><strong>Model</strong></td>
<td><strong><center>Average</center></strong></td>
<td><strong><center>Answers in Ro</center></strong></td>
</tr>
<tr>
<td>gemma-1.1-7b-it</td><td><center>3.38</center></td><td><center><strong>100/100</strong></center></td>
</tr>
<tr>
<td><em>RoGemma-7b-Instruct-2024-06-28</em></td><td><center><em>3.26</em></center></td><td><center><em><strong>100/100</strong></em></center></td>
</tr>
<tr>
<td>RoGemma-7b-Instruct-2024-10-09</td><td><center>3.51</center></td><td><center><strong>100/100</strong></center></td>
</tr>
<tr>
<td>RoGemma-7b-Instruct-DPO-2024-10-09</td><td><center><strong>3.94</strong></center></td><td><center><strong>100/100</strong></center></td>
</tr>
</tbody>
</table>

## RoGemma Model Family

| Model              | Link  |
|--------------------|:--------:|
|*RoGemma-7b-Instruct-2024-06-28*| [link](https://huggingface.co/OpenLLM-Ro/RoGemma-7b-Instruct-2024-06-28) |
|RoGemma-7b-Instruct-2024-10-09| [link](https://huggingface.co/OpenLLM-Ro/RoGemma-7b-Instruct-2024-10-09) |
|RoGemma-7b-Instruct-DPO-2024-10-09| [link](https://huggingface.co/OpenLLM-Ro/RoGemma-7b-Instruct-DPO-2024-10-09) |


## Citation 

```
@misc{masala2024vorbecstiromanecsterecipetrain,
      title={""Vorbe\c{s}ti Rom\^ane\c{s}te?"" A Recipe to Train Powerful Romanian LLMs with English Instructions}, 
      author={Mihai Masala and Denis C. Ilie-Ablachim and Alexandru Dima and Dragos Corlatescu and Miruna Zavelca and Ovio Olaru and Simina Terian-Dan and Andrei Terian-Dan and Marius Leordeanu and Horia Velicu and Marius Popescu and Mihai Dascalu and Traian Rebedea},
      year={2024},
      eprint={2406.18266},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2406.18266}, 
}
```
<!-- **APA:**

[More Information Needed]  -->","{""id"": ""OpenLLM-Ro/RoGemma-7b-Instruct-2024-06-28"", ""author"": ""OpenLLM-Ro"", ""sha"": ""6047b0a61cd334ad7daba918642a495b7e0b3795"", ""last_modified"": ""2024-10-10 18:06:29+00:00"", ""created_at"": ""2024-06-06 13:30:35+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 3, ""downloads_all_time"": null, ""likes"": 1, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""safetensors"", ""gemma"", ""text-generation"", ""conversational"", ""ro"", ""dataset:OpenLLM-Ro/ro_sft_alpaca"", ""dataset:OpenLLM-Ro/ro_sft_alpaca_gpt4"", ""dataset:OpenLLM-Ro/ro_sft_dolly"", ""dataset:OpenLLM-Ro/ro_sft_selfinstruct_gpt4"", ""dataset:OpenLLM-Ro/ro_sft_norobots"", ""dataset:OpenLLM-Ro/ro_sft_orca"", ""dataset:OpenLLM-Ro/ro_sft_camel"", ""arxiv:2406.18266"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""license:cc-by-nc-4.0"", ""model-index"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model:\n- google/gemma-7b\ndatasets:\n- OpenLLM-Ro/ro_sft_alpaca\n- OpenLLM-Ro/ro_sft_alpaca_gpt4\n- OpenLLM-Ro/ro_sft_dolly\n- OpenLLM-Ro/ro_sft_selfinstruct_gpt4\n- OpenLLM-Ro/ro_sft_norobots\n- OpenLLM-Ro/ro_sft_orca\n- OpenLLM-Ro/ro_sft_camel\nlanguage:\n- ro\nlicense: cc-by-nc-4.0\nmodel-index:\n- name: OpenLLM-Ro/RoGemma-7b-Instruct-2024-06-28\n  results:\n  - task:\n      type: text-generation\n    dataset:\n      name: RoMT-Bench\n      type: RoMT-Bench\n    metrics:\n    - type: Score\n      value: 5.26\n      name: Score\n      verified: false\n    - type: Score\n      value: 5.92\n      name: First turn\n      verified: false\n    - type: Score\n      value: 4.6\n      name: Second turn\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: RoCulturaBench\n      type: RoCulturaBench\n    metrics:\n    - type: Score\n      value: 3.26\n      name: Score\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: Romanian_Academic_Benchmarks\n      type: Romanian_Academic_Benchmarks\n    metrics:\n    - type: accuracy\n      value: 53.41\n      name: Average accuracy\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: OpenLLM-Ro/ro_arc_challenge\n      type: OpenLLM-Ro/ro_arc_challenge\n    metrics:\n    - type: accuracy\n      value: 52.44\n      name: Average accuracy\n      verified: false\n    - type: accuracy\n      value: 50.3\n      name: 0-shot\n      verified: false\n    - type: accuracy\n      value: 50.9\n      name: 1-shot\n      verified: false\n    - type: accuracy\n      value: 52.53\n      name: 3-shot\n      verified: false\n    - type: accuracy\n      value: 53.3\n      name: 5-shot\n      verified: false\n    - type: accuracy\n      value: 54.33\n      name: 10-shot\n      verified: false\n    - type: accuracy\n      value: 53.3\n      name: 25-shot\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: OpenLLM-Ro/ro_mmlu\n      type: OpenLLM-Ro/ro_mmlu\n    metrics:\n    - type: accuracy\n      value: 54.44\n      name: Average accuracy\n      verified: false\n    - type: accuracy\n      value: 54.95\n      name: 0-shot\n      verified: false\n    - type: accuracy\n      value: 54.01\n      name: 1-shot\n      verified: false\n    - type: accuracy\n      value: 54.03\n      name: 3-shot\n      verified: false\n    - type: accuracy\n      value: 54.76\n      name: 5-shot\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: OpenLLM-Ro/ro_winogrande\n      type: OpenLLM-Ro/ro_winogrande\n    metrics:\n    - type: accuracy\n      value: 69.36\n      name: Average accuracy\n      verified: false\n    - type: accuracy\n      value: 68.67\n      name: 0-shot\n      verified: false\n    - type: accuracy\n      value: 69.46\n      name: 1-shot\n      verified: false\n    - type: accuracy\n      value: 68.43\n      name: 3-shot\n      verified: false\n    - type: accuracy\n      value: 70.88\n      name: 5-shot\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: OpenLLM-Ro/ro_hellaswag\n      type: OpenLLM-Ro/ro_hellaswag\n    metrics:\n    - type: accuracy\n      value: 61.96\n      name: Average accuracy\n      verified: false\n    - type: accuracy\n      value: 61.54\n      name: 0-shot\n      verified: false\n    - type: accuracy\n      value: 61.54\n      name: 1-shot\n      verified: false\n    - type: accuracy\n      value: 62.08\n      name: 3-shot\n      verified: false\n    - type: accuracy\n      value: 62.12\n      name: 5-shot\n      verified: false\n    - type: accuracy\n      value: 62.51\n      name: 10-shot\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: OpenLLM-Ro/ro_gsm8k\n      type: OpenLLM-Ro/ro_gsm8k\n    metrics:\n    - type: accuracy\n      value: 31.06\n      name: Average accuracy\n      verified: false\n    - type: accuracy\n      value: 24.79\n      name: 1-shot\n      verified: false\n    - type: accuracy\n      value: 34.5\n      name: 3-shot\n      verified: false\n    - type: accuracy\n      value: 33.89\n      name: 5-shot\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: OpenLLM-Ro/ro_truthfulqa\n      type: OpenLLM-Ro/ro_truthfulqa\n    metrics:\n    - type: accuracy\n      value: 51.23\n      name: Average accuracy\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: LaRoSeDa_binary\n      type: LaRoSeDa_binary\n    metrics:\n    - type: macro-f1\n      value: 97.86\n      name: Average macro-f1\n      verified: false\n    - type: macro-f1\n      value: 97.6\n      name: 0-shot\n      verified: false\n    - type: macro-f1\n      value: 97.23\n      name: 1-shot\n      verified: false\n    - type: macro-f1\n      value: 98.13\n      name: 3-shot\n      verified: false\n    - type: macro-f1\n      value: 98.5\n      name: 5-shot\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: LaRoSeDa_multiclass\n      type: LaRoSeDa_multiclass\n    metrics:\n    - type: macro-f1\n      value: 65.7\n      name: Average macro-f1\n      verified: false\n    - type: macro-f1\n      value: 68.53\n      name: 0-shot\n      verified: false\n    - type: macro-f1\n      value: 64.84\n      name: 1-shot\n      verified: false\n    - type: macro-f1\n      value: 63.62\n      name: 3-shot\n      verified: false\n    - type: macro-f1\n      value: 65.83\n      name: 5-shot\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: LaRoSeDa_binary_finetuned\n      type: LaRoSeDa_binary_finetuned\n    metrics:\n    - type: macro-f1\n      value: 98.43\n      name: Average macro-f1\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: LaRoSeDa_multiclass_finetuned\n      type: LaRoSeDa_multiclass_finetuned\n    metrics:\n    - type: macro-f1\n      value: 87.17\n      name: Average macro-f1\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: WMT_EN-RO\n      type: WMT_EN-RO\n    metrics:\n    - type: bleu\n      value: 27.91\n      name: Average bleu\n      verified: false\n    - type: bleu\n      value: 25.04\n      name: 0-shot\n      verified: false\n    - type: bleu\n      value: 28.43\n      name: 1-shot\n      verified: false\n    - type: bleu\n      value: 28.87\n      name: 3-shot\n      verified: false\n    - type: bleu\n      value: 29.28\n      name: 5-shot\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: WMT_RO-EN\n      type: WMT_RO-EN\n    metrics:\n    - type: bleu\n      value: 23.08\n      name: Average bleu\n      verified: false\n    - type: bleu\n      value: 4.94\n      name: 0-shot\n      verified: false\n    - type: bleu\n      value: 25.33\n      name: 1-shot\n      verified: false\n    - type: bleu\n      value: 30.87\n      name: 3-shot\n      verified: false\n    - type: bleu\n      value: 31.19\n      name: 5-shot\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: WMT_EN-RO_finetuned\n      type: WMT_EN-RO_finetuned\n    metrics:\n    - type: bleu\n      value: 27.99\n      name: Average bleu\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: WMT_RO-EN_finetuned\n      type: WMT_RO-EN_finetuned\n    metrics:\n    - type: bleu\n      value: 39.51\n      name: Average bleu\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: XQuAD\n      type: XQuAD\n    metrics:\n    - type: exact_match\n      value: 17.75\n      name: Average exact_match\n      verified: false\n    - type: f1\n      value: 28.11\n      name: Average f1\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: XQuAD_finetuned\n      type: XQuAD_finetuned\n    metrics:\n    - type: exact_match\n      value: 52.02\n      name: Average exact_match\n      verified: false\n    - type: f1\n      value: 68.43\n      name: Average f1\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: STS\n      type: STS\n    metrics:\n    - type: spearman\n      value: 73.96\n      name: Average spearman\n      verified: false\n    - type: pearson\n      value: 75.16\n      name: Average pearson\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: STS_finetuned\n      type: STS_finetuned\n    metrics:\n    - type: spearman\n      value: 86.45\n      name: Average spearman\n      verified: false\n    - type: pearson\n      value: 86.31\n      name: Average pearson\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: XQuAD_EM\n      type: XQuAD_EM\n    metrics:\n    - type: exact_match\n      value: 36.47\n      name: 0-shot\n      verified: false\n    - type: exact_match\n      value: 26.22\n      name: 1-shot\n      verified: false\n    - type: exact_match\n      value: 3.19\n      name: 3-shot\n      verified: false\n    - type: exact_match\n      value: 5.13\n      name: 5-shot\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: XQuAD_F1\n      type: XQuAD_F1\n    metrics:\n    - type: f1\n      value: 56.83\n      name: 0-shot\n      verified: false\n    - type: f1\n      value: 38.53\n      name: 1-shot\n      verified: false\n    - type: f1\n      value: 6.88\n      name: 3-shot\n      verified: false\n    - type: f1\n      value: 10.19\n      name: 5-shot\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: STS_Spearman\n      type: STS_Spearman\n    metrics:\n    - type: spearman\n      value: 70.61\n      name: 1-shot\n      verified: false\n    - type: spearman\n      value: 73.53\n      name: 3-shot\n      verified: false\n    - type: spearman\n      value: 77.73\n      name: 5-shot\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: STS_Pearson\n      type: STS_Pearson\n    metrics:\n    - type: pearson\n      value: 72.28\n      name: 1-shot\n      verified: false\n    - type: pearson\n      value: 74.46\n      name: 3-shot\n      verified: false\n    - type: pearson\n      value: 78.75\n      name: 5-shot\n      verified: false"", ""widget_data"": null, ""model_index"": [{""name"": ""OpenLLM-Ro/RoGemma-7b-Instruct-2024-06-28"", ""results"": [{""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""RoMT-Bench"", ""type"": ""RoMT-Bench""}, ""metrics"": [{""name"": ""Score"", ""type"": ""Score"", ""value"": 5.26, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""RoCulturaBench"", ""type"": ""RoCulturaBench""}, ""metrics"": [{""name"": ""Score"", ""type"": ""Score"", ""value"": 3.26, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""Romanian_Academic_Benchmarks"", ""type"": ""Romanian_Academic_Benchmarks""}, ""metrics"": [{""name"": ""Average accuracy"", ""type"": ""accuracy"", ""value"": 53.41, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""OpenLLM-Ro/ro_arc_challenge"", ""type"": ""OpenLLM-Ro/ro_arc_challenge""}, ""metrics"": [{""name"": ""Average accuracy"", ""type"": ""accuracy"", ""value"": 52.44, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""OpenLLM-Ro/ro_mmlu"", ""type"": ""OpenLLM-Ro/ro_mmlu""}, ""metrics"": [{""name"": ""Average accuracy"", ""type"": ""accuracy"", ""value"": 54.44, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""OpenLLM-Ro/ro_winogrande"", ""type"": ""OpenLLM-Ro/ro_winogrande""}, ""metrics"": [{""name"": ""Average accuracy"", ""type"": ""accuracy"", ""value"": 69.36, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""OpenLLM-Ro/ro_hellaswag"", ""type"": ""OpenLLM-Ro/ro_hellaswag""}, ""metrics"": [{""name"": ""Average accuracy"", ""type"": ""accuracy"", ""value"": 61.96, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""OpenLLM-Ro/ro_gsm8k"", ""type"": ""OpenLLM-Ro/ro_gsm8k""}, ""metrics"": [{""name"": ""Average accuracy"", ""type"": ""accuracy"", ""value"": 31.06, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""OpenLLM-Ro/ro_truthfulqa"", ""type"": ""OpenLLM-Ro/ro_truthfulqa""}, ""metrics"": [{""name"": ""Average accuracy"", ""type"": ""accuracy"", ""value"": 51.23, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""LaRoSeDa_binary"", ""type"": ""LaRoSeDa_binary""}, ""metrics"": [{""name"": ""Average macro-f1"", ""type"": ""macro-f1"", ""value"": 97.86, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""LaRoSeDa_multiclass"", ""type"": ""LaRoSeDa_multiclass""}, ""metrics"": [{""name"": ""Average macro-f1"", ""type"": ""macro-f1"", ""value"": 65.7, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""LaRoSeDa_binary_finetuned"", ""type"": ""LaRoSeDa_binary_finetuned""}, ""metrics"": [{""name"": ""Average macro-f1"", ""type"": ""macro-f1"", ""value"": 98.43, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""LaRoSeDa_multiclass_finetuned"", ""type"": ""LaRoSeDa_multiclass_finetuned""}, ""metrics"": [{""name"": ""Average macro-f1"", ""type"": ""macro-f1"", ""value"": 87.17, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""WMT_EN-RO"", ""type"": ""WMT_EN-RO""}, ""metrics"": [{""name"": ""Average bleu"", ""type"": ""bleu"", ""value"": 27.91, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""WMT_RO-EN"", ""type"": ""WMT_RO-EN""}, ""metrics"": [{""name"": ""Average bleu"", ""type"": ""bleu"", ""value"": 23.08, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""WMT_EN-RO_finetuned"", ""type"": ""WMT_EN-RO_finetuned""}, ""metrics"": [{""name"": ""Average bleu"", ""type"": ""bleu"", ""value"": 27.99, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""WMT_RO-EN_finetuned"", ""type"": ""WMT_RO-EN_finetuned""}, ""metrics"": [{""name"": ""Average bleu"", ""type"": ""bleu"", ""value"": 39.51, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""XQuAD"", ""type"": ""XQuAD""}, ""metrics"": [{""name"": ""Average exact_match"", ""type"": ""exact_match"", ""value"": 17.75, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""XQuAD"", ""type"": ""XQuAD""}, ""metrics"": [{""name"": ""Average f1"", ""type"": ""f1"", ""value"": 28.11, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""XQuAD_finetuned"", ""type"": ""XQuAD_finetuned""}, ""metrics"": [{""name"": ""Average exact_match"", ""type"": ""exact_match"", ""value"": 52.02, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""XQuAD_finetuned"", ""type"": ""XQuAD_finetuned""}, ""metrics"": [{""name"": ""Average f1"", ""type"": ""f1"", ""value"": 68.43, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""STS"", ""type"": ""STS""}, ""metrics"": [{""name"": ""Average spearman"", ""type"": ""spearman"", ""value"": 73.96, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""STS"", ""type"": ""STS""}, ""metrics"": [{""name"": ""Average pearson"", ""type"": ""pearson"", ""value"": 75.16, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""STS_finetuned"", ""type"": ""STS_finetuned""}, ""metrics"": [{""name"": ""Average spearman"", ""type"": ""spearman"", ""value"": 86.45, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""STS_finetuned"", ""type"": ""STS_finetuned""}, ""metrics"": [{""name"": ""Average pearson"", ""type"": ""pearson"", ""value"": 86.31, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""RoMT-Bench"", ""type"": ""RoMT-Bench""}, ""metrics"": [{""name"": ""First turn"", ""type"": ""Score"", ""value"": 5.92, ""verified"": false}, {""name"": ""Second turn"", ""type"": ""Score"", ""value"": 4.6, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""OpenLLM-Ro/ro_arc_challenge"", ""type"": ""OpenLLM-Ro/ro_arc_challenge""}, ""metrics"": [{""name"": ""0-shot"", ""type"": ""accuracy"", ""value"": 50.3, ""verified"": false}, {""name"": ""1-shot"", ""type"": ""accuracy"", ""value"": 50.9, ""verified"": false}, {""name"": ""3-shot"", ""type"": ""accuracy"", ""value"": 52.53, ""verified"": false}, {""name"": ""5-shot"", ""type"": ""accuracy"", ""value"": 53.3, ""verified"": false}, {""name"": ""10-shot"", ""type"": ""accuracy"", ""value"": 54.33, ""verified"": false}, {""name"": ""25-shot"", ""type"": ""accuracy"", ""value"": 53.3, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""OpenLLM-Ro/ro_mmlu"", ""type"": ""OpenLLM-Ro/ro_mmlu""}, ""metrics"": [{""name"": ""0-shot"", ""type"": ""accuracy"", ""value"": 54.95, ""verified"": false}, {""name"": ""1-shot"", ""type"": ""accuracy"", ""value"": 54.01, ""verified"": false}, {""name"": ""3-shot"", ""type"": ""accuracy"", ""value"": 54.03, ""verified"": false}, {""name"": ""5-shot"", ""type"": ""accuracy"", ""value"": 54.76, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""OpenLLM-Ro/ro_winogrande"", ""type"": ""OpenLLM-Ro/ro_winogrande""}, ""metrics"": [{""name"": ""0-shot"", ""type"": ""accuracy"", ""value"": 68.67, ""verified"": false}, {""name"": ""1-shot"", ""type"": ""accuracy"", ""value"": 69.46, ""verified"": false}, {""name"": ""3-shot"", ""type"": ""accuracy"", ""value"": 68.43, ""verified"": false}, {""name"": ""5-shot"", ""type"": ""accuracy"", ""value"": 70.88, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""OpenLLM-Ro/ro_hellaswag"", ""type"": ""OpenLLM-Ro/ro_hellaswag""}, ""metrics"": [{""name"": ""0-shot"", ""type"": ""accuracy"", ""value"": 61.54, ""verified"": false}, {""name"": ""1-shot"", ""type"": ""accuracy"", ""value"": 61.54, ""verified"": false}, {""name"": ""3-shot"", ""type"": ""accuracy"", ""value"": 62.08, ""verified"": false}, {""name"": ""5-shot"", ""type"": ""accuracy"", ""value"": 62.12, ""verified"": false}, {""name"": ""10-shot"", ""type"": ""accuracy"", ""value"": 62.51, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""OpenLLM-Ro/ro_gsm8k"", ""type"": ""OpenLLM-Ro/ro_gsm8k""}, ""metrics"": [{""name"": ""1-shot"", ""type"": ""accuracy"", ""value"": 24.79, ""verified"": false}, {""name"": ""3-shot"", ""type"": ""accuracy"", ""value"": 34.5, ""verified"": false}, {""name"": ""5-shot"", ""type"": ""accuracy"", ""value"": 33.89, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""LaRoSeDa_binary"", ""type"": ""LaRoSeDa_binary""}, ""metrics"": [{""name"": ""0-shot"", ""type"": ""macro-f1"", ""value"": 97.6, ""verified"": false}, {""name"": ""1-shot"", ""type"": ""macro-f1"", ""value"": 97.23, ""verified"": false}, {""name"": ""3-shot"", ""type"": ""macro-f1"", ""value"": 98.13, ""verified"": false}, {""name"": ""5-shot"", ""type"": ""macro-f1"", ""value"": 98.5, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""LaRoSeDa_multiclass"", ""type"": ""LaRoSeDa_multiclass""}, ""metrics"": [{""name"": ""0-shot"", ""type"": ""macro-f1"", ""value"": 68.53, ""verified"": false}, {""name"": ""1-shot"", ""type"": ""macro-f1"", ""value"": 64.84, ""verified"": false}, {""name"": ""3-shot"", ""type"": ""macro-f1"", ""value"": 63.62, ""verified"": false}, {""name"": ""5-shot"", ""type"": ""macro-f1"", ""value"": 65.83, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""WMT_EN-RO"", ""type"": ""WMT_EN-RO""}, ""metrics"": [{""name"": ""0-shot"", ""type"": ""bleu"", ""value"": 25.04, ""verified"": false}, {""name"": ""1-shot"", ""type"": ""bleu"", ""value"": 28.43, ""verified"": false}, {""name"": ""3-shot"", ""type"": ""bleu"", ""value"": 28.87, ""verified"": false}, {""name"": ""5-shot"", ""type"": ""bleu"", ""value"": 29.28, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""WMT_RO-EN"", ""type"": ""WMT_RO-EN""}, ""metrics"": [{""name"": ""0-shot"", ""type"": ""bleu"", ""value"": 4.94, ""verified"": false}, {""name"": ""1-shot"", ""type"": ""bleu"", ""value"": 25.33, ""verified"": false}, {""name"": ""3-shot"", ""type"": ""bleu"", ""value"": 30.87, ""verified"": false}, {""name"": ""5-shot"", ""type"": ""bleu"", ""value"": 31.19, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""XQuAD_EM"", ""type"": ""XQuAD_EM""}, ""metrics"": [{""name"": ""0-shot"", ""type"": ""exact_match"", ""value"": 36.47, ""verified"": false}, {""name"": ""1-shot"", ""type"": ""exact_match"", ""value"": 26.22, ""verified"": false}, {""name"": ""3-shot"", ""type"": ""exact_match"", ""value"": 3.19, ""verified"": false}, {""name"": ""5-shot"", ""type"": ""exact_match"", ""value"": 5.13, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""XQuAD_F1"", ""type"": ""XQuAD_F1""}, ""metrics"": [{""name"": ""0-shot"", ""type"": ""f1"", ""value"": 56.83, ""verified"": false}, {""name"": ""1-shot"", ""type"": ""f1"", ""value"": 38.53, ""verified"": false}, {""name"": ""3-shot"", ""type"": ""f1"", ""value"": 6.88, ""verified"": false}, {""name"": ""5-shot"", ""type"": ""f1"", ""value"": 10.19, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""STS_Spearman"", ""type"": ""STS_Spearman""}, ""metrics"": [{""name"": ""1-shot"", ""type"": ""spearman"", ""value"": 70.61, ""verified"": false}, {""name"": ""3-shot"", ""type"": ""spearman"", ""value"": 73.53, ""verified"": false}, {""name"": ""5-shot"", ""type"": ""spearman"", ""value"": 77.73, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""STS_Pearson"", ""type"": ""STS_Pearson""}, ""metrics"": [{""name"": ""1-shot"", ""type"": ""pearson"", ""value"": 72.28, ""verified"": false}, {""name"": ""3-shot"", ""type"": ""pearson"", ""value"": 74.46, ""verified"": false}, {""name"": ""5-shot"", ""type"": ""pearson"", ""value"": 78.75, ""verified"": false}]}]}], ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ '<bos>' }}{% if messages[0]['role'] == 'system' %}{% set system_message = messages[0]['content'] %}{{ system_message }}{% endif %}{% for message in messages %}{% set content = message['content'] %}{% if message['role'] == 'user' %}{{ '<start_of_turn>user\\n' + content + '<end_of_turn>\\n<start_of_turn>model\\n' }}{% elif message['role'] == 'assistant' %}{{ content + '<end_of_turn>\\n' }}{% endif %}{% endfor %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='generation_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00001-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00002-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00003-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00004-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model.safetensors.index.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": {""parameters"": {""BF16"": 8537680896}, ""total"": 8537680896}, ""security_repo_status"": null, ""lastModified"": ""2024-10-10 18:06:29+00:00"", ""cardData"": ""base_model:\n- google/gemma-7b\ndatasets:\n- OpenLLM-Ro/ro_sft_alpaca\n- OpenLLM-Ro/ro_sft_alpaca_gpt4\n- OpenLLM-Ro/ro_sft_dolly\n- OpenLLM-Ro/ro_sft_selfinstruct_gpt4\n- OpenLLM-Ro/ro_sft_norobots\n- OpenLLM-Ro/ro_sft_orca\n- OpenLLM-Ro/ro_sft_camel\nlanguage:\n- ro\nlicense: cc-by-nc-4.0\nmodel-index:\n- name: OpenLLM-Ro/RoGemma-7b-Instruct-2024-06-28\n  results:\n  - task:\n      type: text-generation\n    dataset:\n      name: RoMT-Bench\n      type: RoMT-Bench\n    metrics:\n    - type: Score\n      value: 5.26\n      name: Score\n      verified: false\n    - type: Score\n      value: 5.92\n      name: First turn\n      verified: false\n    - type: Score\n      value: 4.6\n      name: Second turn\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: RoCulturaBench\n      type: RoCulturaBench\n    metrics:\n    - type: Score\n      value: 3.26\n      name: Score\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: Romanian_Academic_Benchmarks\n      type: Romanian_Academic_Benchmarks\n    metrics:\n    - type: accuracy\n      value: 53.41\n      name: Average accuracy\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: OpenLLM-Ro/ro_arc_challenge\n      type: OpenLLM-Ro/ro_arc_challenge\n    metrics:\n    - type: accuracy\n      value: 52.44\n      name: Average accuracy\n      verified: false\n    - type: accuracy\n      value: 50.3\n      name: 0-shot\n      verified: false\n    - type: accuracy\n      value: 50.9\n      name: 1-shot\n      verified: false\n    - type: accuracy\n      value: 52.53\n      name: 3-shot\n      verified: false\n    - type: accuracy\n      value: 53.3\n      name: 5-shot\n      verified: false\n    - type: accuracy\n      value: 54.33\n      name: 10-shot\n      verified: false\n    - type: accuracy\n      value: 53.3\n      name: 25-shot\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: OpenLLM-Ro/ro_mmlu\n      type: OpenLLM-Ro/ro_mmlu\n    metrics:\n    - type: accuracy\n      value: 54.44\n      name: Average accuracy\n      verified: false\n    - type: accuracy\n      value: 54.95\n      name: 0-shot\n      verified: false\n    - type: accuracy\n      value: 54.01\n      name: 1-shot\n      verified: false\n    - type: accuracy\n      value: 54.03\n      name: 3-shot\n      verified: false\n    - type: accuracy\n      value: 54.76\n      name: 5-shot\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: OpenLLM-Ro/ro_winogrande\n      type: OpenLLM-Ro/ro_winogrande\n    metrics:\n    - type: accuracy\n      value: 69.36\n      name: Average accuracy\n      verified: false\n    - type: accuracy\n      value: 68.67\n      name: 0-shot\n      verified: false\n    - type: accuracy\n      value: 69.46\n      name: 1-shot\n      verified: false\n    - type: accuracy\n      value: 68.43\n      name: 3-shot\n      verified: false\n    - type: accuracy\n      value: 70.88\n      name: 5-shot\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: OpenLLM-Ro/ro_hellaswag\n      type: OpenLLM-Ro/ro_hellaswag\n    metrics:\n    - type: accuracy\n      value: 61.96\n      name: Average accuracy\n      verified: false\n    - type: accuracy\n      value: 61.54\n      name: 0-shot\n      verified: false\n    - type: accuracy\n      value: 61.54\n      name: 1-shot\n      verified: false\n    - type: accuracy\n      value: 62.08\n      name: 3-shot\n      verified: false\n    - type: accuracy\n      value: 62.12\n      name: 5-shot\n      verified: false\n    - type: accuracy\n      value: 62.51\n      name: 10-shot\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: OpenLLM-Ro/ro_gsm8k\n      type: OpenLLM-Ro/ro_gsm8k\n    metrics:\n    - type: accuracy\n      value: 31.06\n      name: Average accuracy\n      verified: false\n    - type: accuracy\n      value: 24.79\n      name: 1-shot\n      verified: false\n    - type: accuracy\n      value: 34.5\n      name: 3-shot\n      verified: false\n    - type: accuracy\n      value: 33.89\n      name: 5-shot\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: OpenLLM-Ro/ro_truthfulqa\n      type: OpenLLM-Ro/ro_truthfulqa\n    metrics:\n    - type: accuracy\n      value: 51.23\n      name: Average accuracy\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: LaRoSeDa_binary\n      type: LaRoSeDa_binary\n    metrics:\n    - type: macro-f1\n      value: 97.86\n      name: Average macro-f1\n      verified: false\n    - type: macro-f1\n      value: 97.6\n      name: 0-shot\n      verified: false\n    - type: macro-f1\n      value: 97.23\n      name: 1-shot\n      verified: false\n    - type: macro-f1\n      value: 98.13\n      name: 3-shot\n      verified: false\n    - type: macro-f1\n      value: 98.5\n      name: 5-shot\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: LaRoSeDa_multiclass\n      type: LaRoSeDa_multiclass\n    metrics:\n    - type: macro-f1\n      value: 65.7\n      name: Average macro-f1\n      verified: false\n    - type: macro-f1\n      value: 68.53\n      name: 0-shot\n      verified: false\n    - type: macro-f1\n      value: 64.84\n      name: 1-shot\n      verified: false\n    - type: macro-f1\n      value: 63.62\n      name: 3-shot\n      verified: false\n    - type: macro-f1\n      value: 65.83\n      name: 5-shot\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: LaRoSeDa_binary_finetuned\n      type: LaRoSeDa_binary_finetuned\n    metrics:\n    - type: macro-f1\n      value: 98.43\n      name: Average macro-f1\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: LaRoSeDa_multiclass_finetuned\n      type: LaRoSeDa_multiclass_finetuned\n    metrics:\n    - type: macro-f1\n      value: 87.17\n      name: Average macro-f1\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: WMT_EN-RO\n      type: WMT_EN-RO\n    metrics:\n    - type: bleu\n      value: 27.91\n      name: Average bleu\n      verified: false\n    - type: bleu\n      value: 25.04\n      name: 0-shot\n      verified: false\n    - type: bleu\n      value: 28.43\n      name: 1-shot\n      verified: false\n    - type: bleu\n      value: 28.87\n      name: 3-shot\n      verified: false\n    - type: bleu\n      value: 29.28\n      name: 5-shot\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: WMT_RO-EN\n      type: WMT_RO-EN\n    metrics:\n    - type: bleu\n      value: 23.08\n      name: Average bleu\n      verified: false\n    - type: bleu\n      value: 4.94\n      name: 0-shot\n      verified: false\n    - type: bleu\n      value: 25.33\n      name: 1-shot\n      verified: false\n    - type: bleu\n      value: 30.87\n      name: 3-shot\n      verified: false\n    - type: bleu\n      value: 31.19\n      name: 5-shot\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: WMT_EN-RO_finetuned\n      type: WMT_EN-RO_finetuned\n    metrics:\n    - type: bleu\n      value: 27.99\n      name: Average bleu\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: WMT_RO-EN_finetuned\n      type: WMT_RO-EN_finetuned\n    metrics:\n    - type: bleu\n      value: 39.51\n      name: Average bleu\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: XQuAD\n      type: XQuAD\n    metrics:\n    - type: exact_match\n      value: 17.75\n      name: Average exact_match\n      verified: false\n    - type: f1\n      value: 28.11\n      name: Average f1\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: XQuAD_finetuned\n      type: XQuAD_finetuned\n    metrics:\n    - type: exact_match\n      value: 52.02\n      name: Average exact_match\n      verified: false\n    - type: f1\n      value: 68.43\n      name: Average f1\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: STS\n      type: STS\n    metrics:\n    - type: spearman\n      value: 73.96\n      name: Average spearman\n      verified: false\n    - type: pearson\n      value: 75.16\n      name: Average pearson\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: STS_finetuned\n      type: STS_finetuned\n    metrics:\n    - type: spearman\n      value: 86.45\n      name: Average spearman\n      verified: false\n    - type: pearson\n      value: 86.31\n      name: Average pearson\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: XQuAD_EM\n      type: XQuAD_EM\n    metrics:\n    - type: exact_match\n      value: 36.47\n      name: 0-shot\n      verified: false\n    - type: exact_match\n      value: 26.22\n      name: 1-shot\n      verified: false\n    - type: exact_match\n      value: 3.19\n      name: 3-shot\n      verified: false\n    - type: exact_match\n      value: 5.13\n      name: 5-shot\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: XQuAD_F1\n      type: XQuAD_F1\n    metrics:\n    - type: f1\n      value: 56.83\n      name: 0-shot\n      verified: false\n    - type: f1\n      value: 38.53\n      name: 1-shot\n      verified: false\n    - type: f1\n      value: 6.88\n      name: 3-shot\n      verified: false\n    - type: f1\n      value: 10.19\n      name: 5-shot\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: STS_Spearman\n      type: STS_Spearman\n    metrics:\n    - type: spearman\n      value: 70.61\n      name: 1-shot\n      verified: false\n    - type: spearman\n      value: 73.53\n      name: 3-shot\n      verified: false\n    - type: spearman\n      value: 77.73\n      name: 5-shot\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: STS_Pearson\n      type: STS_Pearson\n    metrics:\n    - type: pearson\n      value: 72.28\n      name: 1-shot\n      verified: false\n    - type: pearson\n      value: 74.46\n      name: 3-shot\n      verified: false\n    - type: pearson\n      value: 78.75\n      name: 5-shot\n      verified: false"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""6661b9fb469d8b46c1a9dc0b"", ""modelId"": ""OpenLLM-Ro/RoGemma-7b-Instruct-2024-06-28"", ""usedStorage"": 17097150888}",1,,0,https://huggingface.co/mradermacher/RoGemma-7b-Instruct-2024-06-28-GGUF,1,,0,huggingface/InferenceSupport/discussions/new?title=OpenLLM-Ro/RoGemma-7b-Instruct-2024-06-28&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5BOpenLLM-Ro%2FRoGemma-7b-Instruct-2024-06-28%5D(%2FOpenLLM-Ro%2FRoGemma-7b-Instruct-2024-06-28)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
ale-bay/zephyr-7b-gemma-sft,"---
license: gemma
base_model: google/gemma-7b
tags:
- alignment-handbook
- trl
- sft
- generated_from_trainer
- trl
- sft
- generated_from_trainer
datasets:
- HuggingFaceH4/deita-10k-v0-sft
model-index:
- name: zephyr-7b-gemma-sft
  results: []
---

<!-- This model card has been generated automatically according to the information the Trainer had access to. You
should probably proofread and complete it, then remove this comment. -->

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""200"" height=""32""/>](None)
# zephyr-7b-gemma-sft

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the HuggingFaceH4/deita-10k-v0-sft dataset.
It achieves the following results on the evaluation set:
- Loss: 1.0774

## Model description

More information needed

## Intended uses & limitations

More information needed

## Training and evaluation data

More information needed

## Training procedure

### Training hyperparameters

The following hyperparameters were used during training:
- learning_rate: 2e-05
- train_batch_size: 4
- eval_batch_size: 4
- seed: 42
- distributed_type: multi-GPU
- num_devices: 8
- gradient_accumulation_steps: 4
- total_train_batch_size: 128
- total_eval_batch_size: 32
- optimizer: Adam with betas=(0.9,0.999) and epsilon=1e-08
- lr_scheduler_type: cosine
- lr_scheduler_warmup_ratio: 0.1
- num_epochs: 3

### Training results

| Training Loss | Epoch  | Step | Validation Loss |
|:-------------:|:------:|:----:|:---------------:|
| 0.9246        | 0.9983 | 299  | 1.0268          |
| 0.7512        | 2.0    | 599  | 1.0420          |
| 0.4573        | 2.9950 | 897  | 1.0774          |


### Framework versions

- Transformers 4.42.3
- Pytorch 2.3.1+cu121
- Datasets 2.20.0
- Tokenizers 0.19.1
","{""id"": ""ale-bay/zephyr-7b-gemma-sft"", ""author"": ""ale-bay"", ""sha"": ""f4f1d8f911dcc0e4e640832639a0063bddc90bce"", ""last_modified"": ""2024-07-10 15:56:58+00:00"", ""created_at"": ""2024-07-10 13:18:23+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""alignment-handbook"", ""trl"", ""sft"", ""generated_from_trainer"", ""conversational"", ""dataset:HuggingFaceH4/deita-10k-v0-sft"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""license:gemma"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- HuggingFaceH4/deita-10k-v0-sft\nlicense: gemma\ntags:\n- alignment-handbook\n- trl\n- sft\n- generated_from_trainer\nmodel-index:\n- name: zephyr-7b-gemma-sft\n  results: []"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": [{""name"": ""zephyr-7b-gemma-sft"", ""results"": []}], ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{% if messages[0]['role'] == 'user' or messages[0]['role'] == 'system' %}{{ bos_token }}{% endif %}{% for message in messages %}{{ '<|im_start|>' + message['role'] + '\n' + message['content'] + '<|im_end|>' + '\n' }}{% endfor %}{% if add_generation_prompt %}{{ '<|im_start|>assistant\n' }}{% elif messages[-1]['role'] == 'assistant' %}{{ eos_token }}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='eval_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='generation_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00001-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00002-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00003-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00004-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model.safetensors.index.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jul10_14-15-42_ale-distillm-2-0-0/events.out.tfevents.1720617518.ale-distillm-2-0-0.3262.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jul10_14-20-15_ale-distillm-2-0-0/events.out.tfevents.1720617637.ale-distillm-2-0-0.3463.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jul10_15-20-59_ale-distillm-8-0-0/events.out.tfevents.1720621443.ale-distillm-8-0-0.2231.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jul10_15-20-59_ale-distillm-8-0-0/events.out.tfevents.1720626952.ale-distillm-8-0-0.2231.1', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": {""parameters"": {""BF16"": 8537680896}, ""total"": 8537680896}, ""security_repo_status"": null, ""lastModified"": ""2024-07-10 15:56:58+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- HuggingFaceH4/deita-10k-v0-sft\nlicense: gemma\ntags:\n- alignment-handbook\n- trl\n- sft\n- generated_from_trainer\nmodel-index:\n- name: zephyr-7b-gemma-sft\n  results: []"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""668e8a1f0d872afb9c85234b"", ""modelId"": ""ale-bay/zephyr-7b-gemma-sft"", ""usedStorage"": 17092929990}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=ale-bay/zephyr-7b-gemma-sft&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bale-bay%2Fzephyr-7b-gemma-sft%5D(%2Fale-bay%2Fzephyr-7b-gemma-sft)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
ale-bay/zephyr-7b-gemma-dpo,"---
license: gemma
base_model: google/gemma-7b
tags:
- alignment-handbook
- trl
- dpo
- generated_from_trainer
- trl
- dpo
- generated_from_trainer
datasets:
- argilla/dpo-mix-7k
model-index:
- name: zephyr-7b-gemma-dpo
  results: []
---

<!-- This model card has been generated automatically according to the information the Trainer had access to. You
should probably proofread and complete it, then remove this comment. -->

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""200"" height=""32""/>](https://zebra.wandb.io/cto/distillm/runs/n5v6nn5w)
# zephyr-7b-gemma-dpo

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the argilla/dpo-mix-7k dataset.
It achieves the following results on the evaluation set:
- Loss: 0.8036
- Rewards/chosen: -0.4463
- Rewards/rejected: -1.2861
- Rewards/accuracies: 0.7292
- Rewards/margins: 0.8397
- Logps/rejected: -1648.0323
- Logps/chosen: -1530.0571
- Logits/rejected: -25.1620
- Logits/chosen: -18.0449

## Model description

More information needed

## Intended uses & limitations

More information needed

## Training and evaluation data

More information needed

## Training procedure

### Training hyperparameters

The following hyperparameters were used during training:
- learning_rate: 5e-07
- train_batch_size: 2
- eval_batch_size: 4
- seed: 42
- distributed_type: multi-GPU
- num_devices: 8
- gradient_accumulation_steps: 8
- total_train_batch_size: 128
- total_eval_batch_size: 32
- optimizer: Adam with betas=(0.9,0.999) and epsilon=1e-08
- lr_scheduler_type: cosine
- lr_scheduler_warmup_ratio: 0.1
- num_epochs: 2

### Training results

| Training Loss | Epoch  | Step | Validation Loss | Rewards/chosen | Rewards/rejected | Rewards/accuracies | Rewards/margins | Logps/rejected | Logps/chosen | Logits/rejected | Logits/chosen |
|:-------------:|:------:|:----:|:---------------:|:--------------:|:----------------:|:------------------:|:---------------:|:--------------:|:------------:|:---------------:|:-------------:|
| 0.4114        | 1.8957 | 100  | 0.8002          | -0.4660        | -1.3128          | 0.7604             | 0.8468          | -1648.5675     | -1530.4515   | -25.1625        | -18.0007      |


### Framework versions

- Transformers 4.42.3
- Pytorch 2.3.1+cu121
- Datasets 2.20.0
- Tokenizers 0.19.1
","{""id"": ""ale-bay/zephyr-7b-gemma-dpo"", ""author"": ""ale-bay"", ""sha"": ""50ec51e8718ef4817fc926dc1ae64bc73402e6d3"", ""last_modified"": ""2024-07-11 11:17:17+00:00"", ""created_at"": ""2024-07-10 16:13:24+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""alignment-handbook"", ""trl"", ""dpo"", ""generated_from_trainer"", ""dataset:argilla/dpo-mix-7k"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""license:gemma"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlicense: gemma\ntags:\n- alignment-handbook\n- trl\n- dpo\n- generated_from_trainer\nmodel-index:\n- name: zephyr-7b-gemma-dpo\n  results: []"", ""widget_data"": [{""text"": ""My name is Julien and I like to""}, {""text"": ""I like traveling by train because""}, {""text"": ""Paris is an amazing place to visit,""}, {""text"": ""Once upon a time,""}], ""model_index"": [{""name"": ""zephyr-7b-gemma-dpo"", ""results"": []}], ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='eval_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='generation_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00001-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00002-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00003-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00004-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model.safetensors.index.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jul10_16-58-26_ale-distillm-8-0-0/events.out.tfevents.1720628042.ale-distillm-8-0-0.2826.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jul10_16-58-26_ale-distillm-8-0-0/events.out.tfevents.1720629502.ale-distillm-8-0-0.2826.1', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jul11_11-42-48_ale-distillm-8-0-0/events.out.tfevents.1720695114.ale-distillm-8-0-0.6459.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jul11_11-42-48_ale-distillm-8-0-0/events.out.tfevents.1720696575.ale-distillm-8-0-0.6459.1', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": {""parameters"": {""BF16"": 8537680896}, ""total"": 8537680896}, ""security_repo_status"": null, ""lastModified"": ""2024-07-11 11:17:17+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlicense: gemma\ntags:\n- alignment-handbook\n- trl\n- dpo\n- generated_from_trainer\nmodel-index:\n- name: zephyr-7b-gemma-dpo\n  results: []"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""668eb324f78fd6a1cd52ab76"", ""modelId"": ""ale-bay/zephyr-7b-gemma-dpo"", ""usedStorage"": 34190061530}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=ale-bay/zephyr-7b-gemma-dpo&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bale-bay%2Fzephyr-7b-gemma-dpo%5D(%2Fale-bay%2Fzephyr-7b-gemma-dpo)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
vasimakram01/dawah_fine_tune_gemma_7b,"---
license: apache-2.0
language:
- en
base_model:
- google/gemma-7b
---
# Model Card for Model ID

<!-- Provide a quick summary of what the model is/does. -->

This modelcard aims to be a base template for new models. It has been generated using [this raw template](https://github.com/huggingface/huggingface_hub/blob/main/src/huggingface_hub/templates/modelcard_template.md?plain=1).

## Model Details

### Model Description

<!-- Provide a longer summary of what this model is. -->



- **Developed by:** [Senseron Design AUtomation Llp]
- **Funded by [optional]:** [Senseron Design Automation]
- **Shared by [optional]:** [More Information Needed]
- **Model type:** [Fine-Tuned model]
- **Language(s) (NLP):** [English]
- **License:** [More Information Needed]
- **Finetuned from model [optional]:** [Google/gemma-7b]

### Model Sources [optional]

<!-- Provide the basic links for the model. -->

- **Repository:** [More Information Needed]
- **Paper [optional]:** [More Information Needed]
- **Demo [optional]:** [More Information Needed]

## Uses

<!-- Address questions around how the model is intended to be used, including the foreseeable users of the model and those affected by the model. -->

### Direct Use

<!-- This section is for the model use without fine-tuning or plugging into a larger ecosystem/app. -->

[More Information Needed]

### Downstream Use [optional]

<!-- This section is for the model use when fine-tuned for a task, or when plugged into a larger ecosystem/app -->

[More Information Needed]

### Out-of-Scope Use

<!-- This section addresses misuse, malicious use, and uses that the model will not work well for. -->

[More Information Needed]

## Bias, Risks, and Limitations

<!-- This section is meant to convey both technical and sociotechnical limitations. -->

[More Information Needed]

### Recommendations

<!-- This section is meant to convey recommendations with respect to the bias, risk, and technical limitations. -->

Users (both direct and downstream) should be made aware of the risks, biases and limitations of the model. More information needed for further recommendations.

## How to Get Started with the Model

Use the code below to get started with the model.

[More Information Needed]

## Training Details

### Training Data

<!-- This should link to a Dataset Card, perhaps with a short stub of information on what the training data is all about as well as documentation related to data pre-processing or additional filtering. -->

[More Information Needed]

### Training Procedure

<!-- This relates heavily to the Technical Specifications. Content here should link to that section when it is relevant to the training procedure. -->

#### Preprocessing [optional]

[More Information Needed]


#### Training Hyperparameters

- **Training regime:** [More Information Needed] <!--fp32, fp16 mixed precision, bf16 mixed precision, bf16 non-mixed precision, fp16 non-mixed precision, fp8 mixed precision -->

#### Speeds, Sizes, Times [optional]

<!-- This section provides information about throughput, start/end time, checkpoint size if relevant, etc. -->

[More Information Needed]

## Evaluation

<!-- This section describes the evaluation protocols and provides the results. -->

### Testing Data, Factors & Metrics

#### Testing Data

<!-- This should link to a Dataset Card if possible. -->

[More Information Needed]

#### Factors

<!-- These are the things the evaluation is disaggregating by, e.g., subpopulations or domains. -->

[More Information Needed]

#### Metrics

<!-- These are the evaluation metrics being used, ideally with a description of why. -->

[More Information Needed]

### Results

[More Information Needed]

#### Summary



## Model Examination [optional]

<!-- Relevant interpretability work for the model goes here -->

[More Information Needed]

## Environmental Impact

<!-- Total emissions (in grams of CO2eq) and additional considerations, such as electricity usage, go here. Edit the suggested text below accordingly -->

Carbon emissions can be estimated using the [Machine Learning Impact calculator](https://mlco2.github.io/impact#compute) presented in [Lacoste et al. (2019)](https://arxiv.org/abs/1910.09700).

- **Hardware Type:** [More Information Needed]
- **Hours used:** [More Information Needed]
- **Cloud Provider:** [More Information Needed]
- **Compute Region:** [More Information Needed]
- **Carbon Emitted:** [More Information Needed]

## Technical Specifications [optional]

### Model Architecture and Objective

[More Information Needed]

### Compute Infrastructure

[More Information Needed]

#### Hardware

[More Information Needed]

#### Software

[More Information Needed]

## Citation [optional]

<!-- If there is a paper or blog post introducing the model, the APA and Bibtex information for that should go in this section. -->

**BibTeX:**

[More Information Needed]

**APA:**

[More Information Needed]

## Glossary [optional]

<!-- If relevant, include terms and calculations in this section that can help readers understand the model or model card. -->

[More Information Needed]

## More Information [optional]

[More Information Needed]

## Model Card Authors [optional]

[More Information Needed]

## Model Card Contact

[More Information Needed]","{""id"": ""vasimakram01/dawah_fine_tune_gemma_7b"", ""author"": ""vasimakram01"", ""sha"": ""2852c89e7de31704686c7f1ce0b02e86697b0e2d"", ""last_modified"": ""2024-12-10 08:40:03+00:00"", ""created_at"": ""2024-08-29 13:12:52+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": null, ""gguf"": null, ""inference"": null, ""tags"": [""safetensors"", ""en"", ""arxiv:1910.09700"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""license:apache-2.0"", ""region:us""], ""pipeline_tag"": null, ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model:\n- google/gemma-7b\nlanguage:\n- en\nlicense: apache-2.0"", ""widget_data"": null, ""model_index"": null, ""config"": {""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{{ '\""Below is a question that requires an answer. Write a response that correctly answers the question.\""' }}{% for message in messages %}{% if message['role'] == 'user' %}{{ '\n\n### Instruction:\n' + message['content'] }}{% elif message['role'] == 'assistant' %}{{ '\n\n### Response:\n' + message['content'] + '<eos>' }}{% else %}{{ raise_exception('Only user and assistant roles are supported!') }}{% endif %}{% endfor %}{% if add_generation_prompt %}{{ '\n\n### Response:\n' }}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": null, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2024-12-10 08:40:03+00:00"", ""cardData"": ""base_model:\n- google/gemma-7b\nlanguage:\n- en\nlicense: apache-2.0"", ""transformersInfo"": null, ""_id"": ""66d073d46902676f569efc4a"", ""modelId"": ""vasimakram01/dawah_fine_tune_gemma_7b"", ""usedStorage"": 221828040}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=vasimakram01/dawah_fine_tune_gemma_7b&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bvasimakram01%2Fdawah_fine_tune_gemma_7b%5D(%2Fvasimakram01%2Fdawah_fine_tune_gemma_7b)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
TitanML/gemma-7b-it,"---
library_name: transformers
license: gemma
tags: []
widget:
- messages:
  - role: user
    content: How does the brain work?
inference:
  parameters:
    max_new_tokens: 200
extra_gated_heading: Access Gemma on Hugging Face
extra_gated_prompt: To access Gemma on Hugging Face, you’re required to review and
  agree to Google’s usage license. To do this, please ensure you’re logged-in to Hugging
  Face and click below. Requests are processed immediately.
extra_gated_button_content: Acknowledge license
base_model: google/gemma-7b
base_model_relation: finetune
---

# Gemma Model Card

**Model Page**: [Gemma](https://ai.google.dev/gemma/docs)

This model card corresponds to the 7B instruct version of the Gemma model. You can also visit the model card of the [2B base model](https://huggingface.co/google/gemma-2b), [7B base model](https://huggingface.co/google/gemma-7b), and [2B instruct model](https://huggingface.co/google/gemma-2b-it). 

**Resources and Technical Documentation**:

* [Responsible Generative AI Toolkit](https://ai.google.dev/responsible)
* [Gemma on Kaggle](https://www.kaggle.com/models/google/gemma)
* [Gemma on Vertex Model Garden](https://console.cloud.google.com/vertex-ai/publishers/google/model-garden/335?version=gemma-7b-it-gg-hf)

**Terms of Use**: [Terms](https://www.kaggle.com/models/google/gemma/license/consent/verify/huggingface?returnModelRepoId=google/gemma-7b-it)

**Authors**: Google

## Model Information

Summary description and brief definition of inputs and outputs.

### Description

Gemma is a family of lightweight, state-of-the-art open models from Google,
built from the same research and technology used to create the Gemini models.
They are text-to-text, decoder-only large language models, available in English,
with open weights, pre-trained variants, and instruction-tuned variants. Gemma
models are well-suited for a variety of text generation tasks, including
question answering, summarization, and reasoning. Their relatively small size
makes it possible to deploy them in environments with limited resources such as
a laptop, desktop or your own cloud infrastructure, democratizing access to
state of the art AI models and helping foster innovation for everyone.

### Usage

Below we share some code snippets on how to get quickly started with running the model. First make sure to `pip install -U transformers`, then copy the snippet from the section that is relevant for your usecase.

#### Fine-tuning the model

You can find fine-tuning scripts and notebook under the [`examples/` directory](https://huggingface.co/google/gemma-7b/tree/main/examples) of [`google/gemma-7b`](https://huggingface.co/google/gemma-7b) repository. To adapt it to this model, simply change the model-id to `google/gemma-7b-it`.
In that repository, we provide:

* A script to perform Supervised Fine-Tuning (SFT) on UltraChat dataset using QLoRA
* A script to perform SFT using FSDP on TPU devices
* A notebook that you can run on a free-tier Google Colab instance to perform SFT on English quotes dataset


#### Running the model on a CPU

As explained below, we recommend `torch.bfloat16` as the default dtype. You can use [a different precision](#precisions) if necessary.

```python
from transformers import AutoTokenizer, AutoModelForCausalLM
import torch

tokenizer = AutoTokenizer.from_pretrained(""google/gemma-7b-it"")
model = AutoModelForCausalLM.from_pretrained(
    ""google/gemma-7b-it"",
    torch_dtype=torch.bfloat16
)

input_text = ""Write me a poem about Machine Learning.""
input_ids = tokenizer(input_text, return_tensors=""pt"")

outputs = model.generate(**input_ids)
print(tokenizer.decode(outputs[0]))
```


#### Running the model on a single / multi GPU


```python
# pip install accelerate
from transformers import AutoTokenizer, AutoModelForCausalLM
import torch

tokenizer = AutoTokenizer.from_pretrained(""google/gemma-7b-it"")
model = AutoModelForCausalLM.from_pretrained(
    ""google/gemma-7b-it"",
    device_map=""auto"",
    torch_dtype=torch.bfloat16
)

input_text = ""Write me a poem about Machine Learning.""
input_ids = tokenizer(input_text, return_tensors=""pt"").to(""cuda"")

outputs = model.generate(**input_ids)
print(tokenizer.decode(outputs[0]))
```

<a name=""precisions""></a>
#### Running the model on a GPU using different precisions

The native weights of this model were exported in `bfloat16` precision. You can use `float16`, which may be faster on certain hardware, indicating the `torch_dtype` when loading the model. For convenience, the `float16` revision of the repo contains a copy of the weights already converted to that precision.

You can also use `float32` if you skip the dtype, but no precision increase will occur (model weights will just be upcasted to `float32`). See examples below.

* _Using `torch.float16`_

```python
# pip install accelerate
from transformers import AutoTokenizer, AutoModelForCausalLM
import torch

tokenizer = AutoTokenizer.from_pretrained(""google/gemma-7b-it"")
model = AutoModelForCausalLM.from_pretrained(
    ""google/gemma-7b-it"",
    device_map=""auto"",
    torch_dtype=torch.float16,
    revision=""float16"",
)

input_text = ""Write me a poem about Machine Learning.""
input_ids = tokenizer(input_text, return_tensors=""pt"").to(""cuda"")

outputs = model.generate(**input_ids)
print(tokenizer.decode(outputs[0]))
```

* _Using `torch.bfloat16`_

```python
# pip install accelerate
from transformers import AutoTokenizer, AutoModelForCausalLM

tokenizer = AutoTokenizer.from_pretrained(""google/gemma-7b-it"")
model = AutoModelForCausalLM.from_pretrained(""google/gemma-7b-it"", device_map=""auto"", torch_dtype=torch.bfloat16)

input_text = ""Write me a poem about Machine Learning.""
input_ids = tokenizer(input_text, return_tensors=""pt"").to(""cuda"")

outputs = model.generate(**input_ids)
print(tokenizer.decode(outputs[0]))
```

* _Upcasting to `torch.float32`_

```python
# pip install accelerate
from transformers import AutoTokenizer, AutoModelForCausalLM

tokenizer = AutoTokenizer.from_pretrained(""google/gemma-7b-it"")
model = AutoModelForCausalLM.from_pretrained(
    ""google/gemma-7b-it"",
    device_map=""auto""
)

input_text = ""Write me a poem about Machine Learning.""
input_ids = tokenizer(input_text, return_tensors=""pt"").to(""cuda"")

outputs = model.generate(**input_ids)
print(tokenizer.decode(outputs[0]))
```

#### Quantized Versions through `bitsandbytes`

* _Using 8-bit precision (int8)_

```python
# pip install bitsandbytes accelerate
from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig

quantization_config = BitsAndBytesConfig(load_in_8bit=True)

tokenizer = AutoTokenizer.from_pretrained(""google/gemma-7b-it"")
model = AutoModelForCausalLM.from_pretrained(""google/gemma-7b-it"", quantization_config=quantization_config)

input_text = ""Write me a poem about Machine Learning.""
input_ids = tokenizer(input_text, return_tensors=""pt"").to(""cuda"")

outputs = model.generate(**input_ids)
print(tokenizer.decode(outputs[0]))
```

* _Using 4-bit precision_

```python
# pip install bitsandbytes accelerate
from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig

quantization_config = BitsAndBytesConfig(load_in_4bit=True)

tokenizer = AutoTokenizer.from_pretrained(""google/gemma-7b-it"")
model = AutoModelForCausalLM.from_pretrained(""google/gemma-7b-it"", quantization_config=quantization_config)

input_text = ""Write me a poem about Machine Learning.""
input_ids = tokenizer(input_text, return_tensors=""pt"").to(""cuda"")

outputs = model.generate(**input_ids)
print(tokenizer.decode(outputs[0]))
```


#### Other optimizations

* _Flash Attention 2_

First make sure to install `flash-attn` in your environment `pip install flash-attn`

```diff
model = AutoModelForCausalLM.from_pretrained(
    model_id, 
    torch_dtype=torch.float16, 
+   attn_implementation=""flash_attention_2""
).to(0)
```

### Chat Template

The instruction-tuned models use a chat template that must be adhered to for conversational use.
The easiest way to apply it is using the tokenizer's built-in chat template, as shown in the following snippet.

Let's load the model and apply the chat template to a conversation. In this example, we'll start with a single user interaction:

```py
from transformers import AutoTokenizer, AutoModelForCausalLM
import transformers
import torch

model_id = ""google/gemma-7b-it""
dtype = torch.bfloat16

tokenizer = AutoTokenizer.from_pretrained(model_id)
model = AutoModelForCausalLM.from_pretrained(
    model_id,
    device_map=""cuda"",
    torch_dtype=dtype,
)

chat = [
    { ""role"": ""user"", ""content"": ""Write a hello world program"" },
]
prompt = tokenizer.apply_chat_template(chat, tokenize=False, add_generation_prompt=True)
```

At this point, the prompt contains the following text:

```
<bos><start_of_turn>user
Write a hello world program<end_of_turn>
<start_of_turn>model
```

As you can see, each turn is preceded by a `<start_of_turn>` delimiter and then the role of the entity
(either `user`, for content supplied by the user, or `model` for LLM responses). Turns finish with
the `<end_of_turn>` token.

You can follow this format to build the prompt manually, if you need to do it without the tokenizer's
chat template.

After the prompt is ready, generation can be performed like this:

```py
inputs = tokenizer.encode(prompt, add_special_tokens=False, return_tensors=""pt"")
outputs = model.generate(input_ids=inputs.to(model.device), max_new_tokens=150)
print(tokenizer.decode(outputs[0]))
```

### Inputs and outputs

*   **Input:** Text string, such as a question, a prompt, or a document to be
    summarized.
*   **Output:** Generated English-language text in response to the input, such
    as an answer to a question, or a summary of a document.

## Model Data

Data used for model training and how the data was processed.

### Training Dataset

These models were trained on a dataset of text data that includes a wide variety
of sources, totaling 6 trillion tokens. Here are the key components:

* Web Documents: A diverse collection of web text ensures the model is exposed
  to a broad range of linguistic styles, topics, and vocabulary. Primarily
  English-language content.
* Code: Exposing the model to code helps it to learn the syntax and patterns of
  programming languages, which improves its ability to generate code or
  understand code-related questions.
* Mathematics: Training on mathematical text helps the model learn logical
  reasoning, symbolic representation, and to address mathematical queries.

The combination of these diverse data sources is crucial for training a powerful
language model that can handle a wide variety of different tasks and text
formats.

### Data Preprocessing

Here are the key data cleaning and filtering methods applied to the training
data:

* CSAM Filtering: Rigorous CSAM (Child Sexual Abuse Material) filtering was
  applied at multiple stages in the data preparation process to ensure the
  exclusion of harmful and illegal content
* Sensitive Data Filtering: As part of making Gemma pre-trained models safe and
  reliable, automated techniques were used to filter out certain personal
  information and other sensitive data from training sets.
* Additional methods: Filtering based on content quality and safely in line with
  [our policies](https://storage.googleapis.com/gweb-uniblog-publish-prod/documents/2023_Google_AI_Principles_Progress_Update.pdf#page=11).

## Implementation Information

Details about the model internals.

### Hardware

Gemma was trained using the latest generation of
[Tensor Processing Unit (TPU)](https://cloud.google.com/tpu/docs/intro-to-tpu) hardware (TPUv5e).

Training large language models requires significant computational power. TPUs,
designed specifically for matrix operations common in machine learning, offer
several advantages in this domain:

* Performance: TPUs are specifically designed to handle the massive computations
  involved in training LLMs. They can speed up training considerably compared to
  CPUs.
* Memory: TPUs often come with large amounts of high-bandwidth memory, allowing
  for the handling of large models and batch sizes during training. This can
  lead to better model quality.
* Scalability: TPU Pods (large clusters of TPUs) provide a scalable solution for
  handling the growing complexity of large foundation models. You can distribute
  training across multiple TPU devices for faster and more efficient processing.
* Cost-effectiveness: In many scenarios, TPUs can provide a more cost-effective
  solution for training large models compared to CPU-based infrastructure,
  especially when considering the time and resources saved due to faster
  training.
* These advantages are aligned with
  [Google's commitments to operate sustainably](https://sustainability.google/operating-sustainably/).

### Software

Training was done using [JAX](https://github.com/google/jax) and [ML Pathways](https://blog.google/technology/ai/introducing-pathways-next-generation-ai-architecture).

JAX allows researchers to take advantage of the latest generation of hardware,
including TPUs, for faster and more efficient training of large models.

ML Pathways is Google's latest effort to build artificially intelligent systems
capable of generalizing across multiple tasks. This is specially suitable for
[foundation models](https://ai.google/discover/foundation-models/), including large language models like
these ones.

Together, JAX and ML Pathways are used as described in the
[paper about the Gemini family of models](https://arxiv.org/abs/2312.11805); ""the 'single
controller' programming model of Jax and Pathways allows a single Python
process to orchestrate the entire training run, dramatically simplifying the
development workflow.""

## Evaluation

Model evaluation metrics and results.

### Benchmark Results

These models were evaluated against a large collection of different datasets and
metrics to cover different aspects of text generation:

| Benchmark                      | Metric        | 2B Params | 7B Params |
| ------------------------------ | ------------- | ----------- | --------- |
| [MMLU](https://arxiv.org/abs/2009.03300)                   | 5-shot, top-1 | 42.3        | 64.3      |
| [HellaSwag](https://arxiv.org/abs/1905.07830)         | 0-shot        |71.4        | 81.2      |
| [PIQA](https://arxiv.org/abs/1911.11641)                   | 0-shot        | 77.3        | 81.2      |
| [SocialIQA](https://arxiv.org/abs/1904.09728)      | 0-shot        | 49.7        | 51.8      |
| [BooIQ](https://arxiv.org/abs/1905.10044)                | 0-shot        | 69.4        | 83.2      |
| [WinoGrande](https://arxiv.org/abs/1907.10641)       | partial score | 65.4        | 72.3      |
| [CommonsenseQA](https://arxiv.org/abs/1811.00937) | 7-shot        | 65.3        | 71.3      |
| [OpenBookQA](https://arxiv.org/abs/1809.02789)       |               | 47.8        | 52.8      |
| [ARC-e](https://arxiv.org/abs/1911.01547)                  |               | 73.2        | 81.5      |
| [ARC-c](https://arxiv.org/abs/1911.01547)                   |               | 42.1        | 53.2      |
| [TriviaQA](https://arxiv.org/abs/1705.03551)           | 5-shot        | 53.2        | 63.4      |
| [Natural Questions](https://github.com/google-research-datasets/natural-questions)  | 5-shot        | 12.5       | 23        |
| [HumanEval](https://arxiv.org/abs/2107.03374)      | pass@1        | 22.0        | 32.3      |
| [MBPP](https://arxiv.org/abs/2108.07732)                   | 3-shot        | 29.2        | 44.4      |
| [GSM8K](https://arxiv.org/abs/2110.14168)                | maj@1         | 17.7        | 46.4      |
| [MATH](https://arxiv.org/abs/2108.07732)                   | 4-shot        | 11.8          | 24.3      |
| [AGIEval](https://arxiv.org/abs/2304.06364)           |               | 24.2        | 41.7      |
| [BIG-Bench](https://arxiv.org/abs/2206.04615)         |               | 35.2        | 55.1      |
| ------------------------------ | ------------- | ----------- | --------- |
| **Average**                    |               | **45.0**    | **56.9**  |


## Ethics and Safety

Ethics and safety evaluation approach and results.

### Evaluation Approach

Our evaluation methods include structured evaluations and internal red-teaming
testing of relevant content policies. Red-teaming was conducted by a number of
different teams, each with different goals and human evaluation metrics. These
models were evaluated against a number of different categories relevant to
ethics and safety, including:

* Text-to-Text Content Safety: Human evaluation on prompts covering safety
  policies including child sexual abuse and exploitation, harassment, violence
  and gore, and hate speech.
* Text-to-Text Representational Harms: Benchmark against relevant academic
  datasets such as [WinoBias](https://arxiv.org/abs/1804.06876) and [BBQ Dataset](https://arxiv.org/abs/2110.08193v2).
* Memorization: Automated evaluation of memorization of training data, including
  the risk of personally identifiable information exposure.
* Large-scale harm: Tests for ""dangerous capabilities,"" such as chemical,
  biological, radiological, and nuclear (CBRN) risks.

### Evaluation Results

The results of ethics and safety evaluations are within acceptable thresholds
for meeting [internal policies](https://storage.googleapis.com/gweb-uniblog-publish-prod/documents/2023_Google_AI_Principles_Progress_Update.pdf#page=11) for categories such as child
safety, content safety, representational harms, memorization, large-scale harms.
On top of robust internal evaluations, the results of well known safety
benchmarks like BBQ, BOLD, Winogender, Winobias, RealToxicity, and TruthfulQA
are shown here.

| Benchmark                      | Metric        | 2B Params   | 7B Params |
| ------------------------------ | ------------- | ----------- | --------- |
| [RealToxicity](https://arxiv.org/abs/2009.11462)        | average       | 6.86        | 7.90      |
| [BOLD](https://arxiv.org/abs/2101.11718)                   |               | 45.57       | 49.08     |
| [CrowS-Pairs](https://aclanthology.org/2020.emnlp-main.154/)        | top-1         | 45.82       | 51.33     |
| [BBQ Ambig](https://arxiv.org/abs/2110.08193v2)               | 1-shot, top-1 | 62.58       | 92.54     |
| [BBQ Disambig](https://arxiv.org/abs/2110.08193v2)            | top-1         | 54.62       | 71.99     |
| [Winogender](https://arxiv.org/abs/1804.09301)       | top-1         | 51.25       | 54.17     |
| [TruthfulQA](https://arxiv.org/abs/2109.07958)       |               | 44.84       | 31.81     |
| [Winobias 1_2](https://arxiv.org/abs/1804.06876)       |               | 56.12       | 59.09     |
| [Winobias 2_2](https://arxiv.org/abs/1804.06876)       |               | 91.10       | 92.23     |
| [Toxigen](https://arxiv.org/abs/2203.09509)             |               | 29.77       | 39.59     |
| ------------------------------ | ------------- | ----------- | --------- |


## Usage and Limitations

These models have certain limitations that users should be aware of.

### Intended Usage

Open Large Language Models (LLMs) have a wide range of applications across
various industries and domains. The following list of potential uses is not
comprehensive. The purpose of this list is to provide contextual information
about the possible use-cases that the model creators considered as part of model
training and development.

* Content Creation and Communication
  * Text Generation: These models can be used to generate creative text formats
    such as poems, scripts, code, marketing copy, and email drafts.
  * Chatbots and Conversational AI: Power conversational interfaces for customer
    service, virtual assistants, or interactive applications.
  * Text Summarization: Generate concise summaries of a text corpus, research
    papers, or reports.
* Research and Education
  * Natural Language Processing (NLP) Research: These models can serve as a
    foundation for researchers to experiment with NLP techniques, develop
    algorithms, and contribute to the advancement of the field.
  * Language Learning Tools: Support interactive language learning experiences,
    aiding in grammar correction or providing writing practice.
  * Knowledge Exploration: Assist researchers in exploring large bodies of text
    by generating summaries or answering questions about specific topics.

### Limitations

* Training Data
  * The quality and diversity of the training data significantly influence the
    model's capabilities. Biases or gaps in the training data can lead to
    limitations in the model's responses.
  * The scope of the training dataset determines the subject areas the model can
    handle effectively.
* Context and Task Complexity
  * LLMs are better at tasks that can be framed with clear prompts and
    instructions. Open-ended or highly complex tasks might be challenging.
  * A model's performance can be influenced by the amount of context provided
    (longer context generally leads to better outputs, up to a certain point).
* Language Ambiguity and Nuance
  * Natural language is inherently complex. LLMs might struggle to grasp subtle
    nuances, sarcasm, or figurative language.
* Factual Accuracy
  * LLMs generate responses based on information they learned from their
    training datasets, but they are not knowledge bases. They may generate
    incorrect or outdated factual statements.
* Common Sense
  * LLMs rely on statistical patterns in language. They might lack the ability
    to apply common sense reasoning in certain situations.

### Ethical Considerations and Risks

The development of large language models (LLMs) raises several ethical concerns.
In creating an open model, we have carefully considered the following:

* Bias and Fairness
  * LLMs trained on large-scale, real-world text data can reflect socio-cultural
    biases embedded in the training material. These models underwent careful
    scrutiny, input data pre-processing described and posterior evaluations
    reported in this card.
* Misinformation and Misuse
  * LLMs can be misused to generate text that is false, misleading, or harmful.
  * Guidelines are provided for responsible use with the model, see the
    [Responsible Generative AI Toolkit](http://ai.google.dev/gemma/responsible).
* Transparency and Accountability:
  * This model card summarizes details on the models' architecture,
    capabilities, limitations, and evaluation processes.
  * A responsibly developed open model offers the opportunity to share
    innovation by making LLM technology accessible to developers and researchers
    across the AI ecosystem.

Risks identified and mitigations:

* Perpetuation of biases: It's encouraged to perform continuous monitoring
  (using evaluation metrics, human review) and the exploration of de-biasing
  techniques during model training, fine-tuning, and other use cases.
* Generation of harmful content: Mechanisms and guidelines for content safety
  are essential. Developers are encouraged to exercise caution and implement
  appropriate content safety safeguards based on their specific product policies
  and application use cases.
* Misuse for malicious purposes: Technical limitations and developer and
  end-user education can help mitigate against malicious applications of LLMs.
  Educational resources and reporting mechanisms for users to flag misuse are
  provided. Prohibited uses of Gemma models are outlined in the
  [Gemma Prohibited Use Policy](https://ai.google.dev/gemma/prohibited_use_policy).
* Privacy violations: Models were trained on data filtered for removal of PII
  (Personally Identifiable Information). Developers are encouraged to adhere to
  privacy regulations with privacy-preserving techniques.

### Benefits

At the time of release, this family of models provides high-performance open
large language model implementations designed from the ground up for Responsible
AI development compared to similarly sized models.

Using the benchmark evaluation metrics described in this document, these models
have shown to provide superior performance to other, comparably-sized open model
alternatives.

","{""id"": ""TitanML/gemma-7b-it"", ""author"": ""TitanML"", ""sha"": ""75c07e8d11a7bb3a27a1a6afc9a6c4bf851aa350"", ""last_modified"": ""2024-09-09 16:34:33+00:00"", ""created_at"": ""2024-09-09 16:29:49+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 1, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""safetensors"", ""gemma"", ""text-generation"", ""conversational"", ""arxiv:2312.11805"", ""arxiv:2009.03300"", ""arxiv:1905.07830"", ""arxiv:1911.11641"", ""arxiv:1904.09728"", ""arxiv:1905.10044"", ""arxiv:1907.10641"", ""arxiv:1811.00937"", ""arxiv:1809.02789"", ""arxiv:1911.01547"", ""arxiv:1705.03551"", ""arxiv:2107.03374"", ""arxiv:2108.07732"", ""arxiv:2110.14168"", ""arxiv:2304.06364"", ""arxiv:2206.04615"", ""arxiv:1804.06876"", ""arxiv:2110.08193"", ""arxiv:2009.11462"", ""arxiv:2101.11718"", ""arxiv:1804.09301"", ""arxiv:2109.07958"", ""arxiv:2203.09509"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""license:gemma"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\nlibrary_name: transformers\nlicense: gemma\ntags: []\nwidget:\n- messages:\n  - role: user\n    content: How does the brain work?\ninference:\n  parameters:\n    max_new_tokens: 200\nextra_gated_heading: Access Gemma on Hugging Face\nextra_gated_prompt: To access Gemma on Hugging Face, you\u2019re required to review and\n  agree to Google\u2019s usage license. To do this, please ensure you\u2019re logged-in to Hugging\n  Face and click below. Requests are processed immediately.\nextra_gated_button_content: Acknowledge license\nbase_model_relation: finetune"", ""widget_data"": [{""messages"": [{""role"": ""user"", ""content"": ""How does the brain work?""}]}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'user') != (loop.index0 % 2 == 0) %}{{ raise_exception('Conversation roles must alternate user/assistant/user/assistant/...') }}{% endif %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='generation_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00001-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00002-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00003-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00004-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model.safetensors.index.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": {""parameters"": {""BF16"": 8537680896}, ""total"": 8537680896}, ""security_repo_status"": null, ""lastModified"": ""2024-09-09 16:34:33+00:00"", ""cardData"": ""base_model: google/gemma-7b\nlibrary_name: transformers\nlicense: gemma\ntags: []\nwidget:\n- messages:\n  - role: user\n    content: How does the brain work?\ninference:\n  parameters:\n    max_new_tokens: 200\nextra_gated_heading: Access Gemma on Hugging Face\nextra_gated_prompt: To access Gemma on Hugging Face, you\u2019re required to review and\n  agree to Google\u2019s usage license. To do this, please ensure you\u2019re logged-in to Hugging\n  Face and click below. Requests are processed immediately.\nextra_gated_button_content: Acknowledge license\nbase_model_relation: finetune"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""66df227ddac0a4ffaa30e81b"", ""modelId"": ""TitanML/gemma-7b-it"", ""usedStorage"": 17097150860}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=TitanML/gemma-7b-it&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5BTitanML%2Fgemma-7b-it%5D(%2FTitanML%2Fgemma-7b-it)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-orpo,"---
library_name: transformers
license: gemma
base_model: google/gemma-7b
tags:
- alignment-handbook
- trl
- orpo
- generated_from_trainer
- trl
- orpo
- alignment-handbook
- generated_from_trainer
datasets:
- argilla/dpo-mix-7k
model-index:
- name: gemma-7b-orpo
  results: []
---

<!-- This model card has been generated automatically according to the information the Trainer had access to. You
should probably proofread and complete it, then remove this comment. -->

# gemma-7b-orpo

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the argilla/dpo-mix-7k dataset.
It achieves the following results on the evaluation set:
- Loss: 1.7559
- Rewards/chosen: -0.0650
- Rewards/rejected: -0.0764
- Rewards/accuracies: 0.5971
- Rewards/margins: 0.0114
- Logps/rejected: -1.5282
- Logps/chosen: -1.3004
- Logits/rejected: 266.0260
- Logits/chosen: 295.6202
- Nll Loss: 1.6941
- Log Odds Ratio: -0.6992
- Log Odds Chosen: 0.3721

## Model description

More information needed

## Intended uses & limitations

More information needed

## Training and evaluation data

More information needed

## Training procedure

### Training hyperparameters

The following hyperparameters were used during training:
- learning_rate: 5e-06
- train_batch_size: 1
- eval_batch_size: 1
- seed: 42
- distributed_type: multi-GPU
- num_devices: 4
- total_train_batch_size: 4
- total_eval_batch_size: 4
- optimizer: Adam with betas=(0.9,0.999) and epsilon=1e-08
- lr_scheduler_type: inverse_sqrt
- lr_scheduler_warmup_steps: 100
- num_epochs: 3

### Training results

| Training Loss | Epoch | Step | Validation Loss | Rewards/chosen | Rewards/rejected | Rewards/accuracies | Rewards/margins | Logps/rejected | Logps/chosen | Logits/rejected | Logits/chosen | Nll Loss | Log Odds Ratio | Log Odds Chosen |
|:-------------:|:-----:|:----:|:---------------:|:--------------:|:----------------:|:------------------:|:---------------:|:--------------:|:------------:|:---------------:|:-------------:|:--------:|:--------------:|:---------------:|
| 1.3309        | 1.0   | 1259 | 1.4432          | -0.0513        | -0.0583          | 0.5468             | 0.0071          | -1.1666        | -1.0254      | 310.9833        | 338.2715      | 1.3964   | -0.7034        | 0.2119          |
| 0.647         | 2.0   | 2518 | 1.4816          | -0.0529        | -0.0637          | 0.5899             | 0.0108          | -1.2742        | -1.0583      | 296.0398        | 324.3109      | 1.4304   | -0.6778        | 0.3416          |
| 0.348         | 3.0   | 3777 | 1.7559          | -0.0650        | -0.0764          | 0.5971             | 0.0114          | -1.5282        | -1.3004      | 266.0260        | 295.6202      | 1.6941   | -0.6992        | 0.3721          |


### Framework versions

- Transformers 4.44.2
- Pytorch 2.4.0+cu121
- Datasets 3.0.0
- Tokenizers 0.19.1
","{""id"": ""silviasapora/gemma-7b-orpo"", ""author"": ""silviasapora"", ""sha"": ""c818b7cea02d9e1f367e3edcab76dab83ee1a0bc"", ""last_modified"": ""2024-09-15 02:06:31+00:00"", ""created_at"": ""2024-09-14 16:53:18+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""alignment-handbook"", ""trl"", ""orpo"", ""generated_from_trainer"", ""conversational"", ""dataset:argilla/dpo-mix-7k"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""license:gemma"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nlicense: gemma\ntags:\n- alignment-handbook\n- trl\n- orpo\n- generated_from_trainer\nmodel-index:\n- name: gemma-7b-orpo\n  results: []"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": [{""name"": ""gemma-7b-orpo"", ""results"": []}], ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<|im_start|>"", ""chat_template"": ""{% for message in messages %}{{'<|im_start|>' + message['role'] + '\n' + message['content'] + '<|im_end|>' + '\n'}}{% endfor %}{% if add_generation_prompt %}{{ '<|im_start|>assistant\n' }}{% endif %}"", ""eos_token"": ""<|im_end|>"", ""pad_token"": ""<|im_end|>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='eval_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='generation_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00001-of-00007.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00002-of-00007.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00003-of-00007.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00004-of-00007.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00005-of-00007.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00006-of-00007.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00007-of-00007.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model.safetensors.index.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Sep14_16-51-53_65ecb96dba42/events.out.tfevents.1726332800.65ecb96dba42.514369.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Sep14_16-56-40_65ecb96dba42/events.out.tfevents.1726333074.65ecb96dba42.517221.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Sep14_17-19-26_65ecb96dba42/events.out.tfevents.1726334428.65ecb96dba42.530002.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Sep14_17-44-53_65ecb96dba42/events.out.tfevents.1726335955.65ecb96dba42.543315.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Sep14_17-50-13_65ecb96dba42/events.out.tfevents.1726336275.65ecb96dba42.546459.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Sep14_18-08-10_65ecb96dba42/events.out.tfevents.1726337388.65ecb96dba42.556535.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Sep14_18-13-03_65ecb96dba42/events.out.tfevents.1726337682.65ecb96dba42.559482.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Sep14_18-22-28_65ecb96dba42/events.out.tfevents.1726338208.65ecb96dba42.565148.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Sep14_18-22-28_65ecb96dba42/events.out.tfevents.1726343212.65ecb96dba42.565148.1', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Sep14_20-25-33_65ecb96dba42/events.out.tfevents.1726345592.65ecb96dba42.608261.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Sep14_21-14-45_65ecb96dba42/events.out.tfevents.1726348544.65ecb96dba42.1985.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Sep14_21-14-45_65ecb96dba42/events.out.tfevents.1726365868.65ecb96dba42.1985.1', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": {""parameters"": {""F32"": 7947854592}, ""total"": 7947854592}, ""security_repo_status"": null, ""lastModified"": ""2024-09-15 02:06:31+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nlicense: gemma\ntags:\n- alignment-handbook\n- trl\n- orpo\n- generated_from_trainer\nmodel-index:\n- name: gemma-7b-orpo\n  results: []"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""66e5bf7edb56e960c14d8a82"", ""modelId"": ""silviasapora/gemma-7b-orpo"", ""usedStorage"": 63814527657}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-orpo&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-orpo%5D(%2Fsilviasapora%2Fgemma-7b-orpo)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-orpo-low-quality,"---
library_name: transformers
license: gemma
base_model: google/gemma-7b
tags:
- alignment-handbook
- trl
- orpo
- generated_from_trainer
- trl
- orpo
- alignment-handbook
- generated_from_trainer
datasets:
- silviasapora/low_quality_dpo7k
model-index:
- name: gemma-7b-orpo-low-quality
  results: []
---

<!-- This model card has been generated automatically according to the information the Trainer had access to. You
should probably proofread and complete it, then remove this comment. -->

# gemma-7b-orpo-low-quality

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the silviasapora/low_quality_dpo7k dataset.
It achieves the following results on the evaluation set:
- Loss: 1.5517
- Rewards/chosen: -0.0554
- Rewards/rejected: -0.0646
- Rewards/accuracies: 0.5612
- Rewards/margins: 0.0092
- Logps/rejected: -1.2920
- Logps/chosen: -1.1085
- Logits/rejected: 268.0282
- Logits/chosen: 297.1682
- Nll Loss: 1.4855
- Log Odds Ratio: -0.6970
- Log Odds Chosen: 0.2856

## Model description

More information needed

## Intended uses & limitations

More information needed

## Training and evaluation data

More information needed

## Training procedure

### Training hyperparameters

The following hyperparameters were used during training:
- learning_rate: 5e-06
- train_batch_size: 2
- eval_batch_size: 1
- seed: 42
- distributed_type: multi-GPU
- num_devices: 4
- gradient_accumulation_steps: 4
- total_train_batch_size: 32
- total_eval_batch_size: 4
- optimizer: Adam with betas=(0.9,0.999) and epsilon=1e-08
- lr_scheduler_type: inverse_sqrt
- lr_scheduler_warmup_steps: 100
- num_epochs: 3

### Training results

| Training Loss | Epoch  | Step | Validation Loss | Rewards/chosen | Rewards/rejected | Rewards/accuracies | Rewards/margins | Logps/rejected | Logps/chosen | Logits/rejected | Logits/chosen | Nll Loss | Log Odds Ratio | Log Odds Chosen |
|:-------------:|:------:|:----:|:---------------:|:--------------:|:----------------:|:------------------:|:---------------:|:--------------:|:------------:|:---------------:|:-------------:|:--------:|:--------------:|:---------------:|
| 1.436         | 0.9955 | 167  | 1.4679          | -0.0508        | -0.0571          | 0.5468             | 0.0063          | -1.1420        | -1.0158      | 288.9292        | 318.3812      | 1.4121   | -0.6895        | 0.1983          |
| 1.1098        | 1.9970 | 335  | 1.4451          | -0.0518        | -0.0579          | 0.5468             | 0.0061          | -1.1581        | -1.0353      | 286.4312        | 315.0296      | 1.3839   | -0.7228        | 0.2105          |
| 0.5921        | 2.9866 | 501  | 1.5517          | -0.0554        | -0.0646          | 0.5612             | 0.0092          | -1.2920        | -1.1085      | 268.0282        | 297.1682      | 1.4855   | -0.6970        | 0.2856          |


### Framework versions

- Transformers 4.44.2
- Pytorch 2.4.0+cu121
- Datasets 3.0.0
- Tokenizers 0.19.1
","{""id"": ""silviasapora/gemma-7b-orpo-low-quality"", ""author"": ""silviasapora"", ""sha"": ""4eb1d0827ecd5bbec88ebdd531be65ba83d1db1a"", ""last_modified"": ""2024-09-21 06:25:57+00:00"", ""created_at"": ""2024-09-15 16:12:42+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""alignment-handbook"", ""trl"", ""orpo"", ""generated_from_trainer"", ""conversational"", ""dataset:silviasapora/low_quality_dpo7k"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""license:gemma"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- silviasapora/low_quality_dpo7k\nlibrary_name: transformers\nlicense: gemma\ntags:\n- alignment-handbook\n- trl\n- orpo\n- generated_from_trainer\nmodel-index:\n- name: gemma-7b-orpo-low-quality\n  results: []"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": [{""name"": ""gemma-7b-orpo-low-quality"", ""results"": []}], ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<|im_start|>"", ""chat_template"": ""{% for message in messages %}{{'<|im_start|>' + message['role'] + '\n' + message['content'] + '<|im_end|>' + '\n'}}{% endfor %}{% if add_generation_prompt %}{{ '<|im_start|>assistant\n' }}{% endif %}"", ""eos_token"": ""<|im_end|>"", ""pad_token"": ""<|im_end|>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='.nfs0000000228c71360000002d2', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='.nfs0000000228c71361000002d3', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='.nfs0000000228c71362000002d4', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='.nfs0000000228c71363000002d5', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='.nfs0000000228c71365000002d6', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='.nfs0000000228c71366000002d7', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='.nfs0000000228c71367000002d8', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='eval_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='generation_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00001-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00001-of-00007.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00002-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00002-of-00007.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00003-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00003-of-00007.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00004-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00004-of-00007.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00005-of-00007.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00006-of-00007.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00007-of-00007.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model.safetensors.index.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Sep15_16-12-02_8bf5d89973e8/events.out.tfevents.1726416796.8bf5d89973e8.2457.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Sep15_16-23-36_8bf5d89973e8/events.out.tfevents.1726417490.8bf5d89973e8.2803.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Sep15_16-23-36_8bf5d89973e8/events.out.tfevents.1726421976.8bf5d89973e8.2803.1', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Sep17_17-10-42_f5c89788b4e2/events.out.tfevents.1726593195.f5c89788b4e2.2176471.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Sep17_17-16-47_f5c89788b4e2/events.out.tfevents.1726593577.f5c89788b4e2.2179897.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Sep17_17-37-31_f5c89788b4e2/events.out.tfevents.1726594777.f5c89788b4e2.2191357.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Sep17_17-52-37_f5c89788b4e2/events.out.tfevents.1726595681.f5c89788b4e2.2200488.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Sep17_17-52-37_f5c89788b4e2/events.out.tfevents.1726636616.f5c89788b4e2.2200488.1', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Sep18_14-15-33_65ecb96dba42/events.out.tfevents.1726669044.65ecb96dba42.785.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Sep18_19-37-56_65ecb96dba42/events.out.tfevents.1726688361.65ecb96dba42.41972.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Sep18_20-46-35_65ecb96dba42/events.out.tfevents.1726692478.65ecb96dba42.1160.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Sep18_20-46-35_65ecb96dba42/events.out.tfevents.1726706643.65ecb96dba42.1160.1', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Sep20_22-18-14_65ecb96dba42/events.out.tfevents.1726870791.65ecb96dba42.231696.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Sep21_02-30-57_65ecb96dba42/events.out.tfevents.1726885944.65ecb96dba42.269402.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Sep21_02-30-57_65ecb96dba42/events.out.tfevents.1726899896.65ecb96dba42.269402.1', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": {""parameters"": {""BF16"": 8537680896}, ""total"": 8537680896}, ""security_repo_status"": null, ""lastModified"": ""2024-09-21 06:25:57+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- silviasapora/low_quality_dpo7k\nlibrary_name: transformers\nlicense: gemma\ntags:\n- alignment-handbook\n- trl\n- orpo\n- generated_from_trainer\nmodel-index:\n- name: gemma-7b-orpo-low-quality\n  results: []"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""66e7077ac8bad3f385704d92"", ""modelId"": ""silviasapora/gemma-7b-orpo-low-quality"", ""usedStorage"": 83036158976}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-orpo-low-quality&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-orpo-low-quality%5D(%2Fsilviasapora%2Fgemma-7b-orpo-low-quality)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-borpo-low-quality,"---
library_name: transformers
license: gemma
base_model: google/gemma-7b
tags:
- alignment-handbook
- trl
- orpo
- generated_from_trainer
- trl
- orpo
- generated_from_trainer
datasets:
- silviasapora/low_quality_dpo7k
model-index:
- name: gemma-7b-borpo-low-quality
  results: []
---

<!-- This model card has been generated automatically according to the information the Trainer had access to. You
should probably proofread and complete it, then remove this comment. -->

# gemma-7b-borpo-low-quality

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the silviasapora/low_quality_dpo7k dataset.
It achieves the following results on the evaluation set:
- Loss: 1.5380
- Rewards/chosen: -0.0547
- Rewards/rejected: -0.0625
- Rewards/accuracies: 0.5468
- Rewards/margins: 0.0079
- Logps/rejected: -1.2508
- Logps/chosen: -1.0933
- Logits/rejected: 267.2346
- Logits/chosen: 296.6808
- Nll Loss: 1.4703
- Log Odds Ratio: -0.7039
- Log Odds Chosen: 0.2721

## Model description

More information needed

## Intended uses & limitations

More information needed

## Training and evaluation data

More information needed

## Training procedure

### Training hyperparameters

The following hyperparameters were used during training:
- learning_rate: 5e-06
- train_batch_size: 2
- eval_batch_size: 1
- seed: 42
- distributed_type: multi-GPU
- num_devices: 4
- gradient_accumulation_steps: 4
- total_train_batch_size: 32
- total_eval_batch_size: 4
- optimizer: Adam with betas=(0.9,0.999) and epsilon=1e-08
- lr_scheduler_type: inverse_sqrt
- lr_scheduler_warmup_steps: 100
- num_epochs: 3

### Training results

| Training Loss | Epoch  | Step | Validation Loss | Rewards/chosen | Rewards/rejected | Rewards/accuracies | Rewards/margins | Logps/rejected | Logps/chosen | Logits/rejected | Logits/chosen | Nll Loss | Log Odds Ratio | Log Odds Chosen |
|:-------------:|:------:|:----:|:---------------:|:--------------:|:----------------:|:------------------:|:---------------:|:--------------:|:------------:|:---------------:|:-------------:|:--------:|:--------------:|:---------------:|
| 1.436         | 0.9955 | 167  | 1.4639          | -0.0502        | -0.0571          | 0.5540             | 0.0068          | -1.1413        | -1.0048      | 294.2689        | 322.9157      | 1.4152   | -0.6882        | 0.2192          |
| 1.0918        | 1.9970 | 335  | 1.4233          | -0.0501        | -0.0574          | 0.4964             | 0.0073          | -1.1475        | -1.0012      | 284.8744        | 313.3100      | 1.3661   | -0.7028        | 0.2209          |
| 0.576         | 2.9866 | 501  | 1.5380          | -0.0547        | -0.0625          | 0.5468             | 0.0079          | -1.2508        | -1.0933      | 267.2346        | 296.6808      | 1.4703   | -0.7039        | 0.2721          |


### Framework versions

- Transformers 4.44.2
- Pytorch 2.4.0+cu121
- Datasets 3.0.0
- Tokenizers 0.19.1
","{""id"": ""silviasapora/gemma-7b-borpo-low-quality"", ""author"": ""silviasapora"", ""sha"": ""b669047b0495ec223cd3cf7ab316a03842ad6723"", ""last_modified"": ""2024-09-21 02:30:35+00:00"", ""created_at"": ""2024-09-20 21:19:33+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""alignment-handbook"", ""trl"", ""orpo"", ""generated_from_trainer"", ""conversational"", ""dataset:silviasapora/low_quality_dpo7k"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""license:gemma"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- silviasapora/low_quality_dpo7k\nlibrary_name: transformers\nlicense: gemma\ntags:\n- alignment-handbook\n- trl\n- orpo\n- generated_from_trainer\nmodel-index:\n- name: gemma-7b-borpo-low-quality\n  results: []"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": [{""name"": ""gemma-7b-borpo-low-quality"", ""results"": []}], ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<|im_start|>"", ""chat_template"": ""{% for message in messages %}{{'<|im_start|>' + message['role'] + '\n' + message['content'] + '<|im_end|>' + '\n'}}{% endfor %}{% if add_generation_prompt %}{{ '<|im_start|>assistant\n' }}{% endif %}"", ""eos_token"": ""<|im_end|>"", ""pad_token"": ""<|im_end|>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='eval_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='generation_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00001-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00002-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00003-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00004-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model.safetensors.index.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Sep20_21-28-51_65ecb96dba42/events.out.tfevents.1726867828.65ecb96dba42.202062.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Sep20_21-31-58_65ecb96dba42/events.out.tfevents.1726868017.65ecb96dba42.204459.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Sep20_21-39-49_65ecb96dba42/events.out.tfevents.1726868472.65ecb96dba42.209667.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Sep20_21-43-04_65ecb96dba42/events.out.tfevents.1726868682.65ecb96dba42.212134.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Sep20_22-20-48_65ecb96dba42/events.out.tfevents.1726870945.65ecb96dba42.233626.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Sep20_22-31-39_65ecb96dba42/events.out.tfevents.1726871582.65ecb96dba42.240178.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Sep20_22-31-39_65ecb96dba42/events.out.tfevents.1726885774.65ecb96dba42.240178.1', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": {""parameters"": {""BF16"": 8537680896}, ""total"": 8537680896}, ""security_repo_status"": null, ""lastModified"": ""2024-09-21 02:30:35+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- silviasapora/low_quality_dpo7k\nlibrary_name: transformers\nlicense: gemma\ntags:\n- alignment-handbook\n- trl\n- orpo\n- generated_from_trainer\nmodel-index:\n- name: gemma-7b-borpo-low-quality\n  results: []"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""66ede6e50989ae1ac1fc6eff"", ""modelId"": ""silviasapora/gemma-7b-borpo-low-quality"", ""usedStorage"": 17092999478}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-borpo-low-quality&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-borpo-low-quality%5D(%2Fsilviasapora%2Fgemma-7b-borpo-low-quality)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-borpo,"---
library_name: transformers
license: gemma
base_model: google/gemma-7b
tags:
- alignment-handbook
- trl
- orpo
- generated_from_trainer
- trl
- orpo
- generated_from_trainer
datasets:
- argilla/dpo-mix-7k
model-index:
- name: gemma-7b-borpo
  results: []
---

<!-- This model card has been generated automatically according to the information the Trainer had access to. You
should probably proofread and complete it, then remove this comment. -->

# gemma-7b-borpo

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the argilla/dpo-mix-7k dataset.
It achieves the following results on the evaluation set:
- Loss: 1.5984
- Rewards/chosen: -0.0575
- Rewards/rejected: -0.0699
- Rewards/accuracies: 0.5899
- Rewards/margins: 0.0124
- Logps/rejected: -1.3977
- Logps/chosen: -1.1506
- Logits/rejected: 270.9628
- Logits/chosen: 299.8625
- Nll Loss: 1.5312
- Log Odds Ratio: -0.6761
- Log Odds Chosen: 0.3679

## Model description

More information needed

## Intended uses & limitations

More information needed

## Training and evaluation data

More information needed

## Training procedure

### Training hyperparameters

The following hyperparameters were used during training:
- learning_rate: 5e-06
- train_batch_size: 2
- eval_batch_size: 1
- seed: 42
- distributed_type: multi-GPU
- num_devices: 4
- gradient_accumulation_steps: 4
- total_train_batch_size: 32
- total_eval_batch_size: 4
- optimizer: Adam with betas=(0.9,0.999) and epsilon=1e-08
- lr_scheduler_type: inverse_sqrt
- lr_scheduler_warmup_steps: 100
- num_epochs: 3

### Training results

| Training Loss | Epoch  | Step | Validation Loss | Rewards/chosen | Rewards/rejected | Rewards/accuracies | Rewards/margins | Logps/rejected | Logps/chosen | Logits/rejected | Logits/chosen | Nll Loss | Log Odds Ratio | Log Odds Chosen |
|:-------------:|:------:|:----:|:---------------:|:--------------:|:----------------:|:------------------:|:---------------:|:--------------:|:------------:|:---------------:|:-------------:|:--------:|:--------------:|:---------------:|
| 1.4516        | 0.9968 | 157  | 1.4765          | -0.0513        | -0.0577          | 0.5468             | 0.0064          | -1.1547        | -1.0260      | 293.8872        | 321.9495      | 1.4282   | -0.6924        | 0.1911          |
| 1.0587        | 2.0    | 315  | 1.4250          | -0.0502        | -0.0595          | 0.5468             | 0.0093          | -1.1904        | -1.0035      | 296.0850        | 323.6012      | 1.3729   | -0.6901        | 0.2723          |
| 0.5897        | 2.9905 | 471  | 1.5984          | -0.0575        | -0.0699          | 0.5899             | 0.0124          | -1.3977        | -1.1506      | 270.9628        | 299.8625      | 1.5312   | -0.6761        | 0.3679          |


### Framework versions

- Transformers 4.44.2
- Pytorch 2.4.0+cu121
- Datasets 3.0.0
- Tokenizers 0.19.1
","{""id"": ""silviasapora/gemma-7b-borpo"", ""author"": ""silviasapora"", ""sha"": ""799de5bd3046bccd9596ccb59dea9b1d94ad349f"", ""last_modified"": ""2024-09-21 16:20:41+00:00"", ""created_at"": ""2024-09-21 12:43:28+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""alignment-handbook"", ""trl"", ""orpo"", ""generated_from_trainer"", ""conversational"", ""dataset:argilla/dpo-mix-7k"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""license:gemma"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nlicense: gemma\ntags:\n- alignment-handbook\n- trl\n- orpo\n- generated_from_trainer\nmodel-index:\n- name: gemma-7b-borpo\n  results: []"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": [{""name"": ""gemma-7b-borpo"", ""results"": []}], ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<|im_start|>"", ""chat_template"": ""{% for message in messages %}{{'<|im_start|>' + message['role'] + '\n' + message['content'] + '<|im_end|>' + '\n'}}{% endfor %}{% if add_generation_prompt %}{{ '<|im_start|>assistant\n' }}{% endif %}"", ""eos_token"": ""<|im_end|>"", ""pad_token"": ""<|im_end|>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='eval_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='generation_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00001-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00002-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00003-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00004-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model.safetensors.index.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Sep21_12-42-46_65ecb96dba42/events.out.tfevents.1726922648.65ecb96dba42.271982.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Sep21_12-42-46_65ecb96dba42/events.out.tfevents.1726935580.65ecb96dba42.271982.1', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": {""parameters"": {""BF16"": 8537680896}, ""total"": 8537680896}, ""security_repo_status"": null, ""lastModified"": ""2024-09-21 16:20:41+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nlicense: gemma\ntags:\n- alignment-handbook\n- trl\n- orpo\n- generated_from_trainer\nmodel-index:\n- name: gemma-7b-borpo\n  results: []"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""66eebf705a65f26be75412c9"", ""modelId"": ""silviasapora/gemma-7b-borpo"", ""usedStorage"": 17092965476}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-borpo&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-borpo%5D(%2Fsilviasapora%2Fgemma-7b-borpo)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
c-alfano/gemma-7b-borpo-low-quality-v2,"---
library_name: transformers
license: gemma
base_model: google/gemma-7b
tags:
- alignment-handbook
- trl
- orpo
- generated_from_trainer
- trl
- orpo
- generated_from_trainer
datasets:
- silviasapora/low_quality_dpo7k
model-index:
- name: gemma-7b-borpo-low-quality-v2
  results: []
---

<!-- This model card has been generated automatically according to the information the Trainer had access to. You
should probably proofread and complete it, then remove this comment. -->

# gemma-7b-borpo-low-quality-v2

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the silviasapora/low_quality_dpo7k dataset.
It achieves the following results on the evaluation set:
- Loss: 1.6017
- Rewards/chosen: -0.0578
- Rewards/rejected: -0.0690
- Rewards/accuracies: 0.5714
- Rewards/margins: 0.0112
- Logps/rejected: -1.3795
- Logps/chosen: -1.1561
- Logits/rejected: 249.0934
- Logits/chosen: 304.2649
- Nll Loss: 1.5643
- Log Odds Ratio: -0.6745
- Log Odds Chosen: 0.3316

## Model description

More information needed

## Intended uses & limitations

More information needed

## Training and evaluation data

More information needed

## Training procedure

### Training hyperparameters

The following hyperparameters were used during training:
- learning_rate: 5e-06
- train_batch_size: 2
- eval_batch_size: 1
- seed: 42
- distributed_type: multi-GPU
- num_devices: 8
- gradient_accumulation_steps: 2
- total_train_batch_size: 32
- total_eval_batch_size: 8
- optimizer: Adam with betas=(0.9,0.999) and epsilon=1e-08
- lr_scheduler_type: inverse_sqrt
- lr_scheduler_warmup_steps: 100
- num_epochs: 3

### Training results

| Training Loss | Epoch | Step | Validation Loss | Rewards/chosen | Rewards/rejected | Rewards/accuracies | Rewards/margins | Logps/rejected | Logps/chosen | Logits/rejected | Logits/chosen | Nll Loss | Log Odds Ratio | Log Odds Chosen |
|:-------------:|:-----:|:----:|:---------------:|:--------------:|:----------------:|:------------------:|:---------------:|:--------------:|:------------:|:---------------:|:-------------:|:--------:|:--------------:|:---------------:|
| 1.4218        | 1.0   | 168  | 1.4488          | -0.0504        | -0.0580          | 0.5571             | 0.0076          | -1.1591        | -1.0071      | 273.7526        | 326.8029      | 1.4553   | -0.6712        | 0.2324          |
| 1.0804        | 2.0   | 336  | 1.4225          | -0.0511        | -0.0591          | 0.5143             | 0.0080          | -1.1830        | -1.0220      | 278.2473        | 330.5067      | 1.4083   | -0.6897        | 0.2152          |
| 0.5651        | 3.0   | 504  | 1.6017          | -0.0578        | -0.0690          | 0.5714             | 0.0112          | -1.3795        | -1.1561      | 249.0934        | 304.2649      | 1.5643   | -0.6745        | 0.3316          |


### Framework versions

- Transformers 4.44.2
- Pytorch 2.4.1+cu121
- Datasets 3.0.0
- Tokenizers 0.19.1
","{""id"": ""c-alfano/gemma-7b-borpo-low-quality-v2"", ""author"": ""c-alfano"", ""sha"": ""10dc65c0417a709fb05590c9515313feb46ee331"", ""last_modified"": ""2024-09-22 02:47:38+00:00"", ""created_at"": ""2024-09-21 22:12:53+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""alignment-handbook"", ""trl"", ""orpo"", ""generated_from_trainer"", ""conversational"", ""dataset:silviasapora/low_quality_dpo7k"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""license:gemma"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- silviasapora/low_quality_dpo7k\nlibrary_name: transformers\nlicense: gemma\ntags:\n- alignment-handbook\n- trl\n- orpo\n- generated_from_trainer\nmodel-index:\n- name: gemma-7b-borpo-low-quality-v2\n  results: []"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": [{""name"": ""gemma-7b-borpo-low-quality-v2"", ""results"": []}], ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<|im_start|>"", ""chat_template"": ""{% for message in messages %}{{'<|im_start|>' + message['role'] + '\n' + message['content'] + '<|im_end|>' + '\n'}}{% endfor %}{% if add_generation_prompt %}{{ '<|im_start|>assistant\n' }}{% endif %}"", ""eos_token"": ""<|im_end|>"", ""pad_token"": ""<|im_end|>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='eval_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='generation_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00001-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00002-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00003-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00004-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model.safetensors.index.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Sep21_23-19-02_zizgpu06.cpu.stats.ox.ac.uk/events.out.tfevents.1726957242.zizgpu06.cpu.stats.ox.ac.uk.3719260.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Sep21_23-27-14_zizgpu06.cpu.stats.ox.ac.uk/events.out.tfevents.1726957733.zizgpu06.cpu.stats.ox.ac.uk.3721591.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Sep21_23-27-14_zizgpu06.cpu.stats.ox.ac.uk/events.out.tfevents.1726973121.zizgpu06.cpu.stats.ox.ac.uk.3721591.1', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": {""parameters"": {""BF16"": 8537680896}, ""total"": 8537680896}, ""security_repo_status"": null, ""lastModified"": ""2024-09-22 02:47:38+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- silviasapora/low_quality_dpo7k\nlibrary_name: transformers\nlicense: gemma\ntags:\n- alignment-handbook\n- trl\n- orpo\n- generated_from_trainer\nmodel-index:\n- name: gemma-7b-borpo-low-quality-v2\n  results: []"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""66ef44e5e9c6e64c662b506e"", ""modelId"": ""c-alfano/gemma-7b-borpo-low-quality-v2"", ""usedStorage"": 17092976210}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=c-alfano/gemma-7b-borpo-low-quality-v2&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bc-alfano%2Fgemma-7b-borpo-low-quality-v2%5D(%2Fc-alfano%2Fgemma-7b-borpo-low-quality-v2)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
c-alfano/gemma-7b-borpo-low-quality-v3,"---
library_name: transformers
license: gemma
base_model: google/gemma-7b
tags:
- alignment-handbook
- trl
- orpo
- generated_from_trainer
- trl
- orpo
- generated_from_trainer
datasets:
- silviasapora/low_quality_dpo7k
model-index:
- name: gemma-7b-borpo-low-quality-v3
  results: []
---

<!-- This model card has been generated automatically according to the information the Trainer had access to. You
should probably proofread and complete it, then remove this comment. -->

# gemma-7b-borpo-low-quality-v3

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the silviasapora/low_quality_dpo7k dataset.
It achieves the following results on the evaluation set:
- Loss: 2.1095
- Rewards/chosen: -0.6954
- Rewards/rejected: -0.8346
- Rewards/accuracies: 0.5571
- Rewards/margins: 0.1392
- Logps/rejected: -1.6692
- Logps/chosen: -1.3909
- Logits/rejected: 262.5518
- Logits/chosen: 319.3429
- Nll Loss: 1.7836
- Log Odds Ratio: -0.6395
- Log Odds Chosen: 0.4455

## Model description

More information needed

## Intended uses & limitations

More information needed

## Training and evaluation data

More information needed

## Training procedure

### Training hyperparameters

The following hyperparameters were used during training:
- learning_rate: 1e-05
- train_batch_size: 2
- eval_batch_size: 1
- seed: 42
- distributed_type: multi-GPU
- num_devices: 8
- gradient_accumulation_steps: 2
- total_train_batch_size: 32
- total_eval_batch_size: 8
- optimizer: Adam with betas=(0.9,0.999) and epsilon=1e-08
- lr_scheduler_type: inverse_sqrt
- lr_scheduler_warmup_steps: 100
- num_epochs: 3

### Training results

| Training Loss | Epoch | Step | Validation Loss | Rewards/chosen | Rewards/rejected | Rewards/accuracies | Rewards/margins | Logps/rejected | Logps/chosen | Logits/rejected | Logits/chosen | Nll Loss | Log Odds Ratio | Log Odds Chosen |
|:-------------:|:-----:|:----:|:---------------:|:--------------:|:----------------:|:------------------:|:---------------:|:--------------:|:------------:|:---------------:|:-------------:|:--------:|:--------------:|:---------------:|
| 1.9721        | 1.0   | 168  | 1.9526          | -0.6072        | -0.7027          | 0.5571             | 0.0955          | -1.4054        | -1.2144      | 282.1215        | 336.2867      | 1.6515   | -0.6573        | 0.2649          |
| 1.3299        | 2.0   | 336  | 1.9015          | -0.5986        | -0.6805          | 0.5                | 0.0820          | -1.3611        | -1.1972      | 293.2820        | 345.2333      | 1.5933   | -0.6792        | 0.2173          |
| 0.6266        | 3.0   | 504  | 2.1095          | -0.6954        | -0.8346          | 0.5571             | 0.1392          | -1.6692        | -1.3909      | 262.5518        | 319.3429      | 1.7836   | -0.6395        | 0.4455          |


### Framework versions

- Transformers 4.44.2
- Pytorch 2.4.1+cu121
- Datasets 3.0.0
- Tokenizers 0.19.1
","{""id"": ""c-alfano/gemma-7b-borpo-low-quality-v3"", ""author"": ""c-alfano"", ""sha"": ""475332f2a811cc2565c1dfdf4d3361c391de8a23"", ""last_modified"": ""2024-09-22 15:36:57+00:00"", ""created_at"": ""2024-09-22 11:11:58+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""alignment-handbook"", ""trl"", ""orpo"", ""generated_from_trainer"", ""conversational"", ""dataset:silviasapora/low_quality_dpo7k"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""license:gemma"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- silviasapora/low_quality_dpo7k\nlibrary_name: transformers\nlicense: gemma\ntags:\n- alignment-handbook\n- trl\n- orpo\n- generated_from_trainer\nmodel-index:\n- name: gemma-7b-borpo-low-quality-v3\n  results: []"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": [{""name"": ""gemma-7b-borpo-low-quality-v3"", ""results"": []}], ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<|im_start|>"", ""chat_template"": ""{% for message in messages %}{{'<|im_start|>' + message['role'] + '\n' + message['content'] + '<|im_end|>' + '\n'}}{% endfor %}{% if add_generation_prompt %}{{ '<|im_start|>assistant\n' }}{% endif %}"", ""eos_token"": ""<|im_end|>"", ""pad_token"": ""<|im_end|>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='eval_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='generation_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00001-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00002-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00003-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00004-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model.safetensors.index.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Sep22_12-11-01_zizgpu06.cpu.stats.ox.ac.uk/events.out.tfevents.1727003560.zizgpu06.cpu.stats.ox.ac.uk.3873994.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Sep22_12-11-01_zizgpu06.cpu.stats.ox.ac.uk/events.out.tfevents.1727019280.zizgpu06.cpu.stats.ox.ac.uk.3873994.1', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": {""parameters"": {""BF16"": 8537680896}, ""total"": 8537680896}, ""security_repo_status"": null, ""lastModified"": ""2024-09-22 15:36:57+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- silviasapora/low_quality_dpo7k\nlibrary_name: transformers\nlicense: gemma\ntags:\n- alignment-handbook\n- trl\n- orpo\n- generated_from_trainer\nmodel-index:\n- name: gemma-7b-borpo-low-quality-v3\n  results: []"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""66effb7ea67d89bbe42fd96f"", ""modelId"": ""c-alfano/gemma-7b-borpo-low-quality-v3"", ""usedStorage"": 17092970774}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=c-alfano/gemma-7b-borpo-low-quality-v3&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bc-alfano%2Fgemma-7b-borpo-low-quality-v3%5D(%2Fc-alfano%2Fgemma-7b-borpo-low-quality-v3)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
c-alfano/gemma-7b-borpo-low-quality-v4,"---
library_name: transformers
license: gemma
base_model: google/gemma-7b
tags:
- alignment-handbook
- trl
- orpo
- generated_from_trainer
- trl
- orpo
- alignment-handbook
- generated_from_trainer
datasets:
- silviasapora/low_quality_dpo7k
model-index:
- name: gemma-7b-borpo-low-quality-v4
  results: []
---

<!-- This model card has been generated automatically according to the information the Trainer had access to. You
should probably proofread and complete it, then remove this comment. -->

# gemma-7b-borpo-low-quality-v4

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the silviasapora/low_quality_dpo7k dataset.
It achieves the following results on the evaluation set:
- Loss: 1.8577
- Rewards/chosen: -0.5993
- Rewards/rejected: -0.7602
- Rewards/accuracies: 0.6143
- Rewards/margins: 0.1610
- Logps/rejected: -1.5205
- Logps/chosen: -1.1986
- Logits/rejected: 240.3907
- Logits/chosen: 301.1215
- Nll Loss: 1.5532
- Log Odds Ratio: -0.6421
- Log Odds Chosen: 0.4396

## Model description

More information needed

## Intended uses & limitations

More information needed

## Training and evaluation data

More information needed

## Training procedure

### Training hyperparameters

The following hyperparameters were used during training:
- learning_rate: 5e-06
- train_batch_size: 2
- eval_batch_size: 1
- seed: 42
- distributed_type: multi-GPU
- num_devices: 8
- gradient_accumulation_steps: 4
- total_train_batch_size: 64
- total_eval_batch_size: 8
- optimizer: Adam with betas=(0.9,0.999) and epsilon=1e-08
- lr_scheduler_type: inverse_sqrt
- lr_scheduler_warmup_steps: 100
- num_epochs: 3

### Training results

| Training Loss | Epoch | Step | Validation Loss | Rewards/chosen | Rewards/rejected | Rewards/accuracies | Rewards/margins | Logps/rejected | Logps/chosen | Logits/rejected | Logits/chosen | Nll Loss | Log Odds Ratio | Log Odds Chosen |
|:-------------:|:-----:|:----:|:---------------:|:--------------:|:----------------:|:------------------:|:---------------:|:--------------:|:------------:|:---------------:|:-------------:|:--------:|:--------------:|:---------------:|
| 1.8227        | 1.0   | 84   | 1.9616          | -0.6050        | -0.6743          | 0.5                | 0.0693          | -1.3486        | -1.2099      | 257.8447        | 315.1940      | 1.6719   | -0.6903        | 0.1646          |
| 1.4803        | 2.0   | 168  | 1.7681          | -0.5462        | -0.6508          | 0.5286             | 0.1046          | -1.3017        | -1.0924      | 274.3526        | 328.0207      | 1.4854   | -0.6718        | 0.2561          |
| 0.9109        | 3.0   | 252  | 1.8577          | -0.5993        | -0.7602          | 0.6143             | 0.1610          | -1.5205        | -1.1986      | 240.3907        | 301.1215      | 1.5532   | -0.6421        | 0.4396          |


### Framework versions

- Transformers 4.44.2
- Pytorch 2.4.1+cu121
- Datasets 3.0.0
- Tokenizers 0.19.1
","{""id"": ""c-alfano/gemma-7b-borpo-low-quality-v4"", ""author"": ""c-alfano"", ""sha"": ""3d4c927ab780970cee6dae29511aff827d9383e3"", ""last_modified"": ""2024-09-23 20:14:06+00:00"", ""created_at"": ""2024-09-22 16:16:05+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 1, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""alignment-handbook"", ""trl"", ""orpo"", ""generated_from_trainer"", ""conversational"", ""dataset:silviasapora/low_quality_dpo7k"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""license:gemma"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- silviasapora/low_quality_dpo7k\nlibrary_name: transformers\nlicense: gemma\ntags:\n- alignment-handbook\n- trl\n- orpo\n- generated_from_trainer\nmodel-index:\n- name: gemma-7b-borpo-low-quality-v4\n  results: []"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": [{""name"": ""gemma-7b-borpo-low-quality-v4"", ""results"": []}], ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<|im_start|>"", ""chat_template"": ""{% for message in messages %}{{'<|im_start|>' + message['role'] + '\n' + message['content'] + '<|im_end|>' + '\n'}}{% endfor %}{% if add_generation_prompt %}{{ '<|im_start|>assistant\n' }}{% endif %}"", ""eos_token"": ""<|im_end|>"", ""pad_token"": ""<|im_end|>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='eval_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='generation_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00001-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00002-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00003-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00004-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model.safetensors.index.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Sep22_17-15-08_zizgpu06.cpu.stats.ox.ac.uk/events.out.tfevents.1727021816.zizgpu06.cpu.stats.ox.ac.uk.3932700.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Sep22_17-15-08_zizgpu06.cpu.stats.ox.ac.uk/events.out.tfevents.1727054119.zizgpu06.cpu.stats.ox.ac.uk.3932700.1', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Sep23_17-22-00_zizgpu06.cpu.stats.ox.ac.uk/events.out.tfevents.1727108622.zizgpu06.cpu.stats.ox.ac.uk.54426.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Sep23_17-22-00_zizgpu06.cpu.stats.ox.ac.uk/events.out.tfevents.1727122310.zizgpu06.cpu.stats.ox.ac.uk.54426.1', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": {""parameters"": {""BF16"": 8537680896}, ""total"": 8537680896}, ""security_repo_status"": null, ""lastModified"": ""2024-09-23 20:14:06+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- silviasapora/low_quality_dpo7k\nlibrary_name: transformers\nlicense: gemma\ntags:\n- alignment-handbook\n- trl\n- orpo\n- generated_from_trainer\nmodel-index:\n- name: gemma-7b-borpo-low-quality-v4\n  results: []"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""66f042c582d5de5715d737e8"", ""modelId"": ""c-alfano/gemma-7b-borpo-low-quality-v4"", ""usedStorage"": 34168421031}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=c-alfano/gemma-7b-borpo-low-quality-v4&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bc-alfano%2Fgemma-7b-borpo-low-quality-v4%5D(%2Fc-alfano%2Fgemma-7b-borpo-low-quality-v4)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
OpenLLM-Ro/RoGemma-7b-Instruct-2024-10-09,"---
license: cc-by-nc-4.0
language:
- ro
base_model:
- google/gemma-7b
datasets:
- OpenLLM-Ro/ro_sft_alpaca
- OpenLLM-Ro/ro_sft_alpaca_gpt4
- OpenLLM-Ro/ro_sft_dolly
- OpenLLM-Ro/ro_sft_selfinstruct_gpt4
- OpenLLM-Ro/ro_sft_norobots
- OpenLLM-Ro/ro_sft_orca
- OpenLLM-Ro/ro_sft_camel
- OpenLLM-Ro/ro_sft_oasst
- OpenLLM-Ro/ro_sft_ultrachat
model-index:
    - name: OpenLLM-Ro/RoGemma-7b-Instruct-2024-10-09
      results:
        - task:
            type: text-generation
          dataset:
            name: RoMT-Bench
            type: RoMT-Bench
          metrics:
            - name: Score
              type: Score
              value: 5.24
        - task:
            type: text-generation
          dataset:
            name: RoCulturaBench
            type: RoCulturaBench
          metrics:
            - name: Score
              type: Score
              value: 3.51
        - task:
            type: text-generation
          dataset:
            name: Romanian_Academic_Benchmarks
            type: Romanian_Academic_Benchmarks
          metrics:
            - name: Average accuracy
              type: accuracy
              value: 50.48
        - task:
            type: text-generation
          dataset:
            name: OpenLLM-Ro/ro_arc_challenge
            type: OpenLLM-Ro/ro_arc_challenge
          metrics:
            - name: Average accuracy
              type: accuracy
              value: 52.01
        - task:
            type: text-generation
          dataset:
            name: OpenLLM-Ro/ro_mmlu
            type: OpenLLM-Ro/ro_mmlu
          metrics:
            - name: Average accuracy
              type: accuracy
              value: 52.37
        - task:
            type: text-generation
          dataset:
            name: OpenLLM-Ro/ro_winogrande
            type: OpenLLM-Ro/ro_winogrande
          metrics:
            - name: Average accuracy
              type: accuracy
              value: 66.97
        - task:
            type: text-generation
          dataset:
            name: OpenLLM-Ro/ro_hellaswag
            type: OpenLLM-Ro/ro_hellaswag
          metrics:
            - name: Average accuracy
              type: accuracy
              value: 56.34
        - task:
            type: text-generation
          dataset:
            name: OpenLLM-Ro/ro_gsm8k
            type: OpenLLM-Ro/ro_gsm8k
          metrics:
            - name: Average accuracy
              type: accuracy
              value: 25.98
        - task:
            type: text-generation
          dataset:
            name: OpenLLM-Ro/ro_truthfulqa
            type: OpenLLM-Ro/ro_truthfulqa
          metrics:
            - name: Average accuracy
              type: accuracy
              value: 49.18
        - task:
            type: text-generation
          dataset:
            name: LaRoSeDa_binary
            type: LaRoSeDa_binary
          metrics:
            - name: Average macro-f1
              type: macro-f1
              value: 86.96
        - task:
            type: text-generation
          dataset:
            name: LaRoSeDa_multiclass
            type: LaRoSeDa_multiclass
          metrics:
            - name: Average macro-f1
              type: macro-f1
              value: 56.72
        - task:
            type: text-generation
          dataset:
            name: LaRoSeDa_binary_finetuned
            type: LaRoSeDa_binary_finetuned
          metrics:
            - name: Average macro-f1
              type: macro-f1
              value: 98.80
        - task:
            type: text-generation
          dataset:
            name: LaRoSeDa_multiclass_finetuned
            type: LaRoSeDa_multiclass_finetuned
          metrics:
            - name: Average macro-f1
              type: macro-f1
              value: 85.81
        - task:
            type: text-generation
          dataset:
            name: WMT_EN-RO
            type: WMT_EN-RO
          metrics:
            - name: Average bleu
              type: bleu
              value: 24.45
        - task:
            type: text-generation
          dataset:
            name: WMT_RO-EN
            type: WMT_RO-EN
          metrics:
            - name: Average bleu
              type: bleu
              value: 14.20
        - task:
            type: text-generation
          dataset:
            name: WMT_EN-RO_finetuned
            type: WMT_EN-RO_finetuned
          metrics:
            - name: Average bleu
              type: bleu
              value: 25.96
        - task:
            type: text-generation
          dataset:
            name: WMT_RO-EN_finetuned
            type: WMT_RO-EN_finetuned
          metrics:
            - name: Average bleu
              type: bleu
              value: 39.07
        - task:
            type: text-generation
          dataset:
            name: XQuAD
            type: XQuAD
          metrics:
            - name: Average exact_match
              type: exact_match
              value: 26.03
        - task:
            type: text-generation
          dataset:
            name: XQuAD
            type: XQuAD
          metrics:
            - name: Average f1
              type: f1
              value: 41.58
        - task:
            type: text-generation
          dataset:
            name: XQuAD_finetuned
            type: XQuAD_finetuned
          metrics:
            - name: Average exact_match
              type: exact_match
              value: 46.72
        - task:
            type: text-generation
          dataset:
            name: XQuAD_finetuned
            type: XQuAD_finetuned
          metrics:
            - name: Average f1
              type: f1
              value: 60.79
        - task:
            type: text-generation
          dataset:
            name: STS
            type: STS
          metrics:
            - name: Average spearman
              type: spearman
              value: 73.23
        - task:
            type: text-generation
          dataset:
            name: STS
            type: STS
          metrics:
            - name: Average pearson
              type: pearson
              value: 71.58
        - task:
            type: text-generation
          dataset:
            name: STS_finetuned
            type: STS_finetuned
          metrics:
            - name: Average spearman
              type: spearman
              value: 88.42
        - task:
            type: text-generation
          dataset:
            name: STS_finetuned
            type: STS_finetuned
          metrics:
            - name: Average pearson
              type: pearson
              value: 88.45
        - task:
            type: text-generation
          dataset:
            name: RoMT-Bench
            type: RoMT-Bench
          metrics:
            - name: First turn
              type: Score
              value: 5.55
            - name: Second turn
              type: Score
              value: 4.94
        - task:
            type: text-generation
          dataset:
            name: OpenLLM-Ro/ro_arc_challenge
            type: OpenLLM-Ro/ro_arc_challenge
          metrics:
            - name: 0-shot 
              type: accuracy
              value: 49.53
            - name: 1-shot 
              type: accuracy
              value: 52.53
            - name: 3-shot 
              type: accuracy
              value: 51.50
            - name: 5-shot 
              type: accuracy
              value: 53.56
            - name: 10-shot 
              type: accuracy
              value: 52.53
            - name: 25-shot 
              type: accuracy
              value: 52.44
        - task:
            type: text-generation
          dataset:
            name: OpenLLM-Ro/ro_mmlu
            type: OpenLLM-Ro/ro_mmlu
          metrics:
            - name: 0-shot 
              type: accuracy
              value: 51.81
            - name: 1-shot 
              type: accuracy
              value: 52.45
            - name: 3-shot 
              type: accuracy
              value: 52.52
            - name: 5-shot 
              type: accuracy
              value: 52.70
        - task:
            type: text-generation
          dataset:
            name: OpenLLM-Ro/ro_winogrande
            type: OpenLLM-Ro/ro_winogrande
          metrics:
            - name: 0-shot 
              type: accuracy
              value: 66.54
            - name: 1-shot 
              type: accuracy
              value: 66.69
            - name: 3-shot 
              type: accuracy
              value: 67.09
            - name: 5-shot 
              type: accuracy
              value: 67.56
        - task:
            type: text-generation
          dataset:
            name: OpenLLM-Ro/ro_hellaswag
            type: OpenLLM-Ro/ro_hellaswag
          metrics:
            - name: 0-shot 
              type: accuracy
              value: 58.80
            - name: 1-shot 
              type: accuracy
              value: 57.04
            - name: 3-shot 
              type: accuracy
              value: 55.85
            - name: 5-shot 
              type: accuracy
              value: 54.15
            - name: 10-shot 
              type: accuracy
              value: 55.88
        - task:
            type: text-generation
          dataset:
            name: OpenLLM-Ro/ro_gsm8k
            type: OpenLLM-Ro/ro_gsm8k
          metrics:
            - name: 1-shot 
              type: accuracy
              value: 22.06
            - name: 3-shot 
              type: accuracy
              value: 25.40
            - name: 5-shot 
              type: accuracy
              value: 30.48
        - task:
            type: text-generation
          dataset:
            name: LaRoSeDa_binary
            type: LaRoSeDa_binary
          metrics:
            - name: 0-shot 
              type: macro-f1
              value: 87.28
            - name: 1-shot 
              type: macro-f1
              value: 86.40
            - name: 3-shot 
              type: macro-f1
              value: 87.95
            - name: 5-shot 
              type: macro-f1
              value: 86.20
        - task:
            type: text-generation
          dataset:
            name: LaRoSeDa_multiclass
            type: LaRoSeDa_multiclass
          metrics:
            - name: 0-shot 
              type: macro-f1
              value: 38.35
            - name: 1-shot 
              type: macro-f1
              value: 63.86
            - name: 3-shot 
              type: macro-f1
              value: 62.03
            - name: 5-shot 
              type: macro-f1
              value: 62.62
        - task:
            type: text-generation
          dataset:
            name: WMT_EN-RO
            type: WMT_EN-RO
          metrics:
            - name: 0-shot 
              type: bleu
              value: 11.39
            - name: 1-shot 
              type: bleu
              value: 28.08
            - name: 3-shot 
              type: bleu
              value: 29.18
            - name: 5-shot 
              type: bleu
              value: 29.13
        - task:
            type: text-generation
          dataset:
            name: WMT_RO-EN
            type: WMT_RO-EN
          metrics:
            - name: 0-shot 
              type: bleu
              value: 1.92
            - name: 1-shot 
              type: bleu
              value: 9.39
            - name: 3-shot 
              type: bleu
              value: 21.81
            - name: 5-shot 
              type: bleu
              value: 23.66
        - task:
            type: text-generation
          dataset:
            name: XQuAD_EM
            type: XQuAD_EM
          metrics:
            - name: 0-shot 
              type: exact_match
              value: 32.77
            - name: 1-shot 
              type: exact_match
              value: 20.25
            - name: 3-shot 
              type: exact_match
              value: 18.49
            - name: 5-shot 
              type: exact_match
              value: 32.60
        - task:
            type: text-generation
          dataset:
            name: XQuAD_F1
            type: XQuAD_F1
          metrics:
            - name: 0-shot 
              type: f1
              value: 47.98
            - name: 1-shot 
              type: f1
              value: 34.92
            - name: 3-shot 
              type: f1
              value: 33.27
            - name: 5-shot 
              type: f1
              value: 50.14
        - task:
            type: text-generation
          dataset:
            name: STS_Spearman
            type: STS_Spearman
          metrics:
            - name: 1-shot 
              type: spearman
              value: 71.75
            - name: 3-shot 
              type: spearman
              value: 71.83
            - name: 5-shot 
              type: spearman
              value: 76.11
        - task:
            type: text-generation
          dataset:
            name: STS_Pearson
            type: STS_Pearson
          metrics:
            - name: 1-shot 
              type: pearson
              value: 69.97
            - name: 3-shot 
              type: pearson
              value: 69.87
            - name: 5-shot 
              type: pearson
              value: 74.89

---

# Model Card for Model ID

<!-- Provide a quick summary of what the model is/does. -->

RoGemma is a family of pretrained and fine-tuned generative text models for Romanian. This is the repository for the **instruct 7B model**. Links to other models can be found at the bottom of this page.

## Model Details

### Model Description

<!-- Provide a longer summary of what this model is. -->
OpenLLM-Ro represents the first open-source effort to build a LLM specialized for Romanian. OpenLLM-Ro developed and publicly releases a collection of Romanian LLMs, both in the form of foundational model and instruct and chat variants.


- **Developed by:** OpenLLM-Ro
<!-- - **Funded by [optional]:** [More Information Needed] -->
<!-- - **Shared by [optional]:** [More Information Needed] -->
<!-- - **Model type:** [More Information Needed] -->
- **Language(s):** Romanian
- **License:** cc-by-nc-4.0
- **Finetuned from model:** [gemma-7b](https://huggingface.co/google/gemma-7b)
- **Trained using:** [RoAlpaca](https://huggingface.co/datasets/OpenLLM-Ro/ro_sft_alpaca), [RoAlpacaGPT4](https://huggingface.co/datasets/OpenLLM-Ro/ro_sft_alpaca_gpt4), [RoDolly](https://huggingface.co/datasets/OpenLLM-Ro/ro_sft_dolly), [RoSelfInstruct](https://huggingface.co/datasets/OpenLLM-Ro/ro_sft_selfinstruct_gpt4), [RoNoRobots](https://huggingface.co/datasets/OpenLLM-Ro/ro_sft_norobots), [RoOrca](https://huggingface.co/datasets/OpenLLM-Ro/ro_sft_orca), [RoCamel](https://huggingface.co/datasets/OpenLLM-Ro/ro_sft_camel), [RoOpenAssistant](https://huggingface.co/datasets/OpenLLM-Ro/ro_sft_oasst), [RoUltraChat](https://huggingface.co/datasets/OpenLLM-Ro/ro_sft_ultrachat)


### Model Sources

<!-- Provide the basic links for the model. -->

- **Repository:** https://github.com/OpenLLM-Ro/LLaMA-Factory
- **Paper:** https://arxiv.org/abs/2406.18266

## Intended Use

### Intended Use Cases

RoGemma is intented for research use in Romanian. Base models can be adapted for a variety of natural language tasks while instruction and chat tuned models are intended for assistant-like chat.

### Out-of-Scope Use

<!-- This section addresses misuse, malicious use, and uses that the model will not work well for. -->

Use in any manner that violates the license, any applicable laws or regluations, use in languages other than Romanian.



## How to Get Started with the Model

Use the code below to get started with the model.

```python
from transformers import AutoTokenizer, AutoModelForCausalLM

tokenizer = AutoTokenizer.from_pretrained(""OpenLLM-Ro/RoGemma-7b-Instruct-2024-10-09"")
model = AutoModelForCausalLM.from_pretrained(""OpenLLM-Ro/RoGemma-7b-Instruct-2024-10-09"")

instruction = ""Ce jocuri de societate pot juca cu prietenii mei?""
chat = [
        {""role"": ""user"", ""content"": instruction},
        ]
prompt = tokenizer.apply_chat_template(chat, tokenize=False, system_message="""")

inputs = tokenizer.encode(prompt, add_special_tokens=False, return_tensors=""pt"")
outputs = model.generate(input_ids=inputs, max_new_tokens=128)
print(tokenizer.decode(outputs[0]))
```

## Academic Benchmarks

<table>
<tbody>
<tr>
<td><strong>Model</strong></td>
<td><strong><center>Average</center></strong></td>
<td><strong><center>ARC</center></strong></td>
<td><strong><center>MMLU</center></strong></td>
<td><strong><center>Winogrande</center></strong></td>
<td><strong><center>Hellaswag</center></strong></td>
<td><strong><center>GSM8k</center></strong></td>
<td><strong><center>TruthfulQA</center></strong></td>
</tr>
<tr>
<td>gemma-1.1-7b-it</td><td><center>41.44</center></td><td><center>40.32</center></td><td><center>47.22</center></td><td><center>55.01</center></td><td><center>47.03</center></td><td><center>9.50</center></td><td><center>49.58</center></td>
</tr>
<tr>
<td>RoGemma-7b-Instruct-2024-06-28</td><td><center><strong>53.41</strong></center></td><td><center><strong>52.44</strong></center></td><td><center>54.44</center></td><td><center><strong>69.36</strong></center></td><td><center><strong>61.96</strong></center></td><td><center>31.06</center></td><td><center><strong>51.23</strong></center></td>
</tr>
<tr>
<td><em>RoGemma-7b-Instruct-2024-10-09</em></td><td><center><em>50.48</em></center></td><td><center><em>52.01</em></center></td><td><center><em>52.37</em></center></td><td><center><em>66.97</em></center></td><td><center><em>56.34</em></center></td><td><center><em>25.98</em></center></td><td><center><em>49.18</em></center></td>
</tr>
<tr>
<td>RoGemma-7b-Instruct-DPO-2024-10-09</td><td><center>48.27</center></td><td><center>46.66</center></td><td><center><strong>54.45</strong></center></td><td><center>63.73</center></td><td><center>49.33</center></td><td><center><strong>34.98</strong></center></td><td><center>40.45</center></td>
</tr>
</tbody>
</table>


## Downstream tasks

<table>
<tbody>
<tr>
<td></td>
<td colspan=""4""><center><strong>LaRoSeDa</strong></center></td>
<td colspan=""4""><center><strong>WMT</strong></center></td>
</tr>
<tr>
<td></td>
<td colspan=""2""><center><strong>Few-shot</strong></center></td>
<td colspan=""2""><center><strong>Finetuned</strong></center></td>
<td colspan=""2""><center><strong>Few-shot</strong></center></td>
<td colspan=""2""><center><strong>Finetuned</strong></center></td>
</tr>
<tr>
<td><strong>Model</strong></td>
<td><center><strong>Binary<br>(Macro F1)</strong></center></td>
<td><center><strong>Multiclass<br>(Macro F1)</strong></center></td>
<td><center><strong>Binary<br>(Macro F1)</strong></center></td>
<td><center><strong>Multiclass<br>(Macro F1)</strong></center></td>
<td><center><strong>EN-RO<br>(Bleu)</strong></center></td>
<td><center><strong>RO-EN<br>(Bleu)</strong></center></td>
<td><center><strong>EN-RO<br>(Bleu)</strong></center></td>
<td><center><strong>RO-EN<br>(Bleu)</strong></center>
</tr>
<tr>
<td>gemma-1.1-7b-it</td><td><center>87.54</center></td><td><center>51.48</center></td><td><center>83.87</center></td><td><center>85.61</center></td><td><center>17.96</center></td><td><center><strong>27.74</strong></center></td><td><center>25.48</center></td><td><center>36.11</center></td>
</tr>
<tr>
<td>RoGemma-7b-Instruct-2024-06-28</td><td><center><strong>97.86</strong></center></td><td><center><strong>65.70</strong></center></td><td><center>98.43</center></td><td><center><strong>87.17</strong></center></td><td><center><strong>27.91</strong></center></td><td><center>23.08</center></td><td><center><strong>27.99</strong></center></td><td><center><strong>39.51</strong></center></td>
</tr>
<tr>
<td><em>RoGemma-7b-Instruct-2024-10-09</em></td><td><center><em>86.96</em></center></td><td><center><em>56.72</em></center></td><td><center><em><strong>98.80</strong></em></center></td><td><center><em>85.81</em></center></td><td><center><em>24.45</em></center></td><td><center><em>14.20</em></center></td><td><center><em>25.96</em></center></td><td><center><em>39.07</em></center></td>
</tr>
<tr>
<td>RoGemma-7b-Instruct-DPO-2024-10-09</td><td><center>96.45</center></td><td><center>63.23</center></td><td><center>-</center></td><td><center>-</center></td><td><center>20.73</center></td><td><center>7.87</center></td><td><center>-</center></td><td><center>-</center></td>
</tr>
</tbody>
</table>


<table>
<tbody>
<tr>
<td></td>
<td colspan=""4""><center><strong>XQuAD</strong></center></td>
<td colspan=""4""><center><strong>STS</strong></center></td>
</tr>
<tr>
<td></td>
<td colspan=""2""><center><strong>Few-shot</strong></center></td>
<td colspan=""2""><center><strong>Finetuned</strong></center></td>
<td colspan=""2""><center><strong>Few-shot</strong></center></td>
<td colspan=""2""><center><strong>Finetuned</strong></center></td>
</tr>
<tr>
<td><strong>Model</strong></td>
<td><center><strong>(EM)</strong></center></td>
<td><center><strong>(F1)</strong></center></td>
<td><center><strong>(EM)</strong></center></td>
<td><center><strong>(F1)</strong></center></td>
<td><center><strong>(Spearman)</strong></center></td>
<td><center><strong>(Pearson)</strong></center></td>
<td><center><strong>(Spearman)</strong></center></td>
<td><center><strong>(Pearson)</strong></center></td>
</tr>
<tr>
<td>gemma-1.1-7b-it</td><td><center><strong>42.10</strong></center></td><td><center><strong>62.30</strong></center></td><td><center><strong>60.34</strong></center></td><td><center><strong>77.40</strong></center></td><td><center>49.10</center></td><td><center>50.23</center></td><td><center>83.43</center></td><td><center>83.64</center></td>
</tr>
<tr>
<td>RoGemma-7b-Instruct-2024-06-28</td><td><center>17.75</center></td><td><center>28.11</center></td><td><center>52.02</center></td><td><center>68.43</center></td><td><center><strong>73.96</strong></center></td><td><center><strong>75.16</strong></center></td><td><center>86.45</center></td><td><center>86.31</center></td>
</tr>
<tr>
<td><em>RoGemma-7b-Instruct-2024-10-09</em></td><td><center><em>26.03</em></center></td><td><center><em>41.58</em></center></td><td><center><em>46.72</em></center></td><td><center><em>60.79</em></center></td><td><center><em>73.23</em></center></td><td><center><em>71.58</em></center></td><td><center><em><strong>88.42</strong></em></center></td><td><center><em><strong>88.45</strong></em></center></td>
</tr>
<tr>
<td>RoGemma-7b-Instruct-DPO-2024-10-09</td><td><center>19.14</center></td><td><center>38.10</center></td><td><center>-</center></td><td><center>-</center></td><td><center>69.38</center></td><td><center>69.34</center></td><td><center>-</center></td><td><center>-</center></td>
</tr>
</tbody>
</table>


## MT-Bench

<table>
<tbody>
<tr>
<td><strong>Model</strong></td>
<td><strong><center>Average</center></strong></td>
<td><strong><center>1st turn</center></strong></td>
<td><strong><center>2nd turn</center></strong></td>
<td><strong><center>Answers in Ro</center></strong></td>
</tr>
<tr>
<td>gemma-1.1-7b-it</td><td><center>4.83</center></td><td><center>5.11</center></td><td><center>4.55</center></td><td><center><strong>160/160</strong></center></td>
</tr>
<tr>
<td>RoGemma-7b-Instruct-2024-06-28</td><td><center>5.26</center></td><td><center><strong>5.92</strong></center></td><td><center>4.60</center></td><td><center><strong>160/160</strong></center></td>
</tr>
<tr>
<td><em>RoGemma-7b-Instruct-2024-10-09</em></td><td><center><em>5.24</em></center></td><td><center><em>5.55</em></center></td><td><center><em>4.94</em></center></td><td><center><em><strong>160/160</strong></em></center></td>
</tr>
<tr>
<td>RoGemma-7b-Instruct-DPO-2024-10-09</td><td><center><strong>5.47</strong></center></td><td><center><strong>5.92</strong></center></td><td><center><strong>5.03</strong></center></td><td><center><strong>160/160</strong></center></td>
</tr>
</tbody>
</table>

## RoCulturaBench

<table>
<tbody>
<tr>
<td><strong>Model</strong></td>
<td><strong><center>Average</center></strong></td>
<td><strong><center>Answers in Ro</center></strong></td>
</tr>
<tr>
<td>gemma-1.1-7b-it</td><td><center>3.38</center></td><td><center><strong>100/100</strong></center></td>
</tr>
<tr>
<td>RoGemma-7b-Instruct-2024-06-28</td><td><center>3.26</center></td><td><center><strong>100/100</strong></center></td>
</tr>
<tr>
<td><em>RoGemma-7b-Instruct-2024-10-09</em></td><td><center><em>3.51</em></center></td><td><center><em><strong>100/100</strong></em></center></td>
</tr>
<tr>
<td>RoGemma-7b-Instruct-DPO-2024-10-09</td><td><center><strong>3.94</strong></center></td><td><center><strong>100/100</strong></center></td>
</tr>
</tbody>
</table>

## RoGemma Model Family

| Model              | Link  |
|--------------------|:--------:|
|RoGemma-7b-Instruct-2024-06-28| [link](https://huggingface.co/OpenLLM-Ro/RoGemma-7b-Instruct-2024-06-28) |
|*RoGemma-7b-Instruct-2024-10-09*| [link](https://huggingface.co/OpenLLM-Ro/RoGemma-7b-Instruct-2024-10-09) |
|RoGemma-7b-Instruct-DPO-2024-10-09| [link](https://huggingface.co/OpenLLM-Ro/RoGemma-7b-Instruct-DPO-2024-10-09) |


## Citation 

```
@misc{masala2024vorbecstiromanecsterecipetrain,
      title={""Vorbe\c{s}ti Rom\^ane\c{s}te?"" A Recipe to Train Powerful Romanian LLMs with English Instructions}, 
      author={Mihai Masala and Denis C. Ilie-Ablachim and Alexandru Dima and Dragos Corlatescu and Miruna Zavelca and Ovio Olaru and Simina Terian-Dan and Andrei Terian-Dan and Marius Leordeanu and Horia Velicu and Marius Popescu and Mihai Dascalu and Traian Rebedea},
      year={2024},
      eprint={2406.18266},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2406.18266}, 
}
```
<!-- **APA:**

[More Information Needed]  -->","{""id"": ""OpenLLM-Ro/RoGemma-7b-Instruct-2024-10-09"", ""author"": ""OpenLLM-Ro"", ""sha"": ""92dabfebc13190ea108a684d2e36d3a69d9c0e49"", ""last_modified"": ""2024-10-10 18:07:28+00:00"", ""created_at"": ""2024-09-23 16:41:52+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 4, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": null, ""gguf"": null, ""inference"": null, ""tags"": [""safetensors"", ""gemma"", ""ro"", ""dataset:OpenLLM-Ro/ro_sft_alpaca"", ""dataset:OpenLLM-Ro/ro_sft_alpaca_gpt4"", ""dataset:OpenLLM-Ro/ro_sft_dolly"", ""dataset:OpenLLM-Ro/ro_sft_selfinstruct_gpt4"", ""dataset:OpenLLM-Ro/ro_sft_norobots"", ""dataset:OpenLLM-Ro/ro_sft_orca"", ""dataset:OpenLLM-Ro/ro_sft_camel"", ""dataset:OpenLLM-Ro/ro_sft_oasst"", ""dataset:OpenLLM-Ro/ro_sft_ultrachat"", ""arxiv:2406.18266"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""license:cc-by-nc-4.0"", ""model-index"", ""region:us""], ""pipeline_tag"": null, ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model:\n- google/gemma-7b\ndatasets:\n- OpenLLM-Ro/ro_sft_alpaca\n- OpenLLM-Ro/ro_sft_alpaca_gpt4\n- OpenLLM-Ro/ro_sft_dolly\n- OpenLLM-Ro/ro_sft_selfinstruct_gpt4\n- OpenLLM-Ro/ro_sft_norobots\n- OpenLLM-Ro/ro_sft_orca\n- OpenLLM-Ro/ro_sft_camel\n- OpenLLM-Ro/ro_sft_oasst\n- OpenLLM-Ro/ro_sft_ultrachat\nlanguage:\n- ro\nlicense: cc-by-nc-4.0\nmodel-index:\n- name: OpenLLM-Ro/RoGemma-7b-Instruct-2024-10-09\n  results:\n  - task:\n      type: text-generation\n    dataset:\n      name: RoMT-Bench\n      type: RoMT-Bench\n    metrics:\n    - type: Score\n      value: 5.24\n      name: Score\n      verified: false\n    - type: Score\n      value: 5.55\n      name: First turn\n      verified: false\n    - type: Score\n      value: 4.94\n      name: Second turn\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: RoCulturaBench\n      type: RoCulturaBench\n    metrics:\n    - type: Score\n      value: 3.51\n      name: Score\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: Romanian_Academic_Benchmarks\n      type: Romanian_Academic_Benchmarks\n    metrics:\n    - type: accuracy\n      value: 50.48\n      name: Average accuracy\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: OpenLLM-Ro/ro_arc_challenge\n      type: OpenLLM-Ro/ro_arc_challenge\n    metrics:\n    - type: accuracy\n      value: 52.01\n      name: Average accuracy\n      verified: false\n    - type: accuracy\n      value: 49.53\n      name: 0-shot\n      verified: false\n    - type: accuracy\n      value: 52.53\n      name: 1-shot\n      verified: false\n    - type: accuracy\n      value: 51.5\n      name: 3-shot\n      verified: false\n    - type: accuracy\n      value: 53.56\n      name: 5-shot\n      verified: false\n    - type: accuracy\n      value: 52.53\n      name: 10-shot\n      verified: false\n    - type: accuracy\n      value: 52.44\n      name: 25-shot\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: OpenLLM-Ro/ro_mmlu\n      type: OpenLLM-Ro/ro_mmlu\n    metrics:\n    - type: accuracy\n      value: 52.37\n      name: Average accuracy\n      verified: false\n    - type: accuracy\n      value: 51.81\n      name: 0-shot\n      verified: false\n    - type: accuracy\n      value: 52.45\n      name: 1-shot\n      verified: false\n    - type: accuracy\n      value: 52.52\n      name: 3-shot\n      verified: false\n    - type: accuracy\n      value: 52.7\n      name: 5-shot\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: OpenLLM-Ro/ro_winogrande\n      type: OpenLLM-Ro/ro_winogrande\n    metrics:\n    - type: accuracy\n      value: 66.97\n      name: Average accuracy\n      verified: false\n    - type: accuracy\n      value: 66.54\n      name: 0-shot\n      verified: false\n    - type: accuracy\n      value: 66.69\n      name: 1-shot\n      verified: false\n    - type: accuracy\n      value: 67.09\n      name: 3-shot\n      verified: false\n    - type: accuracy\n      value: 67.56\n      name: 5-shot\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: OpenLLM-Ro/ro_hellaswag\n      type: OpenLLM-Ro/ro_hellaswag\n    metrics:\n    - type: accuracy\n      value: 56.34\n      name: Average accuracy\n      verified: false\n    - type: accuracy\n      value: 58.8\n      name: 0-shot\n      verified: false\n    - type: accuracy\n      value: 57.04\n      name: 1-shot\n      verified: false\n    - type: accuracy\n      value: 55.85\n      name: 3-shot\n      verified: false\n    - type: accuracy\n      value: 54.15\n      name: 5-shot\n      verified: false\n    - type: accuracy\n      value: 55.88\n      name: 10-shot\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: OpenLLM-Ro/ro_gsm8k\n      type: OpenLLM-Ro/ro_gsm8k\n    metrics:\n    - type: accuracy\n      value: 25.98\n      name: Average accuracy\n      verified: false\n    - type: accuracy\n      value: 22.06\n      name: 1-shot\n      verified: false\n    - type: accuracy\n      value: 25.4\n      name: 3-shot\n      verified: false\n    - type: accuracy\n      value: 30.48\n      name: 5-shot\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: OpenLLM-Ro/ro_truthfulqa\n      type: OpenLLM-Ro/ro_truthfulqa\n    metrics:\n    - type: accuracy\n      value: 49.18\n      name: Average accuracy\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: LaRoSeDa_binary\n      type: LaRoSeDa_binary\n    metrics:\n    - type: macro-f1\n      value: 86.96\n      name: Average macro-f1\n      verified: false\n    - type: macro-f1\n      value: 87.28\n      name: 0-shot\n      verified: false\n    - type: macro-f1\n      value: 86.4\n      name: 1-shot\n      verified: false\n    - type: macro-f1\n      value: 87.95\n      name: 3-shot\n      verified: false\n    - type: macro-f1\n      value: 86.2\n      name: 5-shot\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: LaRoSeDa_multiclass\n      type: LaRoSeDa_multiclass\n    metrics:\n    - type: macro-f1\n      value: 56.72\n      name: Average macro-f1\n      verified: false\n    - type: macro-f1\n      value: 38.35\n      name: 0-shot\n      verified: false\n    - type: macro-f1\n      value: 63.86\n      name: 1-shot\n      verified: false\n    - type: macro-f1\n      value: 62.03\n      name: 3-shot\n      verified: false\n    - type: macro-f1\n      value: 62.62\n      name: 5-shot\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: LaRoSeDa_binary_finetuned\n      type: LaRoSeDa_binary_finetuned\n    metrics:\n    - type: macro-f1\n      value: 98.8\n      name: Average macro-f1\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: LaRoSeDa_multiclass_finetuned\n      type: LaRoSeDa_multiclass_finetuned\n    metrics:\n    - type: macro-f1\n      value: 85.81\n      name: Average macro-f1\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: WMT_EN-RO\n      type: WMT_EN-RO\n    metrics:\n    - type: bleu\n      value: 24.45\n      name: Average bleu\n      verified: false\n    - type: bleu\n      value: 11.39\n      name: 0-shot\n      verified: false\n    - type: bleu\n      value: 28.08\n      name: 1-shot\n      verified: false\n    - type: bleu\n      value: 29.18\n      name: 3-shot\n      verified: false\n    - type: bleu\n      value: 29.13\n      name: 5-shot\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: WMT_RO-EN\n      type: WMT_RO-EN\n    metrics:\n    - type: bleu\n      value: 14.2\n      name: Average bleu\n      verified: false\n    - type: bleu\n      value: 1.92\n      name: 0-shot\n      verified: false\n    - type: bleu\n      value: 9.39\n      name: 1-shot\n      verified: false\n    - type: bleu\n      value: 21.81\n      name: 3-shot\n      verified: false\n    - type: bleu\n      value: 23.66\n      name: 5-shot\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: WMT_EN-RO_finetuned\n      type: WMT_EN-RO_finetuned\n    metrics:\n    - type: bleu\n      value: 25.96\n      name: Average bleu\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: WMT_RO-EN_finetuned\n      type: WMT_RO-EN_finetuned\n    metrics:\n    - type: bleu\n      value: 39.07\n      name: Average bleu\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: XQuAD\n      type: XQuAD\n    metrics:\n    - type: exact_match\n      value: 26.03\n      name: Average exact_match\n      verified: false\n    - type: f1\n      value: 41.58\n      name: Average f1\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: XQuAD_finetuned\n      type: XQuAD_finetuned\n    metrics:\n    - type: exact_match\n      value: 46.72\n      name: Average exact_match\n      verified: false\n    - type: f1\n      value: 60.79\n      name: Average f1\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: STS\n      type: STS\n    metrics:\n    - type: spearman\n      value: 73.23\n      name: Average spearman\n      verified: false\n    - type: pearson\n      value: 71.58\n      name: Average pearson\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: STS_finetuned\n      type: STS_finetuned\n    metrics:\n    - type: spearman\n      value: 88.42\n      name: Average spearman\n      verified: false\n    - type: pearson\n      value: 88.45\n      name: Average pearson\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: XQuAD_EM\n      type: XQuAD_EM\n    metrics:\n    - type: exact_match\n      value: 32.77\n      name: 0-shot\n      verified: false\n    - type: exact_match\n      value: 20.25\n      name: 1-shot\n      verified: false\n    - type: exact_match\n      value: 18.49\n      name: 3-shot\n      verified: false\n    - type: exact_match\n      value: 32.6\n      name: 5-shot\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: XQuAD_F1\n      type: XQuAD_F1\n    metrics:\n    - type: f1\n      value: 47.98\n      name: 0-shot\n      verified: false\n    - type: f1\n      value: 34.92\n      name: 1-shot\n      verified: false\n    - type: f1\n      value: 33.27\n      name: 3-shot\n      verified: false\n    - type: f1\n      value: 50.14\n      name: 5-shot\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: STS_Spearman\n      type: STS_Spearman\n    metrics:\n    - type: spearman\n      value: 71.75\n      name: 1-shot\n      verified: false\n    - type: spearman\n      value: 71.83\n      name: 3-shot\n      verified: false\n    - type: spearman\n      value: 76.11\n      name: 5-shot\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: STS_Pearson\n      type: STS_Pearson\n    metrics:\n    - type: pearson\n      value: 69.97\n      name: 1-shot\n      verified: false\n    - type: pearson\n      value: 69.87\n      name: 3-shot\n      verified: false\n    - type: pearson\n      value: 74.89\n      name: 5-shot\n      verified: false"", ""widget_data"": null, ""model_index"": [{""name"": ""OpenLLM-Ro/RoGemma-7b-Instruct-2024-10-09"", ""results"": [{""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""RoMT-Bench"", ""type"": ""RoMT-Bench""}, ""metrics"": [{""name"": ""Score"", ""type"": ""Score"", ""value"": 5.24, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""RoCulturaBench"", ""type"": ""RoCulturaBench""}, ""metrics"": [{""name"": ""Score"", ""type"": ""Score"", ""value"": 3.51, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""Romanian_Academic_Benchmarks"", ""type"": ""Romanian_Academic_Benchmarks""}, ""metrics"": [{""name"": ""Average accuracy"", ""type"": ""accuracy"", ""value"": 50.48, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""OpenLLM-Ro/ro_arc_challenge"", ""type"": ""OpenLLM-Ro/ro_arc_challenge""}, ""metrics"": [{""name"": ""Average accuracy"", ""type"": ""accuracy"", ""value"": 52.01, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""OpenLLM-Ro/ro_mmlu"", ""type"": ""OpenLLM-Ro/ro_mmlu""}, ""metrics"": [{""name"": ""Average accuracy"", ""type"": ""accuracy"", ""value"": 52.37, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""OpenLLM-Ro/ro_winogrande"", ""type"": ""OpenLLM-Ro/ro_winogrande""}, ""metrics"": [{""name"": ""Average accuracy"", ""type"": ""accuracy"", ""value"": 66.97, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""OpenLLM-Ro/ro_hellaswag"", ""type"": ""OpenLLM-Ro/ro_hellaswag""}, ""metrics"": [{""name"": ""Average accuracy"", ""type"": ""accuracy"", ""value"": 56.34, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""OpenLLM-Ro/ro_gsm8k"", ""type"": ""OpenLLM-Ro/ro_gsm8k""}, ""metrics"": [{""name"": ""Average accuracy"", ""type"": ""accuracy"", ""value"": 25.98, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""OpenLLM-Ro/ro_truthfulqa"", ""type"": ""OpenLLM-Ro/ro_truthfulqa""}, ""metrics"": [{""name"": ""Average accuracy"", ""type"": ""accuracy"", ""value"": 49.18, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""LaRoSeDa_binary"", ""type"": ""LaRoSeDa_binary""}, ""metrics"": [{""name"": ""Average macro-f1"", ""type"": ""macro-f1"", ""value"": 86.96, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""LaRoSeDa_multiclass"", ""type"": ""LaRoSeDa_multiclass""}, ""metrics"": [{""name"": ""Average macro-f1"", ""type"": ""macro-f1"", ""value"": 56.72, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""LaRoSeDa_binary_finetuned"", ""type"": ""LaRoSeDa_binary_finetuned""}, ""metrics"": [{""name"": ""Average macro-f1"", ""type"": ""macro-f1"", ""value"": 98.8, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""LaRoSeDa_multiclass_finetuned"", ""type"": ""LaRoSeDa_multiclass_finetuned""}, ""metrics"": [{""name"": ""Average macro-f1"", ""type"": ""macro-f1"", ""value"": 85.81, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""WMT_EN-RO"", ""type"": ""WMT_EN-RO""}, ""metrics"": [{""name"": ""Average bleu"", ""type"": ""bleu"", ""value"": 24.45, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""WMT_RO-EN"", ""type"": ""WMT_RO-EN""}, ""metrics"": [{""name"": ""Average bleu"", ""type"": ""bleu"", ""value"": 14.2, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""WMT_EN-RO_finetuned"", ""type"": ""WMT_EN-RO_finetuned""}, ""metrics"": [{""name"": ""Average bleu"", ""type"": ""bleu"", ""value"": 25.96, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""WMT_RO-EN_finetuned"", ""type"": ""WMT_RO-EN_finetuned""}, ""metrics"": [{""name"": ""Average bleu"", ""type"": ""bleu"", ""value"": 39.07, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""XQuAD"", ""type"": ""XQuAD""}, ""metrics"": [{""name"": ""Average exact_match"", ""type"": ""exact_match"", ""value"": 26.03, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""XQuAD"", ""type"": ""XQuAD""}, ""metrics"": [{""name"": ""Average f1"", ""type"": ""f1"", ""value"": 41.58, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""XQuAD_finetuned"", ""type"": ""XQuAD_finetuned""}, ""metrics"": [{""name"": ""Average exact_match"", ""type"": ""exact_match"", ""value"": 46.72, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""XQuAD_finetuned"", ""type"": ""XQuAD_finetuned""}, ""metrics"": [{""name"": ""Average f1"", ""type"": ""f1"", ""value"": 60.79, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""STS"", ""type"": ""STS""}, ""metrics"": [{""name"": ""Average spearman"", ""type"": ""spearman"", ""value"": 73.23, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""STS"", ""type"": ""STS""}, ""metrics"": [{""name"": ""Average pearson"", ""type"": ""pearson"", ""value"": 71.58, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""STS_finetuned"", ""type"": ""STS_finetuned""}, ""metrics"": [{""name"": ""Average spearman"", ""type"": ""spearman"", ""value"": 88.42, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""STS_finetuned"", ""type"": ""STS_finetuned""}, ""metrics"": [{""name"": ""Average pearson"", ""type"": ""pearson"", ""value"": 88.45, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""RoMT-Bench"", ""type"": ""RoMT-Bench""}, ""metrics"": [{""name"": ""First turn"", ""type"": ""Score"", ""value"": 5.55, ""verified"": false}, {""name"": ""Second turn"", ""type"": ""Score"", ""value"": 4.94, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""OpenLLM-Ro/ro_arc_challenge"", ""type"": ""OpenLLM-Ro/ro_arc_challenge""}, ""metrics"": [{""name"": ""0-shot"", ""type"": ""accuracy"", ""value"": 49.53, ""verified"": false}, {""name"": ""1-shot"", ""type"": ""accuracy"", ""value"": 52.53, ""verified"": false}, {""name"": ""3-shot"", ""type"": ""accuracy"", ""value"": 51.5, ""verified"": false}, {""name"": ""5-shot"", ""type"": ""accuracy"", ""value"": 53.56, ""verified"": false}, {""name"": ""10-shot"", ""type"": ""accuracy"", ""value"": 52.53, ""verified"": false}, {""name"": ""25-shot"", ""type"": ""accuracy"", ""value"": 52.44, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""OpenLLM-Ro/ro_mmlu"", ""type"": ""OpenLLM-Ro/ro_mmlu""}, ""metrics"": [{""name"": ""0-shot"", ""type"": ""accuracy"", ""value"": 51.81, ""verified"": false}, {""name"": ""1-shot"", ""type"": ""accuracy"", ""value"": 52.45, ""verified"": false}, {""name"": ""3-shot"", ""type"": ""accuracy"", ""value"": 52.52, ""verified"": false}, {""name"": ""5-shot"", ""type"": ""accuracy"", ""value"": 52.7, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""OpenLLM-Ro/ro_winogrande"", ""type"": ""OpenLLM-Ro/ro_winogrande""}, ""metrics"": [{""name"": ""0-shot"", ""type"": ""accuracy"", ""value"": 66.54, ""verified"": false}, {""name"": ""1-shot"", ""type"": ""accuracy"", ""value"": 66.69, ""verified"": false}, {""name"": ""3-shot"", ""type"": ""accuracy"", ""value"": 67.09, ""verified"": false}, {""name"": ""5-shot"", ""type"": ""accuracy"", ""value"": 67.56, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""OpenLLM-Ro/ro_hellaswag"", ""type"": ""OpenLLM-Ro/ro_hellaswag""}, ""metrics"": [{""name"": ""0-shot"", ""type"": ""accuracy"", ""value"": 58.8, ""verified"": false}, {""name"": ""1-shot"", ""type"": ""accuracy"", ""value"": 57.04, ""verified"": false}, {""name"": ""3-shot"", ""type"": ""accuracy"", ""value"": 55.85, ""verified"": false}, {""name"": ""5-shot"", ""type"": ""accuracy"", ""value"": 54.15, ""verified"": false}, {""name"": ""10-shot"", ""type"": ""accuracy"", ""value"": 55.88, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""OpenLLM-Ro/ro_gsm8k"", ""type"": ""OpenLLM-Ro/ro_gsm8k""}, ""metrics"": [{""name"": ""1-shot"", ""type"": ""accuracy"", ""value"": 22.06, ""verified"": false}, {""name"": ""3-shot"", ""type"": ""accuracy"", ""value"": 25.4, ""verified"": false}, {""name"": ""5-shot"", ""type"": ""accuracy"", ""value"": 30.48, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""LaRoSeDa_binary"", ""type"": ""LaRoSeDa_binary""}, ""metrics"": [{""name"": ""0-shot"", ""type"": ""macro-f1"", ""value"": 87.28, ""verified"": false}, {""name"": ""1-shot"", ""type"": ""macro-f1"", ""value"": 86.4, ""verified"": false}, {""name"": ""3-shot"", ""type"": ""macro-f1"", ""value"": 87.95, ""verified"": false}, {""name"": ""5-shot"", ""type"": ""macro-f1"", ""value"": 86.2, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""LaRoSeDa_multiclass"", ""type"": ""LaRoSeDa_multiclass""}, ""metrics"": [{""name"": ""0-shot"", ""type"": ""macro-f1"", ""value"": 38.35, ""verified"": false}, {""name"": ""1-shot"", ""type"": ""macro-f1"", ""value"": 63.86, ""verified"": false}, {""name"": ""3-shot"", ""type"": ""macro-f1"", ""value"": 62.03, ""verified"": false}, {""name"": ""5-shot"", ""type"": ""macro-f1"", ""value"": 62.62, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""WMT_EN-RO"", ""type"": ""WMT_EN-RO""}, ""metrics"": [{""name"": ""0-shot"", ""type"": ""bleu"", ""value"": 11.39, ""verified"": false}, {""name"": ""1-shot"", ""type"": ""bleu"", ""value"": 28.08, ""verified"": false}, {""name"": ""3-shot"", ""type"": ""bleu"", ""value"": 29.18, ""verified"": false}, {""name"": ""5-shot"", ""type"": ""bleu"", ""value"": 29.13, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""WMT_RO-EN"", ""type"": ""WMT_RO-EN""}, ""metrics"": [{""name"": ""0-shot"", ""type"": ""bleu"", ""value"": 1.92, ""verified"": false}, {""name"": ""1-shot"", ""type"": ""bleu"", ""value"": 9.39, ""verified"": false}, {""name"": ""3-shot"", ""type"": ""bleu"", ""value"": 21.81, ""verified"": false}, {""name"": ""5-shot"", ""type"": ""bleu"", ""value"": 23.66, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""XQuAD_EM"", ""type"": ""XQuAD_EM""}, ""metrics"": [{""name"": ""0-shot"", ""type"": ""exact_match"", ""value"": 32.77, ""verified"": false}, {""name"": ""1-shot"", ""type"": ""exact_match"", ""value"": 20.25, ""verified"": false}, {""name"": ""3-shot"", ""type"": ""exact_match"", ""value"": 18.49, ""verified"": false}, {""name"": ""5-shot"", ""type"": ""exact_match"", ""value"": 32.6, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""XQuAD_F1"", ""type"": ""XQuAD_F1""}, ""metrics"": [{""name"": ""0-shot"", ""type"": ""f1"", ""value"": 47.98, ""verified"": false}, {""name"": ""1-shot"", ""type"": ""f1"", ""value"": 34.92, ""verified"": false}, {""name"": ""3-shot"", ""type"": ""f1"", ""value"": 33.27, ""verified"": false}, {""name"": ""5-shot"", ""type"": ""f1"", ""value"": 50.14, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""STS_Spearman"", ""type"": ""STS_Spearman""}, ""metrics"": [{""name"": ""1-shot"", ""type"": ""spearman"", ""value"": 71.75, ""verified"": false}, {""name"": ""3-shot"", ""type"": ""spearman"", ""value"": 71.83, ""verified"": false}, {""name"": ""5-shot"", ""type"": ""spearman"", ""value"": 76.11, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""STS_Pearson"", ""type"": ""STS_Pearson""}, ""metrics"": [{""name"": ""1-shot"", ""type"": ""pearson"", ""value"": 69.97, ""verified"": false}, {""name"": ""3-shot"", ""type"": ""pearson"", ""value"": 69.87, ""verified"": false}, {""name"": ""5-shot"", ""type"": ""pearson"", ""value"": 74.89, ""verified"": false}]}]}], ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ '<bos>' }}{% if messages[0]['role'] == 'system' %}{% set system_message = messages[0]['content'] %}{% endif %}{% if system_message is defined %}{{ system_message }}{% endif %}{% for message in messages %}{% set content = message['content'] %}{% if message['role'] == 'user' %}{{ '<start_of_turn>user\n' + content + '<end_of_turn>\n<start_of_turn>model\n' }}{% elif message['role'] == 'assistant' %}{{ content + '<end_of_turn>\n' }}{% endif %}{% endfor %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": null, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='generation_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00001-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00002-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00003-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00004-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model.safetensors.index.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": {""parameters"": {""BF16"": 8537680896}, ""total"": 8537680896}, ""security_repo_status"": null, ""lastModified"": ""2024-10-10 18:07:28+00:00"", ""cardData"": ""base_model:\n- google/gemma-7b\ndatasets:\n- OpenLLM-Ro/ro_sft_alpaca\n- OpenLLM-Ro/ro_sft_alpaca_gpt4\n- OpenLLM-Ro/ro_sft_dolly\n- OpenLLM-Ro/ro_sft_selfinstruct_gpt4\n- OpenLLM-Ro/ro_sft_norobots\n- OpenLLM-Ro/ro_sft_orca\n- OpenLLM-Ro/ro_sft_camel\n- OpenLLM-Ro/ro_sft_oasst\n- OpenLLM-Ro/ro_sft_ultrachat\nlanguage:\n- ro\nlicense: cc-by-nc-4.0\nmodel-index:\n- name: OpenLLM-Ro/RoGemma-7b-Instruct-2024-10-09\n  results:\n  - task:\n      type: text-generation\n    dataset:\n      name: RoMT-Bench\n      type: RoMT-Bench\n    metrics:\n    - type: Score\n      value: 5.24\n      name: Score\n      verified: false\n    - type: Score\n      value: 5.55\n      name: First turn\n      verified: false\n    - type: Score\n      value: 4.94\n      name: Second turn\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: RoCulturaBench\n      type: RoCulturaBench\n    metrics:\n    - type: Score\n      value: 3.51\n      name: Score\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: Romanian_Academic_Benchmarks\n      type: Romanian_Academic_Benchmarks\n    metrics:\n    - type: accuracy\n      value: 50.48\n      name: Average accuracy\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: OpenLLM-Ro/ro_arc_challenge\n      type: OpenLLM-Ro/ro_arc_challenge\n    metrics:\n    - type: accuracy\n      value: 52.01\n      name: Average accuracy\n      verified: false\n    - type: accuracy\n      value: 49.53\n      name: 0-shot\n      verified: false\n    - type: accuracy\n      value: 52.53\n      name: 1-shot\n      verified: false\n    - type: accuracy\n      value: 51.5\n      name: 3-shot\n      verified: false\n    - type: accuracy\n      value: 53.56\n      name: 5-shot\n      verified: false\n    - type: accuracy\n      value: 52.53\n      name: 10-shot\n      verified: false\n    - type: accuracy\n      value: 52.44\n      name: 25-shot\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: OpenLLM-Ro/ro_mmlu\n      type: OpenLLM-Ro/ro_mmlu\n    metrics:\n    - type: accuracy\n      value: 52.37\n      name: Average accuracy\n      verified: false\n    - type: accuracy\n      value: 51.81\n      name: 0-shot\n      verified: false\n    - type: accuracy\n      value: 52.45\n      name: 1-shot\n      verified: false\n    - type: accuracy\n      value: 52.52\n      name: 3-shot\n      verified: false\n    - type: accuracy\n      value: 52.7\n      name: 5-shot\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: OpenLLM-Ro/ro_winogrande\n      type: OpenLLM-Ro/ro_winogrande\n    metrics:\n    - type: accuracy\n      value: 66.97\n      name: Average accuracy\n      verified: false\n    - type: accuracy\n      value: 66.54\n      name: 0-shot\n      verified: false\n    - type: accuracy\n      value: 66.69\n      name: 1-shot\n      verified: false\n    - type: accuracy\n      value: 67.09\n      name: 3-shot\n      verified: false\n    - type: accuracy\n      value: 67.56\n      name: 5-shot\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: OpenLLM-Ro/ro_hellaswag\n      type: OpenLLM-Ro/ro_hellaswag\n    metrics:\n    - type: accuracy\n      value: 56.34\n      name: Average accuracy\n      verified: false\n    - type: accuracy\n      value: 58.8\n      name: 0-shot\n      verified: false\n    - type: accuracy\n      value: 57.04\n      name: 1-shot\n      verified: false\n    - type: accuracy\n      value: 55.85\n      name: 3-shot\n      verified: false\n    - type: accuracy\n      value: 54.15\n      name: 5-shot\n      verified: false\n    - type: accuracy\n      value: 55.88\n      name: 10-shot\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: OpenLLM-Ro/ro_gsm8k\n      type: OpenLLM-Ro/ro_gsm8k\n    metrics:\n    - type: accuracy\n      value: 25.98\n      name: Average accuracy\n      verified: false\n    - type: accuracy\n      value: 22.06\n      name: 1-shot\n      verified: false\n    - type: accuracy\n      value: 25.4\n      name: 3-shot\n      verified: false\n    - type: accuracy\n      value: 30.48\n      name: 5-shot\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: OpenLLM-Ro/ro_truthfulqa\n      type: OpenLLM-Ro/ro_truthfulqa\n    metrics:\n    - type: accuracy\n      value: 49.18\n      name: Average accuracy\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: LaRoSeDa_binary\n      type: LaRoSeDa_binary\n    metrics:\n    - type: macro-f1\n      value: 86.96\n      name: Average macro-f1\n      verified: false\n    - type: macro-f1\n      value: 87.28\n      name: 0-shot\n      verified: false\n    - type: macro-f1\n      value: 86.4\n      name: 1-shot\n      verified: false\n    - type: macro-f1\n      value: 87.95\n      name: 3-shot\n      verified: false\n    - type: macro-f1\n      value: 86.2\n      name: 5-shot\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: LaRoSeDa_multiclass\n      type: LaRoSeDa_multiclass\n    metrics:\n    - type: macro-f1\n      value: 56.72\n      name: Average macro-f1\n      verified: false\n    - type: macro-f1\n      value: 38.35\n      name: 0-shot\n      verified: false\n    - type: macro-f1\n      value: 63.86\n      name: 1-shot\n      verified: false\n    - type: macro-f1\n      value: 62.03\n      name: 3-shot\n      verified: false\n    - type: macro-f1\n      value: 62.62\n      name: 5-shot\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: LaRoSeDa_binary_finetuned\n      type: LaRoSeDa_binary_finetuned\n    metrics:\n    - type: macro-f1\n      value: 98.8\n      name: Average macro-f1\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: LaRoSeDa_multiclass_finetuned\n      type: LaRoSeDa_multiclass_finetuned\n    metrics:\n    - type: macro-f1\n      value: 85.81\n      name: Average macro-f1\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: WMT_EN-RO\n      type: WMT_EN-RO\n    metrics:\n    - type: bleu\n      value: 24.45\n      name: Average bleu\n      verified: false\n    - type: bleu\n      value: 11.39\n      name: 0-shot\n      verified: false\n    - type: bleu\n      value: 28.08\n      name: 1-shot\n      verified: false\n    - type: bleu\n      value: 29.18\n      name: 3-shot\n      verified: false\n    - type: bleu\n      value: 29.13\n      name: 5-shot\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: WMT_RO-EN\n      type: WMT_RO-EN\n    metrics:\n    - type: bleu\n      value: 14.2\n      name: Average bleu\n      verified: false\n    - type: bleu\n      value: 1.92\n      name: 0-shot\n      verified: false\n    - type: bleu\n      value: 9.39\n      name: 1-shot\n      verified: false\n    - type: bleu\n      value: 21.81\n      name: 3-shot\n      verified: false\n    - type: bleu\n      value: 23.66\n      name: 5-shot\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: WMT_EN-RO_finetuned\n      type: WMT_EN-RO_finetuned\n    metrics:\n    - type: bleu\n      value: 25.96\n      name: Average bleu\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: WMT_RO-EN_finetuned\n      type: WMT_RO-EN_finetuned\n    metrics:\n    - type: bleu\n      value: 39.07\n      name: Average bleu\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: XQuAD\n      type: XQuAD\n    metrics:\n    - type: exact_match\n      value: 26.03\n      name: Average exact_match\n      verified: false\n    - type: f1\n      value: 41.58\n      name: Average f1\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: XQuAD_finetuned\n      type: XQuAD_finetuned\n    metrics:\n    - type: exact_match\n      value: 46.72\n      name: Average exact_match\n      verified: false\n    - type: f1\n      value: 60.79\n      name: Average f1\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: STS\n      type: STS\n    metrics:\n    - type: spearman\n      value: 73.23\n      name: Average spearman\n      verified: false\n    - type: pearson\n      value: 71.58\n      name: Average pearson\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: STS_finetuned\n      type: STS_finetuned\n    metrics:\n    - type: spearman\n      value: 88.42\n      name: Average spearman\n      verified: false\n    - type: pearson\n      value: 88.45\n      name: Average pearson\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: XQuAD_EM\n      type: XQuAD_EM\n    metrics:\n    - type: exact_match\n      value: 32.77\n      name: 0-shot\n      verified: false\n    - type: exact_match\n      value: 20.25\n      name: 1-shot\n      verified: false\n    - type: exact_match\n      value: 18.49\n      name: 3-shot\n      verified: false\n    - type: exact_match\n      value: 32.6\n      name: 5-shot\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: XQuAD_F1\n      type: XQuAD_F1\n    metrics:\n    - type: f1\n      value: 47.98\n      name: 0-shot\n      verified: false\n    - type: f1\n      value: 34.92\n      name: 1-shot\n      verified: false\n    - type: f1\n      value: 33.27\n      name: 3-shot\n      verified: false\n    - type: f1\n      value: 50.14\n      name: 5-shot\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: STS_Spearman\n      type: STS_Spearman\n    metrics:\n    - type: spearman\n      value: 71.75\n      name: 1-shot\n      verified: false\n    - type: spearman\n      value: 71.83\n      name: 3-shot\n      verified: false\n    - type: spearman\n      value: 76.11\n      name: 5-shot\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: STS_Pearson\n      type: STS_Pearson\n    metrics:\n    - type: pearson\n      value: 69.97\n      name: 1-shot\n      verified: false\n    - type: pearson\n      value: 69.87\n      name: 3-shot\n      verified: false\n    - type: pearson\n      value: 74.89\n      name: 5-shot\n      verified: false"", ""transformersInfo"": null, ""_id"": ""66f19a507972f6224f62bcec"", ""modelId"": ""OpenLLM-Ro/RoGemma-7b-Instruct-2024-10-09"", ""usedStorage"": 17097150888}",1,"https://huggingface.co/OpenLLM-Ro/RoGemma-7b-Instruct-DPO, https://huggingface.co/OpenLLM-Ro/RoGemma-7b-Instruct-DPO-2024-10-09",2,https://huggingface.co/mradermacher/RoGemma-7b-Instruct-2024-10-09-GGUF,1,,0,huggingface/InferenceSupport/discussions/new?title=OpenLLM-Ro/RoGemma-7b-Instruct-2024-10-09&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5BOpenLLM-Ro%2FRoGemma-7b-Instruct-2024-10-09%5D(%2FOpenLLM-Ro%2FRoGemma-7b-Instruct-2024-10-09)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
OpenLLM-Ro/RoGemma-7b-Instruct-DPO,"---
license: cc-by-nc-4.0
language:
- ro
base_model:
- OpenLLM-Ro/RoGemma-7b-Instruct-2024-10-09
datasets:
- OpenLLM-Ro/ro_dpo_helpsteer
model-index:
    - name: OpenLLM-Ro/RoGemma-7b-Instruct-DPO-2024-10-09
      results:
        - task:
            type: text-generation
          dataset:
            name: RoMT-Bench
            type: RoMT-Bench
          metrics:
            - name: Score
              type: Score
              value: 5.47
        - task:
            type: text-generation
          dataset:
            name: RoCulturaBench
            type: RoCulturaBench
          metrics:
            - name: Score
              type: Score
              value: 3.94
        - task:
            type: text-generation
          dataset:
            name: Romanian_Academic_Benchmarks
            type: Romanian_Academic_Benchmarks
          metrics:
            - name: Average accuracy
              type: accuracy
              value: 48.27
        - task:
            type: text-generation
          dataset:
            name: OpenLLM-Ro/ro_arc_challenge
            type: OpenLLM-Ro/ro_arc_challenge
          metrics:
            - name: Average accuracy
              type: accuracy
              value: 46.66
        - task:
            type: text-generation
          dataset:
            name: OpenLLM-Ro/ro_mmlu
            type: OpenLLM-Ro/ro_mmlu
          metrics:
            - name: Average accuracy
              type: accuracy
              value: 54.45
        - task:
            type: text-generation
          dataset:
            name: OpenLLM-Ro/ro_winogrande
            type: OpenLLM-Ro/ro_winogrande
          metrics:
            - name: Average accuracy
              type: accuracy
              value: 63.73
        - task:
            type: text-generation
          dataset:
            name: OpenLLM-Ro/ro_hellaswag
            type: OpenLLM-Ro/ro_hellaswag
          metrics:
            - name: Average accuracy
              type: accuracy
              value: 49.33
        - task:
            type: text-generation
          dataset:
            name: OpenLLM-Ro/ro_gsm8k
            type: OpenLLM-Ro/ro_gsm8k
          metrics:
            - name: Average accuracy
              type: accuracy
              value: 34.98
        - task:
            type: text-generation
          dataset:
            name: OpenLLM-Ro/ro_truthfulqa
            type: OpenLLM-Ro/ro_truthfulqa
          metrics:
            - name: Average accuracy
              type: accuracy
              value: 40.45
        - task:
            type: text-generation
          dataset:
            name: LaRoSeDa_binary
            type: LaRoSeDa_binary
          metrics:
            - name: Average macro-f1
              type: macro-f1
              value: 96.45
        - task:
            type: text-generation
          dataset:
            name: LaRoSeDa_multiclass
            type: LaRoSeDa_multiclass
          metrics:
            - name: Average macro-f1
              type: macro-f1
              value: 63.23
        - task:
            type: text-generation
          dataset:
            name: LaRoSeDa_binary_finetuned
            type: LaRoSeDa_binary_finetuned
          metrics:
            - name: Average macro-f1
              type: macro-f1
              value: 0.00
        - task:
            type: text-generation
          dataset:
            name: LaRoSeDa_multiclass_finetuned
            type: LaRoSeDa_multiclass_finetuned
          metrics:
            - name: Average macro-f1
              type: macro-f1
              value: 0.00
        - task:
            type: text-generation
          dataset:
            name: WMT_EN-RO
            type: WMT_EN-RO
          metrics:
            - name: Average bleu
              type: bleu
              value: 20.73
        - task:
            type: text-generation
          dataset:
            name: WMT_RO-EN
            type: WMT_RO-EN
          metrics:
            - name: Average bleu
              type: bleu
              value: 7.87
        - task:
            type: text-generation
          dataset:
            name: WMT_EN-RO_finetuned
            type: WMT_EN-RO_finetuned
          metrics:
            - name: Average bleu
              type: bleu
              value: 0.00
        - task:
            type: text-generation
          dataset:
            name: WMT_RO-EN_finetuned
            type: WMT_RO-EN_finetuned
          metrics:
            - name: Average bleu
              type: bleu
              value: 0.00
        - task:
            type: text-generation
          dataset:
            name: XQuAD
            type: XQuAD
          metrics:
            - name: Average exact_match
              type: exact_match
              value: 19.14
        - task:
            type: text-generation
          dataset:
            name: XQuAD
            type: XQuAD
          metrics:
            - name: Average f1
              type: f1
              value: 38.10
        - task:
            type: text-generation
          dataset:
            name: XQuAD_finetuned
            type: XQuAD_finetuned
          metrics:
            - name: Average exact_match
              type: exact_match
              value: 0.00
        - task:
            type: text-generation
          dataset:
            name: XQuAD_finetuned
            type: XQuAD_finetuned
          metrics:
            - name: Average f1
              type: f1
              value: 0.00
        - task:
            type: text-generation
          dataset:
            name: STS
            type: STS
          metrics:
            - name: Average spearman
              type: spearman
              value: 69.38
        - task:
            type: text-generation
          dataset:
            name: STS
            type: STS
          metrics:
            - name: Average pearson
              type: pearson
              value: 69.34
        - task:
            type: text-generation
          dataset:
            name: STS_finetuned
            type: STS_finetuned
          metrics:
            - name: Average spearman
              type: spearman
              value: 0.00
        - task:
            type: text-generation
          dataset:
            name: STS_finetuned
            type: STS_finetuned
          metrics:
            - name: Average pearson
              type: pearson
              value: 0.00
        - task:
            type: text-generation
          dataset:
            name: RoMT-Bench
            type: RoMT-Bench
          metrics:
            - name: First turn
              type: Score
              value: 5.92
            - name: Second turn
              type: Score
              value: 5.03
        - task:
            type: text-generation
          dataset:
            name: OpenLLM-Ro/ro_arc_challenge
            type: OpenLLM-Ro/ro_arc_challenge
          metrics:
            - name: 0-shot 
              type: accuracy
              value: 48.84
            - name: 1-shot 
              type: accuracy
              value: 46.27
            - name: 3-shot 
              type: accuracy
              value: 44.64
            - name: 5-shot 
              type: accuracy
              value: 45.76
            - name: 10-shot 
              type: accuracy
              value: 46.62
            - name: 25-shot 
              type: accuracy
              value: 47.81
        - task:
            type: text-generation
          dataset:
            name: OpenLLM-Ro/ro_mmlu
            type: OpenLLM-Ro/ro_mmlu
          metrics:
            - name: 0-shot 
              type: accuracy
              value: 52.47
            - name: 1-shot 
              type: accuracy
              value: 54.40
            - name: 3-shot 
              type: accuracy
              value: 55.63
            - name: 5-shot 
              type: accuracy
              value: 55.30
        - task:
            type: text-generation
          dataset:
            name: OpenLLM-Ro/ro_winogrande
            type: OpenLLM-Ro/ro_winogrande
          metrics:
            - name: 0-shot 
              type: accuracy
              value: 60.54
            - name: 1-shot 
              type: accuracy
              value: 63.54
            - name: 3-shot 
              type: accuracy
              value: 63.46
            - name: 5-shot 
              type: accuracy
              value: 67.40
        - task:
            type: text-generation
          dataset:
            name: OpenLLM-Ro/ro_hellaswag
            type: OpenLLM-Ro/ro_hellaswag
          metrics:
            - name: 0-shot 
              type: accuracy
              value: 52.67
            - name: 1-shot 
              type: accuracy
              value: 50.89
            - name: 3-shot 
              type: accuracy
              value: 47.85
            - name: 5-shot 
              type: accuracy
              value: 45.98
            - name: 10-shot 
              type: accuracy
              value: 49.26
        - task:
            type: text-generation
          dataset:
            name: OpenLLM-Ro/ro_gsm8k
            type: OpenLLM-Ro/ro_gsm8k
          metrics:
            - name: 1-shot 
              type: accuracy
              value: 27.45
            - name: 3-shot 
              type: accuracy
              value: 36.32
            - name: 5-shot 
              type: accuracy
              value: 41.17
        - task:
            type: text-generation
          dataset:
            name: LaRoSeDa_binary
            type: LaRoSeDa_binary
          metrics:
            - name: 0-shot 
              type: macro-f1
              value: 95.90
            - name: 1-shot 
              type: macro-f1
              value: 95.36
            - name: 3-shot 
              type: macro-f1
              value: 97.13
            - name: 5-shot 
              type: macro-f1
              value: 97.43
        - task:
            type: text-generation
          dataset:
            name: LaRoSeDa_multiclass
            type: LaRoSeDa_multiclass
          metrics:
            - name: 0-shot 
              type: macro-f1
              value: 66.82
            - name: 1-shot 
              type: macro-f1
              value: 59.47
            - name: 3-shot 
              type: macro-f1
              value: 62.88
            - name: 5-shot 
              type: macro-f1
              value: 63.77
        - task:
            type: text-generation
          dataset:
            name: WMT_EN-RO
            type: WMT_EN-RO
          metrics:
            - name: 0-shot 
              type: bleu
              value: 8.00
            - name: 1-shot 
              type: bleu
              value: 24.37
            - name: 3-shot 
              type: bleu
              value: 26.19
            - name: 5-shot 
              type: bleu
              value: 24.36
        - task:
            type: text-generation
          dataset:
            name: WMT_RO-EN
            type: WMT_RO-EN
          metrics:
            - name: 0-shot 
              type: bleu
              value: 0.76
            - name: 1-shot 
              type: bleu
              value: 4.67
            - name: 3-shot 
              type: bleu
              value: 13.33
            - name: 5-shot 
              type: bleu
              value: 12.73
        - task:
            type: text-generation
          dataset:
            name: XQuAD_EM
            type: XQuAD_EM
          metrics:
            - name: 0-shot 
              type: exact_match
              value: 14.37
            - name: 1-shot 
              type: exact_match
              value: 19.08
            - name: 3-shot 
              type: exact_match
              value: 17.73
            - name: 5-shot 
              type: exact_match
              value: 25.38
        - task:
            type: text-generation
          dataset:
            name: XQuAD_F1
            type: XQuAD_F1
          metrics:
            - name: 0-shot 
              type: f1
              value: 33.52
            - name: 1-shot 
              type: f1
              value: 37.27
            - name: 3-shot 
              type: f1
              value: 35.77
            - name: 5-shot 
              type: f1
              value: 45.84
        - task:
            type: text-generation
          dataset:
            name: STS_Spearman
            type: STS_Spearman
          metrics:
            - name: 1-shot 
              type: spearman
              value: 54.50
            - name: 3-shot 
              type: spearman
              value: 74.93
            - name: 5-shot 
              type: spearman
              value: 78.70
        - task:
            type: text-generation
          dataset:
            name: STS_Pearson
            type: STS_Pearson
          metrics:
            - name: 1-shot 
              type: pearson
              value: 54.91
            - name: 3-shot 
              type: pearson
              value: 74.98
            - name: 5-shot 
              type: pearson
              value: 78.13

---

# Model Card for Model ID

<!-- Provide a quick summary of what the model is/does. -->
This model points/is identical to [RoGemma-7b-Instruct-DPO-2024-10-09](https://huggingface.co/OpenLLM-Ro/RoGemma-7b-Instruct-DPO-2024-10-09).


RoGemma is a family of pretrained and fine-tuned generative text models for Romanian. This is the repository for the **human aligned instruct 7B model**. Links to other models can be found at the bottom of this page.

## Model Details

### Model Description

<!-- Provide a longer summary of what this model is. -->
OpenLLM-Ro represents the first open-source effort to build a LLM specialized for Romanian. OpenLLM-Ro developed and publicly releases a collection of Romanian LLMs, both in the form of foundational model and instruct and chat variants.


- **Developed by:** OpenLLM-Ro
<!-- - **Funded by [optional]:** [More Information Needed] -->
<!-- - **Shared by [optional]:** [More Information Needed] -->
<!-- - **Model type:** [More Information Needed] -->
- **Language(s):** Romanian
- **License:** cc-by-nc-4.0
- **Finetuned from model:** [RoGemma-7b-Instruct-2024-10-09](https://huggingface.co/OpenLLM-Ro/RoGemma-7b-Instruct-2024-10-09)
- **Trained using:** [RoHelpSteer](https://huggingface.co/datasets/OpenLLM-Ro/ro_dpo_helpsteer)


### Model Sources

<!-- Provide the basic links for the model. -->

- **Repository:** https://github.com/OpenLLM-Ro/LLaMA-Factory
- **Paper:** https://arxiv.org/abs/2406.18266

## Intended Use

### Intended Use Cases

RoGemma is intented for research use in Romanian. Base models can be adapted for a variety of natural language tasks while instruction and chat tuned models are intended for assistant-like chat.

### Out-of-Scope Use

<!-- This section addresses misuse, malicious use, and uses that the model will not work well for. -->

Use in any manner that violates the license, any applicable laws or regluations, use in languages other than Romanian.



## How to Get Started with the Model

Use the code below to get started with the model.

```python
from transformers import AutoTokenizer, AutoModelForCausalLM

tokenizer = AutoTokenizer.from_pretrained(""OpenLLM-Ro/RoGemma-7b-Instruct-DPO"")
model = AutoModelForCausalLM.from_pretrained(""OpenLLM-Ro/RoGemma-7b-Instruct-DPO"")

instruction = ""Ce jocuri de societate pot juca cu prietenii mei?""
chat = [
        {""role"": ""user"", ""content"": instruction},
        ]
prompt = tokenizer.apply_chat_template(chat, tokenize=False, system_message="""")

inputs = tokenizer.encode(prompt, add_special_tokens=False, return_tensors=""pt"")
outputs = model.generate(input_ids=inputs, max_new_tokens=128)
print(tokenizer.decode(outputs[0]))
```

## Academic Benchmarks

<table>
<tbody>
<tr>
<td><strong>Model</strong></td>
<td><strong><center>Average</center></strong></td>
<td><strong><center>ARC</center></strong></td>
<td><strong><center>MMLU</center></strong></td>
<td><strong><center>Winogrande</center></strong></td>
<td><strong><center>Hellaswag</center></strong></td>
<td><strong><center>GSM8k</center></strong></td>
<td><strong><center>TruthfulQA</center></strong></td>
</tr>
<tr>
<td>gemma-1.1-7b-it</td><td><center>41.44</center></td><td><center>40.32</center></td><td><center>47.22</center></td><td><center>55.01</center></td><td><center>47.03</center></td><td><center>9.50</center></td><td><center>49.58</center></td>
</tr>
<tr>
<td>RoGemma-7b-Instruct-2024-06-28</td><td><center><strong>53.41</strong></center></td><td><center><strong>52.44</strong></center></td><td><center>54.44</center></td><td><center><strong>69.36</strong></center></td><td><center><strong>61.96</strong></center></td><td><center>31.06</center></td><td><center><strong>51.23</strong></center></td>
</tr>
<tr>
<td>RoGemma-7b-Instruct-2024-10-09</td><td><center>50.48</center></td><td><center>52.01</center></td><td><center>52.37</center></td><td><center>66.97</center></td><td><center>56.34</center></td><td><center>25.98</center></td><td><center>49.18</center></td>
</tr>
<tr>
<td><em>RoGemma-7b-Instruct-DPO-2024-10-09</em></td><td><center><em>48.27</em></center></td><td><center><em>46.66</em></center></td><td><center><em><strong>54.45</strong></em></center></td><td><center><em>63.73</em></center></td><td><center><em>49.33</em></center></td><td><center><em><strong>34.98</strong></em></center></td><td><center><em>40.45</em></center></td>
</tr>
</tbody>
</table>


## Downstream tasks

<table>
<tbody>
<tr>
<td></td>
<td colspan=""4""><center><strong>LaRoSeDa</strong></center></td>
<td colspan=""4""><center><strong>WMT</strong></center></td>
</tr>
<tr>
<td></td>
<td colspan=""2""><center><strong>Few-shot</strong></center></td>
<td colspan=""2""><center><strong>Finetuned</strong></center></td>
<td colspan=""2""><center><strong>Few-shot</strong></center></td>
<td colspan=""2""><center><strong>Finetuned</strong></center></td>
</tr>
<tr>
<td><strong>Model</strong></td>
<td><center><strong>Binary<br>(Macro F1)</strong></center></td>
<td><center><strong>Multiclass<br>(Macro F1)</strong></center></td>
<td><center><strong>Binary<br>(Macro F1)</strong></center></td>
<td><center><strong>Multiclass<br>(Macro F1)</strong></center></td>
<td><center><strong>EN-RO<br>(Bleu)</strong></center></td>
<td><center><strong>RO-EN<br>(Bleu)</strong></center></td>
<td><center><strong>EN-RO<br>(Bleu)</strong></center></td>
<td><center><strong>RO-EN<br>(Bleu)</strong></center>
</tr>
<tr>
<td>gemma-1.1-7b-it</td><td><center>87.54</center></td><td><center>51.48</center></td><td><center>83.87</center></td><td><center>85.61</center></td><td><center>17.96</center></td><td><center><strong>27.74</strong></center></td><td><center>25.48</center></td><td><center>36.11</center></td>
</tr>
<tr>
<td>RoGemma-7b-Instruct-2024-06-28</td><td><center><strong>97.86</strong></center></td><td><center><strong>65.70</strong></center></td><td><center>98.43</center></td><td><center><strong>87.17</strong></center></td><td><center><strong>27.91</strong></center></td><td><center>23.08</center></td><td><center><strong>27.99</strong></center></td><td><center><strong>39.51</strong></center></td>
</tr>
<tr>
<td>RoGemma-7b-Instruct-2024-10-09</td><td><center>86.96</center></td><td><center>56.72</center></td><td><center><strong>98.80</strong></center></td><td><center>85.81</center></td><td><center>24.45</center></td><td><center>14.20</center></td><td><center>25.96</center></td><td><center>39.07</center></td>
</tr>
<tr>
<td><em>RoGemma-7b-Instruct-DPO-2024-10-09</em></td><td><center><em>96.45</em></center></td><td><center><em>63.23</em></center></td><td><center><em>-</em></center></td><td><center><em>-</em></center></td><td><center><em>20.73</em></center></td><td><center><em>7.87</em></center></td><td><center><em>-</em></center></td><td><center><em>-</em></center></td>
</tr>
</tbody>
</table>


<table>
<tbody>
<tr>
<td></td>
<td colspan=""4""><center><strong>XQuAD</strong></center></td>
<td colspan=""4""><center><strong>STS</strong></center></td>
</tr>
<tr>
<td></td>
<td colspan=""2""><center><strong>Few-shot</strong></center></td>
<td colspan=""2""><center><strong>Finetuned</strong></center></td>
<td colspan=""2""><center><strong>Few-shot</strong></center></td>
<td colspan=""2""><center><strong>Finetuned</strong></center></td>
</tr>
<tr>
<td><strong>Model</strong></td>
<td><center><strong>(EM)</strong></center></td>
<td><center><strong>(F1)</strong></center></td>
<td><center><strong>(EM)</strong></center></td>
<td><center><strong>(F1)</strong></center></td>
<td><center><strong>(Spearman)</strong></center></td>
<td><center><strong>(Pearson)</strong></center></td>
<td><center><strong>(Spearman)</strong></center></td>
<td><center><strong>(Pearson)</strong></center></td>
</tr>
<tr>
<td>gemma-1.1-7b-it</td><td><center><strong>42.10</strong></center></td><td><center><strong>62.30</strong></center></td><td><center><strong>60.34</strong></center></td><td><center><strong>77.40</strong></center></td><td><center>49.10</center></td><td><center>50.23</center></td><td><center>83.43</center></td><td><center>83.64</center></td>
</tr>
<tr>
<td>RoGemma-7b-Instruct-2024-06-28</td><td><center>17.75</center></td><td><center>28.11</center></td><td><center>52.02</center></td><td><center>68.43</center></td><td><center><strong>73.96</strong></center></td><td><center><strong>75.16</strong></center></td><td><center>86.45</center></td><td><center>86.31</center></td>
</tr>
<tr>
<td>RoGemma-7b-Instruct-2024-10-09</td><td><center>26.03</center></td><td><center>41.58</center></td><td><center>46.72</center></td><td><center>60.79</center></td><td><center>73.23</center></td><td><center>71.58</center></td><td><center><strong>88.42</strong></center></td><td><center><strong>88.45</strong></center></td>
</tr>
<tr>
<td><em>RoGemma-7b-Instruct-DPO-2024-10-09</em></td><td><center><em>19.14</em></center></td><td><center><em>38.10</em></center></td><td><center><em>-</em></center></td><td><center><em>-</em></center></td><td><center><em>69.38</em></center></td><td><center><em>69.34</em></center></td><td><center><em>-</em></center></td><td><center><em>-</em></center></td>
</tr>
</tbody>
</table>

## MT-Bench

<<table>
<tbody>
<tr>
<td><strong>Model</strong></td>
<td><strong><center>Average</center></strong></td>
<td><strong><center>1st turn</center></strong></td>
<td><strong><center>2nd turn</center></strong></td>
<td><strong><center>Answers in Ro</center></strong></td>
</tr>
<tr>
<td>gemma-1.1-7b-it</td><td><center>4.83</center></td><td><center>5.11</center></td><td><center>4.55</center></td><td><center><strong>160/160</strong></center></td>
</tr>
<tr>
<td>RoGemma-7b-Instruct-2024-06-28</td><td><center>5.26</center></td><td><center><strong>5.92</strong></center></td><td><center>4.60</center></td><td><center><strong>160/160</strong></center></td>
</tr>
<tr>
<td>RoGemma-7b-Instruct-2024-10-09</td><td><center>5.24</center></td><td><center>5.55</center></td><td><center>4.94</center></td><td><center><strong>160/160</strong></center></td>
</tr>
<tr>
<td><em>RoGemma-7b-Instruct-DPO-2024-10-09</em></td><td><center><em><strong>5.47</strong></em></center></td><td><center><em><strong>5.92</strong></em></center></td><td><center><em><strong>5.03</strong></em></center></td><td><center><em><strong>160/160</strong></em></center></td>
</tr>
</tbody>
</table>

## RoCulturaBench

<table>
<tbody>
<tr>
<td><strong>Model</strong></td>
<td><strong><center>Average</center></strong></td>
<td><strong><center>Answers in Ro</center></strong></td>
</tr>
<tr>
<td>gemma-1.1-7b-it</td><td><center>3.38</center></td><td><center><strong>100/100</strong></center></td>
</tr>
<tr>
<td>RoGemma-7b-Instruct-2024-06-28</td><td><center>3.26</center></td><td><center><strong>100/100</strong></center></td>
</tr>
<tr>
<td>RoGemma-7b-Instruct-2024-10-09</td><td><center>3.51</center></td><td><center><strong>100/100</strong></center></td>
</tr>
<tr>
<td><em>RoGemma-7b-Instruct-DPO-2024-10-09</em></td><td><center><em><strong>3.94</strong></em></center></td><td><center><em><strong>100/100</strong></em></center></td>
</tr>
</tbody>
</table>

## RoGemma Model Family

| Model              | Link  |
|--------------------|:--------:|
|RoGemma-7b-Instruct-2024-06-28| [link](https://huggingface.co/OpenLLM-Ro/RoGemma-7b-Instruct-2024-06-28) |
|RoGemma-7b-Instruct-2024-10-09| [link](https://huggingface.co/OpenLLM-Ro/RoGemma-7b-Instruct-2024-10-09) |
|*RoGemma-7b-Instruct-DPO-2024-10-09*| [link](https://huggingface.co/OpenLLM-Ro/RoGemma-7b-Instruct-DPO-2024-10-09) |


## Citation 

```
@misc{masala2024vorbecstiromanecsterecipetrain,
      title={""Vorbe\c{s}ti Rom\^ane\c{s}te?"" A Recipe to Train Powerful Romanian LLMs with English Instructions}, 
      author={Mihai Masala and Denis C. Ilie-Ablachim and Alexandru Dima and Dragos Corlatescu and Miruna Zavelca and Ovio Olaru and Simina Terian-Dan and Andrei Terian-Dan and Marius Leordeanu and Horia Velicu and Marius Popescu and Mihai Dascalu and Traian Rebedea},
      year={2024},
      eprint={2406.18266},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2406.18266}, 
}
```
<!-- **APA:**

[More Information Needed]  -->","{""id"": ""OpenLLM-Ro/RoGemma-7b-Instruct-DPO"", ""author"": ""OpenLLM-Ro"", ""sha"": ""d114d0f964a5bfa710f501c3e37a892d0360b4f8"", ""last_modified"": ""2024-10-10 18:21:22+00:00"", ""created_at"": ""2024-10-10 14:02:58+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 4, ""downloads_all_time"": null, ""likes"": 1, ""library_name"": null, ""gguf"": null, ""inference"": null, ""tags"": [""safetensors"", ""gemma"", ""ro"", ""dataset:OpenLLM-Ro/ro_dpo_helpsteer"", ""arxiv:2406.18266"", ""base_model:OpenLLM-Ro/RoGemma-7b-Instruct-2024-10-09"", ""base_model:finetune:OpenLLM-Ro/RoGemma-7b-Instruct-2024-10-09"", ""license:cc-by-nc-4.0"", ""model-index"", ""region:us""], ""pipeline_tag"": null, ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model:\n- OpenLLM-Ro/RoGemma-7b-Instruct-2024-10-09\ndatasets:\n- OpenLLM-Ro/ro_dpo_helpsteer\nlanguage:\n- ro\nlicense: cc-by-nc-4.0\nmodel-index:\n- name: OpenLLM-Ro/RoGemma-7b-Instruct-DPO-2024-10-09\n  results:\n  - task:\n      type: text-generation\n    dataset:\n      name: RoMT-Bench\n      type: RoMT-Bench\n    metrics:\n    - type: Score\n      value: 5.47\n      name: Score\n      verified: false\n    - type: Score\n      value: 5.92\n      name: First turn\n      verified: false\n    - type: Score\n      value: 5.03\n      name: Second turn\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: RoCulturaBench\n      type: RoCulturaBench\n    metrics:\n    - type: Score\n      value: 3.94\n      name: Score\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: Romanian_Academic_Benchmarks\n      type: Romanian_Academic_Benchmarks\n    metrics:\n    - type: accuracy\n      value: 48.27\n      name: Average accuracy\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: OpenLLM-Ro/ro_arc_challenge\n      type: OpenLLM-Ro/ro_arc_challenge\n    metrics:\n    - type: accuracy\n      value: 46.66\n      name: Average accuracy\n      verified: false\n    - type: accuracy\n      value: 48.84\n      name: 0-shot\n      verified: false\n    - type: accuracy\n      value: 46.27\n      name: 1-shot\n      verified: false\n    - type: accuracy\n      value: 44.64\n      name: 3-shot\n      verified: false\n    - type: accuracy\n      value: 45.76\n      name: 5-shot\n      verified: false\n    - type: accuracy\n      value: 46.62\n      name: 10-shot\n      verified: false\n    - type: accuracy\n      value: 47.81\n      name: 25-shot\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: OpenLLM-Ro/ro_mmlu\n      type: OpenLLM-Ro/ro_mmlu\n    metrics:\n    - type: accuracy\n      value: 54.45\n      name: Average accuracy\n      verified: false\n    - type: accuracy\n      value: 52.47\n      name: 0-shot\n      verified: false\n    - type: accuracy\n      value: 54.4\n      name: 1-shot\n      verified: false\n    - type: accuracy\n      value: 55.63\n      name: 3-shot\n      verified: false\n    - type: accuracy\n      value: 55.3\n      name: 5-shot\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: OpenLLM-Ro/ro_winogrande\n      type: OpenLLM-Ro/ro_winogrande\n    metrics:\n    - type: accuracy\n      value: 63.73\n      name: Average accuracy\n      verified: false\n    - type: accuracy\n      value: 60.54\n      name: 0-shot\n      verified: false\n    - type: accuracy\n      value: 63.54\n      name: 1-shot\n      verified: false\n    - type: accuracy\n      value: 63.46\n      name: 3-shot\n      verified: false\n    - type: accuracy\n      value: 67.4\n      name: 5-shot\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: OpenLLM-Ro/ro_hellaswag\n      type: OpenLLM-Ro/ro_hellaswag\n    metrics:\n    - type: accuracy\n      value: 49.33\n      name: Average accuracy\n      verified: false\n    - type: accuracy\n      value: 52.67\n      name: 0-shot\n      verified: false\n    - type: accuracy\n      value: 50.89\n      name: 1-shot\n      verified: false\n    - type: accuracy\n      value: 47.85\n      name: 3-shot\n      verified: false\n    - type: accuracy\n      value: 45.98\n      name: 5-shot\n      verified: false\n    - type: accuracy\n      value: 49.26\n      name: 10-shot\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: OpenLLM-Ro/ro_gsm8k\n      type: OpenLLM-Ro/ro_gsm8k\n    metrics:\n    - type: accuracy\n      value: 34.98\n      name: Average accuracy\n      verified: false\n    - type: accuracy\n      value: 27.45\n      name: 1-shot\n      verified: false\n    - type: accuracy\n      value: 36.32\n      name: 3-shot\n      verified: false\n    - type: accuracy\n      value: 41.17\n      name: 5-shot\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: OpenLLM-Ro/ro_truthfulqa\n      type: OpenLLM-Ro/ro_truthfulqa\n    metrics:\n    - type: accuracy\n      value: 40.45\n      name: Average accuracy\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: LaRoSeDa_binary\n      type: LaRoSeDa_binary\n    metrics:\n    - type: macro-f1\n      value: 96.45\n      name: Average macro-f1\n      verified: false\n    - type: macro-f1\n      value: 95.9\n      name: 0-shot\n      verified: false\n    - type: macro-f1\n      value: 95.36\n      name: 1-shot\n      verified: false\n    - type: macro-f1\n      value: 97.13\n      name: 3-shot\n      verified: false\n    - type: macro-f1\n      value: 97.43\n      name: 5-shot\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: LaRoSeDa_multiclass\n      type: LaRoSeDa_multiclass\n    metrics:\n    - type: macro-f1\n      value: 63.23\n      name: Average macro-f1\n      verified: false\n    - type: macro-f1\n      value: 66.82\n      name: 0-shot\n      verified: false\n    - type: macro-f1\n      value: 59.47\n      name: 1-shot\n      verified: false\n    - type: macro-f1\n      value: 62.88\n      name: 3-shot\n      verified: false\n    - type: macro-f1\n      value: 63.77\n      name: 5-shot\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: LaRoSeDa_binary_finetuned\n      type: LaRoSeDa_binary_finetuned\n    metrics:\n    - type: macro-f1\n      value: 0\n      name: Average macro-f1\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: LaRoSeDa_multiclass_finetuned\n      type: LaRoSeDa_multiclass_finetuned\n    metrics:\n    - type: macro-f1\n      value: 0\n      name: Average macro-f1\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: WMT_EN-RO\n      type: WMT_EN-RO\n    metrics:\n    - type: bleu\n      value: 20.73\n      name: Average bleu\n      verified: false\n    - type: bleu\n      value: 8\n      name: 0-shot\n      verified: false\n    - type: bleu\n      value: 24.37\n      name: 1-shot\n      verified: false\n    - type: bleu\n      value: 26.19\n      name: 3-shot\n      verified: false\n    - type: bleu\n      value: 24.36\n      name: 5-shot\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: WMT_RO-EN\n      type: WMT_RO-EN\n    metrics:\n    - type: bleu\n      value: 7.87\n      name: Average bleu\n      verified: false\n    - type: bleu\n      value: 0.76\n      name: 0-shot\n      verified: false\n    - type: bleu\n      value: 4.67\n      name: 1-shot\n      verified: false\n    - type: bleu\n      value: 13.33\n      name: 3-shot\n      verified: false\n    - type: bleu\n      value: 12.73\n      name: 5-shot\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: WMT_EN-RO_finetuned\n      type: WMT_EN-RO_finetuned\n    metrics:\n    - type: bleu\n      value: 0\n      name: Average bleu\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: WMT_RO-EN_finetuned\n      type: WMT_RO-EN_finetuned\n    metrics:\n    - type: bleu\n      value: 0\n      name: Average bleu\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: XQuAD\n      type: XQuAD\n    metrics:\n    - type: exact_match\n      value: 19.14\n      name: Average exact_match\n      verified: false\n    - type: f1\n      value: 38.1\n      name: Average f1\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: XQuAD_finetuned\n      type: XQuAD_finetuned\n    metrics:\n    - type: exact_match\n      value: 0\n      name: Average exact_match\n      verified: false\n    - type: f1\n      value: 0\n      name: Average f1\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: STS\n      type: STS\n    metrics:\n    - type: spearman\n      value: 69.38\n      name: Average spearman\n      verified: false\n    - type: pearson\n      value: 69.34\n      name: Average pearson\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: STS_finetuned\n      type: STS_finetuned\n    metrics:\n    - type: spearman\n      value: 0\n      name: Average spearman\n      verified: false\n    - type: pearson\n      value: 0\n      name: Average pearson\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: XQuAD_EM\n      type: XQuAD_EM\n    metrics:\n    - type: exact_match\n      value: 14.37\n      name: 0-shot\n      verified: false\n    - type: exact_match\n      value: 19.08\n      name: 1-shot\n      verified: false\n    - type: exact_match\n      value: 17.73\n      name: 3-shot\n      verified: false\n    - type: exact_match\n      value: 25.38\n      name: 5-shot\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: XQuAD_F1\n      type: XQuAD_F1\n    metrics:\n    - type: f1\n      value: 33.52\n      name: 0-shot\n      verified: false\n    - type: f1\n      value: 37.27\n      name: 1-shot\n      verified: false\n    - type: f1\n      value: 35.77\n      name: 3-shot\n      verified: false\n    - type: f1\n      value: 45.84\n      name: 5-shot\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: STS_Spearman\n      type: STS_Spearman\n    metrics:\n    - type: spearman\n      value: 54.5\n      name: 1-shot\n      verified: false\n    - type: spearman\n      value: 74.93\n      name: 3-shot\n      verified: false\n    - type: spearman\n      value: 78.7\n      name: 5-shot\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: STS_Pearson\n      type: STS_Pearson\n    metrics:\n    - type: pearson\n      value: 54.91\n      name: 1-shot\n      verified: false\n    - type: pearson\n      value: 74.98\n      name: 3-shot\n      verified: false\n    - type: pearson\n      value: 78.13\n      name: 5-shot\n      verified: false"", ""widget_data"": null, ""model_index"": [{""name"": ""OpenLLM-Ro/RoGemma-7b-Instruct-DPO-2024-10-09"", ""results"": [{""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""RoMT-Bench"", ""type"": ""RoMT-Bench""}, ""metrics"": [{""name"": ""Score"", ""type"": ""Score"", ""value"": 5.47, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""RoCulturaBench"", ""type"": ""RoCulturaBench""}, ""metrics"": [{""name"": ""Score"", ""type"": ""Score"", ""value"": 3.94, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""Romanian_Academic_Benchmarks"", ""type"": ""Romanian_Academic_Benchmarks""}, ""metrics"": [{""name"": ""Average accuracy"", ""type"": ""accuracy"", ""value"": 48.27, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""OpenLLM-Ro/ro_arc_challenge"", ""type"": ""OpenLLM-Ro/ro_arc_challenge""}, ""metrics"": [{""name"": ""Average accuracy"", ""type"": ""accuracy"", ""value"": 46.66, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""OpenLLM-Ro/ro_mmlu"", ""type"": ""OpenLLM-Ro/ro_mmlu""}, ""metrics"": [{""name"": ""Average accuracy"", ""type"": ""accuracy"", ""value"": 54.45, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""OpenLLM-Ro/ro_winogrande"", ""type"": ""OpenLLM-Ro/ro_winogrande""}, ""metrics"": [{""name"": ""Average accuracy"", ""type"": ""accuracy"", ""value"": 63.73, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""OpenLLM-Ro/ro_hellaswag"", ""type"": ""OpenLLM-Ro/ro_hellaswag""}, ""metrics"": [{""name"": ""Average accuracy"", ""type"": ""accuracy"", ""value"": 49.33, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""OpenLLM-Ro/ro_gsm8k"", ""type"": ""OpenLLM-Ro/ro_gsm8k""}, ""metrics"": [{""name"": ""Average accuracy"", ""type"": ""accuracy"", ""value"": 34.98, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""OpenLLM-Ro/ro_truthfulqa"", ""type"": ""OpenLLM-Ro/ro_truthfulqa""}, ""metrics"": [{""name"": ""Average accuracy"", ""type"": ""accuracy"", ""value"": 40.45, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""LaRoSeDa_binary"", ""type"": ""LaRoSeDa_binary""}, ""metrics"": [{""name"": ""Average macro-f1"", ""type"": ""macro-f1"", ""value"": 96.45, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""LaRoSeDa_multiclass"", ""type"": ""LaRoSeDa_multiclass""}, ""metrics"": [{""name"": ""Average macro-f1"", ""type"": ""macro-f1"", ""value"": 63.23, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""LaRoSeDa_binary_finetuned"", ""type"": ""LaRoSeDa_binary_finetuned""}, ""metrics"": [{""name"": ""Average macro-f1"", ""type"": ""macro-f1"", ""value"": 0, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""LaRoSeDa_multiclass_finetuned"", ""type"": ""LaRoSeDa_multiclass_finetuned""}, ""metrics"": [{""name"": ""Average macro-f1"", ""type"": ""macro-f1"", ""value"": 0, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""WMT_EN-RO"", ""type"": ""WMT_EN-RO""}, ""metrics"": [{""name"": ""Average bleu"", ""type"": ""bleu"", ""value"": 20.73, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""WMT_RO-EN"", ""type"": ""WMT_RO-EN""}, ""metrics"": [{""name"": ""Average bleu"", ""type"": ""bleu"", ""value"": 7.87, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""WMT_EN-RO_finetuned"", ""type"": ""WMT_EN-RO_finetuned""}, ""metrics"": [{""name"": ""Average bleu"", ""type"": ""bleu"", ""value"": 0, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""WMT_RO-EN_finetuned"", ""type"": ""WMT_RO-EN_finetuned""}, ""metrics"": [{""name"": ""Average bleu"", ""type"": ""bleu"", ""value"": 0, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""XQuAD"", ""type"": ""XQuAD""}, ""metrics"": [{""name"": ""Average exact_match"", ""type"": ""exact_match"", ""value"": 19.14, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""XQuAD"", ""type"": ""XQuAD""}, ""metrics"": [{""name"": ""Average f1"", ""type"": ""f1"", ""value"": 38.1, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""XQuAD_finetuned"", ""type"": ""XQuAD_finetuned""}, ""metrics"": [{""name"": ""Average exact_match"", ""type"": ""exact_match"", ""value"": 0, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""XQuAD_finetuned"", ""type"": ""XQuAD_finetuned""}, ""metrics"": [{""name"": ""Average f1"", ""type"": ""f1"", ""value"": 0, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""STS"", ""type"": ""STS""}, ""metrics"": [{""name"": ""Average spearman"", ""type"": ""spearman"", ""value"": 69.38, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""STS"", ""type"": ""STS""}, ""metrics"": [{""name"": ""Average pearson"", ""type"": ""pearson"", ""value"": 69.34, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""STS_finetuned"", ""type"": ""STS_finetuned""}, ""metrics"": [{""name"": ""Average spearman"", ""type"": ""spearman"", ""value"": 0, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""STS_finetuned"", ""type"": ""STS_finetuned""}, ""metrics"": [{""name"": ""Average pearson"", ""type"": ""pearson"", ""value"": 0, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""RoMT-Bench"", ""type"": ""RoMT-Bench""}, ""metrics"": [{""name"": ""First turn"", ""type"": ""Score"", ""value"": 5.92, ""verified"": false}, {""name"": ""Second turn"", ""type"": ""Score"", ""value"": 5.03, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""OpenLLM-Ro/ro_arc_challenge"", ""type"": ""OpenLLM-Ro/ro_arc_challenge""}, ""metrics"": [{""name"": ""0-shot"", ""type"": ""accuracy"", ""value"": 48.84, ""verified"": false}, {""name"": ""1-shot"", ""type"": ""accuracy"", ""value"": 46.27, ""verified"": false}, {""name"": ""3-shot"", ""type"": ""accuracy"", ""value"": 44.64, ""verified"": false}, {""name"": ""5-shot"", ""type"": ""accuracy"", ""value"": 45.76, ""verified"": false}, {""name"": ""10-shot"", ""type"": ""accuracy"", ""value"": 46.62, ""verified"": false}, {""name"": ""25-shot"", ""type"": ""accuracy"", ""value"": 47.81, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""OpenLLM-Ro/ro_mmlu"", ""type"": ""OpenLLM-Ro/ro_mmlu""}, ""metrics"": [{""name"": ""0-shot"", ""type"": ""accuracy"", ""value"": 52.47, ""verified"": false}, {""name"": ""1-shot"", ""type"": ""accuracy"", ""value"": 54.4, ""verified"": false}, {""name"": ""3-shot"", ""type"": ""accuracy"", ""value"": 55.63, ""verified"": false}, {""name"": ""5-shot"", ""type"": ""accuracy"", ""value"": 55.3, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""OpenLLM-Ro/ro_winogrande"", ""type"": ""OpenLLM-Ro/ro_winogrande""}, ""metrics"": [{""name"": ""0-shot"", ""type"": ""accuracy"", ""value"": 60.54, ""verified"": false}, {""name"": ""1-shot"", ""type"": ""accuracy"", ""value"": 63.54, ""verified"": false}, {""name"": ""3-shot"", ""type"": ""accuracy"", ""value"": 63.46, ""verified"": false}, {""name"": ""5-shot"", ""type"": ""accuracy"", ""value"": 67.4, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""OpenLLM-Ro/ro_hellaswag"", ""type"": ""OpenLLM-Ro/ro_hellaswag""}, ""metrics"": [{""name"": ""0-shot"", ""type"": ""accuracy"", ""value"": 52.67, ""verified"": false}, {""name"": ""1-shot"", ""type"": ""accuracy"", ""value"": 50.89, ""verified"": false}, {""name"": ""3-shot"", ""type"": ""accuracy"", ""value"": 47.85, ""verified"": false}, {""name"": ""5-shot"", ""type"": ""accuracy"", ""value"": 45.98, ""verified"": false}, {""name"": ""10-shot"", ""type"": ""accuracy"", ""value"": 49.26, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""OpenLLM-Ro/ro_gsm8k"", ""type"": ""OpenLLM-Ro/ro_gsm8k""}, ""metrics"": [{""name"": ""1-shot"", ""type"": ""accuracy"", ""value"": 27.45, ""verified"": false}, {""name"": ""3-shot"", ""type"": ""accuracy"", ""value"": 36.32, ""verified"": false}, {""name"": ""5-shot"", ""type"": ""accuracy"", ""value"": 41.17, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""LaRoSeDa_binary"", ""type"": ""LaRoSeDa_binary""}, ""metrics"": [{""name"": ""0-shot"", ""type"": ""macro-f1"", ""value"": 95.9, ""verified"": false}, {""name"": ""1-shot"", ""type"": ""macro-f1"", ""value"": 95.36, ""verified"": false}, {""name"": ""3-shot"", ""type"": ""macro-f1"", ""value"": 97.13, ""verified"": false}, {""name"": ""5-shot"", ""type"": ""macro-f1"", ""value"": 97.43, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""LaRoSeDa_multiclass"", ""type"": ""LaRoSeDa_multiclass""}, ""metrics"": [{""name"": ""0-shot"", ""type"": ""macro-f1"", ""value"": 66.82, ""verified"": false}, {""name"": ""1-shot"", ""type"": ""macro-f1"", ""value"": 59.47, ""verified"": false}, {""name"": ""3-shot"", ""type"": ""macro-f1"", ""value"": 62.88, ""verified"": false}, {""name"": ""5-shot"", ""type"": ""macro-f1"", ""value"": 63.77, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""WMT_EN-RO"", ""type"": ""WMT_EN-RO""}, ""metrics"": [{""name"": ""0-shot"", ""type"": ""bleu"", ""value"": 8, ""verified"": false}, {""name"": ""1-shot"", ""type"": ""bleu"", ""value"": 24.37, ""verified"": false}, {""name"": ""3-shot"", ""type"": ""bleu"", ""value"": 26.19, ""verified"": false}, {""name"": ""5-shot"", ""type"": ""bleu"", ""value"": 24.36, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""WMT_RO-EN"", ""type"": ""WMT_RO-EN""}, ""metrics"": [{""name"": ""0-shot"", ""type"": ""bleu"", ""value"": 0.76, ""verified"": false}, {""name"": ""1-shot"", ""type"": ""bleu"", ""value"": 4.67, ""verified"": false}, {""name"": ""3-shot"", ""type"": ""bleu"", ""value"": 13.33, ""verified"": false}, {""name"": ""5-shot"", ""type"": ""bleu"", ""value"": 12.73, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""XQuAD_EM"", ""type"": ""XQuAD_EM""}, ""metrics"": [{""name"": ""0-shot"", ""type"": ""exact_match"", ""value"": 14.37, ""verified"": false}, {""name"": ""1-shot"", ""type"": ""exact_match"", ""value"": 19.08, ""verified"": false}, {""name"": ""3-shot"", ""type"": ""exact_match"", ""value"": 17.73, ""verified"": false}, {""name"": ""5-shot"", ""type"": ""exact_match"", ""value"": 25.38, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""XQuAD_F1"", ""type"": ""XQuAD_F1""}, ""metrics"": [{""name"": ""0-shot"", ""type"": ""f1"", ""value"": 33.52, ""verified"": false}, {""name"": ""1-shot"", ""type"": ""f1"", ""value"": 37.27, ""verified"": false}, {""name"": ""3-shot"", ""type"": ""f1"", ""value"": 35.77, ""verified"": false}, {""name"": ""5-shot"", ""type"": ""f1"", ""value"": 45.84, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""STS_Spearman"", ""type"": ""STS_Spearman""}, ""metrics"": [{""name"": ""1-shot"", ""type"": ""spearman"", ""value"": 54.5, ""verified"": false}, {""name"": ""3-shot"", ""type"": ""spearman"", ""value"": 74.93, ""verified"": false}, {""name"": ""5-shot"", ""type"": ""spearman"", ""value"": 78.7, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""STS_Pearson"", ""type"": ""STS_Pearson""}, ""metrics"": [{""name"": ""1-shot"", ""type"": ""pearson"", ""value"": 54.91, ""verified"": false}, {""name"": ""3-shot"", ""type"": ""pearson"", ""value"": 74.98, ""verified"": false}, {""name"": ""5-shot"", ""type"": ""pearson"", ""value"": 78.13, ""verified"": false}]}]}], ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ '<bos>' }}{% if messages[0]['role'] == 'system' %}{% set loop_messages = messages[1:] %}{% set system_message = messages[0]['content'] %}{% else %}{% set loop_messages = messages %}{% endif %}{% if system_message is defined %}{{ system_message }}{% endif %}{% for message in loop_messages %}{% set content = message['content'] %}{% if message['role'] == 'user' %}{{ '<start_of_turn>user\n' + content + '<end_of_turn>\n<start_of_turn>model\n' }}{% elif message['role'] == 'assistant' %}{{ content + '<end_of_turn>\n' }}{% endif %}{% endfor %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": null, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='generation_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00001-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00002-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00003-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00004-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model.safetensors.index.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": {""parameters"": {""BF16"": 8537680896}, ""total"": 8537680896}, ""security_repo_status"": null, ""lastModified"": ""2024-10-10 18:21:22+00:00"", ""cardData"": ""base_model:\n- OpenLLM-Ro/RoGemma-7b-Instruct-2024-10-09\ndatasets:\n- OpenLLM-Ro/ro_dpo_helpsteer\nlanguage:\n- ro\nlicense: cc-by-nc-4.0\nmodel-index:\n- name: OpenLLM-Ro/RoGemma-7b-Instruct-DPO-2024-10-09\n  results:\n  - task:\n      type: text-generation\n    dataset:\n      name: RoMT-Bench\n      type: RoMT-Bench\n    metrics:\n    - type: Score\n      value: 5.47\n      name: Score\n      verified: false\n    - type: Score\n      value: 5.92\n      name: First turn\n      verified: false\n    - type: Score\n      value: 5.03\n      name: Second turn\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: RoCulturaBench\n      type: RoCulturaBench\n    metrics:\n    - type: Score\n      value: 3.94\n      name: Score\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: Romanian_Academic_Benchmarks\n      type: Romanian_Academic_Benchmarks\n    metrics:\n    - type: accuracy\n      value: 48.27\n      name: Average accuracy\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: OpenLLM-Ro/ro_arc_challenge\n      type: OpenLLM-Ro/ro_arc_challenge\n    metrics:\n    - type: accuracy\n      value: 46.66\n      name: Average accuracy\n      verified: false\n    - type: accuracy\n      value: 48.84\n      name: 0-shot\n      verified: false\n    - type: accuracy\n      value: 46.27\n      name: 1-shot\n      verified: false\n    - type: accuracy\n      value: 44.64\n      name: 3-shot\n      verified: false\n    - type: accuracy\n      value: 45.76\n      name: 5-shot\n      verified: false\n    - type: accuracy\n      value: 46.62\n      name: 10-shot\n      verified: false\n    - type: accuracy\n      value: 47.81\n      name: 25-shot\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: OpenLLM-Ro/ro_mmlu\n      type: OpenLLM-Ro/ro_mmlu\n    metrics:\n    - type: accuracy\n      value: 54.45\n      name: Average accuracy\n      verified: false\n    - type: accuracy\n      value: 52.47\n      name: 0-shot\n      verified: false\n    - type: accuracy\n      value: 54.4\n      name: 1-shot\n      verified: false\n    - type: accuracy\n      value: 55.63\n      name: 3-shot\n      verified: false\n    - type: accuracy\n      value: 55.3\n      name: 5-shot\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: OpenLLM-Ro/ro_winogrande\n      type: OpenLLM-Ro/ro_winogrande\n    metrics:\n    - type: accuracy\n      value: 63.73\n      name: Average accuracy\n      verified: false\n    - type: accuracy\n      value: 60.54\n      name: 0-shot\n      verified: false\n    - type: accuracy\n      value: 63.54\n      name: 1-shot\n      verified: false\n    - type: accuracy\n      value: 63.46\n      name: 3-shot\n      verified: false\n    - type: accuracy\n      value: 67.4\n      name: 5-shot\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: OpenLLM-Ro/ro_hellaswag\n      type: OpenLLM-Ro/ro_hellaswag\n    metrics:\n    - type: accuracy\n      value: 49.33\n      name: Average accuracy\n      verified: false\n    - type: accuracy\n      value: 52.67\n      name: 0-shot\n      verified: false\n    - type: accuracy\n      value: 50.89\n      name: 1-shot\n      verified: false\n    - type: accuracy\n      value: 47.85\n      name: 3-shot\n      verified: false\n    - type: accuracy\n      value: 45.98\n      name: 5-shot\n      verified: false\n    - type: accuracy\n      value: 49.26\n      name: 10-shot\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: OpenLLM-Ro/ro_gsm8k\n      type: OpenLLM-Ro/ro_gsm8k\n    metrics:\n    - type: accuracy\n      value: 34.98\n      name: Average accuracy\n      verified: false\n    - type: accuracy\n      value: 27.45\n      name: 1-shot\n      verified: false\n    - type: accuracy\n      value: 36.32\n      name: 3-shot\n      verified: false\n    - type: accuracy\n      value: 41.17\n      name: 5-shot\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: OpenLLM-Ro/ro_truthfulqa\n      type: OpenLLM-Ro/ro_truthfulqa\n    metrics:\n    - type: accuracy\n      value: 40.45\n      name: Average accuracy\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: LaRoSeDa_binary\n      type: LaRoSeDa_binary\n    metrics:\n    - type: macro-f1\n      value: 96.45\n      name: Average macro-f1\n      verified: false\n    - type: macro-f1\n      value: 95.9\n      name: 0-shot\n      verified: false\n    - type: macro-f1\n      value: 95.36\n      name: 1-shot\n      verified: false\n    - type: macro-f1\n      value: 97.13\n      name: 3-shot\n      verified: false\n    - type: macro-f1\n      value: 97.43\n      name: 5-shot\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: LaRoSeDa_multiclass\n      type: LaRoSeDa_multiclass\n    metrics:\n    - type: macro-f1\n      value: 63.23\n      name: Average macro-f1\n      verified: false\n    - type: macro-f1\n      value: 66.82\n      name: 0-shot\n      verified: false\n    - type: macro-f1\n      value: 59.47\n      name: 1-shot\n      verified: false\n    - type: macro-f1\n      value: 62.88\n      name: 3-shot\n      verified: false\n    - type: macro-f1\n      value: 63.77\n      name: 5-shot\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: LaRoSeDa_binary_finetuned\n      type: LaRoSeDa_binary_finetuned\n    metrics:\n    - type: macro-f1\n      value: 0\n      name: Average macro-f1\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: LaRoSeDa_multiclass_finetuned\n      type: LaRoSeDa_multiclass_finetuned\n    metrics:\n    - type: macro-f1\n      value: 0\n      name: Average macro-f1\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: WMT_EN-RO\n      type: WMT_EN-RO\n    metrics:\n    - type: bleu\n      value: 20.73\n      name: Average bleu\n      verified: false\n    - type: bleu\n      value: 8\n      name: 0-shot\n      verified: false\n    - type: bleu\n      value: 24.37\n      name: 1-shot\n      verified: false\n    - type: bleu\n      value: 26.19\n      name: 3-shot\n      verified: false\n    - type: bleu\n      value: 24.36\n      name: 5-shot\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: WMT_RO-EN\n      type: WMT_RO-EN\n    metrics:\n    - type: bleu\n      value: 7.87\n      name: Average bleu\n      verified: false\n    - type: bleu\n      value: 0.76\n      name: 0-shot\n      verified: false\n    - type: bleu\n      value: 4.67\n      name: 1-shot\n      verified: false\n    - type: bleu\n      value: 13.33\n      name: 3-shot\n      verified: false\n    - type: bleu\n      value: 12.73\n      name: 5-shot\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: WMT_EN-RO_finetuned\n      type: WMT_EN-RO_finetuned\n    metrics:\n    - type: bleu\n      value: 0\n      name: Average bleu\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: WMT_RO-EN_finetuned\n      type: WMT_RO-EN_finetuned\n    metrics:\n    - type: bleu\n      value: 0\n      name: Average bleu\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: XQuAD\n      type: XQuAD\n    metrics:\n    - type: exact_match\n      value: 19.14\n      name: Average exact_match\n      verified: false\n    - type: f1\n      value: 38.1\n      name: Average f1\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: XQuAD_finetuned\n      type: XQuAD_finetuned\n    metrics:\n    - type: exact_match\n      value: 0\n      name: Average exact_match\n      verified: false\n    - type: f1\n      value: 0\n      name: Average f1\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: STS\n      type: STS\n    metrics:\n    - type: spearman\n      value: 69.38\n      name: Average spearman\n      verified: false\n    - type: pearson\n      value: 69.34\n      name: Average pearson\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: STS_finetuned\n      type: STS_finetuned\n    metrics:\n    - type: spearman\n      value: 0\n      name: Average spearman\n      verified: false\n    - type: pearson\n      value: 0\n      name: Average pearson\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: XQuAD_EM\n      type: XQuAD_EM\n    metrics:\n    - type: exact_match\n      value: 14.37\n      name: 0-shot\n      verified: false\n    - type: exact_match\n      value: 19.08\n      name: 1-shot\n      verified: false\n    - type: exact_match\n      value: 17.73\n      name: 3-shot\n      verified: false\n    - type: exact_match\n      value: 25.38\n      name: 5-shot\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: XQuAD_F1\n      type: XQuAD_F1\n    metrics:\n    - type: f1\n      value: 33.52\n      name: 0-shot\n      verified: false\n    - type: f1\n      value: 37.27\n      name: 1-shot\n      verified: false\n    - type: f1\n      value: 35.77\n      name: 3-shot\n      verified: false\n    - type: f1\n      value: 45.84\n      name: 5-shot\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: STS_Spearman\n      type: STS_Spearman\n    metrics:\n    - type: spearman\n      value: 54.5\n      name: 1-shot\n      verified: false\n    - type: spearman\n      value: 74.93\n      name: 3-shot\n      verified: false\n    - type: spearman\n      value: 78.7\n      name: 5-shot\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: STS_Pearson\n      type: STS_Pearson\n    metrics:\n    - type: pearson\n      value: 54.91\n      name: 1-shot\n      verified: false\n    - type: pearson\n      value: 74.98\n      name: 3-shot\n      verified: false\n    - type: pearson\n      value: 78.13\n      name: 5-shot\n      verified: false"", ""transformersInfo"": null, ""_id"": ""6707de9205f8cf31c90d0e2f"", ""modelId"": ""OpenLLM-Ro/RoGemma-7b-Instruct-DPO"", ""usedStorage"": 17097150888}",2,,0,https://huggingface.co/mradermacher/RoGemma-7b-Instruct-DPO-GGUF,1,,0,huggingface/InferenceSupport/discussions/new?title=OpenLLM-Ro/RoGemma-7b-Instruct-DPO&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5BOpenLLM-Ro%2FRoGemma-7b-Instruct-DPO%5D(%2FOpenLLM-Ro%2FRoGemma-7b-Instruct-DPO)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
OpenLLM-Ro/RoGemma-7b-Instruct-DPO-2024-10-09,"---
license: cc-by-nc-4.0
language:
- ro
base_model:
- OpenLLM-Ro/RoGemma-7b-Instruct-2024-10-09
datasets:
- OpenLLM-Ro/ro_dpo_helpsteer
model-index:
    - name: OpenLLM-Ro/RoGemma-7b-Instruct-DPO-2024-10-09
      results:
        - task:
            type: text-generation
          dataset:
            name: RoMT-Bench
            type: RoMT-Bench
          metrics:
            - name: Score
              type: Score
              value: 5.47
        - task:
            type: text-generation
          dataset:
            name: RoCulturaBench
            type: RoCulturaBench
          metrics:
            - name: Score
              type: Score
              value: 3.94
        - task:
            type: text-generation
          dataset:
            name: Romanian_Academic_Benchmarks
            type: Romanian_Academic_Benchmarks
          metrics:
            - name: Average accuracy
              type: accuracy
              value: 48.27
        - task:
            type: text-generation
          dataset:
            name: OpenLLM-Ro/ro_arc_challenge
            type: OpenLLM-Ro/ro_arc_challenge
          metrics:
            - name: Average accuracy
              type: accuracy
              value: 46.66
        - task:
            type: text-generation
          dataset:
            name: OpenLLM-Ro/ro_mmlu
            type: OpenLLM-Ro/ro_mmlu
          metrics:
            - name: Average accuracy
              type: accuracy
              value: 54.45
        - task:
            type: text-generation
          dataset:
            name: OpenLLM-Ro/ro_winogrande
            type: OpenLLM-Ro/ro_winogrande
          metrics:
            - name: Average accuracy
              type: accuracy
              value: 63.73
        - task:
            type: text-generation
          dataset:
            name: OpenLLM-Ro/ro_hellaswag
            type: OpenLLM-Ro/ro_hellaswag
          metrics:
            - name: Average accuracy
              type: accuracy
              value: 49.33
        - task:
            type: text-generation
          dataset:
            name: OpenLLM-Ro/ro_gsm8k
            type: OpenLLM-Ro/ro_gsm8k
          metrics:
            - name: Average accuracy
              type: accuracy
              value: 34.98
        - task:
            type: text-generation
          dataset:
            name: OpenLLM-Ro/ro_truthfulqa
            type: OpenLLM-Ro/ro_truthfulqa
          metrics:
            - name: Average accuracy
              type: accuracy
              value: 40.45
        - task:
            type: text-generation
          dataset:
            name: LaRoSeDa_binary
            type: LaRoSeDa_binary
          metrics:
            - name: Average macro-f1
              type: macro-f1
              value: 96.45
        - task:
            type: text-generation
          dataset:
            name: LaRoSeDa_multiclass
            type: LaRoSeDa_multiclass
          metrics:
            - name: Average macro-f1
              type: macro-f1
              value: 63.23
        - task:
            type: text-generation
          dataset:
            name: LaRoSeDa_binary_finetuned
            type: LaRoSeDa_binary_finetuned
          metrics:
            - name: Average macro-f1
              type: macro-f1
              value: 0.00
        - task:
            type: text-generation
          dataset:
            name: LaRoSeDa_multiclass_finetuned
            type: LaRoSeDa_multiclass_finetuned
          metrics:
            - name: Average macro-f1
              type: macro-f1
              value: 0.00
        - task:
            type: text-generation
          dataset:
            name: WMT_EN-RO
            type: WMT_EN-RO
          metrics:
            - name: Average bleu
              type: bleu
              value: 20.73
        - task:
            type: text-generation
          dataset:
            name: WMT_RO-EN
            type: WMT_RO-EN
          metrics:
            - name: Average bleu
              type: bleu
              value: 7.87
        - task:
            type: text-generation
          dataset:
            name: WMT_EN-RO_finetuned
            type: WMT_EN-RO_finetuned
          metrics:
            - name: Average bleu
              type: bleu
              value: 0.00
        - task:
            type: text-generation
          dataset:
            name: WMT_RO-EN_finetuned
            type: WMT_RO-EN_finetuned
          metrics:
            - name: Average bleu
              type: bleu
              value: 0.00
        - task:
            type: text-generation
          dataset:
            name: XQuAD
            type: XQuAD
          metrics:
            - name: Average exact_match
              type: exact_match
              value: 19.14
        - task:
            type: text-generation
          dataset:
            name: XQuAD
            type: XQuAD
          metrics:
            - name: Average f1
              type: f1
              value: 38.10
        - task:
            type: text-generation
          dataset:
            name: XQuAD_finetuned
            type: XQuAD_finetuned
          metrics:
            - name: Average exact_match
              type: exact_match
              value: 0.00
        - task:
            type: text-generation
          dataset:
            name: XQuAD_finetuned
            type: XQuAD_finetuned
          metrics:
            - name: Average f1
              type: f1
              value: 0.00
        - task:
            type: text-generation
          dataset:
            name: STS
            type: STS
          metrics:
            - name: Average spearman
              type: spearman
              value: 69.38
        - task:
            type: text-generation
          dataset:
            name: STS
            type: STS
          metrics:
            - name: Average pearson
              type: pearson
              value: 69.34
        - task:
            type: text-generation
          dataset:
            name: STS_finetuned
            type: STS_finetuned
          metrics:
            - name: Average spearman
              type: spearman
              value: 0.00
        - task:
            type: text-generation
          dataset:
            name: STS_finetuned
            type: STS_finetuned
          metrics:
            - name: Average pearson
              type: pearson
              value: 0.00
        - task:
            type: text-generation
          dataset:
            name: RoMT-Bench
            type: RoMT-Bench
          metrics:
            - name: First turn
              type: Score
              value: 5.92
            - name: Second turn
              type: Score
              value: 5.03
        - task:
            type: text-generation
          dataset:
            name: OpenLLM-Ro/ro_arc_challenge
            type: OpenLLM-Ro/ro_arc_challenge
          metrics:
            - name: 0-shot 
              type: accuracy
              value: 48.84
            - name: 1-shot 
              type: accuracy
              value: 46.27
            - name: 3-shot 
              type: accuracy
              value: 44.64
            - name: 5-shot 
              type: accuracy
              value: 45.76
            - name: 10-shot 
              type: accuracy
              value: 46.62
            - name: 25-shot 
              type: accuracy
              value: 47.81
        - task:
            type: text-generation
          dataset:
            name: OpenLLM-Ro/ro_mmlu
            type: OpenLLM-Ro/ro_mmlu
          metrics:
            - name: 0-shot 
              type: accuracy
              value: 52.47
            - name: 1-shot 
              type: accuracy
              value: 54.40
            - name: 3-shot 
              type: accuracy
              value: 55.63
            - name: 5-shot 
              type: accuracy
              value: 55.30
        - task:
            type: text-generation
          dataset:
            name: OpenLLM-Ro/ro_winogrande
            type: OpenLLM-Ro/ro_winogrande
          metrics:
            - name: 0-shot 
              type: accuracy
              value: 60.54
            - name: 1-shot 
              type: accuracy
              value: 63.54
            - name: 3-shot 
              type: accuracy
              value: 63.46
            - name: 5-shot 
              type: accuracy
              value: 67.40
        - task:
            type: text-generation
          dataset:
            name: OpenLLM-Ro/ro_hellaswag
            type: OpenLLM-Ro/ro_hellaswag
          metrics:
            - name: 0-shot 
              type: accuracy
              value: 52.67
            - name: 1-shot 
              type: accuracy
              value: 50.89
            - name: 3-shot 
              type: accuracy
              value: 47.85
            - name: 5-shot 
              type: accuracy
              value: 45.98
            - name: 10-shot 
              type: accuracy
              value: 49.26
        - task:
            type: text-generation
          dataset:
            name: OpenLLM-Ro/ro_gsm8k
            type: OpenLLM-Ro/ro_gsm8k
          metrics:
            - name: 1-shot 
              type: accuracy
              value: 27.45
            - name: 3-shot 
              type: accuracy
              value: 36.32
            - name: 5-shot 
              type: accuracy
              value: 41.17
        - task:
            type: text-generation
          dataset:
            name: LaRoSeDa_binary
            type: LaRoSeDa_binary
          metrics:
            - name: 0-shot 
              type: macro-f1
              value: 95.90
            - name: 1-shot 
              type: macro-f1
              value: 95.36
            - name: 3-shot 
              type: macro-f1
              value: 97.13
            - name: 5-shot 
              type: macro-f1
              value: 97.43
        - task:
            type: text-generation
          dataset:
            name: LaRoSeDa_multiclass
            type: LaRoSeDa_multiclass
          metrics:
            - name: 0-shot 
              type: macro-f1
              value: 66.82
            - name: 1-shot 
              type: macro-f1
              value: 59.47
            - name: 3-shot 
              type: macro-f1
              value: 62.88
            - name: 5-shot 
              type: macro-f1
              value: 63.77
        - task:
            type: text-generation
          dataset:
            name: WMT_EN-RO
            type: WMT_EN-RO
          metrics:
            - name: 0-shot 
              type: bleu
              value: 8.00
            - name: 1-shot 
              type: bleu
              value: 24.37
            - name: 3-shot 
              type: bleu
              value: 26.19
            - name: 5-shot 
              type: bleu
              value: 24.36
        - task:
            type: text-generation
          dataset:
            name: WMT_RO-EN
            type: WMT_RO-EN
          metrics:
            - name: 0-shot 
              type: bleu
              value: 0.76
            - name: 1-shot 
              type: bleu
              value: 4.67
            - name: 3-shot 
              type: bleu
              value: 13.33
            - name: 5-shot 
              type: bleu
              value: 12.73
        - task:
            type: text-generation
          dataset:
            name: XQuAD_EM
            type: XQuAD_EM
          metrics:
            - name: 0-shot 
              type: exact_match
              value: 14.37
            - name: 1-shot 
              type: exact_match
              value: 19.08
            - name: 3-shot 
              type: exact_match
              value: 17.73
            - name: 5-shot 
              type: exact_match
              value: 25.38
        - task:
            type: text-generation
          dataset:
            name: XQuAD_F1
            type: XQuAD_F1
          metrics:
            - name: 0-shot 
              type: f1
              value: 33.52
            - name: 1-shot 
              type: f1
              value: 37.27
            - name: 3-shot 
              type: f1
              value: 35.77
            - name: 5-shot 
              type: f1
              value: 45.84
        - task:
            type: text-generation
          dataset:
            name: STS_Spearman
            type: STS_Spearman
          metrics:
            - name: 1-shot 
              type: spearman
              value: 54.50
            - name: 3-shot 
              type: spearman
              value: 74.93
            - name: 5-shot 
              type: spearman
              value: 78.70
        - task:
            type: text-generation
          dataset:
            name: STS_Pearson
            type: STS_Pearson
          metrics:
            - name: 1-shot 
              type: pearson
              value: 54.91
            - name: 3-shot 
              type: pearson
              value: 74.98
            - name: 5-shot 
              type: pearson
              value: 78.13

---

# Model Card for Model ID

<!-- Provide a quick summary of what the model is/does. -->

RoGemma is a family of pretrained and fine-tuned generative text models for Romanian. This is the repository for the **human aligned instruct 7B model**. Links to other models can be found at the bottom of this page.

## Model Details

### Model Description

<!-- Provide a longer summary of what this model is. -->
OpenLLM-Ro represents the first open-source effort to build a LLM specialized for Romanian. OpenLLM-Ro developed and publicly releases a collection of Romanian LLMs, both in the form of foundational model and instruct and chat variants.


- **Developed by:** OpenLLM-Ro
<!-- - **Funded by [optional]:** [More Information Needed] -->
<!-- - **Shared by [optional]:** [More Information Needed] -->
<!-- - **Model type:** [More Information Needed] -->
- **Language(s):** Romanian
- **License:** cc-by-nc-4.0
- **Finetuned from model:** [RoGemma-7b-Instruct-2024-10-09](https://huggingface.co/OpenLLM-Ro/RoGemma-7b-Instruct-2024-10-09)
- **Trained using:** [RoHelpSteer](https://huggingface.co/datasets/OpenLLM-Ro/ro_dpo_helpsteer)


### Model Sources

<!-- Provide the basic links for the model. -->

- **Repository:** https://github.com/OpenLLM-Ro/LLaMA-Factory
- **Paper:** https://arxiv.org/abs/2406.18266

## Intended Use

### Intended Use Cases

RoGemma is intented for research use in Romanian. Base models can be adapted for a variety of natural language tasks while instruction and chat tuned models are intended for assistant-like chat.

### Out-of-Scope Use

<!-- This section addresses misuse, malicious use, and uses that the model will not work well for. -->

Use in any manner that violates the license, any applicable laws or regluations, use in languages other than Romanian.



## How to Get Started with the Model

Use the code below to get started with the model.

```python
from transformers import AutoTokenizer, AutoModelForCausalLM

tokenizer = AutoTokenizer.from_pretrained(""OpenLLM-Ro/RoGemma-7b-Instruct-DPO-2024-10-09"")
model = AutoModelForCausalLM.from_pretrained(""OpenLLM-Ro/RoGemma-7b-Instruct-DPO-2024-10-09"")

instruction = ""Ce jocuri de societate pot juca cu prietenii mei?""
chat = [
        {""role"": ""user"", ""content"": instruction},
        ]
prompt = tokenizer.apply_chat_template(chat, tokenize=False, system_message="""")

inputs = tokenizer.encode(prompt, add_special_tokens=False, return_tensors=""pt"")
outputs = model.generate(input_ids=inputs, max_new_tokens=128)
print(tokenizer.decode(outputs[0]))
```

## Academic Benchmarks

<table>
<tbody>
<tr>
<td><strong>Model</strong></td>
<td><strong><center>Average</center></strong></td>
<td><strong><center>ARC</center></strong></td>
<td><strong><center>MMLU</center></strong></td>
<td><strong><center>Winogrande</center></strong></td>
<td><strong><center>Hellaswag</center></strong></td>
<td><strong><center>GSM8k</center></strong></td>
<td><strong><center>TruthfulQA</center></strong></td>
</tr>
<tr>
<td>gemma-1.1-7b-it</td><td><center>41.44</center></td><td><center>40.32</center></td><td><center>47.22</center></td><td><center>55.01</center></td><td><center>47.03</center></td><td><center>9.50</center></td><td><center>49.58</center></td>
</tr>
<tr>
<td>RoGemma-7b-Instruct-2024-06-28</td><td><center><strong>53.41</strong></center></td><td><center><strong>52.44</strong></center></td><td><center>54.44</center></td><td><center><strong>69.36</strong></center></td><td><center><strong>61.96</strong></center></td><td><center>31.06</center></td><td><center><strong>51.23</strong></center></td>
</tr>
<tr>
<td>RoGemma-7b-Instruct-2024-10-09</td><td><center>50.48</center></td><td><center>52.01</center></td><td><center>52.37</center></td><td><center>66.97</center></td><td><center>56.34</center></td><td><center>25.98</center></td><td><center>49.18</center></td>
</tr>
<tr>
<td><em>RoGemma-7b-Instruct-DPO-2024-10-09</em></td><td><center><em>48.27</em></center></td><td><center><em>46.66</em></center></td><td><center><em><strong>54.45</strong></em></center></td><td><center><em>63.73</em></center></td><td><center><em>49.33</em></center></td><td><center><em><strong>34.98</strong></em></center></td><td><center><em>40.45</em></center></td>
</tr>
</tbody>
</table>


## Downstream tasks

<table>
<tbody>
<tr>
<td></td>
<td colspan=""4""><center><strong>LaRoSeDa</strong></center></td>
<td colspan=""4""><center><strong>WMT</strong></center></td>
</tr>
<tr>
<td></td>
<td colspan=""2""><center><strong>Few-shot</strong></center></td>
<td colspan=""2""><center><strong>Finetuned</strong></center></td>
<td colspan=""2""><center><strong>Few-shot</strong></center></td>
<td colspan=""2""><center><strong>Finetuned</strong></center></td>
</tr>
<tr>
<td><strong>Model</strong></td>
<td><center><strong>Binary<br>(Macro F1)</strong></center></td>
<td><center><strong>Multiclass<br>(Macro F1)</strong></center></td>
<td><center><strong>Binary<br>(Macro F1)</strong></center></td>
<td><center><strong>Multiclass<br>(Macro F1)</strong></center></td>
<td><center><strong>EN-RO<br>(Bleu)</strong></center></td>
<td><center><strong>RO-EN<br>(Bleu)</strong></center></td>
<td><center><strong>EN-RO<br>(Bleu)</strong></center></td>
<td><center><strong>RO-EN<br>(Bleu)</strong></center>
</tr>
<tr>
<td>gemma-1.1-7b-it</td><td><center>87.54</center></td><td><center>51.48</center></td><td><center>83.87</center></td><td><center>85.61</center></td><td><center>17.96</center></td><td><center><strong>27.74</strong></center></td><td><center>25.48</center></td><td><center>36.11</center></td>
</tr>
<tr>
<td>RoGemma-7b-Instruct-2024-06-28</td><td><center><strong>97.86</strong></center></td><td><center><strong>65.70</strong></center></td><td><center>98.43</center></td><td><center><strong>87.17</strong></center></td><td><center><strong>27.91</strong></center></td><td><center>23.08</center></td><td><center><strong>27.99</strong></center></td><td><center><strong>39.51</strong></center></td>
</tr>
<tr>
<td>RoGemma-7b-Instruct-2024-10-09</td><td><center>86.96</center></td><td><center>56.72</center></td><td><center><strong>98.80</strong></center></td><td><center>85.81</center></td><td><center>24.45</center></td><td><center>14.20</center></td><td><center>25.96</center></td><td><center>39.07</center></td>
</tr>
<tr>
<td><em>RoGemma-7b-Instruct-DPO-2024-10-09</em></td><td><center><em>96.45</em></center></td><td><center><em>63.23</em></center></td><td><center><em>-</em></center></td><td><center><em>-</em></center></td><td><center><em>20.73</em></center></td><td><center><em>7.87</em></center></td><td><center><em>-</em></center></td><td><center><em>-</em></center></td>
</tr>
</tbody>
</table>


<table>
<tbody>
<tr>
<td></td>
<td colspan=""4""><center><strong>XQuAD</strong></center></td>
<td colspan=""4""><center><strong>STS</strong></center></td>
</tr>
<tr>
<td></td>
<td colspan=""2""><center><strong>Few-shot</strong></center></td>
<td colspan=""2""><center><strong>Finetuned</strong></center></td>
<td colspan=""2""><center><strong>Few-shot</strong></center></td>
<td colspan=""2""><center><strong>Finetuned</strong></center></td>
</tr>
<tr>
<td><strong>Model</strong></td>
<td><center><strong>(EM)</strong></center></td>
<td><center><strong>(F1)</strong></center></td>
<td><center><strong>(EM)</strong></center></td>
<td><center><strong>(F1)</strong></center></td>
<td><center><strong>(Spearman)</strong></center></td>
<td><center><strong>(Pearson)</strong></center></td>
<td><center><strong>(Spearman)</strong></center></td>
<td><center><strong>(Pearson)</strong></center></td>
</tr>
<tr>
<td>gemma-1.1-7b-it</td><td><center><strong>42.10</strong></center></td><td><center><strong>62.30</strong></center></td><td><center><strong>60.34</strong></center></td><td><center><strong>77.40</strong></center></td><td><center>49.10</center></td><td><center>50.23</center></td><td><center>83.43</center></td><td><center>83.64</center></td>
</tr>
<tr>
<td>RoGemma-7b-Instruct-2024-06-28</td><td><center>17.75</center></td><td><center>28.11</center></td><td><center>52.02</center></td><td><center>68.43</center></td><td><center><strong>73.96</strong></center></td><td><center><strong>75.16</strong></center></td><td><center>86.45</center></td><td><center>86.31</center></td>
</tr>
<tr>
<td>RoGemma-7b-Instruct-2024-10-09</td><td><center>26.03</center></td><td><center>41.58</center></td><td><center>46.72</center></td><td><center>60.79</center></td><td><center>73.23</center></td><td><center>71.58</center></td><td><center><strong>88.42</strong></center></td><td><center><strong>88.45</strong></center></td>
</tr>
<tr>
<td><em>RoGemma-7b-Instruct-DPO-2024-10-09</em></td><td><center><em>19.14</em></center></td><td><center><em>38.10</em></center></td><td><center><em>-</em></center></td><td><center><em>-</em></center></td><td><center><em>69.38</em></center></td><td><center><em>69.34</em></center></td><td><center><em>-</em></center></td><td><center><em>-</em></center></td>
</tr>
</tbody>
</table>

## MT-Bench

<<table>
<tbody>
<tr>
<td><strong>Model</strong></td>
<td><strong><center>Average</center></strong></td>
<td><strong><center>1st turn</center></strong></td>
<td><strong><center>2nd turn</center></strong></td>
<td><strong><center>Answers in Ro</center></strong></td>
</tr>
<tr>
<td>gemma-1.1-7b-it</td><td><center>4.83</center></td><td><center>5.11</center></td><td><center>4.55</center></td><td><center><strong>160/160</strong></center></td>
</tr>
<tr>
<td>RoGemma-7b-Instruct-2024-06-28</td><td><center>5.26</center></td><td><center><strong>5.92</strong></center></td><td><center>4.60</center></td><td><center><strong>160/160</strong></center></td>
</tr>
<tr>
<td>RoGemma-7b-Instruct-2024-10-09</td><td><center>5.24</center></td><td><center>5.55</center></td><td><center>4.94</center></td><td><center><strong>160/160</strong></center></td>
</tr>
<tr>
<td><em>RoGemma-7b-Instruct-DPO-2024-10-09</em></td><td><center><em><strong>5.47</strong></em></center></td><td><center><em><strong>5.92</strong></em></center></td><td><center><em><strong>5.03</strong></em></center></td><td><center><em><strong>160/160</strong></em></center></td>
</tr>
</tbody>
</table>

## RoCulturaBench

<table>
<tbody>
<tr>
<td><strong>Model</strong></td>
<td><strong><center>Average</center></strong></td>
<td><strong><center>Answers in Ro</center></strong></td>
</tr>
<tr>
<td>gemma-1.1-7b-it</td><td><center>3.38</center></td><td><center><strong>100/100</strong></center></td>
</tr>
<tr>
<td>RoGemma-7b-Instruct-2024-06-28</td><td><center>3.26</center></td><td><center><strong>100/100</strong></center></td>
</tr>
<tr>
<td>RoGemma-7b-Instruct-2024-10-09</td><td><center>3.51</center></td><td><center><strong>100/100</strong></center></td>
</tr>
<tr>
<td><em>RoGemma-7b-Instruct-DPO-2024-10-09</em></td><td><center><em><strong>3.94</strong></em></center></td><td><center><em><strong>100/100</strong></em></center></td>
</tr>
</tbody>
</table>

## RoGemma Model Family

| Model              | Link  |
|--------------------|:--------:|
|RoGemma-7b-Instruct-2024-06-28| [link](https://huggingface.co/OpenLLM-Ro/RoGemma-7b-Instruct-2024-06-28) |
|RoGemma-7b-Instruct-2024-10-09| [link](https://huggingface.co/OpenLLM-Ro/RoGemma-7b-Instruct-2024-10-09) |
|*RoGemma-7b-Instruct-DPO-2024-10-09*| [link](https://huggingface.co/OpenLLM-Ro/RoGemma-7b-Instruct-DPO-2024-10-09) |


## Citation 

```
@misc{masala2024vorbecstiromanecsterecipetrain,
      title={""Vorbe\c{s}ti Rom\^ane\c{s}te?"" A Recipe to Train Powerful Romanian LLMs with English Instructions}, 
      author={Mihai Masala and Denis C. Ilie-Ablachim and Alexandru Dima and Dragos Corlatescu and Miruna Zavelca and Ovio Olaru and Simina Terian-Dan and Andrei Terian-Dan and Marius Leordeanu and Horia Velicu and Marius Popescu and Mihai Dascalu and Traian Rebedea},
      year={2024},
      eprint={2406.18266},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2406.18266}, 
}
```
<!-- **APA:**

[More Information Needed]  -->","{""id"": ""OpenLLM-Ro/RoGemma-7b-Instruct-DPO-2024-10-09"", ""author"": ""OpenLLM-Ro"", ""sha"": ""741722daf63cbd8da0bd89a13fd1ed0e9ed16949"", ""last_modified"": ""2024-10-10 18:20:19+00:00"", ""created_at"": ""2024-09-23 17:19:09+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 1, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": null, ""gguf"": null, ""inference"": null, ""tags"": [""safetensors"", ""gemma"", ""ro"", ""dataset:OpenLLM-Ro/ro_dpo_helpsteer"", ""arxiv:2406.18266"", ""base_model:OpenLLM-Ro/RoGemma-7b-Instruct-2024-10-09"", ""base_model:finetune:OpenLLM-Ro/RoGemma-7b-Instruct-2024-10-09"", ""license:cc-by-nc-4.0"", ""model-index"", ""region:us""], ""pipeline_tag"": null, ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model:\n- OpenLLM-Ro/RoGemma-7b-Instruct-2024-10-09\ndatasets:\n- OpenLLM-Ro/ro_dpo_helpsteer\nlanguage:\n- ro\nlicense: cc-by-nc-4.0\nmodel-index:\n- name: OpenLLM-Ro/RoGemma-7b-Instruct-DPO-2024-10-09\n  results:\n  - task:\n      type: text-generation\n    dataset:\n      name: RoMT-Bench\n      type: RoMT-Bench\n    metrics:\n    - type: Score\n      value: 5.47\n      name: Score\n      verified: false\n    - type: Score\n      value: 5.92\n      name: First turn\n      verified: false\n    - type: Score\n      value: 5.03\n      name: Second turn\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: RoCulturaBench\n      type: RoCulturaBench\n    metrics:\n    - type: Score\n      value: 3.94\n      name: Score\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: Romanian_Academic_Benchmarks\n      type: Romanian_Academic_Benchmarks\n    metrics:\n    - type: accuracy\n      value: 48.27\n      name: Average accuracy\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: OpenLLM-Ro/ro_arc_challenge\n      type: OpenLLM-Ro/ro_arc_challenge\n    metrics:\n    - type: accuracy\n      value: 46.66\n      name: Average accuracy\n      verified: false\n    - type: accuracy\n      value: 48.84\n      name: 0-shot\n      verified: false\n    - type: accuracy\n      value: 46.27\n      name: 1-shot\n      verified: false\n    - type: accuracy\n      value: 44.64\n      name: 3-shot\n      verified: false\n    - type: accuracy\n      value: 45.76\n      name: 5-shot\n      verified: false\n    - type: accuracy\n      value: 46.62\n      name: 10-shot\n      verified: false\n    - type: accuracy\n      value: 47.81\n      name: 25-shot\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: OpenLLM-Ro/ro_mmlu\n      type: OpenLLM-Ro/ro_mmlu\n    metrics:\n    - type: accuracy\n      value: 54.45\n      name: Average accuracy\n      verified: false\n    - type: accuracy\n      value: 52.47\n      name: 0-shot\n      verified: false\n    - type: accuracy\n      value: 54.4\n      name: 1-shot\n      verified: false\n    - type: accuracy\n      value: 55.63\n      name: 3-shot\n      verified: false\n    - type: accuracy\n      value: 55.3\n      name: 5-shot\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: OpenLLM-Ro/ro_winogrande\n      type: OpenLLM-Ro/ro_winogrande\n    metrics:\n    - type: accuracy\n      value: 63.73\n      name: Average accuracy\n      verified: false\n    - type: accuracy\n      value: 60.54\n      name: 0-shot\n      verified: false\n    - type: accuracy\n      value: 63.54\n      name: 1-shot\n      verified: false\n    - type: accuracy\n      value: 63.46\n      name: 3-shot\n      verified: false\n    - type: accuracy\n      value: 67.4\n      name: 5-shot\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: OpenLLM-Ro/ro_hellaswag\n      type: OpenLLM-Ro/ro_hellaswag\n    metrics:\n    - type: accuracy\n      value: 49.33\n      name: Average accuracy\n      verified: false\n    - type: accuracy\n      value: 52.67\n      name: 0-shot\n      verified: false\n    - type: accuracy\n      value: 50.89\n      name: 1-shot\n      verified: false\n    - type: accuracy\n      value: 47.85\n      name: 3-shot\n      verified: false\n    - type: accuracy\n      value: 45.98\n      name: 5-shot\n      verified: false\n    - type: accuracy\n      value: 49.26\n      name: 10-shot\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: OpenLLM-Ro/ro_gsm8k\n      type: OpenLLM-Ro/ro_gsm8k\n    metrics:\n    - type: accuracy\n      value: 34.98\n      name: Average accuracy\n      verified: false\n    - type: accuracy\n      value: 27.45\n      name: 1-shot\n      verified: false\n    - type: accuracy\n      value: 36.32\n      name: 3-shot\n      verified: false\n    - type: accuracy\n      value: 41.17\n      name: 5-shot\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: OpenLLM-Ro/ro_truthfulqa\n      type: OpenLLM-Ro/ro_truthfulqa\n    metrics:\n    - type: accuracy\n      value: 40.45\n      name: Average accuracy\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: LaRoSeDa_binary\n      type: LaRoSeDa_binary\n    metrics:\n    - type: macro-f1\n      value: 96.45\n      name: Average macro-f1\n      verified: false\n    - type: macro-f1\n      value: 95.9\n      name: 0-shot\n      verified: false\n    - type: macro-f1\n      value: 95.36\n      name: 1-shot\n      verified: false\n    - type: macro-f1\n      value: 97.13\n      name: 3-shot\n      verified: false\n    - type: macro-f1\n      value: 97.43\n      name: 5-shot\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: LaRoSeDa_multiclass\n      type: LaRoSeDa_multiclass\n    metrics:\n    - type: macro-f1\n      value: 63.23\n      name: Average macro-f1\n      verified: false\n    - type: macro-f1\n      value: 66.82\n      name: 0-shot\n      verified: false\n    - type: macro-f1\n      value: 59.47\n      name: 1-shot\n      verified: false\n    - type: macro-f1\n      value: 62.88\n      name: 3-shot\n      verified: false\n    - type: macro-f1\n      value: 63.77\n      name: 5-shot\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: LaRoSeDa_binary_finetuned\n      type: LaRoSeDa_binary_finetuned\n    metrics:\n    - type: macro-f1\n      value: 0\n      name: Average macro-f1\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: LaRoSeDa_multiclass_finetuned\n      type: LaRoSeDa_multiclass_finetuned\n    metrics:\n    - type: macro-f1\n      value: 0\n      name: Average macro-f1\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: WMT_EN-RO\n      type: WMT_EN-RO\n    metrics:\n    - type: bleu\n      value: 20.73\n      name: Average bleu\n      verified: false\n    - type: bleu\n      value: 8\n      name: 0-shot\n      verified: false\n    - type: bleu\n      value: 24.37\n      name: 1-shot\n      verified: false\n    - type: bleu\n      value: 26.19\n      name: 3-shot\n      verified: false\n    - type: bleu\n      value: 24.36\n      name: 5-shot\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: WMT_RO-EN\n      type: WMT_RO-EN\n    metrics:\n    - type: bleu\n      value: 7.87\n      name: Average bleu\n      verified: false\n    - type: bleu\n      value: 0.76\n      name: 0-shot\n      verified: false\n    - type: bleu\n      value: 4.67\n      name: 1-shot\n      verified: false\n    - type: bleu\n      value: 13.33\n      name: 3-shot\n      verified: false\n    - type: bleu\n      value: 12.73\n      name: 5-shot\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: WMT_EN-RO_finetuned\n      type: WMT_EN-RO_finetuned\n    metrics:\n    - type: bleu\n      value: 0\n      name: Average bleu\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: WMT_RO-EN_finetuned\n      type: WMT_RO-EN_finetuned\n    metrics:\n    - type: bleu\n      value: 0\n      name: Average bleu\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: XQuAD\n      type: XQuAD\n    metrics:\n    - type: exact_match\n      value: 19.14\n      name: Average exact_match\n      verified: false\n    - type: f1\n      value: 38.1\n      name: Average f1\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: XQuAD_finetuned\n      type: XQuAD_finetuned\n    metrics:\n    - type: exact_match\n      value: 0\n      name: Average exact_match\n      verified: false\n    - type: f1\n      value: 0\n      name: Average f1\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: STS\n      type: STS\n    metrics:\n    - type: spearman\n      value: 69.38\n      name: Average spearman\n      verified: false\n    - type: pearson\n      value: 69.34\n      name: Average pearson\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: STS_finetuned\n      type: STS_finetuned\n    metrics:\n    - type: spearman\n      value: 0\n      name: Average spearman\n      verified: false\n    - type: pearson\n      value: 0\n      name: Average pearson\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: XQuAD_EM\n      type: XQuAD_EM\n    metrics:\n    - type: exact_match\n      value: 14.37\n      name: 0-shot\n      verified: false\n    - type: exact_match\n      value: 19.08\n      name: 1-shot\n      verified: false\n    - type: exact_match\n      value: 17.73\n      name: 3-shot\n      verified: false\n    - type: exact_match\n      value: 25.38\n      name: 5-shot\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: XQuAD_F1\n      type: XQuAD_F1\n    metrics:\n    - type: f1\n      value: 33.52\n      name: 0-shot\n      verified: false\n    - type: f1\n      value: 37.27\n      name: 1-shot\n      verified: false\n    - type: f1\n      value: 35.77\n      name: 3-shot\n      verified: false\n    - type: f1\n      value: 45.84\n      name: 5-shot\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: STS_Spearman\n      type: STS_Spearman\n    metrics:\n    - type: spearman\n      value: 54.5\n      name: 1-shot\n      verified: false\n    - type: spearman\n      value: 74.93\n      name: 3-shot\n      verified: false\n    - type: spearman\n      value: 78.7\n      name: 5-shot\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: STS_Pearson\n      type: STS_Pearson\n    metrics:\n    - type: pearson\n      value: 54.91\n      name: 1-shot\n      verified: false\n    - type: pearson\n      value: 74.98\n      name: 3-shot\n      verified: false\n    - type: pearson\n      value: 78.13\n      name: 5-shot\n      verified: false"", ""widget_data"": null, ""model_index"": [{""name"": ""OpenLLM-Ro/RoGemma-7b-Instruct-DPO-2024-10-09"", ""results"": [{""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""RoMT-Bench"", ""type"": ""RoMT-Bench""}, ""metrics"": [{""name"": ""Score"", ""type"": ""Score"", ""value"": 5.47, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""RoCulturaBench"", ""type"": ""RoCulturaBench""}, ""metrics"": [{""name"": ""Score"", ""type"": ""Score"", ""value"": 3.94, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""Romanian_Academic_Benchmarks"", ""type"": ""Romanian_Academic_Benchmarks""}, ""metrics"": [{""name"": ""Average accuracy"", ""type"": ""accuracy"", ""value"": 48.27, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""OpenLLM-Ro/ro_arc_challenge"", ""type"": ""OpenLLM-Ro/ro_arc_challenge""}, ""metrics"": [{""name"": ""Average accuracy"", ""type"": ""accuracy"", ""value"": 46.66, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""OpenLLM-Ro/ro_mmlu"", ""type"": ""OpenLLM-Ro/ro_mmlu""}, ""metrics"": [{""name"": ""Average accuracy"", ""type"": ""accuracy"", ""value"": 54.45, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""OpenLLM-Ro/ro_winogrande"", ""type"": ""OpenLLM-Ro/ro_winogrande""}, ""metrics"": [{""name"": ""Average accuracy"", ""type"": ""accuracy"", ""value"": 63.73, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""OpenLLM-Ro/ro_hellaswag"", ""type"": ""OpenLLM-Ro/ro_hellaswag""}, ""metrics"": [{""name"": ""Average accuracy"", ""type"": ""accuracy"", ""value"": 49.33, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""OpenLLM-Ro/ro_gsm8k"", ""type"": ""OpenLLM-Ro/ro_gsm8k""}, ""metrics"": [{""name"": ""Average accuracy"", ""type"": ""accuracy"", ""value"": 34.98, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""OpenLLM-Ro/ro_truthfulqa"", ""type"": ""OpenLLM-Ro/ro_truthfulqa""}, ""metrics"": [{""name"": ""Average accuracy"", ""type"": ""accuracy"", ""value"": 40.45, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""LaRoSeDa_binary"", ""type"": ""LaRoSeDa_binary""}, ""metrics"": [{""name"": ""Average macro-f1"", ""type"": ""macro-f1"", ""value"": 96.45, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""LaRoSeDa_multiclass"", ""type"": ""LaRoSeDa_multiclass""}, ""metrics"": [{""name"": ""Average macro-f1"", ""type"": ""macro-f1"", ""value"": 63.23, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""LaRoSeDa_binary_finetuned"", ""type"": ""LaRoSeDa_binary_finetuned""}, ""metrics"": [{""name"": ""Average macro-f1"", ""type"": ""macro-f1"", ""value"": 0, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""LaRoSeDa_multiclass_finetuned"", ""type"": ""LaRoSeDa_multiclass_finetuned""}, ""metrics"": [{""name"": ""Average macro-f1"", ""type"": ""macro-f1"", ""value"": 0, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""WMT_EN-RO"", ""type"": ""WMT_EN-RO""}, ""metrics"": [{""name"": ""Average bleu"", ""type"": ""bleu"", ""value"": 20.73, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""WMT_RO-EN"", ""type"": ""WMT_RO-EN""}, ""metrics"": [{""name"": ""Average bleu"", ""type"": ""bleu"", ""value"": 7.87, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""WMT_EN-RO_finetuned"", ""type"": ""WMT_EN-RO_finetuned""}, ""metrics"": [{""name"": ""Average bleu"", ""type"": ""bleu"", ""value"": 0, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""WMT_RO-EN_finetuned"", ""type"": ""WMT_RO-EN_finetuned""}, ""metrics"": [{""name"": ""Average bleu"", ""type"": ""bleu"", ""value"": 0, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""XQuAD"", ""type"": ""XQuAD""}, ""metrics"": [{""name"": ""Average exact_match"", ""type"": ""exact_match"", ""value"": 19.14, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""XQuAD"", ""type"": ""XQuAD""}, ""metrics"": [{""name"": ""Average f1"", ""type"": ""f1"", ""value"": 38.1, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""XQuAD_finetuned"", ""type"": ""XQuAD_finetuned""}, ""metrics"": [{""name"": ""Average exact_match"", ""type"": ""exact_match"", ""value"": 0, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""XQuAD_finetuned"", ""type"": ""XQuAD_finetuned""}, ""metrics"": [{""name"": ""Average f1"", ""type"": ""f1"", ""value"": 0, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""STS"", ""type"": ""STS""}, ""metrics"": [{""name"": ""Average spearman"", ""type"": ""spearman"", ""value"": 69.38, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""STS"", ""type"": ""STS""}, ""metrics"": [{""name"": ""Average pearson"", ""type"": ""pearson"", ""value"": 69.34, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""STS_finetuned"", ""type"": ""STS_finetuned""}, ""metrics"": [{""name"": ""Average spearman"", ""type"": ""spearman"", ""value"": 0, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""STS_finetuned"", ""type"": ""STS_finetuned""}, ""metrics"": [{""name"": ""Average pearson"", ""type"": ""pearson"", ""value"": 0, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""RoMT-Bench"", ""type"": ""RoMT-Bench""}, ""metrics"": [{""name"": ""First turn"", ""type"": ""Score"", ""value"": 5.92, ""verified"": false}, {""name"": ""Second turn"", ""type"": ""Score"", ""value"": 5.03, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""OpenLLM-Ro/ro_arc_challenge"", ""type"": ""OpenLLM-Ro/ro_arc_challenge""}, ""metrics"": [{""name"": ""0-shot"", ""type"": ""accuracy"", ""value"": 48.84, ""verified"": false}, {""name"": ""1-shot"", ""type"": ""accuracy"", ""value"": 46.27, ""verified"": false}, {""name"": ""3-shot"", ""type"": ""accuracy"", ""value"": 44.64, ""verified"": false}, {""name"": ""5-shot"", ""type"": ""accuracy"", ""value"": 45.76, ""verified"": false}, {""name"": ""10-shot"", ""type"": ""accuracy"", ""value"": 46.62, ""verified"": false}, {""name"": ""25-shot"", ""type"": ""accuracy"", ""value"": 47.81, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""OpenLLM-Ro/ro_mmlu"", ""type"": ""OpenLLM-Ro/ro_mmlu""}, ""metrics"": [{""name"": ""0-shot"", ""type"": ""accuracy"", ""value"": 52.47, ""verified"": false}, {""name"": ""1-shot"", ""type"": ""accuracy"", ""value"": 54.4, ""verified"": false}, {""name"": ""3-shot"", ""type"": ""accuracy"", ""value"": 55.63, ""verified"": false}, {""name"": ""5-shot"", ""type"": ""accuracy"", ""value"": 55.3, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""OpenLLM-Ro/ro_winogrande"", ""type"": ""OpenLLM-Ro/ro_winogrande""}, ""metrics"": [{""name"": ""0-shot"", ""type"": ""accuracy"", ""value"": 60.54, ""verified"": false}, {""name"": ""1-shot"", ""type"": ""accuracy"", ""value"": 63.54, ""verified"": false}, {""name"": ""3-shot"", ""type"": ""accuracy"", ""value"": 63.46, ""verified"": false}, {""name"": ""5-shot"", ""type"": ""accuracy"", ""value"": 67.4, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""OpenLLM-Ro/ro_hellaswag"", ""type"": ""OpenLLM-Ro/ro_hellaswag""}, ""metrics"": [{""name"": ""0-shot"", ""type"": ""accuracy"", ""value"": 52.67, ""verified"": false}, {""name"": ""1-shot"", ""type"": ""accuracy"", ""value"": 50.89, ""verified"": false}, {""name"": ""3-shot"", ""type"": ""accuracy"", ""value"": 47.85, ""verified"": false}, {""name"": ""5-shot"", ""type"": ""accuracy"", ""value"": 45.98, ""verified"": false}, {""name"": ""10-shot"", ""type"": ""accuracy"", ""value"": 49.26, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""OpenLLM-Ro/ro_gsm8k"", ""type"": ""OpenLLM-Ro/ro_gsm8k""}, ""metrics"": [{""name"": ""1-shot"", ""type"": ""accuracy"", ""value"": 27.45, ""verified"": false}, {""name"": ""3-shot"", ""type"": ""accuracy"", ""value"": 36.32, ""verified"": false}, {""name"": ""5-shot"", ""type"": ""accuracy"", ""value"": 41.17, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""LaRoSeDa_binary"", ""type"": ""LaRoSeDa_binary""}, ""metrics"": [{""name"": ""0-shot"", ""type"": ""macro-f1"", ""value"": 95.9, ""verified"": false}, {""name"": ""1-shot"", ""type"": ""macro-f1"", ""value"": 95.36, ""verified"": false}, {""name"": ""3-shot"", ""type"": ""macro-f1"", ""value"": 97.13, ""verified"": false}, {""name"": ""5-shot"", ""type"": ""macro-f1"", ""value"": 97.43, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""LaRoSeDa_multiclass"", ""type"": ""LaRoSeDa_multiclass""}, ""metrics"": [{""name"": ""0-shot"", ""type"": ""macro-f1"", ""value"": 66.82, ""verified"": false}, {""name"": ""1-shot"", ""type"": ""macro-f1"", ""value"": 59.47, ""verified"": false}, {""name"": ""3-shot"", ""type"": ""macro-f1"", ""value"": 62.88, ""verified"": false}, {""name"": ""5-shot"", ""type"": ""macro-f1"", ""value"": 63.77, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""WMT_EN-RO"", ""type"": ""WMT_EN-RO""}, ""metrics"": [{""name"": ""0-shot"", ""type"": ""bleu"", ""value"": 8, ""verified"": false}, {""name"": ""1-shot"", ""type"": ""bleu"", ""value"": 24.37, ""verified"": false}, {""name"": ""3-shot"", ""type"": ""bleu"", ""value"": 26.19, ""verified"": false}, {""name"": ""5-shot"", ""type"": ""bleu"", ""value"": 24.36, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""WMT_RO-EN"", ""type"": ""WMT_RO-EN""}, ""metrics"": [{""name"": ""0-shot"", ""type"": ""bleu"", ""value"": 0.76, ""verified"": false}, {""name"": ""1-shot"", ""type"": ""bleu"", ""value"": 4.67, ""verified"": false}, {""name"": ""3-shot"", ""type"": ""bleu"", ""value"": 13.33, ""verified"": false}, {""name"": ""5-shot"", ""type"": ""bleu"", ""value"": 12.73, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""XQuAD_EM"", ""type"": ""XQuAD_EM""}, ""metrics"": [{""name"": ""0-shot"", ""type"": ""exact_match"", ""value"": 14.37, ""verified"": false}, {""name"": ""1-shot"", ""type"": ""exact_match"", ""value"": 19.08, ""verified"": false}, {""name"": ""3-shot"", ""type"": ""exact_match"", ""value"": 17.73, ""verified"": false}, {""name"": ""5-shot"", ""type"": ""exact_match"", ""value"": 25.38, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""XQuAD_F1"", ""type"": ""XQuAD_F1""}, ""metrics"": [{""name"": ""0-shot"", ""type"": ""f1"", ""value"": 33.52, ""verified"": false}, {""name"": ""1-shot"", ""type"": ""f1"", ""value"": 37.27, ""verified"": false}, {""name"": ""3-shot"", ""type"": ""f1"", ""value"": 35.77, ""verified"": false}, {""name"": ""5-shot"", ""type"": ""f1"", ""value"": 45.84, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""STS_Spearman"", ""type"": ""STS_Spearman""}, ""metrics"": [{""name"": ""1-shot"", ""type"": ""spearman"", ""value"": 54.5, ""verified"": false}, {""name"": ""3-shot"", ""type"": ""spearman"", ""value"": 74.93, ""verified"": false}, {""name"": ""5-shot"", ""type"": ""spearman"", ""value"": 78.7, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""STS_Pearson"", ""type"": ""STS_Pearson""}, ""metrics"": [{""name"": ""1-shot"", ""type"": ""pearson"", ""value"": 54.91, ""verified"": false}, {""name"": ""3-shot"", ""type"": ""pearson"", ""value"": 74.98, ""verified"": false}, {""name"": ""5-shot"", ""type"": ""pearson"", ""value"": 78.13, ""verified"": false}]}]}], ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ '<bos>' }}{% if messages[0]['role'] == 'system' %}{% set loop_messages = messages[1:] %}{% set system_message = messages[0]['content'] %}{% else %}{% set loop_messages = messages %}{% endif %}{% if system_message is defined %}{{ system_message }}{% endif %}{% for message in loop_messages %}{% set content = message['content'] %}{% if message['role'] == 'user' %}{{ '<start_of_turn>user\n' + content + '<end_of_turn>\n<start_of_turn>model\n' }}{% elif message['role'] == 'assistant' %}{{ content + '<end_of_turn>\n' }}{% endif %}{% endfor %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": null, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='generation_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00001-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00002-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00003-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00004-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model.safetensors.index.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": {""parameters"": {""BF16"": 8537680896}, ""total"": 8537680896}, ""security_repo_status"": null, ""lastModified"": ""2024-10-10 18:20:19+00:00"", ""cardData"": ""base_model:\n- OpenLLM-Ro/RoGemma-7b-Instruct-2024-10-09\ndatasets:\n- OpenLLM-Ro/ro_dpo_helpsteer\nlanguage:\n- ro\nlicense: cc-by-nc-4.0\nmodel-index:\n- name: OpenLLM-Ro/RoGemma-7b-Instruct-DPO-2024-10-09\n  results:\n  - task:\n      type: text-generation\n    dataset:\n      name: RoMT-Bench\n      type: RoMT-Bench\n    metrics:\n    - type: Score\n      value: 5.47\n      name: Score\n      verified: false\n    - type: Score\n      value: 5.92\n      name: First turn\n      verified: false\n    - type: Score\n      value: 5.03\n      name: Second turn\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: RoCulturaBench\n      type: RoCulturaBench\n    metrics:\n    - type: Score\n      value: 3.94\n      name: Score\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: Romanian_Academic_Benchmarks\n      type: Romanian_Academic_Benchmarks\n    metrics:\n    - type: accuracy\n      value: 48.27\n      name: Average accuracy\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: OpenLLM-Ro/ro_arc_challenge\n      type: OpenLLM-Ro/ro_arc_challenge\n    metrics:\n    - type: accuracy\n      value: 46.66\n      name: Average accuracy\n      verified: false\n    - type: accuracy\n      value: 48.84\n      name: 0-shot\n      verified: false\n    - type: accuracy\n      value: 46.27\n      name: 1-shot\n      verified: false\n    - type: accuracy\n      value: 44.64\n      name: 3-shot\n      verified: false\n    - type: accuracy\n      value: 45.76\n      name: 5-shot\n      verified: false\n    - type: accuracy\n      value: 46.62\n      name: 10-shot\n      verified: false\n    - type: accuracy\n      value: 47.81\n      name: 25-shot\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: OpenLLM-Ro/ro_mmlu\n      type: OpenLLM-Ro/ro_mmlu\n    metrics:\n    - type: accuracy\n      value: 54.45\n      name: Average accuracy\n      verified: false\n    - type: accuracy\n      value: 52.47\n      name: 0-shot\n      verified: false\n    - type: accuracy\n      value: 54.4\n      name: 1-shot\n      verified: false\n    - type: accuracy\n      value: 55.63\n      name: 3-shot\n      verified: false\n    - type: accuracy\n      value: 55.3\n      name: 5-shot\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: OpenLLM-Ro/ro_winogrande\n      type: OpenLLM-Ro/ro_winogrande\n    metrics:\n    - type: accuracy\n      value: 63.73\n      name: Average accuracy\n      verified: false\n    - type: accuracy\n      value: 60.54\n      name: 0-shot\n      verified: false\n    - type: accuracy\n      value: 63.54\n      name: 1-shot\n      verified: false\n    - type: accuracy\n      value: 63.46\n      name: 3-shot\n      verified: false\n    - type: accuracy\n      value: 67.4\n      name: 5-shot\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: OpenLLM-Ro/ro_hellaswag\n      type: OpenLLM-Ro/ro_hellaswag\n    metrics:\n    - type: accuracy\n      value: 49.33\n      name: Average accuracy\n      verified: false\n    - type: accuracy\n      value: 52.67\n      name: 0-shot\n      verified: false\n    - type: accuracy\n      value: 50.89\n      name: 1-shot\n      verified: false\n    - type: accuracy\n      value: 47.85\n      name: 3-shot\n      verified: false\n    - type: accuracy\n      value: 45.98\n      name: 5-shot\n      verified: false\n    - type: accuracy\n      value: 49.26\n      name: 10-shot\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: OpenLLM-Ro/ro_gsm8k\n      type: OpenLLM-Ro/ro_gsm8k\n    metrics:\n    - type: accuracy\n      value: 34.98\n      name: Average accuracy\n      verified: false\n    - type: accuracy\n      value: 27.45\n      name: 1-shot\n      verified: false\n    - type: accuracy\n      value: 36.32\n      name: 3-shot\n      verified: false\n    - type: accuracy\n      value: 41.17\n      name: 5-shot\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: OpenLLM-Ro/ro_truthfulqa\n      type: OpenLLM-Ro/ro_truthfulqa\n    metrics:\n    - type: accuracy\n      value: 40.45\n      name: Average accuracy\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: LaRoSeDa_binary\n      type: LaRoSeDa_binary\n    metrics:\n    - type: macro-f1\n      value: 96.45\n      name: Average macro-f1\n      verified: false\n    - type: macro-f1\n      value: 95.9\n      name: 0-shot\n      verified: false\n    - type: macro-f1\n      value: 95.36\n      name: 1-shot\n      verified: false\n    - type: macro-f1\n      value: 97.13\n      name: 3-shot\n      verified: false\n    - type: macro-f1\n      value: 97.43\n      name: 5-shot\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: LaRoSeDa_multiclass\n      type: LaRoSeDa_multiclass\n    metrics:\n    - type: macro-f1\n      value: 63.23\n      name: Average macro-f1\n      verified: false\n    - type: macro-f1\n      value: 66.82\n      name: 0-shot\n      verified: false\n    - type: macro-f1\n      value: 59.47\n      name: 1-shot\n      verified: false\n    - type: macro-f1\n      value: 62.88\n      name: 3-shot\n      verified: false\n    - type: macro-f1\n      value: 63.77\n      name: 5-shot\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: LaRoSeDa_binary_finetuned\n      type: LaRoSeDa_binary_finetuned\n    metrics:\n    - type: macro-f1\n      value: 0\n      name: Average macro-f1\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: LaRoSeDa_multiclass_finetuned\n      type: LaRoSeDa_multiclass_finetuned\n    metrics:\n    - type: macro-f1\n      value: 0\n      name: Average macro-f1\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: WMT_EN-RO\n      type: WMT_EN-RO\n    metrics:\n    - type: bleu\n      value: 20.73\n      name: Average bleu\n      verified: false\n    - type: bleu\n      value: 8\n      name: 0-shot\n      verified: false\n    - type: bleu\n      value: 24.37\n      name: 1-shot\n      verified: false\n    - type: bleu\n      value: 26.19\n      name: 3-shot\n      verified: false\n    - type: bleu\n      value: 24.36\n      name: 5-shot\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: WMT_RO-EN\n      type: WMT_RO-EN\n    metrics:\n    - type: bleu\n      value: 7.87\n      name: Average bleu\n      verified: false\n    - type: bleu\n      value: 0.76\n      name: 0-shot\n      verified: false\n    - type: bleu\n      value: 4.67\n      name: 1-shot\n      verified: false\n    - type: bleu\n      value: 13.33\n      name: 3-shot\n      verified: false\n    - type: bleu\n      value: 12.73\n      name: 5-shot\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: WMT_EN-RO_finetuned\n      type: WMT_EN-RO_finetuned\n    metrics:\n    - type: bleu\n      value: 0\n      name: Average bleu\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: WMT_RO-EN_finetuned\n      type: WMT_RO-EN_finetuned\n    metrics:\n    - type: bleu\n      value: 0\n      name: Average bleu\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: XQuAD\n      type: XQuAD\n    metrics:\n    - type: exact_match\n      value: 19.14\n      name: Average exact_match\n      verified: false\n    - type: f1\n      value: 38.1\n      name: Average f1\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: XQuAD_finetuned\n      type: XQuAD_finetuned\n    metrics:\n    - type: exact_match\n      value: 0\n      name: Average exact_match\n      verified: false\n    - type: f1\n      value: 0\n      name: Average f1\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: STS\n      type: STS\n    metrics:\n    - type: spearman\n      value: 69.38\n      name: Average spearman\n      verified: false\n    - type: pearson\n      value: 69.34\n      name: Average pearson\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: STS_finetuned\n      type: STS_finetuned\n    metrics:\n    - type: spearman\n      value: 0\n      name: Average spearman\n      verified: false\n    - type: pearson\n      value: 0\n      name: Average pearson\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: XQuAD_EM\n      type: XQuAD_EM\n    metrics:\n    - type: exact_match\n      value: 14.37\n      name: 0-shot\n      verified: false\n    - type: exact_match\n      value: 19.08\n      name: 1-shot\n      verified: false\n    - type: exact_match\n      value: 17.73\n      name: 3-shot\n      verified: false\n    - type: exact_match\n      value: 25.38\n      name: 5-shot\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: XQuAD_F1\n      type: XQuAD_F1\n    metrics:\n    - type: f1\n      value: 33.52\n      name: 0-shot\n      verified: false\n    - type: f1\n      value: 37.27\n      name: 1-shot\n      verified: false\n    - type: f1\n      value: 35.77\n      name: 3-shot\n      verified: false\n    - type: f1\n      value: 45.84\n      name: 5-shot\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: STS_Spearman\n      type: STS_Spearman\n    metrics:\n    - type: spearman\n      value: 54.5\n      name: 1-shot\n      verified: false\n    - type: spearman\n      value: 74.93\n      name: 3-shot\n      verified: false\n    - type: spearman\n      value: 78.7\n      name: 5-shot\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: STS_Pearson\n      type: STS_Pearson\n    metrics:\n    - type: pearson\n      value: 54.91\n      name: 1-shot\n      verified: false\n    - type: pearson\n      value: 74.98\n      name: 3-shot\n      verified: false\n    - type: pearson\n      value: 78.13\n      name: 5-shot\n      verified: false"", ""transformersInfo"": null, ""_id"": ""66f1a30d63dbeeb116104b93"", ""modelId"": ""OpenLLM-Ro/RoGemma-7b-Instruct-DPO-2024-10-09"", ""usedStorage"": 17097150888}",2,,0,https://huggingface.co/mradermacher/RoGemma-7b-Instruct-DPO-2024-10-09-GGUF,1,,0,huggingface/InferenceSupport/discussions/new?title=OpenLLM-Ro/RoGemma-7b-Instruct-DPO-2024-10-09&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5BOpenLLM-Ro%2FRoGemma-7b-Instruct-DPO-2024-10-09%5D(%2FOpenLLM-Ro%2FRoGemma-7b-Instruct-DPO-2024-10-09)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
klcsp/gemma7b-gpt4o_1k_summarize-fft,"---
library_name: transformers
license: gemma
base_model: google/gemma-7b
tags:
- trl
- sft
- generated_from_trainer
datasets:
- generator
model-index:
- name: gemma7b-gpt4o_1k_summarize-fft
  results: []
---

<!-- This model card has been generated automatically according to the information the Trainer had access to. You
should probably proofread and complete it, then remove this comment. -->

# gemma7b-gpt4o_1k_summarize-fft

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the generator dataset.
It achieves the following results on the evaluation set:
- Loss: 6.4970

## Model description

More information needed

## Intended uses & limitations

More information needed

## Training and evaluation data

More information needed

## Training procedure

### Training hyperparameters

The following hyperparameters were used during training:
- learning_rate: 0.0003
- train_batch_size: 2
- eval_batch_size: 2
- seed: 42
- distributed_type: multi-GPU
- num_devices: 8
- gradient_accumulation_steps: 2
- total_train_batch_size: 32
- total_eval_batch_size: 16
- optimizer: Adam with betas=(0.9,0.999) and epsilon=1e-08
- lr_scheduler_type: cosine
- lr_scheduler_warmup_ratio: 0.1
- num_epochs: 1

### Training results

| Training Loss | Epoch | Step | Validation Loss |
|:-------------:|:-----:|:----:|:---------------:|
| 1.9687        | 1.0   | 392  | 6.4970          |


### Framework versions

- Transformers 4.45.1
- Pytorch 2.4.1+cu121
- Datasets 3.0.1
- Tokenizers 0.20.0
","{""id"": ""klcsp/gemma7b-gpt4o_1k_summarize-fft"", ""author"": ""klcsp"", ""sha"": ""f7f016c0854d78b7474a4e1b17abd0a45af6576c"", ""last_modified"": ""2024-09-27 09:03:39+00:00"", ""created_at"": ""2024-09-27 04:24:48+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""trl"", ""sft"", ""generated_from_trainer"", ""conversational"", ""dataset:generator"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""license:gemma"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- generator\nlibrary_name: transformers\nlicense: gemma\ntags:\n- trl\n- sft\n- generated_from_trainer\nmodel-index:\n- name: gemma7b-gpt4o_1k_summarize-fft\n  results: []"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": [{""name"": ""gemma7b-gpt4o_1k_summarize-fft"", ""results"": []}], ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{% if messages[0]['role'] == 'user' or messages[0]['role'] == 'system' %}{{ bos_token }}{% endif %}{% for message in messages %}{{ '<|im_start|>' + message['role'] + '\n' + message['content'] + '<|im_end|>' + '\n' }}{% endfor %}{% if add_generation_prompt %}{{ '<|im_start|>assistant\n' }}{% elif messages[-1]['role'] == 'assistant' %}{{ eos_token }}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='generation_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00001-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00002-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00003-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00004-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model.safetensors.index.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Sep27_05-57-37_6dc6f291b653/events.out.tfevents.1727417880.6dc6f291b653.5992.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": {""parameters"": {""BF16"": 8537680896}, ""total"": 8537680896}, ""security_repo_status"": null, ""lastModified"": ""2024-09-27 09:03:39+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- generator\nlibrary_name: transformers\nlicense: gemma\ntags:\n- trl\n- sft\n- generated_from_trainer\nmodel-index:\n- name: gemma7b-gpt4o_1k_summarize-fft\n  results: []"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""66f6339044e5614334976688"", ""modelId"": ""klcsp/gemma7b-gpt4o_1k_summarize-fft"", ""usedStorage"": 68335953264}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=klcsp/gemma7b-gpt4o_1k_summarize-fft&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bklcsp%2Fgemma7b-gpt4o_1k_summarize-fft%5D(%2Fklcsp%2Fgemma7b-gpt4o_1k_summarize-fft)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
klcsp/gemma7b-gpt4o_1k_classification-fft,"---
library_name: transformers
license: gemma
base_model: google/gemma-7b
tags:
- alignment-handbook
- trl
- sft
- generated_from_trainer
- trl
- sft
- generated_from_trainer
datasets:
- llama-duo/synth_classification_dataset_dedup
model-index:
- name: gemma7b-gpt4o_1k_classification-fft
  results: []
---

<!-- This model card has been generated automatically according to the information the Trainer had access to. You
should probably proofread and complete it, then remove this comment. -->

# gemma7b-gpt4o_1k_classification-fft

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the llama-duo/synth_classification_dataset_dedup dataset.
It achieves the following results on the evaluation set:
- Loss: 5.7345

## Model description

More information needed

## Intended uses & limitations

More information needed

## Training and evaluation data

More information needed

## Training procedure

### Training hyperparameters

The following hyperparameters were used during training:
- learning_rate: 0.0003
- train_batch_size: 2
- eval_batch_size: 2
- seed: 42
- distributed_type: multi-GPU
- num_devices: 8
- gradient_accumulation_steps: 2
- total_train_batch_size: 32
- total_eval_batch_size: 16
- optimizer: Adam with betas=(0.9,0.999) and epsilon=1e-08
- lr_scheduler_type: cosine
- lr_scheduler_warmup_ratio: 0.1
- num_epochs: 1

### Training results

| Training Loss | Epoch  | Step | Validation Loss |
|:-------------:|:------:|:----:|:---------------:|
| 4.3115        | 0.9979 | 239  | 5.7345          |


### Framework versions

- Transformers 4.45.1
- Pytorch 2.4.1+cu121
- Datasets 3.0.1
- Tokenizers 0.20.0
","{""id"": ""klcsp/gemma7b-gpt4o_1k_classification-fft"", ""author"": ""klcsp"", ""sha"": ""6f37a27b4a8a01b50e3084a5475fbe25c0560746"", ""last_modified"": ""2024-09-27 15:25:52+00:00"", ""created_at"": ""2024-09-27 13:47:13+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 3, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""alignment-handbook"", ""trl"", ""sft"", ""generated_from_trainer"", ""conversational"", ""dataset:llama-duo/synth_classification_dataset_dedup"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""license:gemma"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- llama-duo/synth_classification_dataset_dedup\nlibrary_name: transformers\nlicense: gemma\ntags:\n- alignment-handbook\n- trl\n- sft\n- generated_from_trainer\nmodel-index:\n- name: gemma7b-gpt4o_1k_classification-fft\n  results: []"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": [{""name"": ""gemma7b-gpt4o_1k_classification-fft"", ""results"": []}], ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{% if messages[0]['role'] == 'user' or messages[0]['role'] == 'system' %}{{ bos_token }}{% endif %}{% for message in messages %}{{ '<|im_start|>' + message['role'] + '\n' + message['content'] + '<|im_end|>' + '\n' }}{% endfor %}{% if add_generation_prompt %}{{ '<|im_start|>assistant\n' }}{% elif messages[-1]['role'] == 'assistant' %}{{ eos_token }}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='eval_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='generation_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00001-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00002-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00003-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00004-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model.safetensors.index.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Sep27_13-32-42_1cc748c90ddb/events.out.tfevents.1727444838.1cc748c90ddb.2924.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Sep27_13-49-39_1cc748c90ddb/events.out.tfevents.1727445007.1cc748c90ddb.12320.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Sep27_14-38-33_1cc748c90ddb/events.out.tfevents.1727447956.1cc748c90ddb.39559.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Sep27_14-38-33_1cc748c90ddb/events.out.tfevents.1727450610.1cc748c90ddb.39559.1', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": {""parameters"": {""BF16"": 8537680896}, ""total"": 8537680896}, ""security_repo_status"": null, ""lastModified"": ""2024-09-27 15:25:52+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- llama-duo/synth_classification_dataset_dedup\nlibrary_name: transformers\nlicense: gemma\ntags:\n- alignment-handbook\n- trl\n- sft\n- generated_from_trainer\nmodel-index:\n- name: gemma7b-gpt4o_1k_classification-fft\n  results: []"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""66f6b7610e8a7a9782561e3f"", ""modelId"": ""klcsp/gemma7b-gpt4o_1k_classification-fft"", ""usedStorage"": 51260555717}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=klcsp/gemma7b-gpt4o_1k_classification-fft&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bklcsp%2Fgemma7b-gpt4o_1k_classification-fft%5D(%2Fklcsp%2Fgemma7b-gpt4o_1k_classification-fft)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
klcsp/gemma7b-gpt4o_1k_coding-fft,"---
library_name: transformers
license: gemma
base_model: google/gemma-7b
tags:
- alignment-handbook
- trl
- sft
- generated_from_trainer
- trl
- sft
- generated_from_trainer
datasets:
- llama-duo/synth_coding_dataset_dedup
model-index:
- name: gemma7b-gpt4o_1k_coding-fft
  results: []
---

<!-- This model card has been generated automatically according to the information the Trainer had access to. You
should probably proofread and complete it, then remove this comment. -->

# gemma7b-gpt4o_1k_coding-fft

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the llama-duo/synth_coding_dataset_dedup dataset.
It achieves the following results on the evaluation set:
- Loss: 4.8389

## Model description

More information needed

## Intended uses & limitations

More information needed

## Training and evaluation data

More information needed

## Training procedure

### Training hyperparameters

The following hyperparameters were used during training:
- learning_rate: 0.0003
- train_batch_size: 2
- eval_batch_size: 2
- seed: 42
- distributed_type: multi-GPU
- num_devices: 8
- gradient_accumulation_steps: 2
- total_train_batch_size: 32
- total_eval_batch_size: 16
- optimizer: Adam with betas=(0.9,0.999) and epsilon=1e-08
- lr_scheduler_type: cosine
- lr_scheduler_warmup_ratio: 0.1
- num_epochs: 1

### Training results

| Training Loss | Epoch | Step | Validation Loss |
|:-------------:|:-----:|:----:|:---------------:|
| 1.8           | 1.0   | 598  | 4.8389          |


### Framework versions

- Transformers 4.45.1
- Pytorch 2.4.1+cu121
- Datasets 3.0.1
- Tokenizers 0.20.0
","{""id"": ""klcsp/gemma7b-gpt4o_1k_coding-fft"", ""author"": ""klcsp"", ""sha"": ""3373fc6403f7d4b4c872cc3b49fca79f3440a7fa"", ""last_modified"": ""2024-09-27 18:17:39+00:00"", ""created_at"": ""2024-09-27 15:41:00+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""alignment-handbook"", ""trl"", ""sft"", ""generated_from_trainer"", ""conversational"", ""dataset:llama-duo/synth_coding_dataset_dedup"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""license:gemma"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- llama-duo/synth_coding_dataset_dedup\nlibrary_name: transformers\nlicense: gemma\ntags:\n- alignment-handbook\n- trl\n- sft\n- generated_from_trainer\nmodel-index:\n- name: gemma7b-gpt4o_1k_coding-fft\n  results: []"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": [{""name"": ""gemma7b-gpt4o_1k_coding-fft"", ""results"": []}], ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{% if messages[0]['role'] == 'user' or messages[0]['role'] == 'system' %}{{ bos_token }}{% endif %}{% for message in messages %}{{ '<|im_start|>' + message['role'] + '\n' + message['content'] + '<|im_end|>' + '\n' }}{% endfor %}{% if add_generation_prompt %}{{ '<|im_start|>assistant\n' }}{% elif messages[-1]['role'] == 'assistant' %}{{ eos_token }}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='eval_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='generation_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00001-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00002-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00003-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00004-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model.safetensors.index.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Sep27_15-49-38_1cc748c90ddb/events.out.tfevents.1727452206.1cc748c90ddb.81052.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Sep27_15-49-38_1cc748c90ddb/events.out.tfevents.1727460938.1cc748c90ddb.81052.1', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": {""parameters"": {""BF16"": 8537680896}, ""total"": 8537680896}, ""security_repo_status"": null, ""lastModified"": ""2024-09-27 18:17:39+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- llama-duo/synth_coding_dataset_dedup\nlibrary_name: transformers\nlicense: gemma\ntags:\n- alignment-handbook\n- trl\n- sft\n- generated_from_trainer\nmodel-index:\n- name: gemma7b-gpt4o_1k_coding-fft\n  results: []"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""66f6d20c05ca5aa614c8bf66"", ""modelId"": ""klcsp/gemma7b-gpt4o_1k_coding-fft"", ""usedStorage"": 102486794546}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=klcsp/gemma7b-gpt4o_1k_coding-fft&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bklcsp%2Fgemma7b-gpt4o_1k_coding-fft%5D(%2Fklcsp%2Fgemma7b-gpt4o_1k_coding-fft)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
klcsp/gemma7b-gpt4o_1k_closedqa-fft,"---
library_name: transformers
license: gemma
base_model: google/gemma-7b
tags:
- alignment-handbook
- trl
- sft
- generated_from_trainer
- trl
- sft
- generated_from_trainer
datasets:
- llama-duo/synth_closed_qa_dataset_dedup
model-index:
- name: gemma7b-gpt4o_1k_closedqa-fft
  results: []
---

<!-- This model card has been generated automatically according to the information the Trainer had access to. You
should probably proofread and complete it, then remove this comment. -->

# gemma7b-gpt4o_1k_closedqa-fft

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the llama-duo/synth_closed_qa_dataset_dedup dataset.
It achieves the following results on the evaluation set:
- Loss: 5.6168

## Model description

More information needed

## Intended uses & limitations

More information needed

## Training and evaluation data

More information needed

## Training procedure

### Training hyperparameters

The following hyperparameters were used during training:
- learning_rate: 0.0003
- train_batch_size: 2
- eval_batch_size: 2
- seed: 42
- distributed_type: multi-GPU
- num_devices: 8
- gradient_accumulation_steps: 2
- total_train_batch_size: 32
- total_eval_batch_size: 16
- optimizer: Adam with betas=(0.9,0.999) and epsilon=1e-08
- lr_scheduler_type: cosine
- lr_scheduler_warmup_ratio: 0.1
- num_epochs: 1

### Training results

| Training Loss | Epoch  | Step | Validation Loss |
|:-------------:|:------:|:----:|:---------------:|
| 2.1274        | 0.9990 | 519  | 5.6168          |


### Framework versions

- Transformers 4.45.1
- Pytorch 2.4.1+cu121
- Datasets 3.0.1
- Tokenizers 0.20.0
","{""id"": ""klcsp/gemma7b-gpt4o_1k_closedqa-fft"", ""author"": ""klcsp"", ""sha"": ""699ea90a5596fc3b748a59d784388495aa3fa8ef"", ""last_modified"": ""2024-09-27 20:39:11+00:00"", ""created_at"": ""2024-09-27 15:45:03+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""alignment-handbook"", ""trl"", ""sft"", ""generated_from_trainer"", ""conversational"", ""dataset:llama-duo/synth_closed_qa_dataset_dedup"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""license:gemma"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- llama-duo/synth_closed_qa_dataset_dedup\nlibrary_name: transformers\nlicense: gemma\ntags:\n- alignment-handbook\n- trl\n- sft\n- generated_from_trainer\nmodel-index:\n- name: gemma7b-gpt4o_1k_closedqa-fft\n  results: []"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": [{""name"": ""gemma7b-gpt4o_1k_closedqa-fft"", ""results"": []}], ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{% if messages[0]['role'] == 'user' or messages[0]['role'] == 'system' %}{{ bos_token }}{% endif %}{% for message in messages %}{{ '<|im_start|>' + message['role'] + '\n' + message['content'] + '<|im_end|>' + '\n' }}{% endfor %}{% if add_generation_prompt %}{{ '<|im_start|>assistant\n' }}{% elif messages[-1]['role'] == 'assistant' %}{{ eos_token }}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='eval_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='generation_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00001-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00002-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00003-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00004-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model.safetensors.index.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Sep27_18-18-16_1cc748c90ddb/events.out.tfevents.1727461126.1cc748c90ddb.159347.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Sep27_18-18-16_1cc748c90ddb/events.out.tfevents.1727469360.1cc748c90ddb.159347.1', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": {""parameters"": {""BF16"": 8537680896}, ""total"": 8537680896}, ""security_repo_status"": null, ""lastModified"": ""2024-09-27 20:39:11+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- llama-duo/synth_closed_qa_dataset_dedup\nlibrary_name: transformers\nlicense: gemma\ntags:\n- alignment-handbook\n- trl\n- sft\n- generated_from_trainer\nmodel-index:\n- name: gemma7b-gpt4o_1k_closedqa-fft\n  results: []"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""66f6d2ff78e0f4f61e456fc9"", ""modelId"": ""klcsp/gemma7b-gpt4o_1k_closedqa-fft"", ""usedStorage"": 102486791218}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=klcsp/gemma7b-gpt4o_1k_closedqa-fft&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bklcsp%2Fgemma7b-gpt4o_1k_closedqa-fft%5D(%2Fklcsp%2Fgemma7b-gpt4o_1k_closedqa-fft)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
c-alfano/gemma-7b-borpo-low-quality-v5,"---
library_name: transformers
license: gemma
base_model: google/gemma-7b
tags:
- alignment-handbook
- trl
- orpo
- generated_from_trainer
- trl
- orpo
- generated_from_trainer
datasets:
- silviasapora/low_quality_dpo7k
model-index:
- name: gemma-7b-borpo-low-quality-v5
  results: []
---

<!-- This model card has been generated automatically according to the information the Trainer had access to. You
should probably proofread and complete it, then remove this comment. -->

# gemma-7b-borpo-low-quality-v5

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the silviasapora/low_quality_dpo7k dataset.
It achieves the following results on the evaluation set:
- Loss: 2.0035
- Rewards/chosen: -0.6455
- Rewards/rejected: -0.7620
- Rewards/accuracies: 0.6115
- Rewards/margins: 0.1164
- Logps/rejected: -1.5240
- Logps/chosen: -1.2911
- Logits/rejected: 259.2041
- Logits/chosen: 292.7468
- Nll Loss: 1.6440
- Log Odds Ratio: -0.6769
- Log Odds Chosen: 0.3357

## Model description

More information needed

## Intended uses & limitations

More information needed

## Training and evaluation data

More information needed

## Training procedure

### Training hyperparameters

The following hyperparameters were used during training:
- learning_rate: 7.5e-06
- train_batch_size: 2
- eval_batch_size: 1
- seed: 42
- distributed_type: multi-GPU
- num_devices: 4
- gradient_accumulation_steps: 4
- total_train_batch_size: 32
- total_eval_batch_size: 4
- optimizer: Adam with betas=(0.9,0.999) and epsilon=1e-08
- lr_scheduler_type: inverse_sqrt
- lr_scheduler_warmup_steps: 100
- num_epochs: 3

### Training results

| Training Loss | Epoch  | Step | Validation Loss | Rewards/chosen | Rewards/rejected | Rewards/accuracies | Rewards/margins | Logps/rejected | Logps/chosen | Logits/rejected | Logits/chosen | Nll Loss | Log Odds Ratio | Log Odds Chosen |
|:-------------:|:------:|:----:|:---------------:|:--------------:|:----------------:|:------------------:|:---------------:|:--------------:|:------------:|:---------------:|:-------------:|:--------:|:--------------:|:---------------:|
| 1.8398        | 0.9955 | 167  | 1.8982          | -0.5762        | -0.6715          | 0.5180             | 0.0953          | -1.3431        | -1.1525      | 302.9095        | 331.1552      | 1.5454   | -0.6749        | 0.2542          |
| 1.299         | 1.9970 | 335  | 1.8186          | -0.5507        | -0.6510          | 0.5396             | 0.1003          | -1.3021        | -1.1014      | 282.3183        | 313.4974      | 1.4682   | -0.6666        | 0.3074          |
| 0.6379        | 2.9866 | 501  | 2.0035          | -0.6455        | -0.7620          | 0.6115             | 0.1164          | -1.5240        | -1.2911      | 259.2041        | 292.7468      | 1.6440   | -0.6769        | 0.3357          |


### Framework versions

- Transformers 4.45.1
- Pytorch 2.4.1+cu121
- Datasets 3.0.1
- Tokenizers 0.20.0
","{""id"": ""c-alfano/gemma-7b-borpo-low-quality-v5"", ""author"": ""c-alfano"", ""sha"": ""c07e618d354cccdd2d7211c313d661cacc990101"", ""last_modified"": ""2024-09-30 00:33:20+00:00"", ""created_at"": ""2024-09-29 14:32:11+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""alignment-handbook"", ""trl"", ""orpo"", ""generated_from_trainer"", ""conversational"", ""dataset:silviasapora/low_quality_dpo7k"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""license:gemma"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- silviasapora/low_quality_dpo7k\nlibrary_name: transformers\nlicense: gemma\ntags:\n- alignment-handbook\n- trl\n- orpo\n- generated_from_trainer\nmodel-index:\n- name: gemma-7b-borpo-low-quality-v5\n  results: []"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": [{""name"": ""gemma-7b-borpo-low-quality-v5"", ""results"": []}], ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<|im_start|>"", ""chat_template"": ""{% for message in messages %}{{'<|im_start|>' + message['role'] + '\n' + message['content'] + '<|im_end|>' + '\n'}}{% endfor %}{% if add_generation_prompt %}{{ '<|im_start|>assistant\n' }}{% endif %}"", ""eos_token"": ""<|im_end|>"", ""pad_token"": ""<|im_end|>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='eval_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='generation_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00001-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00002-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00003-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00004-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model.safetensors.index.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Sep29_15-47-27_zizgpu06.cpu.stats.ox.ac.uk/events.out.tfevents.1727621355.zizgpu06.cpu.stats.ox.ac.uk.1837986.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Sep29_15-57-26_zizgpu06.cpu.stats.ox.ac.uk/events.out.tfevents.1727621956.zizgpu06.cpu.stats.ox.ac.uk.1840392.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Sep29_15-57-26_zizgpu06.cpu.stats.ox.ac.uk/events.out.tfevents.1727656261.zizgpu06.cpu.stats.ox.ac.uk.1840392.1', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": {""parameters"": {""BF16"": 8537680896}, ""total"": 8537680896}, ""security_repo_status"": null, ""lastModified"": ""2024-09-30 00:33:20+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- silviasapora/low_quality_dpo7k\nlibrary_name: transformers\nlicense: gemma\ntags:\n- alignment-handbook\n- trl\n- orpo\n- generated_from_trainer\nmodel-index:\n- name: gemma-7b-borpo-low-quality-v5\n  results: []"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""66f964eb3d94062a4aa3a84c"", ""modelId"": ""c-alfano/gemma-7b-borpo-low-quality-v5"", ""usedStorage"": 17109813850}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=c-alfano/gemma-7b-borpo-low-quality-v5&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bc-alfano%2Fgemma-7b-borpo-low-quality-v5%5D(%2Fc-alfano%2Fgemma-7b-borpo-low-quality-v5)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
OpenLLM-Ro/RoGemma-7b-Instruct,"---
license: cc-by-nc-4.0
language:
- ro
base_model:
- google/gemma-7b
datasets:
- OpenLLM-Ro/ro_sft_alpaca
- OpenLLM-Ro/ro_sft_alpaca_gpt4
- OpenLLM-Ro/ro_sft_dolly
- OpenLLM-Ro/ro_sft_selfinstruct_gpt4
- OpenLLM-Ro/ro_sft_norobots
- OpenLLM-Ro/ro_sft_orca
- OpenLLM-Ro/ro_sft_camel
- OpenLLM-Ro/ro_sft_oasst
- OpenLLM-Ro/ro_sft_ultrachat
model-index:
    - name: OpenLLM-Ro/RoGemma-7b-Instruct-2024-10-09
      results:
        - task:
            type: text-generation
          dataset:
            name: RoMT-Bench
            type: RoMT-Bench
          metrics:
            - name: Score
              type: Score
              value: 5.24
        - task:
            type: text-generation
          dataset:
            name: RoCulturaBench
            type: RoCulturaBench
          metrics:
            - name: Score
              type: Score
              value: 3.51
        - task:
            type: text-generation
          dataset:
            name: Romanian_Academic_Benchmarks
            type: Romanian_Academic_Benchmarks
          metrics:
            - name: Average accuracy
              type: accuracy
              value: 50.48
        - task:
            type: text-generation
          dataset:
            name: OpenLLM-Ro/ro_arc_challenge
            type: OpenLLM-Ro/ro_arc_challenge
          metrics:
            - name: Average accuracy
              type: accuracy
              value: 52.01
        - task:
            type: text-generation
          dataset:
            name: OpenLLM-Ro/ro_mmlu
            type: OpenLLM-Ro/ro_mmlu
          metrics:
            - name: Average accuracy
              type: accuracy
              value: 52.37
        - task:
            type: text-generation
          dataset:
            name: OpenLLM-Ro/ro_winogrande
            type: OpenLLM-Ro/ro_winogrande
          metrics:
            - name: Average accuracy
              type: accuracy
              value: 66.97
        - task:
            type: text-generation
          dataset:
            name: OpenLLM-Ro/ro_hellaswag
            type: OpenLLM-Ro/ro_hellaswag
          metrics:
            - name: Average accuracy
              type: accuracy
              value: 56.34
        - task:
            type: text-generation
          dataset:
            name: OpenLLM-Ro/ro_gsm8k
            type: OpenLLM-Ro/ro_gsm8k
          metrics:
            - name: Average accuracy
              type: accuracy
              value: 25.98
        - task:
            type: text-generation
          dataset:
            name: OpenLLM-Ro/ro_truthfulqa
            type: OpenLLM-Ro/ro_truthfulqa
          metrics:
            - name: Average accuracy
              type: accuracy
              value: 49.18
        - task:
            type: text-generation
          dataset:
            name: LaRoSeDa_binary
            type: LaRoSeDa_binary
          metrics:
            - name: Average macro-f1
              type: macro-f1
              value: 86.96
        - task:
            type: text-generation
          dataset:
            name: LaRoSeDa_multiclass
            type: LaRoSeDa_multiclass
          metrics:
            - name: Average macro-f1
              type: macro-f1
              value: 56.72
        - task:
            type: text-generation
          dataset:
            name: LaRoSeDa_binary_finetuned
            type: LaRoSeDa_binary_finetuned
          metrics:
            - name: Average macro-f1
              type: macro-f1
              value: 98.80
        - task:
            type: text-generation
          dataset:
            name: LaRoSeDa_multiclass_finetuned
            type: LaRoSeDa_multiclass_finetuned
          metrics:
            - name: Average macro-f1
              type: macro-f1
              value: 85.81
        - task:
            type: text-generation
          dataset:
            name: WMT_EN-RO
            type: WMT_EN-RO
          metrics:
            - name: Average bleu
              type: bleu
              value: 24.45
        - task:
            type: text-generation
          dataset:
            name: WMT_RO-EN
            type: WMT_RO-EN
          metrics:
            - name: Average bleu
              type: bleu
              value: 14.20
        - task:
            type: text-generation
          dataset:
            name: WMT_EN-RO_finetuned
            type: WMT_EN-RO_finetuned
          metrics:
            - name: Average bleu
              type: bleu
              value: 25.96
        - task:
            type: text-generation
          dataset:
            name: WMT_RO-EN_finetuned
            type: WMT_RO-EN_finetuned
          metrics:
            - name: Average bleu
              type: bleu
              value: 39.07
        - task:
            type: text-generation
          dataset:
            name: XQuAD
            type: XQuAD
          metrics:
            - name: Average exact_match
              type: exact_match
              value: 26.03
        - task:
            type: text-generation
          dataset:
            name: XQuAD
            type: XQuAD
          metrics:
            - name: Average f1
              type: f1
              value: 41.58
        - task:
            type: text-generation
          dataset:
            name: XQuAD_finetuned
            type: XQuAD_finetuned
          metrics:
            - name: Average exact_match
              type: exact_match
              value: 46.72
        - task:
            type: text-generation
          dataset:
            name: XQuAD_finetuned
            type: XQuAD_finetuned
          metrics:
            - name: Average f1
              type: f1
              value: 60.79
        - task:
            type: text-generation
          dataset:
            name: STS
            type: STS
          metrics:
            - name: Average spearman
              type: spearman
              value: 73.23
        - task:
            type: text-generation
          dataset:
            name: STS
            type: STS
          metrics:
            - name: Average pearson
              type: pearson
              value: 71.58
        - task:
            type: text-generation
          dataset:
            name: STS_finetuned
            type: STS_finetuned
          metrics:
            - name: Average spearman
              type: spearman
              value: 88.42
        - task:
            type: text-generation
          dataset:
            name: STS_finetuned
            type: STS_finetuned
          metrics:
            - name: Average pearson
              type: pearson
              value: 88.45
        - task:
            type: text-generation
          dataset:
            name: RoMT-Bench
            type: RoMT-Bench
          metrics:
            - name: First turn
              type: Score
              value: 5.55
            - name: Second turn
              type: Score
              value: 4.94
        - task:
            type: text-generation
          dataset:
            name: OpenLLM-Ro/ro_arc_challenge
            type: OpenLLM-Ro/ro_arc_challenge
          metrics:
            - name: 0-shot 
              type: accuracy
              value: 49.53
            - name: 1-shot 
              type: accuracy
              value: 52.53
            - name: 3-shot 
              type: accuracy
              value: 51.50
            - name: 5-shot 
              type: accuracy
              value: 53.56
            - name: 10-shot 
              type: accuracy
              value: 52.53
            - name: 25-shot 
              type: accuracy
              value: 52.44
        - task:
            type: text-generation
          dataset:
            name: OpenLLM-Ro/ro_mmlu
            type: OpenLLM-Ro/ro_mmlu
          metrics:
            - name: 0-shot 
              type: accuracy
              value: 51.81
            - name: 1-shot 
              type: accuracy
              value: 52.45
            - name: 3-shot 
              type: accuracy
              value: 52.52
            - name: 5-shot 
              type: accuracy
              value: 52.70
        - task:
            type: text-generation
          dataset:
            name: OpenLLM-Ro/ro_winogrande
            type: OpenLLM-Ro/ro_winogrande
          metrics:
            - name: 0-shot 
              type: accuracy
              value: 66.54
            - name: 1-shot 
              type: accuracy
              value: 66.69
            - name: 3-shot 
              type: accuracy
              value: 67.09
            - name: 5-shot 
              type: accuracy
              value: 67.56
        - task:
            type: text-generation
          dataset:
            name: OpenLLM-Ro/ro_hellaswag
            type: OpenLLM-Ro/ro_hellaswag
          metrics:
            - name: 0-shot 
              type: accuracy
              value: 58.80
            - name: 1-shot 
              type: accuracy
              value: 57.04
            - name: 3-shot 
              type: accuracy
              value: 55.85
            - name: 5-shot 
              type: accuracy
              value: 54.15
            - name: 10-shot 
              type: accuracy
              value: 55.88
        - task:
            type: text-generation
          dataset:
            name: OpenLLM-Ro/ro_gsm8k
            type: OpenLLM-Ro/ro_gsm8k
          metrics:
            - name: 1-shot 
              type: accuracy
              value: 22.06
            - name: 3-shot 
              type: accuracy
              value: 25.40
            - name: 5-shot 
              type: accuracy
              value: 30.48
        - task:
            type: text-generation
          dataset:
            name: LaRoSeDa_binary
            type: LaRoSeDa_binary
          metrics:
            - name: 0-shot 
              type: macro-f1
              value: 87.28
            - name: 1-shot 
              type: macro-f1
              value: 86.40
            - name: 3-shot 
              type: macro-f1
              value: 87.95
            - name: 5-shot 
              type: macro-f1
              value: 86.20
        - task:
            type: text-generation
          dataset:
            name: LaRoSeDa_multiclass
            type: LaRoSeDa_multiclass
          metrics:
            - name: 0-shot 
              type: macro-f1
              value: 38.35
            - name: 1-shot 
              type: macro-f1
              value: 63.86
            - name: 3-shot 
              type: macro-f1
              value: 62.03
            - name: 5-shot 
              type: macro-f1
              value: 62.62
        - task:
            type: text-generation
          dataset:
            name: WMT_EN-RO
            type: WMT_EN-RO
          metrics:
            - name: 0-shot 
              type: bleu
              value: 11.39
            - name: 1-shot 
              type: bleu
              value: 28.08
            - name: 3-shot 
              type: bleu
              value: 29.18
            - name: 5-shot 
              type: bleu
              value: 29.13
        - task:
            type: text-generation
          dataset:
            name: WMT_RO-EN
            type: WMT_RO-EN
          metrics:
            - name: 0-shot 
              type: bleu
              value: 1.92
            - name: 1-shot 
              type: bleu
              value: 9.39
            - name: 3-shot 
              type: bleu
              value: 21.81
            - name: 5-shot 
              type: bleu
              value: 23.66
        - task:
            type: text-generation
          dataset:
            name: XQuAD_EM
            type: XQuAD_EM
          metrics:
            - name: 0-shot 
              type: exact_match
              value: 32.77
            - name: 1-shot 
              type: exact_match
              value: 20.25
            - name: 3-shot 
              type: exact_match
              value: 18.49
            - name: 5-shot 
              type: exact_match
              value: 32.60
        - task:
            type: text-generation
          dataset:
            name: XQuAD_F1
            type: XQuAD_F1
          metrics:
            - name: 0-shot 
              type: f1
              value: 47.98
            - name: 1-shot 
              type: f1
              value: 34.92
            - name: 3-shot 
              type: f1
              value: 33.27
            - name: 5-shot 
              type: f1
              value: 50.14
        - task:
            type: text-generation
          dataset:
            name: STS_Spearman
            type: STS_Spearman
          metrics:
            - name: 1-shot 
              type: spearman
              value: 71.75
            - name: 3-shot 
              type: spearman
              value: 71.83
            - name: 5-shot 
              type: spearman
              value: 76.11
        - task:
            type: text-generation
          dataset:
            name: STS_Pearson
            type: STS_Pearson
          metrics:
            - name: 1-shot 
              type: pearson
              value: 69.97
            - name: 3-shot 
              type: pearson
              value: 69.87
            - name: 5-shot 
              type: pearson
              value: 74.89

---

# Model Card for Model ID

<!-- Provide a quick summary of what the model is/does. -->

This model points/is identical to [RoGemma-7b-Instruct-2024-10-09](https://huggingface.co/OpenLLM-Ro/RoGemma-7b-Instruct-2024-10-09).

RoGemma is a family of pretrained and fine-tuned generative text models for Romanian. This is the repository for the **instruct 7B model**. Links to other models can be found at the bottom of this page.

## Model Details

### Model Description

<!-- Provide a longer summary of what this model is. -->
OpenLLM-Ro represents the first open-source effort to build a LLM specialized for Romanian. OpenLLM-Ro developed and publicly releases a collection of Romanian LLMs, both in the form of foundational model and instruct and chat variants.


- **Developed by:** OpenLLM-Ro
<!-- - **Funded by [optional]:** [More Information Needed] -->
<!-- - **Shared by [optional]:** [More Information Needed] -->
<!-- - **Model type:** [More Information Needed] -->
- **Language(s):** Romanian
- **License:** cc-by-nc-4.0
- **Finetuned from model:** [gemma-7b](https://huggingface.co/google/gemma-7b)
- **Trained using:** [RoAlpaca](https://huggingface.co/datasets/OpenLLM-Ro/ro_sft_alpaca), [RoAlpacaGPT4](https://huggingface.co/datasets/OpenLLM-Ro/ro_sft_alpaca_gpt4), [RoDolly](https://huggingface.co/datasets/OpenLLM-Ro/ro_sft_dolly), [RoSelfInstruct](https://huggingface.co/datasets/OpenLLM-Ro/ro_sft_selfinstruct_gpt4), [RoNoRobots](https://huggingface.co/datasets/OpenLLM-Ro/ro_sft_norobots), [RoOrca](https://huggingface.co/datasets/OpenLLM-Ro/ro_sft_orca), [RoCamel](https://huggingface.co/datasets/OpenLLM-Ro/ro_sft_camel), [RoOpenAssistant](https://huggingface.co/datasets/OpenLLM-Ro/ro_sft_oasst), [RoUltraChat](https://huggingface.co/datasets/OpenLLM-Ro/ro_sft_ultrachat)


### Model Sources

<!-- Provide the basic links for the model. -->

- **Repository:** https://github.com/OpenLLM-Ro/LLaMA-Factory
- **Paper:** https://arxiv.org/abs/2406.18266

## Intended Use

### Intended Use Cases

RoGemma is intented for research use in Romanian. Base models can be adapted for a variety of natural language tasks while instruction and chat tuned models are intended for assistant-like chat.

### Out-of-Scope Use

<!-- This section addresses misuse, malicious use, and uses that the model will not work well for. -->

Use in any manner that violates the license, any applicable laws or regluations, use in languages other than Romanian.



## How to Get Started with the Model

Use the code below to get started with the model.

```python
from transformers import AutoTokenizer, AutoModelForCausalLM

tokenizer = AutoTokenizer.from_pretrained(""OpenLLM-Ro/RoGemma-7b-Instruct"")
model = AutoModelForCausalLM.from_pretrained(""OpenLLM-Ro/RoGemma-7b-Instruct"")

instruction = ""Ce jocuri de societate pot juca cu prietenii mei?""
chat = [
        {""role"": ""user"", ""content"": instruction},
        ]
prompt = tokenizer.apply_chat_template(chat, tokenize=False, system_message="""")

inputs = tokenizer.encode(prompt, add_special_tokens=False, return_tensors=""pt"")
outputs = model.generate(input_ids=inputs, max_new_tokens=128)
print(tokenizer.decode(outputs[0]))
```

## Academic Benchmarks

<table>
<tbody>
<tr>
<td><strong>Model</strong></td>
<td><strong><center>Average</center></strong></td>
<td><strong><center>ARC</center></strong></td>
<td><strong><center>MMLU</center></strong></td>
<td><strong><center>Winogrande</center></strong></td>
<td><strong><center>Hellaswag</center></strong></td>
<td><strong><center>GSM8k</center></strong></td>
<td><strong><center>TruthfulQA</center></strong></td>
</tr>
<tr>
<td>gemma-1.1-7b-it</td><td><center>41.44</center></td><td><center>40.32</center></td><td><center>47.22</center></td><td><center>55.01</center></td><td><center>47.03</center></td><td><center>9.50</center></td><td><center>49.58</center></td>
</tr>
<tr>
<td>RoGemma-7b-Instruct-2024-06-28</td><td><center><strong>53.41</strong></center></td><td><center><strong>52.44</strong></center></td><td><center>54.44</center></td><td><center><strong>69.36</strong></center></td><td><center><strong>61.96</strong></center></td><td><center>31.06</center></td><td><center><strong>51.23</strong></center></td>
</tr>
<tr>
<td><em>RoGemma-7b-Instruct-2024-10-09</em></td><td><center><em>50.48</em></center></td><td><center><em>52.01</em></center></td><td><center><em>52.37</em></center></td><td><center><em>66.97</em></center></td><td><center><em>56.34</em></center></td><td><center><em>25.98</em></center></td><td><center><em>49.18</em></center></td>
</tr>
<tr>
<td>RoGemma-7b-Instruct-DPO-2024-10-09</td><td><center>48.27</center></td><td><center>46.66</center></td><td><center><strong>54.45</strong></center></td><td><center>63.73</center></td><td><center>49.33</center></td><td><center><strong>34.98</strong></center></td><td><center>40.45</center></td>
</tr>
</tbody>
</table>


## Downstream tasks

<table>
<tbody>
<tr>
<td></td>
<td colspan=""4""><center><strong>LaRoSeDa</strong></center></td>
<td colspan=""4""><center><strong>WMT</strong></center></td>
</tr>
<tr>
<td></td>
<td colspan=""2""><center><strong>Few-shot</strong></center></td>
<td colspan=""2""><center><strong>Finetuned</strong></center></td>
<td colspan=""2""><center><strong>Few-shot</strong></center></td>
<td colspan=""2""><center><strong>Finetuned</strong></center></td>
</tr>
<tr>
<td><strong>Model</strong></td>
<td><center><strong>Binary<br>(Macro F1)</strong></center></td>
<td><center><strong>Multiclass<br>(Macro F1)</strong></center></td>
<td><center><strong>Binary<br>(Macro F1)</strong></center></td>
<td><center><strong>Multiclass<br>(Macro F1)</strong></center></td>
<td><center><strong>EN-RO<br>(Bleu)</strong></center></td>
<td><center><strong>RO-EN<br>(Bleu)</strong></center></td>
<td><center><strong>EN-RO<br>(Bleu)</strong></center></td>
<td><center><strong>RO-EN<br>(Bleu)</strong></center>
</tr>
<tr>
<td>gemma-1.1-7b-it</td><td><center>87.54</center></td><td><center>51.48</center></td><td><center>83.87</center></td><td><center>85.61</center></td><td><center>17.96</center></td><td><center><strong>27.74</strong></center></td><td><center>25.48</center></td><td><center>36.11</center></td>
</tr>
<tr>
<td>RoGemma-7b-Instruct-2024-06-28</td><td><center><strong>97.86</strong></center></td><td><center><strong>65.70</strong></center></td><td><center>98.43</center></td><td><center><strong>87.17</strong></center></td><td><center><strong>27.91</strong></center></td><td><center>23.08</center></td><td><center><strong>27.99</strong></center></td><td><center><strong>39.51</strong></center></td>
</tr>
<tr>
<td><em>RoGemma-7b-Instruct-2024-10-09</em></td><td><center><em>86.96</em></center></td><td><center><em>56.72</em></center></td><td><center><em><strong>98.80</strong></em></center></td><td><center><em>85.81</em></center></td><td><center><em>24.45</em></center></td><td><center><em>14.20</em></center></td><td><center><em>25.96</em></center></td><td><center><em>39.07</em></center></td>
</tr>
<tr>
<td>RoGemma-7b-Instruct-DPO-2024-10-09</td><td><center>96.45</center></td><td><center>63.23</center></td><td><center>-</center></td><td><center>-</center></td><td><center>20.73</center></td><td><center>7.87</center></td><td><center>-</center></td><td><center>-</center></td>
</tr>
</tbody>
</table>


<table>
<tbody>
<tr>
<td></td>
<td colspan=""4""><center><strong>XQuAD</strong></center></td>
<td colspan=""4""><center><strong>STS</strong></center></td>
</tr>
<tr>
<td></td>
<td colspan=""2""><center><strong>Few-shot</strong></center></td>
<td colspan=""2""><center><strong>Finetuned</strong></center></td>
<td colspan=""2""><center><strong>Few-shot</strong></center></td>
<td colspan=""2""><center><strong>Finetuned</strong></center></td>
</tr>
<tr>
<td><strong>Model</strong></td>
<td><center><strong>(EM)</strong></center></td>
<td><center><strong>(F1)</strong></center></td>
<td><center><strong>(EM)</strong></center></td>
<td><center><strong>(F1)</strong></center></td>
<td><center><strong>(Spearman)</strong></center></td>
<td><center><strong>(Pearson)</strong></center></td>
<td><center><strong>(Spearman)</strong></center></td>
<td><center><strong>(Pearson)</strong></center></td>
</tr>
<tr>
<td>gemma-1.1-7b-it</td><td><center><strong>42.10</strong></center></td><td><center><strong>62.30</strong></center></td><td><center><strong>60.34</strong></center></td><td><center><strong>77.40</strong></center></td><td><center>49.10</center></td><td><center>50.23</center></td><td><center>83.43</center></td><td><center>83.64</center></td>
</tr>
<tr>
<td>RoGemma-7b-Instruct-2024-06-28</td><td><center>17.75</center></td><td><center>28.11</center></td><td><center>52.02</center></td><td><center>68.43</center></td><td><center><strong>73.96</strong></center></td><td><center><strong>75.16</strong></center></td><td><center>86.45</center></td><td><center>86.31</center></td>
</tr>
<tr>
<td><em>RoGemma-7b-Instruct-2024-10-09</em></td><td><center><em>26.03</em></center></td><td><center><em>41.58</em></center></td><td><center><em>46.72</em></center></td><td><center><em>60.79</em></center></td><td><center><em>73.23</em></center></td><td><center><em>71.58</em></center></td><td><center><em><strong>88.42</strong></em></center></td><td><center><em><strong>88.45</strong></em></center></td>
</tr>
<tr>
<td>RoGemma-7b-Instruct-DPO-2024-10-09</td><td><center>19.14</center></td><td><center>38.10</center></td><td><center>-</center></td><td><center>-</center></td><td><center>69.38</center></td><td><center>69.34</center></td><td><center>-</center></td><td><center>-</center></td>
</tr>
</tbody>
</table>


## MT-Bench

<table>
<tbody>
<tr>
<td><strong>Model</strong></td>
<td><strong><center>Average</center></strong></td>
<td><strong><center>1st turn</center></strong></td>
<td><strong><center>2nd turn</center></strong></td>
<td><strong><center>Answers in Ro</center></strong></td>
</tr>
<tr>
<td>gemma-1.1-7b-it</td><td><center>4.83</center></td><td><center>5.11</center></td><td><center>4.55</center></td><td><center><strong>160/160</strong></center></td>
</tr>
<tr>
<td>RoGemma-7b-Instruct-2024-06-28</td><td><center>5.26</center></td><td><center><strong>5.92</strong></center></td><td><center>4.60</center></td><td><center><strong>160/160</strong></center></td>
</tr>
<tr>
<td><em>RoGemma-7b-Instruct-2024-10-09</em></td><td><center><em>5.24</em></center></td><td><center><em>5.55</em></center></td><td><center><em>4.94</em></center></td><td><center><em><strong>160/160</strong></em></center></td>
</tr>
<tr>
<td>RoGemma-7b-Instruct-DPO-2024-10-09</td><td><center><strong>5.47</strong></center></td><td><center><strong>5.92</strong></center></td><td><center><strong>5.03</strong></center></td><td><center><strong>160/160</strong></center></td>
</tr>
</tbody>
</table>

## RoCulturaBench

<table>
<tbody>
<tr>
<td><strong>Model</strong></td>
<td><strong><center>Average</center></strong></td>
<td><strong><center>Answers in Ro</center></strong></td>
</tr>
<tr>
<td>gemma-1.1-7b-it</td><td><center>3.38</center></td><td><center><strong>100/100</strong></center></td>
</tr>
<tr>
<td>RoGemma-7b-Instruct-2024-06-28</td><td><center>3.26</center></td><td><center><strong>100/100</strong></center></td>
</tr>
<tr>
<td><em>RoGemma-7b-Instruct-2024-10-09</em></td><td><center><em>3.51</em></center></td><td><center><em><strong>100/100</strong></em></center></td>
</tr>
<tr>
<td>RoGemma-7b-Instruct-DPO-2024-10-09</td><td><center><strong>3.94</strong></center></td><td><center><strong>100/100</strong></center></td>
</tr>
</tbody>
</table>

## RoGemma Model Family

| Model              | Link  |
|--------------------|:--------:|
|RoGemma-7b-Instruct-2024-06-28| [link](https://huggingface.co/OpenLLM-Ro/RoGemma-7b-Instruct-2024-06-28) |
|*RoGemma-7b-Instruct-2024-10-09*| [link](https://huggingface.co/OpenLLM-Ro/RoGemma-7b-Instruct-2024-10-09) |
|RoGemma-7b-Instruct-DPO-2024-10-09| [link](https://huggingface.co/OpenLLM-Ro/RoGemma-7b-Instruct-DPO-2024-10-09) |


## Citation 

```
@misc{masala2024vorbecstiromanecsterecipetrain,
      title={""Vorbe\c{s}ti Rom\^ane\c{s}te?"" A Recipe to Train Powerful Romanian LLMs with English Instructions}, 
      author={Mihai Masala and Denis C. Ilie-Ablachim and Alexandru Dima and Dragos Corlatescu and Miruna Zavelca and Ovio Olaru and Simina Terian-Dan and Andrei Terian-Dan and Marius Leordeanu and Horia Velicu and Marius Popescu and Mihai Dascalu and Traian Rebedea},
      year={2024},
      eprint={2406.18266},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2406.18266}, 
}
```
<!-- **APA:**

[More Information Needed]  -->","{""id"": ""OpenLLM-Ro/RoGemma-7b-Instruct"", ""author"": ""OpenLLM-Ro"", ""sha"": ""c662c25006ddc13a77347cb1fcd295ed5c152731"", ""last_modified"": ""2024-10-10 18:09:18+00:00"", ""created_at"": ""2024-10-10 14:04:05+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 27, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": null, ""gguf"": null, ""inference"": null, ""tags"": [""safetensors"", ""gemma"", ""ro"", ""dataset:OpenLLM-Ro/ro_sft_alpaca"", ""dataset:OpenLLM-Ro/ro_sft_alpaca_gpt4"", ""dataset:OpenLLM-Ro/ro_sft_dolly"", ""dataset:OpenLLM-Ro/ro_sft_selfinstruct_gpt4"", ""dataset:OpenLLM-Ro/ro_sft_norobots"", ""dataset:OpenLLM-Ro/ro_sft_orca"", ""dataset:OpenLLM-Ro/ro_sft_camel"", ""dataset:OpenLLM-Ro/ro_sft_oasst"", ""dataset:OpenLLM-Ro/ro_sft_ultrachat"", ""arxiv:2406.18266"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""license:cc-by-nc-4.0"", ""model-index"", ""region:us""], ""pipeline_tag"": null, ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model:\n- google/gemma-7b\ndatasets:\n- OpenLLM-Ro/ro_sft_alpaca\n- OpenLLM-Ro/ro_sft_alpaca_gpt4\n- OpenLLM-Ro/ro_sft_dolly\n- OpenLLM-Ro/ro_sft_selfinstruct_gpt4\n- OpenLLM-Ro/ro_sft_norobots\n- OpenLLM-Ro/ro_sft_orca\n- OpenLLM-Ro/ro_sft_camel\n- OpenLLM-Ro/ro_sft_oasst\n- OpenLLM-Ro/ro_sft_ultrachat\nlanguage:\n- ro\nlicense: cc-by-nc-4.0\nmodel-index:\n- name: OpenLLM-Ro/RoGemma-7b-Instruct-2024-10-09\n  results:\n  - task:\n      type: text-generation\n    dataset:\n      name: RoMT-Bench\n      type: RoMT-Bench\n    metrics:\n    - type: Score\n      value: 5.24\n      name: Score\n      verified: false\n    - type: Score\n      value: 5.55\n      name: First turn\n      verified: false\n    - type: Score\n      value: 4.94\n      name: Second turn\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: RoCulturaBench\n      type: RoCulturaBench\n    metrics:\n    - type: Score\n      value: 3.51\n      name: Score\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: Romanian_Academic_Benchmarks\n      type: Romanian_Academic_Benchmarks\n    metrics:\n    - type: accuracy\n      value: 50.48\n      name: Average accuracy\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: OpenLLM-Ro/ro_arc_challenge\n      type: OpenLLM-Ro/ro_arc_challenge\n    metrics:\n    - type: accuracy\n      value: 52.01\n      name: Average accuracy\n      verified: false\n    - type: accuracy\n      value: 49.53\n      name: 0-shot\n      verified: false\n    - type: accuracy\n      value: 52.53\n      name: 1-shot\n      verified: false\n    - type: accuracy\n      value: 51.5\n      name: 3-shot\n      verified: false\n    - type: accuracy\n      value: 53.56\n      name: 5-shot\n      verified: false\n    - type: accuracy\n      value: 52.53\n      name: 10-shot\n      verified: false\n    - type: accuracy\n      value: 52.44\n      name: 25-shot\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: OpenLLM-Ro/ro_mmlu\n      type: OpenLLM-Ro/ro_mmlu\n    metrics:\n    - type: accuracy\n      value: 52.37\n      name: Average accuracy\n      verified: false\n    - type: accuracy\n      value: 51.81\n      name: 0-shot\n      verified: false\n    - type: accuracy\n      value: 52.45\n      name: 1-shot\n      verified: false\n    - type: accuracy\n      value: 52.52\n      name: 3-shot\n      verified: false\n    - type: accuracy\n      value: 52.7\n      name: 5-shot\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: OpenLLM-Ro/ro_winogrande\n      type: OpenLLM-Ro/ro_winogrande\n    metrics:\n    - type: accuracy\n      value: 66.97\n      name: Average accuracy\n      verified: false\n    - type: accuracy\n      value: 66.54\n      name: 0-shot\n      verified: false\n    - type: accuracy\n      value: 66.69\n      name: 1-shot\n      verified: false\n    - type: accuracy\n      value: 67.09\n      name: 3-shot\n      verified: false\n    - type: accuracy\n      value: 67.56\n      name: 5-shot\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: OpenLLM-Ro/ro_hellaswag\n      type: OpenLLM-Ro/ro_hellaswag\n    metrics:\n    - type: accuracy\n      value: 56.34\n      name: Average accuracy\n      verified: false\n    - type: accuracy\n      value: 58.8\n      name: 0-shot\n      verified: false\n    - type: accuracy\n      value: 57.04\n      name: 1-shot\n      verified: false\n    - type: accuracy\n      value: 55.85\n      name: 3-shot\n      verified: false\n    - type: accuracy\n      value: 54.15\n      name: 5-shot\n      verified: false\n    - type: accuracy\n      value: 55.88\n      name: 10-shot\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: OpenLLM-Ro/ro_gsm8k\n      type: OpenLLM-Ro/ro_gsm8k\n    metrics:\n    - type: accuracy\n      value: 25.98\n      name: Average accuracy\n      verified: false\n    - type: accuracy\n      value: 22.06\n      name: 1-shot\n      verified: false\n    - type: accuracy\n      value: 25.4\n      name: 3-shot\n      verified: false\n    - type: accuracy\n      value: 30.48\n      name: 5-shot\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: OpenLLM-Ro/ro_truthfulqa\n      type: OpenLLM-Ro/ro_truthfulqa\n    metrics:\n    - type: accuracy\n      value: 49.18\n      name: Average accuracy\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: LaRoSeDa_binary\n      type: LaRoSeDa_binary\n    metrics:\n    - type: macro-f1\n      value: 86.96\n      name: Average macro-f1\n      verified: false\n    - type: macro-f1\n      value: 87.28\n      name: 0-shot\n      verified: false\n    - type: macro-f1\n      value: 86.4\n      name: 1-shot\n      verified: false\n    - type: macro-f1\n      value: 87.95\n      name: 3-shot\n      verified: false\n    - type: macro-f1\n      value: 86.2\n      name: 5-shot\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: LaRoSeDa_multiclass\n      type: LaRoSeDa_multiclass\n    metrics:\n    - type: macro-f1\n      value: 56.72\n      name: Average macro-f1\n      verified: false\n    - type: macro-f1\n      value: 38.35\n      name: 0-shot\n      verified: false\n    - type: macro-f1\n      value: 63.86\n      name: 1-shot\n      verified: false\n    - type: macro-f1\n      value: 62.03\n      name: 3-shot\n      verified: false\n    - type: macro-f1\n      value: 62.62\n      name: 5-shot\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: LaRoSeDa_binary_finetuned\n      type: LaRoSeDa_binary_finetuned\n    metrics:\n    - type: macro-f1\n      value: 98.8\n      name: Average macro-f1\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: LaRoSeDa_multiclass_finetuned\n      type: LaRoSeDa_multiclass_finetuned\n    metrics:\n    - type: macro-f1\n      value: 85.81\n      name: Average macro-f1\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: WMT_EN-RO\n      type: WMT_EN-RO\n    metrics:\n    - type: bleu\n      value: 24.45\n      name: Average bleu\n      verified: false\n    - type: bleu\n      value: 11.39\n      name: 0-shot\n      verified: false\n    - type: bleu\n      value: 28.08\n      name: 1-shot\n      verified: false\n    - type: bleu\n      value: 29.18\n      name: 3-shot\n      verified: false\n    - type: bleu\n      value: 29.13\n      name: 5-shot\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: WMT_RO-EN\n      type: WMT_RO-EN\n    metrics:\n    - type: bleu\n      value: 14.2\n      name: Average bleu\n      verified: false\n    - type: bleu\n      value: 1.92\n      name: 0-shot\n      verified: false\n    - type: bleu\n      value: 9.39\n      name: 1-shot\n      verified: false\n    - type: bleu\n      value: 21.81\n      name: 3-shot\n      verified: false\n    - type: bleu\n      value: 23.66\n      name: 5-shot\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: WMT_EN-RO_finetuned\n      type: WMT_EN-RO_finetuned\n    metrics:\n    - type: bleu\n      value: 25.96\n      name: Average bleu\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: WMT_RO-EN_finetuned\n      type: WMT_RO-EN_finetuned\n    metrics:\n    - type: bleu\n      value: 39.07\n      name: Average bleu\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: XQuAD\n      type: XQuAD\n    metrics:\n    - type: exact_match\n      value: 26.03\n      name: Average exact_match\n      verified: false\n    - type: f1\n      value: 41.58\n      name: Average f1\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: XQuAD_finetuned\n      type: XQuAD_finetuned\n    metrics:\n    - type: exact_match\n      value: 46.72\n      name: Average exact_match\n      verified: false\n    - type: f1\n      value: 60.79\n      name: Average f1\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: STS\n      type: STS\n    metrics:\n    - type: spearman\n      value: 73.23\n      name: Average spearman\n      verified: false\n    - type: pearson\n      value: 71.58\n      name: Average pearson\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: STS_finetuned\n      type: STS_finetuned\n    metrics:\n    - type: spearman\n      value: 88.42\n      name: Average spearman\n      verified: false\n    - type: pearson\n      value: 88.45\n      name: Average pearson\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: XQuAD_EM\n      type: XQuAD_EM\n    metrics:\n    - type: exact_match\n      value: 32.77\n      name: 0-shot\n      verified: false\n    - type: exact_match\n      value: 20.25\n      name: 1-shot\n      verified: false\n    - type: exact_match\n      value: 18.49\n      name: 3-shot\n      verified: false\n    - type: exact_match\n      value: 32.6\n      name: 5-shot\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: XQuAD_F1\n      type: XQuAD_F1\n    metrics:\n    - type: f1\n      value: 47.98\n      name: 0-shot\n      verified: false\n    - type: f1\n      value: 34.92\n      name: 1-shot\n      verified: false\n    - type: f1\n      value: 33.27\n      name: 3-shot\n      verified: false\n    - type: f1\n      value: 50.14\n      name: 5-shot\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: STS_Spearman\n      type: STS_Spearman\n    metrics:\n    - type: spearman\n      value: 71.75\n      name: 1-shot\n      verified: false\n    - type: spearman\n      value: 71.83\n      name: 3-shot\n      verified: false\n    - type: spearman\n      value: 76.11\n      name: 5-shot\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: STS_Pearson\n      type: STS_Pearson\n    metrics:\n    - type: pearson\n      value: 69.97\n      name: 1-shot\n      verified: false\n    - type: pearson\n      value: 69.87\n      name: 3-shot\n      verified: false\n    - type: pearson\n      value: 74.89\n      name: 5-shot\n      verified: false"", ""widget_data"": null, ""model_index"": [{""name"": ""OpenLLM-Ro/RoGemma-7b-Instruct-2024-10-09"", ""results"": [{""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""RoMT-Bench"", ""type"": ""RoMT-Bench""}, ""metrics"": [{""name"": ""Score"", ""type"": ""Score"", ""value"": 5.24, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""RoCulturaBench"", ""type"": ""RoCulturaBench""}, ""metrics"": [{""name"": ""Score"", ""type"": ""Score"", ""value"": 3.51, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""Romanian_Academic_Benchmarks"", ""type"": ""Romanian_Academic_Benchmarks""}, ""metrics"": [{""name"": ""Average accuracy"", ""type"": ""accuracy"", ""value"": 50.48, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""OpenLLM-Ro/ro_arc_challenge"", ""type"": ""OpenLLM-Ro/ro_arc_challenge""}, ""metrics"": [{""name"": ""Average accuracy"", ""type"": ""accuracy"", ""value"": 52.01, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""OpenLLM-Ro/ro_mmlu"", ""type"": ""OpenLLM-Ro/ro_mmlu""}, ""metrics"": [{""name"": ""Average accuracy"", ""type"": ""accuracy"", ""value"": 52.37, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""OpenLLM-Ro/ro_winogrande"", ""type"": ""OpenLLM-Ro/ro_winogrande""}, ""metrics"": [{""name"": ""Average accuracy"", ""type"": ""accuracy"", ""value"": 66.97, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""OpenLLM-Ro/ro_hellaswag"", ""type"": ""OpenLLM-Ro/ro_hellaswag""}, ""metrics"": [{""name"": ""Average accuracy"", ""type"": ""accuracy"", ""value"": 56.34, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""OpenLLM-Ro/ro_gsm8k"", ""type"": ""OpenLLM-Ro/ro_gsm8k""}, ""metrics"": [{""name"": ""Average accuracy"", ""type"": ""accuracy"", ""value"": 25.98, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""OpenLLM-Ro/ro_truthfulqa"", ""type"": ""OpenLLM-Ro/ro_truthfulqa""}, ""metrics"": [{""name"": ""Average accuracy"", ""type"": ""accuracy"", ""value"": 49.18, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""LaRoSeDa_binary"", ""type"": ""LaRoSeDa_binary""}, ""metrics"": [{""name"": ""Average macro-f1"", ""type"": ""macro-f1"", ""value"": 86.96, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""LaRoSeDa_multiclass"", ""type"": ""LaRoSeDa_multiclass""}, ""metrics"": [{""name"": ""Average macro-f1"", ""type"": ""macro-f1"", ""value"": 56.72, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""LaRoSeDa_binary_finetuned"", ""type"": ""LaRoSeDa_binary_finetuned""}, ""metrics"": [{""name"": ""Average macro-f1"", ""type"": ""macro-f1"", ""value"": 98.8, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""LaRoSeDa_multiclass_finetuned"", ""type"": ""LaRoSeDa_multiclass_finetuned""}, ""metrics"": [{""name"": ""Average macro-f1"", ""type"": ""macro-f1"", ""value"": 85.81, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""WMT_EN-RO"", ""type"": ""WMT_EN-RO""}, ""metrics"": [{""name"": ""Average bleu"", ""type"": ""bleu"", ""value"": 24.45, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""WMT_RO-EN"", ""type"": ""WMT_RO-EN""}, ""metrics"": [{""name"": ""Average bleu"", ""type"": ""bleu"", ""value"": 14.2, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""WMT_EN-RO_finetuned"", ""type"": ""WMT_EN-RO_finetuned""}, ""metrics"": [{""name"": ""Average bleu"", ""type"": ""bleu"", ""value"": 25.96, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""WMT_RO-EN_finetuned"", ""type"": ""WMT_RO-EN_finetuned""}, ""metrics"": [{""name"": ""Average bleu"", ""type"": ""bleu"", ""value"": 39.07, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""XQuAD"", ""type"": ""XQuAD""}, ""metrics"": [{""name"": ""Average exact_match"", ""type"": ""exact_match"", ""value"": 26.03, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""XQuAD"", ""type"": ""XQuAD""}, ""metrics"": [{""name"": ""Average f1"", ""type"": ""f1"", ""value"": 41.58, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""XQuAD_finetuned"", ""type"": ""XQuAD_finetuned""}, ""metrics"": [{""name"": ""Average exact_match"", ""type"": ""exact_match"", ""value"": 46.72, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""XQuAD_finetuned"", ""type"": ""XQuAD_finetuned""}, ""metrics"": [{""name"": ""Average f1"", ""type"": ""f1"", ""value"": 60.79, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""STS"", ""type"": ""STS""}, ""metrics"": [{""name"": ""Average spearman"", ""type"": ""spearman"", ""value"": 73.23, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""STS"", ""type"": ""STS""}, ""metrics"": [{""name"": ""Average pearson"", ""type"": ""pearson"", ""value"": 71.58, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""STS_finetuned"", ""type"": ""STS_finetuned""}, ""metrics"": [{""name"": ""Average spearman"", ""type"": ""spearman"", ""value"": 88.42, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""STS_finetuned"", ""type"": ""STS_finetuned""}, ""metrics"": [{""name"": ""Average pearson"", ""type"": ""pearson"", ""value"": 88.45, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""RoMT-Bench"", ""type"": ""RoMT-Bench""}, ""metrics"": [{""name"": ""First turn"", ""type"": ""Score"", ""value"": 5.55, ""verified"": false}, {""name"": ""Second turn"", ""type"": ""Score"", ""value"": 4.94, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""OpenLLM-Ro/ro_arc_challenge"", ""type"": ""OpenLLM-Ro/ro_arc_challenge""}, ""metrics"": [{""name"": ""0-shot"", ""type"": ""accuracy"", ""value"": 49.53, ""verified"": false}, {""name"": ""1-shot"", ""type"": ""accuracy"", ""value"": 52.53, ""verified"": false}, {""name"": ""3-shot"", ""type"": ""accuracy"", ""value"": 51.5, ""verified"": false}, {""name"": ""5-shot"", ""type"": ""accuracy"", ""value"": 53.56, ""verified"": false}, {""name"": ""10-shot"", ""type"": ""accuracy"", ""value"": 52.53, ""verified"": false}, {""name"": ""25-shot"", ""type"": ""accuracy"", ""value"": 52.44, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""OpenLLM-Ro/ro_mmlu"", ""type"": ""OpenLLM-Ro/ro_mmlu""}, ""metrics"": [{""name"": ""0-shot"", ""type"": ""accuracy"", ""value"": 51.81, ""verified"": false}, {""name"": ""1-shot"", ""type"": ""accuracy"", ""value"": 52.45, ""verified"": false}, {""name"": ""3-shot"", ""type"": ""accuracy"", ""value"": 52.52, ""verified"": false}, {""name"": ""5-shot"", ""type"": ""accuracy"", ""value"": 52.7, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""OpenLLM-Ro/ro_winogrande"", ""type"": ""OpenLLM-Ro/ro_winogrande""}, ""metrics"": [{""name"": ""0-shot"", ""type"": ""accuracy"", ""value"": 66.54, ""verified"": false}, {""name"": ""1-shot"", ""type"": ""accuracy"", ""value"": 66.69, ""verified"": false}, {""name"": ""3-shot"", ""type"": ""accuracy"", ""value"": 67.09, ""verified"": false}, {""name"": ""5-shot"", ""type"": ""accuracy"", ""value"": 67.56, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""OpenLLM-Ro/ro_hellaswag"", ""type"": ""OpenLLM-Ro/ro_hellaswag""}, ""metrics"": [{""name"": ""0-shot"", ""type"": ""accuracy"", ""value"": 58.8, ""verified"": false}, {""name"": ""1-shot"", ""type"": ""accuracy"", ""value"": 57.04, ""verified"": false}, {""name"": ""3-shot"", ""type"": ""accuracy"", ""value"": 55.85, ""verified"": false}, {""name"": ""5-shot"", ""type"": ""accuracy"", ""value"": 54.15, ""verified"": false}, {""name"": ""10-shot"", ""type"": ""accuracy"", ""value"": 55.88, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""OpenLLM-Ro/ro_gsm8k"", ""type"": ""OpenLLM-Ro/ro_gsm8k""}, ""metrics"": [{""name"": ""1-shot"", ""type"": ""accuracy"", ""value"": 22.06, ""verified"": false}, {""name"": ""3-shot"", ""type"": ""accuracy"", ""value"": 25.4, ""verified"": false}, {""name"": ""5-shot"", ""type"": ""accuracy"", ""value"": 30.48, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""LaRoSeDa_binary"", ""type"": ""LaRoSeDa_binary""}, ""metrics"": [{""name"": ""0-shot"", ""type"": ""macro-f1"", ""value"": 87.28, ""verified"": false}, {""name"": ""1-shot"", ""type"": ""macro-f1"", ""value"": 86.4, ""verified"": false}, {""name"": ""3-shot"", ""type"": ""macro-f1"", ""value"": 87.95, ""verified"": false}, {""name"": ""5-shot"", ""type"": ""macro-f1"", ""value"": 86.2, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""LaRoSeDa_multiclass"", ""type"": ""LaRoSeDa_multiclass""}, ""metrics"": [{""name"": ""0-shot"", ""type"": ""macro-f1"", ""value"": 38.35, ""verified"": false}, {""name"": ""1-shot"", ""type"": ""macro-f1"", ""value"": 63.86, ""verified"": false}, {""name"": ""3-shot"", ""type"": ""macro-f1"", ""value"": 62.03, ""verified"": false}, {""name"": ""5-shot"", ""type"": ""macro-f1"", ""value"": 62.62, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""WMT_EN-RO"", ""type"": ""WMT_EN-RO""}, ""metrics"": [{""name"": ""0-shot"", ""type"": ""bleu"", ""value"": 11.39, ""verified"": false}, {""name"": ""1-shot"", ""type"": ""bleu"", ""value"": 28.08, ""verified"": false}, {""name"": ""3-shot"", ""type"": ""bleu"", ""value"": 29.18, ""verified"": false}, {""name"": ""5-shot"", ""type"": ""bleu"", ""value"": 29.13, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""WMT_RO-EN"", ""type"": ""WMT_RO-EN""}, ""metrics"": [{""name"": ""0-shot"", ""type"": ""bleu"", ""value"": 1.92, ""verified"": false}, {""name"": ""1-shot"", ""type"": ""bleu"", ""value"": 9.39, ""verified"": false}, {""name"": ""3-shot"", ""type"": ""bleu"", ""value"": 21.81, ""verified"": false}, {""name"": ""5-shot"", ""type"": ""bleu"", ""value"": 23.66, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""XQuAD_EM"", ""type"": ""XQuAD_EM""}, ""metrics"": [{""name"": ""0-shot"", ""type"": ""exact_match"", ""value"": 32.77, ""verified"": false}, {""name"": ""1-shot"", ""type"": ""exact_match"", ""value"": 20.25, ""verified"": false}, {""name"": ""3-shot"", ""type"": ""exact_match"", ""value"": 18.49, ""verified"": false}, {""name"": ""5-shot"", ""type"": ""exact_match"", ""value"": 32.6, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""XQuAD_F1"", ""type"": ""XQuAD_F1""}, ""metrics"": [{""name"": ""0-shot"", ""type"": ""f1"", ""value"": 47.98, ""verified"": false}, {""name"": ""1-shot"", ""type"": ""f1"", ""value"": 34.92, ""verified"": false}, {""name"": ""3-shot"", ""type"": ""f1"", ""value"": 33.27, ""verified"": false}, {""name"": ""5-shot"", ""type"": ""f1"", ""value"": 50.14, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""STS_Spearman"", ""type"": ""STS_Spearman""}, ""metrics"": [{""name"": ""1-shot"", ""type"": ""spearman"", ""value"": 71.75, ""verified"": false}, {""name"": ""3-shot"", ""type"": ""spearman"", ""value"": 71.83, ""verified"": false}, {""name"": ""5-shot"", ""type"": ""spearman"", ""value"": 76.11, ""verified"": false}]}, {""task"": {""type"": ""text-generation""}, ""dataset"": {""name"": ""STS_Pearson"", ""type"": ""STS_Pearson""}, ""metrics"": [{""name"": ""1-shot"", ""type"": ""pearson"", ""value"": 69.97, ""verified"": false}, {""name"": ""3-shot"", ""type"": ""pearson"", ""value"": 69.87, ""verified"": false}, {""name"": ""5-shot"", ""type"": ""pearson"", ""value"": 74.89, ""verified"": false}]}]}], ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ '<bos>' }}{% if messages[0]['role'] == 'system' %}{% set system_message = messages[0]['content'] %}{% endif %}{% if system_message is defined %}{{ system_message }}{% endif %}{% for message in messages %}{% set content = message['content'] %}{% if message['role'] == 'user' %}{{ '<start_of_turn>user\n' + content + '<end_of_turn>\n<start_of_turn>model\n' }}{% elif message['role'] == 'assistant' %}{{ content + '<end_of_turn>\n' }}{% endif %}{% endfor %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": null, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='generation_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00001-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00002-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00003-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00004-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model.safetensors.index.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": {""parameters"": {""BF16"": 8537680896}, ""total"": 8537680896}, ""security_repo_status"": null, ""lastModified"": ""2024-10-10 18:09:18+00:00"", ""cardData"": ""base_model:\n- google/gemma-7b\ndatasets:\n- OpenLLM-Ro/ro_sft_alpaca\n- OpenLLM-Ro/ro_sft_alpaca_gpt4\n- OpenLLM-Ro/ro_sft_dolly\n- OpenLLM-Ro/ro_sft_selfinstruct_gpt4\n- OpenLLM-Ro/ro_sft_norobots\n- OpenLLM-Ro/ro_sft_orca\n- OpenLLM-Ro/ro_sft_camel\n- OpenLLM-Ro/ro_sft_oasst\n- OpenLLM-Ro/ro_sft_ultrachat\nlanguage:\n- ro\nlicense: cc-by-nc-4.0\nmodel-index:\n- name: OpenLLM-Ro/RoGemma-7b-Instruct-2024-10-09\n  results:\n  - task:\n      type: text-generation\n    dataset:\n      name: RoMT-Bench\n      type: RoMT-Bench\n    metrics:\n    - type: Score\n      value: 5.24\n      name: Score\n      verified: false\n    - type: Score\n      value: 5.55\n      name: First turn\n      verified: false\n    - type: Score\n      value: 4.94\n      name: Second turn\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: RoCulturaBench\n      type: RoCulturaBench\n    metrics:\n    - type: Score\n      value: 3.51\n      name: Score\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: Romanian_Academic_Benchmarks\n      type: Romanian_Academic_Benchmarks\n    metrics:\n    - type: accuracy\n      value: 50.48\n      name: Average accuracy\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: OpenLLM-Ro/ro_arc_challenge\n      type: OpenLLM-Ro/ro_arc_challenge\n    metrics:\n    - type: accuracy\n      value: 52.01\n      name: Average accuracy\n      verified: false\n    - type: accuracy\n      value: 49.53\n      name: 0-shot\n      verified: false\n    - type: accuracy\n      value: 52.53\n      name: 1-shot\n      verified: false\n    - type: accuracy\n      value: 51.5\n      name: 3-shot\n      verified: false\n    - type: accuracy\n      value: 53.56\n      name: 5-shot\n      verified: false\n    - type: accuracy\n      value: 52.53\n      name: 10-shot\n      verified: false\n    - type: accuracy\n      value: 52.44\n      name: 25-shot\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: OpenLLM-Ro/ro_mmlu\n      type: OpenLLM-Ro/ro_mmlu\n    metrics:\n    - type: accuracy\n      value: 52.37\n      name: Average accuracy\n      verified: false\n    - type: accuracy\n      value: 51.81\n      name: 0-shot\n      verified: false\n    - type: accuracy\n      value: 52.45\n      name: 1-shot\n      verified: false\n    - type: accuracy\n      value: 52.52\n      name: 3-shot\n      verified: false\n    - type: accuracy\n      value: 52.7\n      name: 5-shot\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: OpenLLM-Ro/ro_winogrande\n      type: OpenLLM-Ro/ro_winogrande\n    metrics:\n    - type: accuracy\n      value: 66.97\n      name: Average accuracy\n      verified: false\n    - type: accuracy\n      value: 66.54\n      name: 0-shot\n      verified: false\n    - type: accuracy\n      value: 66.69\n      name: 1-shot\n      verified: false\n    - type: accuracy\n      value: 67.09\n      name: 3-shot\n      verified: false\n    - type: accuracy\n      value: 67.56\n      name: 5-shot\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: OpenLLM-Ro/ro_hellaswag\n      type: OpenLLM-Ro/ro_hellaswag\n    metrics:\n    - type: accuracy\n      value: 56.34\n      name: Average accuracy\n      verified: false\n    - type: accuracy\n      value: 58.8\n      name: 0-shot\n      verified: false\n    - type: accuracy\n      value: 57.04\n      name: 1-shot\n      verified: false\n    - type: accuracy\n      value: 55.85\n      name: 3-shot\n      verified: false\n    - type: accuracy\n      value: 54.15\n      name: 5-shot\n      verified: false\n    - type: accuracy\n      value: 55.88\n      name: 10-shot\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: OpenLLM-Ro/ro_gsm8k\n      type: OpenLLM-Ro/ro_gsm8k\n    metrics:\n    - type: accuracy\n      value: 25.98\n      name: Average accuracy\n      verified: false\n    - type: accuracy\n      value: 22.06\n      name: 1-shot\n      verified: false\n    - type: accuracy\n      value: 25.4\n      name: 3-shot\n      verified: false\n    - type: accuracy\n      value: 30.48\n      name: 5-shot\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: OpenLLM-Ro/ro_truthfulqa\n      type: OpenLLM-Ro/ro_truthfulqa\n    metrics:\n    - type: accuracy\n      value: 49.18\n      name: Average accuracy\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: LaRoSeDa_binary\n      type: LaRoSeDa_binary\n    metrics:\n    - type: macro-f1\n      value: 86.96\n      name: Average macro-f1\n      verified: false\n    - type: macro-f1\n      value: 87.28\n      name: 0-shot\n      verified: false\n    - type: macro-f1\n      value: 86.4\n      name: 1-shot\n      verified: false\n    - type: macro-f1\n      value: 87.95\n      name: 3-shot\n      verified: false\n    - type: macro-f1\n      value: 86.2\n      name: 5-shot\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: LaRoSeDa_multiclass\n      type: LaRoSeDa_multiclass\n    metrics:\n    - type: macro-f1\n      value: 56.72\n      name: Average macro-f1\n      verified: false\n    - type: macro-f1\n      value: 38.35\n      name: 0-shot\n      verified: false\n    - type: macro-f1\n      value: 63.86\n      name: 1-shot\n      verified: false\n    - type: macro-f1\n      value: 62.03\n      name: 3-shot\n      verified: false\n    - type: macro-f1\n      value: 62.62\n      name: 5-shot\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: LaRoSeDa_binary_finetuned\n      type: LaRoSeDa_binary_finetuned\n    metrics:\n    - type: macro-f1\n      value: 98.8\n      name: Average macro-f1\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: LaRoSeDa_multiclass_finetuned\n      type: LaRoSeDa_multiclass_finetuned\n    metrics:\n    - type: macro-f1\n      value: 85.81\n      name: Average macro-f1\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: WMT_EN-RO\n      type: WMT_EN-RO\n    metrics:\n    - type: bleu\n      value: 24.45\n      name: Average bleu\n      verified: false\n    - type: bleu\n      value: 11.39\n      name: 0-shot\n      verified: false\n    - type: bleu\n      value: 28.08\n      name: 1-shot\n      verified: false\n    - type: bleu\n      value: 29.18\n      name: 3-shot\n      verified: false\n    - type: bleu\n      value: 29.13\n      name: 5-shot\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: WMT_RO-EN\n      type: WMT_RO-EN\n    metrics:\n    - type: bleu\n      value: 14.2\n      name: Average bleu\n      verified: false\n    - type: bleu\n      value: 1.92\n      name: 0-shot\n      verified: false\n    - type: bleu\n      value: 9.39\n      name: 1-shot\n      verified: false\n    - type: bleu\n      value: 21.81\n      name: 3-shot\n      verified: false\n    - type: bleu\n      value: 23.66\n      name: 5-shot\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: WMT_EN-RO_finetuned\n      type: WMT_EN-RO_finetuned\n    metrics:\n    - type: bleu\n      value: 25.96\n      name: Average bleu\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: WMT_RO-EN_finetuned\n      type: WMT_RO-EN_finetuned\n    metrics:\n    - type: bleu\n      value: 39.07\n      name: Average bleu\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: XQuAD\n      type: XQuAD\n    metrics:\n    - type: exact_match\n      value: 26.03\n      name: Average exact_match\n      verified: false\n    - type: f1\n      value: 41.58\n      name: Average f1\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: XQuAD_finetuned\n      type: XQuAD_finetuned\n    metrics:\n    - type: exact_match\n      value: 46.72\n      name: Average exact_match\n      verified: false\n    - type: f1\n      value: 60.79\n      name: Average f1\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: STS\n      type: STS\n    metrics:\n    - type: spearman\n      value: 73.23\n      name: Average spearman\n      verified: false\n    - type: pearson\n      value: 71.58\n      name: Average pearson\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: STS_finetuned\n      type: STS_finetuned\n    metrics:\n    - type: spearman\n      value: 88.42\n      name: Average spearman\n      verified: false\n    - type: pearson\n      value: 88.45\n      name: Average pearson\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: XQuAD_EM\n      type: XQuAD_EM\n    metrics:\n    - type: exact_match\n      value: 32.77\n      name: 0-shot\n      verified: false\n    - type: exact_match\n      value: 20.25\n      name: 1-shot\n      verified: false\n    - type: exact_match\n      value: 18.49\n      name: 3-shot\n      verified: false\n    - type: exact_match\n      value: 32.6\n      name: 5-shot\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: XQuAD_F1\n      type: XQuAD_F1\n    metrics:\n    - type: f1\n      value: 47.98\n      name: 0-shot\n      verified: false\n    - type: f1\n      value: 34.92\n      name: 1-shot\n      verified: false\n    - type: f1\n      value: 33.27\n      name: 3-shot\n      verified: false\n    - type: f1\n      value: 50.14\n      name: 5-shot\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: STS_Spearman\n      type: STS_Spearman\n    metrics:\n    - type: spearman\n      value: 71.75\n      name: 1-shot\n      verified: false\n    - type: spearman\n      value: 71.83\n      name: 3-shot\n      verified: false\n    - type: spearman\n      value: 76.11\n      name: 5-shot\n      verified: false\n  - task:\n      type: text-generation\n    dataset:\n      name: STS_Pearson\n      type: STS_Pearson\n    metrics:\n    - type: pearson\n      value: 69.97\n      name: 1-shot\n      verified: false\n    - type: pearson\n      value: 69.87\n      name: 3-shot\n      verified: false\n    - type: pearson\n      value: 74.89\n      name: 5-shot\n      verified: false"", ""transformersInfo"": null, ""_id"": ""6707ded5d54e96ce20c7a8d2"", ""modelId"": ""OpenLLM-Ro/RoGemma-7b-Instruct"", ""usedStorage"": 17097150888}",1,,0,"https://huggingface.co/legraphista/RoGemma-7b-Instruct-IMat-GGUF, https://huggingface.co/mradermacher/RoGemma-7b-Instruct-GGUF",2,,0,huggingface/InferenceSupport/discussions/new?title=OpenLLM-Ro/RoGemma-7b-Instruct&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5BOpenLLM-Ro%2FRoGemma-7b-Instruct%5D(%2FOpenLLM-Ro%2FRoGemma-7b-Instruct)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
jcantu217/gemma-2-7b-invasive-plant-chatbot,"---
license: apache-2.0
language:
- en
base_model:
- google/gemma-7b
datasets:
- jcantu217/QA-Invasive-Plants-USA
---

### Description
This model provides detailed information about invasive plant species in the U.S. through a chatbot interface. Fine-tuned with LoRA on the powerful Gemma-7B language model, it was trained on a curated dataset covering questions on plant species' invasive status, ecological impacts, growth habits, and appearances at different developmental stages.

With Gemma-7B’s 7 billion parameters, the model delivers accurate, context-aware responses, offering valuable insights into invasive species and their ecological threats. It serves as a useful tool for conservationists, land managers, and nature enthusiasts seeking to better understand and manage invasive plants.

__Key Features:__
- Invasive Status Identification:
The model distinguishes between plant species that are ""native"" or ""exotic"" (invasive) to the United States. Users can easily inquire about the invasive nature of a plant with questions like, “Is [plant name] native to the U.S.?” and receive quick, accurate feedback on the plant's origin and potential invasiveness.

- Ecological Threat Assessment:
The model provides critical information about the environmental and ecological impacts of invasive species. It answers questions such as, “What ecological threats does [plant name] pose?”, offering details on how certain species disrupt ecosystems, compete with native plants, and threaten biodiversity. This feature helps users understand the broader ecological consequences of invasive species in local environments.

- Growth Habit Descriptions:
Users can learn about the growth patterns of various plants, including whether they grow as vines, shrubs, trees, or other forms. For example, you can ask, “What is the growth habit of [plant name]?” and the model will provide an informative response detailing the plant's structural characteristics and common growth environments.

- Visual Characteristics Across Developmental Stages:
The model is equipped to describe the appearance of plants at different stages of their life cycle, including seedling, juvenile, and mature forms. Users can ask questions like, “What does [plant name] look like in its seedling stage?”, and the model will provide visual and descriptive information to assist with identification throughout the plant's development. This feature is particularly helpful for those working in conservation or fieldwork, where identifying plants in various stages is crucial.","{""id"": ""jcantu217/gemma-2-7b-invasive-plant-chatbot"", ""author"": ""jcantu217"", ""sha"": ""0855ab2d40617aa86d9970725cba1862ac432ecf"", ""last_modified"": ""2024-10-24 19:55:01+00:00"", ""created_at"": ""2024-10-24 19:27:53+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 2, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": null, ""gguf"": null, ""inference"": null, ""tags"": [""pytorch"", ""gemma"", ""en"", ""dataset:jcantu217/QA-Invasive-Plants-USA"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""license:apache-2.0"", ""region:us""], ""pipeline_tag"": null, ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model:\n- google/gemma-7b\ndatasets:\n- jcantu217/QA-Invasive-Plants-USA\nlanguage:\n- en\nlicense: apache-2.0"", ""widget_data"": null, ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": null, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='eval_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='generation_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='pytorch_model-00001-of-00004.bin', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='pytorch_model-00002-of-00004.bin', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='pytorch_model-00003-of-00004.bin', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='pytorch_model-00004-of-00004.bin', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='pytorch_model.bin.index.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='requirements.txt', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2024-10-24 19:55:01+00:00"", ""cardData"": ""base_model:\n- google/gemma-7b\ndatasets:\n- jcantu217/QA-Invasive-Plants-USA\nlanguage:\n- en\nlicense: apache-2.0"", ""transformersInfo"": null, ""_id"": ""671a9fb93415196089c36c3b"", ""modelId"": ""jcantu217/gemma-2-7b-invasive-plant-chatbot"", ""usedStorage"": 17092968333}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=jcantu217/gemma-2-7b-invasive-plant-chatbot&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bjcantu217%2Fgemma-2-7b-invasive-plant-chatbot%5D(%2Fjcantu217%2Fgemma-2-7b-invasive-plant-chatbot)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
OpenVINO/gemma-7b-fp16-ov,"---
license: gemma
license_link: https://choosealicense.com/licenses/gemma/
base_model:
- google/gemma-7b
---
# gemma-7b-fp16-ov
* Model creator: [Google](https://huggingface.co/google)
 * Original model: [gemma-7b](https://huggingface.co/google/gemma-7b)

## Description

## Compatibility

The provided OpenVINO™ IR model is compatible with:

* OpenVINO version 2024.4.0 and higher
* Optimum Intel 1.20.0 and higher

## Running Model Inference with [Optimum Intel](https://huggingface.co/docs/optimum/intel/index)

1. Install packages required for using [Optimum Intel](https://huggingface.co/docs/optimum/intel/index) integration with the OpenVINO backend:

```
pip install optimum[openvino]
```

2. Run model inference:

```
from transformers import AutoTokenizer
from optimum.intel.openvino import OVModelForCausalLM

model_id = ""OpenVINO/gemma-7b-fp16-ov""
tokenizer = AutoTokenizer.from_pretrained(model_id)
model = OVModelForCausalLM.from_pretrained(model_id)

inputs = tokenizer(""What is OpenVINO?"", return_tensors=""pt"")

outputs = model.generate(**inputs, max_length=200)
text = tokenizer.batch_decode(outputs)[0]
print(text)
```

For more examples and possible optimizations, refer to the [OpenVINO Large Language Model Inference Guide](https://docs.openvino.ai/2024/learn-openvino/llm_inference_guide.html).

## Running Model Inference with [OpenVINO GenAI](https://github.com/openvinotoolkit/openvino.genai)

1. Install packages required for using OpenVINO GenAI.
```
pip install openvino-genai huggingface_hub
```

2. Download model from HuggingFace Hub
   
```
import huggingface_hub as hf_hub

model_id = ""OpenVINO/gemma-7b-fp16-ov""
model_path = ""gemma-7b-fp16-ov""

hf_hub.snapshot_download(model_id, local_dir=model_path)

```

3. Run model inference:

```
import openvino_genai as ov_genai

device = ""CPU""
pipe = ov_genai.LLMPipeline(model_path, device)
print(pipe.generate(""What is OpenVINO?"", max_length=200))
```

More GenAI usage examples can be found in OpenVINO GenAI library [docs](https://github.com/openvinotoolkit/openvino.genai/blob/master/src/README.md) and [samples](https://github.com/openvinotoolkit/openvino.genai?tab=readme-ov-file#openvino-genai-samples)

## Limitations

Check the original model card for [original model card](https://huggingface.co/google/gemma-7b) for limitations.

## Legal information

The original model is distributed under [gemma](https://choosealicense.com/licenses/gemma/) license. More details can be found in [original model card](https://huggingface.co/google/gemma-7b).

## Disclaimer

Intel is committed to respecting human rights and avoiding causing or contributing to adverse impacts on human rights. See [Intel’s Global Human Rights Principles](https://www.intel.com/content/dam/www/central-libraries/us/en/documents/policy-human-rights.pdf). Intel’s products and software are intended only to be used in applications that do not cause or contribute to adverse impacts on human rights.","{""id"": ""OpenVINO/gemma-7b-fp16-ov"", ""author"": ""OpenVINO"", ""sha"": ""d56dcb17c38435e06decf49d1edc9a02cd937b88"", ""last_modified"": ""2024-11-05 10:42:21+00:00"", ""created_at"": ""2024-10-30 07:19:49+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 3, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": null, ""gguf"": null, ""inference"": null, ""tags"": [""openvino"", ""gemma"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""license:gemma"", ""region:us""], ""pipeline_tag"": null, ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model:\n- google/gemma-7b\nlicense: gemma\nlicense_link: https://choosealicense.com/licenses/gemma/"", ""widget_data"": null, ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": null, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='generation_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='openvino_detokenizer.bin', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='openvino_detokenizer.xml', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='openvino_model.bin', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='openvino_model.xml', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='openvino_tokenizer.bin', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='openvino_tokenizer.xml', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2024-11-05 10:42:21+00:00"", ""cardData"": ""base_model:\n- google/gemma-7b\nlicense: gemma\nlicense_link: https://choosealicense.com/licenses/gemma/"", ""transformersInfo"": null, ""_id"": ""6721de157f0f53536fa88eb4"", ""modelId"": ""OpenVINO/gemma-7b-fp16-ov"", ""usedStorage"": 17129158949}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=OpenVINO/gemma-7b-fp16-ov&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5BOpenVINO%2Fgemma-7b-fp16-ov%5D(%2FOpenVINO%2Fgemma-7b-fp16-ov)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
vermouthliu/gemma_298,"---
base_model: google/gemma-7b
library_name: transformers
---

# Model Card for Model ID

<!-- Provide a quick summary of what the model is/does. -->



## Model Details

### Model Description

<!-- Provide a longer summary of what this model is. -->



- **Developed by:** [More Information Needed]
- **Funded by [optional]:** [More Information Needed]
- **Shared by [optional]:** [More Information Needed]
- **Model type:** [More Information Needed]
- **Language(s) (NLP):** [More Information Needed]
- **License:** [More Information Needed]
- **Finetuned from model [optional]:** [More Information Needed]

### Model Sources [optional]

<!-- Provide the basic links for the model. -->

- **Repository:** [More Information Needed]
- **Paper [optional]:** [More Information Needed]
- **Demo [optional]:** [More Information Needed]

## Uses

<!-- Address questions around how the model is intended to be used, including the foreseeable users of the model and those affected by the model. -->

### Direct Use

<!-- This section is for the model use without fine-tuning or plugging into a larger ecosystem/app. -->

[More Information Needed]

### Downstream Use [optional]

<!-- This section is for the model use when fine-tuned for a task, or when plugged into a larger ecosystem/app -->

[More Information Needed]

### Out-of-Scope Use

<!-- This section addresses misuse, malicious use, and uses that the model will not work well for. -->

[More Information Needed]

## Bias, Risks, and Limitations

<!-- This section is meant to convey both technical and sociotechnical limitations. -->

[More Information Needed]

### Recommendations

<!-- This section is meant to convey recommendations with respect to the bias, risk, and technical limitations. -->

Users (both direct and downstream) should be made aware of the risks, biases and limitations of the model. More information needed for further recommendations.

## How to Get Started with the Model

Use the code below to get started with the model.

[More Information Needed]

## Training Details

### Training Data

<!-- This should link to a Dataset Card, perhaps with a short stub of information on what the training data is all about as well as documentation related to data pre-processing or additional filtering. -->

[More Information Needed]

### Training Procedure

<!-- This relates heavily to the Technical Specifications. Content here should link to that section when it is relevant to the training procedure. -->

#### Preprocessing [optional]

[More Information Needed]


#### Training Hyperparameters

- **Training regime:** [More Information Needed] <!--fp32, fp16 mixed precision, bf16 mixed precision, bf16 non-mixed precision, fp16 non-mixed precision, fp8 mixed precision -->

#### Speeds, Sizes, Times [optional]

<!-- This section provides information about throughput, start/end time, checkpoint size if relevant, etc. -->

[More Information Needed]

## Evaluation

<!-- This section describes the evaluation protocols and provides the results. -->

### Testing Data, Factors & Metrics

#### Testing Data

<!-- This should link to a Dataset Card if possible. -->

[More Information Needed]

#### Factors

<!-- These are the things the evaluation is disaggregating by, e.g., subpopulations or domains. -->

[More Information Needed]

#### Metrics

<!-- These are the evaluation metrics being used, ideally with a description of why. -->

[More Information Needed]

### Results

[More Information Needed]

#### Summary



## Model Examination [optional]

<!-- Relevant interpretability work for the model goes here -->

[More Information Needed]

## Environmental Impact

<!-- Total emissions (in grams of CO2eq) and additional considerations, such as electricity usage, go here. Edit the suggested text below accordingly -->

Carbon emissions can be estimated using the [Machine Learning Impact calculator](https://mlco2.github.io/impact#compute) presented in [Lacoste et al. (2019)](https://arxiv.org/abs/1910.09700).

- **Hardware Type:** [More Information Needed]
- **Hours used:** [More Information Needed]
- **Cloud Provider:** [More Information Needed]
- **Compute Region:** [More Information Needed]
- **Carbon Emitted:** [More Information Needed]

## Technical Specifications [optional]

### Model Architecture and Objective

[More Information Needed]

### Compute Infrastructure

[More Information Needed]

#### Hardware

[More Information Needed]

#### Software

[More Information Needed]

## Citation [optional]

<!-- If there is a paper or blog post introducing the model, the APA and Bibtex information for that should go in this section. -->

**BibTeX:**

[More Information Needed]

**APA:**

[More Information Needed]

## Glossary [optional]

<!-- If relevant, include terms and calculations in this section that can help readers understand the model or model card. -->

[More Information Needed]

## More Information [optional]

[More Information Needed]

## Model Card Authors [optional]

[More Information Needed]

## Model Card Contact

[More Information Needed]
### Framework versions

- PEFT 0.13.2","{""id"": ""vermouthliu/gemma_298"", ""author"": ""vermouthliu"", ""sha"": ""56df05feec6d507f524f80bb9b3212a0d8630d74"", ""last_modified"": ""2024-11-25 00:34:07+00:00"", ""created_at"": ""2024-11-07 00:57:44+00:00"", ""private"": false, ""gated"": ""auto"", ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""safetensors"", ""arxiv:1910.09700"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": null, ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\nlibrary_name: transformers"", ""widget_data"": null, ""model_index"": null, ""config"": {""tokenizer_config"": {""bos_token"": ""<bos>"", ""eos_token"": ""<eos>"", ""pad_token"": ""<eos>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModel"", ""custom_class"": null, ""pipeline_tag"": null, ""processor"": null}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='optimizer.pt', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='rng_state.pth', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='scheduler.pt', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2024-11-25 00:34:07+00:00"", ""cardData"": ""base_model: google/gemma-7b\nlibrary_name: transformers"", ""transformersInfo"": {""auto_model"": ""AutoModel"", ""custom_class"": null, ""pipeline_tag"": null, ""processor"": null}, ""_id"": ""672c1088fa7f9a2a47d44749"", ""modelId"": ""vermouthliu/gemma_298"", ""usedStorage"": 1222166537}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=vermouthliu/gemma_298&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bvermouthliu%2Fgemma_298%5D(%2Fvermouthliu%2Fgemma_298)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
baidu/HH-RLHF-Gemma-7B-MA-PPO-Fixed5,"---
license: mit
datasets:
- Dahoas/full-hh-rlhf
base_model:
- google/gemma-7b
---
# Model Card for MA-RLHF
<a href=""https://iclr.cc/Conferences/2024"" target=""_blank"">
      <img alt=""ICLR 2025"" src=""https://img.shields.io/badge/Proceedings-ICLR2025-red"" />
</a>
<a href=""https://github.com/ernie-research/MA-RLHF"" target=""_blank"">
      <img alt=""Github"" src=""https://img.shields.io/badge/Github-MA_RLHF-green"" />
   </a>

This repository contains the official checkpoint for [Reinforcement Learning From Human Feedback with Macro Actions (MA-RLHF)](https://arxiv.org/pdf/2410.02743). 

## Model Description

MA-RLHF is a novel framework that integrates macro actions into conventional RLHF. The macro actions are sequences of tokens or higher-level language constructs, with can be computed through different defined termination conditions, like n-gram based, perplexity-based, or parsing-based termination conditions. By introducing macro actions into RLHF, we reduce the number of decision points and shorten decision trajectories, alleviating the credit assignment problem caused by long temporal distances.


|Model|Checkpoint|Base Model|Dataset| 
|-----|----------|-|-|
|TLDR-Gemma-2B-MA-PPO-Fixed5|🤗 [HF Link](https://huggingface.co/baidu/TLDR-Gemma-2B-MA-PPO-Fixed5)|[google/gemma-2b](https://huggingface.co/google/gemma-2b)|[openai/summarize_from_feedback](https://huggingface.co/datasets/openai/summarize_from_feedback)
|TLDR-Gemma-7B-MA-PPO-Fixed5|🤗 [HF Link](https://huggingface.co/baidu/TLDR-Gemma-7B-MA-PPO-Fixed5)|[google/gemma-7b](https://huggingface.co/google/gemma-7b)|[openai/summarize_from_feedback](https://huggingface.co/datasets/openai/summarize_from_feedback)
|TLDR-Gemma-2-27B-MA-PPO-Fixed5|🤗 [HF Link](https://huggingface.co/baidu/TLDR-Gemma-2-27B-MA-PPO-Fixed5)|[google/gemma-2-27b](https://huggingface.co/google/gemma-2-27b)|[openai/summarize_from_feedback](https://huggingface.co/datasets/openai/summarize_from_feedback)
|HH-RLHF-Gemma-2B-MA-PPO-Fixed5|🤗 [HF Link](https://huggingface.co/baidu/HH-RLHF-Gemma-2B-MA-PPO-Fixed5) |[google/gemma-2b](https://huggingface.co/google/gemma-2b)|[Dahoas/full-hh-rlhf](https://huggingface.co/datasets/Dahoas/full-hh-rlhf)
|HH-RLHF-Gemma-7B-MA-PPO-Fixed5|🤗 [HF Link](https://huggingface.co/baidu/HH-RLHF-Gemma-7B-MA-PPO-Fixed5) |[google/gemma-7b](https://huggingface.co/google/gemma-7b)|[Dahoas/full-hh-rlhf](https://huggingface.co/datasets/Dahoas/full-hh-rlhf)
|APPS-Gemma-2B-MA-PPO-Fixed10|🤗 [HF Link](https://huggingface.co/baidu/APPS-Gemma-2B-MA-PPO-Fixed10) |[google/codegemma-2b](https://huggingface.co/google/codegemma-2b)|[codeparrot/apps](https://huggingface.co/datasets/codeparrot/apps)
|APPS-Gemma-7B-MA-PPO-Fixed10|🤗 [HF Link](https://huggingface.co/baidu/APPS-Gemma-7B-MA-PPO-Fixed10) |[google/codegemma-7b-it](https://huggingface.co/google/codegemma-7b-it)|[codeparrot/apps](https://huggingface.co/datasets/codeparrot/apps)


## Model Usage

```python
from transformers import AutoModelForCausalLM, AutoTokenizer

model_path = ""baidu/HH-RLHF-Gemma-7B-MA-PPO-Fixed5""

tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)

model = AutoModelForCausalLM.from_pretrained(model_path, device_map=""auto"", torch_dtype='auto', trust_remote_code=True)

input_text = """"""
Human: Would you be able to explain the differences between the Spanish
and Italian language? Assistant: Of course. Can you tell me more about
the specific areas where you’re interested in knowing more? Human: I’m
thinking between the Spanish spoken in Mexico and Italian spoken in Italy.
Assistant: 
""""""

input_ids = tokenizer(input_text, return_tensors='pt').to(model.device)
output_ids = model.generate(**input_ids, max_new_tokens=20)
response = tokenizer.decode(output_ids[0], skip_special_tokens=True)

print(response)
```

## Citation

```
@inproceedings{
  chai2025marlhf,
  title={{MA}-{RLHF}: Reinforcement Learning from Human Feedback with Macro Actions},
  author={Yekun Chai and Haoran Sun and Huang Fang and Shuohuan Wang and Yu Sun and Hua Wu},
  booktitle={The Thirteenth International Conference on Learning Representations},
  year={2025},
  url={https://openreview.net/forum?id=WWXjMYZxfH}
}
```","{""id"": ""baidu/HH-RLHF-Gemma-7B-MA-PPO-Fixed5"", ""author"": ""baidu"", ""sha"": ""fb862924245e2494ba644c9a7d3dae03a8d02365"", ""last_modified"": ""2025-02-14 13:53:25+00:00"", ""created_at"": ""2024-11-16 11:07:39+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 7, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": null, ""gguf"": null, ""inference"": null, ""tags"": [""safetensors"", ""gemma"", ""dataset:Dahoas/full-hh-rlhf"", ""arxiv:2410.02743"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""license:mit"", ""region:us""], ""pipeline_tag"": null, ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model:\n- google/gemma-7b\ndatasets:\n- Dahoas/full-hh-rlhf\nlicense: mit"", ""widget_data"": null, ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": null, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='generation_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00001-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00002-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00003-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00004-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model.safetensors.index.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": {""parameters"": {""F16"": 8537680896}, ""total"": 8537680896}, ""security_repo_status"": null, ""lastModified"": ""2025-02-14 13:53:25+00:00"", ""cardData"": ""base_model:\n- google/gemma-7b\ndatasets:\n- Dahoas/full-hh-rlhf\nlicense: mit"", ""transformersInfo"": null, ""_id"": ""67387cfb41d69ace67b7d138"", ""modelId"": ""baidu/HH-RLHF-Gemma-7B-MA-PPO-Fixed5"", ""usedStorage"": 17097150632}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=baidu/HH-RLHF-Gemma-7B-MA-PPO-Fixed5&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bbaidu%2FHH-RLHF-Gemma-7B-MA-PPO-Fixed5%5D(%2Fbaidu%2FHH-RLHF-Gemma-7B-MA-PPO-Fixed5)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
baidu/TLDR-Gemma-7B-MA-PPO-Fixed5,"---
license: mit
datasets:
- openai/summarize_from_feedback
base_model:
- google/gemma-7b
---
# Model Card for MA-RLHF
<a href=""https://iclr.cc/Conferences/2024"" target=""_blank"">
      <img alt=""ICLR 2025"" src=""https://img.shields.io/badge/Proceedings-ICLR2025-red"" />
</a>
<a href=""https://github.com/ernie-research/MA-RLHF"" target=""_blank"">
      <img alt=""Github"" src=""https://img.shields.io/badge/Github-MA_RLHF-green"" />
   </a>

This repository contains the official checkpoint for [Reinforcement Learning From Human Feedback with Macro Actions (MA-RLHF)](https://arxiv.org/pdf/2410.02743). 

## Model Description

MA-RLHF is a novel framework that integrates macro actions into conventional RLHF. The macro actions are sequences of tokens or higher-level language constructs, with can be computed through different defined termination conditions, like n-gram based, perplexity-based, or parsing-based termination conditions. By introducing macro actions into RLHF, we reduce the number of decision points and shorten decision trajectories, alleviating the credit assignment problem caused by long temporal distances.


|Model|Checkpoint|Base Model|Dataset| 
|-----|----------|-|-|
|TLDR-Gemma-2B-MA-PPO-Fixed5|🤗 [HF Link](https://huggingface.co/baidu/TLDR-Gemma-2B-MA-PPO-Fixed5)|[google/gemma-2b](https://huggingface.co/google/gemma-2b)|[openai/summarize_from_feedback](https://huggingface.co/datasets/openai/summarize_from_feedback)
|TLDR-Gemma-7B-MA-PPO-Fixed5|🤗 [HF Link](https://huggingface.co/baidu/TLDR-Gemma-7B-MA-PPO-Fixed5)|[google/gemma-7b](https://huggingface.co/google/gemma-7b)|[openai/summarize_from_feedback](https://huggingface.co/datasets/openai/summarize_from_feedback)
|TLDR-Gemma-2-27B-MA-PPO-Fixed5|🤗 [HF Link](https://huggingface.co/baidu/TLDR-Gemma-2-27B-MA-PPO-Fixed5)|[google/gemma-2-27b](https://huggingface.co/google/gemma-2-27b)|[openai/summarize_from_feedback](https://huggingface.co/datasets/openai/summarize_from_feedback)
|HH-RLHF-Gemma-2B-MA-PPO-Fixed5|🤗 [HF Link](https://huggingface.co/baidu/HH-RLHF-Gemma-2B-MA-PPO-Fixed5) |[google/gemma-2b](https://huggingface.co/google/gemma-2b)|[Dahoas/full-hh-rlhf](https://huggingface.co/datasets/Dahoas/full-hh-rlhf)
|HH-RLHF-Gemma-7B-MA-PPO-Fixed5|🤗 [HF Link](https://huggingface.co/baidu/HH-RLHF-Gemma-7B-MA-PPO-Fixed5) |[google/gemma-7b](https://huggingface.co/google/gemma-7b)|[Dahoas/full-hh-rlhf](https://huggingface.co/datasets/Dahoas/full-hh-rlhf)
|APPS-Gemma-2B-MA-PPO-Fixed10|🤗 [HF Link](https://huggingface.co/baidu/APPS-Gemma-2B-MA-PPO-Fixed10) |[google/codegemma-2b](https://huggingface.co/google/codegemma-2b)|[codeparrot/apps](https://huggingface.co/datasets/codeparrot/apps)
|APPS-Gemma-7B-MA-PPO-Fixed10|🤗 [HF Link](https://huggingface.co/baidu/APPS-Gemma-7B-MA-PPO-Fixed10) |[google/codegemma-7b-it](https://huggingface.co/google/codegemma-7b-it)|[codeparrot/apps](https://huggingface.co/datasets/codeparrot/apps)


## Model Usage

```python
from transformers import AutoModelForCausalLM, AutoTokenizer

model_path = ""baidu/TLDR-Gemma-7B-MA-PPO-Fixed5""

tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)

model = AutoModelForCausalLM.from_pretrained(model_path, device_map=""auto"", torch_dtype='auto', trust_remote_code=True)

input_text = """"""
POST Subreddit: r/cats
Hello everyone! One of my cats is about 10 years old now, she is pretty much strictly
indoors save for some time she spends on our screened in porch each day. (She likes
to watch the birds in the yard while she suns herself by the pool, quite the princess).
Anyway, when she was younger she was very active and quite small, however with
age she has put on a pretty hefty amount of weight. I feed her indoor cat food
for weight control, I’ve switched brands a few times trying to find something that
works, I’ve cut back on feeding her by a lot (she gets very angry and demanding
when she wants food but I don’t give in) however, nothing really seems to work.
I’ve tried cat toys, and bought a harness thinking I could try to walk her but she just
lays down and looks at me like I’m stupid. Basically I just want to know if you all
have any suggestions for exercise or food. I care about her and don’t want this to
get any worse. I also have another cat that eats the same amount and type of food
as her and is a completely normal weight and only a year younger, however he is a
male, not sure if that makes a difference in predisposition for weight gain. They are
also both fixed. TL;DR: 
""""""

input_ids = tokenizer(input_text, return_tensors='pt').to(model.device)
output_ids = model.generate(**input_ids, max_new_tokens=20)
response = tokenizer.decode(output_ids[0], skip_special_tokens=True)

print(response)
```

## Citation

```
@inproceedings{
  chai2025marlhf,
  title={{MA}-{RLHF}: Reinforcement Learning from Human Feedback with Macro Actions},
  author={Yekun Chai and Haoran Sun and Huang Fang and Shuohuan Wang and Yu Sun and Hua Wu},
  booktitle={The Thirteenth International Conference on Learning Representations},
  year={2025},
  url={https://openreview.net/forum?id=WWXjMYZxfH}
}
```","{""id"": ""baidu/TLDR-Gemma-7B-MA-PPO-Fixed5"", ""author"": ""baidu"", ""sha"": ""b8ac22d973aa79d257d9195ed8897b4c082165e8"", ""last_modified"": ""2025-02-14 13:46:10+00:00"", ""created_at"": ""2024-11-16 15:45:05+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 7, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": null, ""gguf"": null, ""inference"": null, ""tags"": [""safetensors"", ""gemma"", ""dataset:openai/summarize_from_feedback"", ""arxiv:2410.02743"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""license:mit"", ""region:us""], ""pipeline_tag"": null, ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model:\n- google/gemma-7b\ndatasets:\n- openai/summarize_from_feedback\nlicense: mit"", ""widget_data"": null, ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": null, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='generation_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00001-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00002-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00003-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00004-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model.safetensors.index.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": {""parameters"": {""F16"": 8537680896}, ""total"": 8537680896}, ""security_repo_status"": null, ""lastModified"": ""2025-02-14 13:46:10+00:00"", ""cardData"": ""base_model:\n- google/gemma-7b\ndatasets:\n- openai/summarize_from_feedback\nlicense: mit"", ""transformersInfo"": null, ""_id"": ""6738be0119cbbe3091b0a1e8"", ""modelId"": ""baidu/TLDR-Gemma-7B-MA-PPO-Fixed5"", ""usedStorage"": 17097150632}",1,,0,https://huggingface.co/mradermacher/TLDR-Gemma-7B-MA-PPO-Fixed5-GGUF,1,,0,huggingface/InferenceSupport/discussions/new?title=baidu/TLDR-Gemma-7B-MA-PPO-Fixed5&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bbaidu%2FTLDR-Gemma-7B-MA-PPO-Fixed5%5D(%2Fbaidu%2FTLDR-Gemma-7B-MA-PPO-Fixed5)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
klcsp/gemma7b-fft-classification-11-v1,"---
library_name: transformers
license: gemma
base_model: google/gemma-7b
tags:
- trl
- sft
- generated_from_trainer
datasets:
- generator
model-index:
- name: gemma7b-fft-classification-11-v1
  results: []
---

<!-- This model card has been generated automatically according to the information the Trainer had access to. You
should probably proofread and complete it, then remove this comment. -->

# gemma7b-fft-classification-11-v1

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the generator dataset.
It achieves the following results on the evaluation set:
- Loss: 2.8768

## Model description

More information needed

## Intended uses & limitations

More information needed

## Training and evaluation data

More information needed

## Training procedure

### Training hyperparameters

The following hyperparameters were used during training:
- learning_rate: 2e-05
- train_batch_size: 16
- eval_batch_size: 16
- seed: 42
- distributed_type: multi-GPU
- num_devices: 8
- gradient_accumulation_steps: 4
- total_train_batch_size: 512
- total_eval_batch_size: 128
- optimizer: Use OptimizerNames.ADAMW_TORCH with betas=(0.9,0.999) and epsilon=1e-08 and optimizer_args=No additional optimizer arguments
- lr_scheduler_type: cosine
- lr_scheduler_warmup_ratio: 0.1
- num_epochs: 1

### Training results

| Training Loss | Epoch | Step | Validation Loss |
|:-------------:|:-----:|:----:|:---------------:|
| 2.3447        | 1.0   | 30   | 2.8768          |


### Framework versions

- Transformers 4.46.3
- Pytorch 2.3.1+cu121
- Datasets 3.1.0
- Tokenizers 0.20.3
","{""id"": ""klcsp/gemma7b-fft-classification-11-v1"", ""author"": ""klcsp"", ""sha"": ""0c3e5ec681b15eb95d9b5499acccb826d7c14dce"", ""last_modified"": ""2024-11-21 16:21:40+00:00"", ""created_at"": ""2024-11-21 16:06:37+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""trl"", ""sft"", ""generated_from_trainer"", ""conversational"", ""dataset:generator"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""license:gemma"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- generator\nlibrary_name: transformers\nlicense: gemma\ntags:\n- trl\n- sft\n- generated_from_trainer\nmodel-index:\n- name: gemma7b-fft-classification-11-v1\n  results: []"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": [{""name"": ""gemma7b-fft-classification-11-v1"", ""results"": []}], ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{% if messages[0]['role'] == 'user' or messages[0]['role'] == 'system' %}{{ bos_token }}{% endif %}{% for message in messages %}{{ '<|im_start|>' + message['role'] + '\n' + message['content'] + '<|im_end|>' + '\n' }}{% endfor %}{% if add_generation_prompt %}{{ '<|im_start|>assistant\n' }}{% elif messages[-1]['role'] == 'assistant' %}{{ eos_token }}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='eval_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='generation_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00001-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00002-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00003-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00004-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model.safetensors.index.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Nov21_10-56-31_main-fft-mistral7b-alpaca-0-0/events.out.tfevents.1732205202.main-fft-mistral7b-alpaca-0-0.546.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Nov21_10-56-31_main-fft-mistral7b-alpaca-0-0/events.out.tfevents.1732205937.main-fft-mistral7b-alpaca-0-0.546.1', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": {""parameters"": {""BF16"": 8537680896}, ""total"": 8537680896}, ""security_repo_status"": null, ""lastModified"": ""2024-11-21 16:21:40+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- generator\nlibrary_name: transformers\nlicense: gemma\ntags:\n- trl\n- sft\n- generated_from_trainer\nmodel-index:\n- name: gemma7b-fft-classification-11-v1\n  results: []"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""673f5a8d039b1ab3a81eaf3f"", ""modelId"": ""klcsp/gemma7b-fft-classification-11-v1"", ""usedStorage"": 17109721956}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=klcsp/gemma7b-fft-classification-11-v1&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bklcsp%2Fgemma7b-fft-classification-11-v1%5D(%2Fklcsp%2Fgemma7b-fft-classification-11-v1)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
klcsp/gemma7b-fft-alpaca-11-v1,"---
library_name: transformers
license: gemma
base_model: google/gemma-7b
tags:
- trl
- sft
- generated_from_trainer
datasets:
- generator
model-index:
- name: gemma7b-fft-alpaca-11-v1
  results: []
---

<!-- This model card has been generated automatically according to the information the Trainer had access to. You
should probably proofread and complete it, then remove this comment. -->

# gemma7b-fft-alpaca-11-v1

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the generator dataset.
It achieves the following results on the evaluation set:
- Loss: 1.3197

## Model description

More information needed

## Intended uses & limitations

More information needed

## Training and evaluation data

More information needed

## Training procedure

### Training hyperparameters

The following hyperparameters were used during training:
- learning_rate: 2e-05
- train_batch_size: 8
- eval_batch_size: 8
- seed: 42
- distributed_type: multi-GPU
- num_devices: 8
- gradient_accumulation_steps: 4
- total_train_batch_size: 256
- total_eval_batch_size: 64
- optimizer: Use OptimizerNames.ADAMW_TORCH with betas=(0.9,0.999) and epsilon=1e-08 and optimizer_args=No additional optimizer arguments
- lr_scheduler_type: cosine
- lr_scheduler_warmup_ratio: 0.1
- num_epochs: 1

### Training results

| Training Loss | Epoch  | Step | Validation Loss |
|:-------------:|:------:|:----:|:---------------:|
| 1.327         | 0.9892 | 69   | 1.3197          |


### Framework versions

- Transformers 4.46.3
- Pytorch 2.3.1+cu121
- Datasets 3.1.0
- Tokenizers 0.20.3
","{""id"": ""klcsp/gemma7b-fft-alpaca-11-v1"", ""author"": ""klcsp"", ""sha"": ""1674440acb4adb63673fba39bfaf9b3a825b0a08"", ""last_modified"": ""2024-11-21 16:30:14+00:00"", ""created_at"": ""2024-11-21 16:13:02+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""trl"", ""sft"", ""generated_from_trainer"", ""conversational"", ""dataset:generator"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""license:gemma"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- generator\nlibrary_name: transformers\nlicense: gemma\ntags:\n- trl\n- sft\n- generated_from_trainer\nmodel-index:\n- name: gemma7b-fft-alpaca-11-v1\n  results: []"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": [{""name"": ""gemma7b-fft-alpaca-11-v1"", ""results"": []}], ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{% if messages[0]['role'] == 'user' or messages[0]['role'] == 'system' %}{{ bos_token }}{% endif %}{% for message in messages %}{{ '<|im_start|>' + message['role'] + '\n' + message['content'] + '<|im_end|>' + '\n' }}{% endfor %}{% if add_generation_prompt %}{{ '<|im_start|>assistant\n' }}{% elif messages[-1]['role'] == 'assistant' %}{{ eos_token }}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='eval_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='generation_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00001-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00002-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00003-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00004-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model.safetensors.index.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Nov21_11-03-42_main-fft-gemma7b-alpaca-0-0/events.out.tfevents.1732205587.main-fft-gemma7b-alpaca-0-0.546.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Nov21_11-03-42_main-fft-gemma7b-alpaca-0-0/events.out.tfevents.1732206451.main-fft-gemma7b-alpaca-0-0.546.1', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": {""parameters"": {""BF16"": 8537680896}, ""total"": 8537680896}, ""security_repo_status"": null, ""lastModified"": ""2024-11-21 16:30:14+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- generator\nlibrary_name: transformers\nlicense: gemma\ntags:\n- trl\n- sft\n- generated_from_trainer\nmodel-index:\n- name: gemma7b-fft-alpaca-11-v1\n  results: []"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""673f5c0ee79f140ff4496547"", ""modelId"": ""klcsp/gemma7b-fft-alpaca-11-v1"", ""usedStorage"": 17109723369}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=klcsp/gemma7b-fft-alpaca-11-v1&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bklcsp%2Fgemma7b-fft-alpaca-11-v1%5D(%2Fklcsp%2Fgemma7b-fft-alpaca-11-v1)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
klcsp/gemma7b-fft-closedqa-11-v1,"---
library_name: transformers
license: gemma
base_model: google/gemma-7b
tags:
- trl
- sft
- generated_from_trainer
datasets:
- generator
model-index:
- name: gemma7b-fft-closedqa-11-v1
  results: []
---

<!-- This model card has been generated automatically according to the information the Trainer had access to. You
should probably proofread and complete it, then remove this comment. -->

# gemma7b-fft-closedqa-11-v1

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the generator dataset.
It achieves the following results on the evaluation set:
- Loss: 2.2840

## Model description

More information needed

## Intended uses & limitations

More information needed

## Training and evaluation data

More information needed

## Training procedure

### Training hyperparameters

The following hyperparameters were used during training:
- learning_rate: 2e-05
- train_batch_size: 8
- eval_batch_size: 8
- seed: 42
- distributed_type: multi-GPU
- num_devices: 8
- gradient_accumulation_steps: 4
- total_train_batch_size: 256
- total_eval_batch_size: 64
- optimizer: Use OptimizerNames.ADAMW_TORCH with betas=(0.9,0.999) and epsilon=1e-08 and optimizer_args=No additional optimizer arguments
- lr_scheduler_type: cosine
- lr_scheduler_warmup_ratio: 0.1
- num_epochs: 1

### Training results

| Training Loss | Epoch | Step | Validation Loss |
|:-------------:|:-----:|:----:|:---------------:|
| 0.7805        | 1.0   | 130  | 2.2840          |


### Framework versions

- Transformers 4.46.3
- Pytorch 2.3.1+cu121
- Datasets 3.1.0
- Tokenizers 0.20.3
","{""id"": ""klcsp/gemma7b-fft-closedqa-11-v1"", ""author"": ""klcsp"", ""sha"": ""96564e6c17b37519eaebe7d7d1e02d6b280ddcb9"", ""last_modified"": ""2024-11-21 23:47:56+00:00"", ""created_at"": ""2024-11-21 17:07:02+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""trl"", ""sft"", ""generated_from_trainer"", ""conversational"", ""dataset:generator"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""license:gemma"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- generator\nlibrary_name: transformers\nlicense: gemma\ntags:\n- trl\n- sft\n- generated_from_trainer\nmodel-index:\n- name: gemma7b-fft-closedqa-11-v1\n  results: []"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": [{""name"": ""gemma7b-fft-closedqa-11-v1"", ""results"": []}], ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{% if messages[0]['role'] == 'user' or messages[0]['role'] == 'system' %}{{ bos_token }}{% endif %}{% for message in messages %}{{ '<|im_start|>' + message['role'] + '\n' + message['content'] + '<|im_end|>' + '\n' }}{% endfor %}{% if add_generation_prompt %}{{ '<|im_start|>assistant\n' }}{% elif messages[-1]['role'] == 'assistant' %}{{ eos_token }}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='eval_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='generation_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00001-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00002-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00003-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00004-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model.safetensors.index.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Nov21_11-55-46_main-fft-mistral7b-alpaca-0-0/events.out.tfevents.1732208827.main-fft-mistral7b-alpaca-0-0.545.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Nov21_11-55-46_main-fft-mistral7b-alpaca-0-0/events.out.tfevents.1732210102.main-fft-mistral7b-alpaca-0-0.545.1', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Nov21_18-12-56_main-fft-gemma7b-closedqa-0-0/events.out.tfevents.1732231455.main-fft-gemma7b-closedqa-0-0.544.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Nov21_18-12-56_main-fft-gemma7b-closedqa-0-0/events.out.tfevents.1732232713.main-fft-gemma7b-closedqa-0-0.544.1', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": {""parameters"": {""BF16"": 8537680896}, ""total"": 8537680896}, ""security_repo_status"": null, ""lastModified"": ""2024-11-21 23:47:56+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- generator\nlibrary_name: transformers\nlicense: gemma\ntags:\n- trl\n- sft\n- generated_from_trainer\nmodel-index:\n- name: gemma7b-fft-closedqa-11-v1\n  results: []"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""673f68b66aa40c3ae5f87486"", ""modelId"": ""klcsp/gemma7b-fft-closedqa-11-v1"", ""usedStorage"": 34185137163}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=klcsp/gemma7b-fft-closedqa-11-v1&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bklcsp%2Fgemma7b-fft-closedqa-11-v1%5D(%2Fklcsp%2Fgemma7b-fft-closedqa-11-v1)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
klcsp/gemma7b-fft-coding-11-v1,"---
library_name: transformers
license: gemma
base_model: google/gemma-7b
tags:
- trl
- sft
- generated_from_trainer
datasets:
- generator
model-index:
- name: gemma7b-fft-coding-11-v1
  results: []
---

<!-- This model card has been generated automatically according to the information the Trainer had access to. You
should probably proofread and complete it, then remove this comment. -->

# gemma7b-fft-coding-11-v1

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the generator dataset.
It achieves the following results on the evaluation set:
- Loss: 1.3609

## Model description

More information needed

## Intended uses & limitations

More information needed

## Training and evaluation data

More information needed

## Training procedure

### Training hyperparameters

The following hyperparameters were used during training:
- learning_rate: 2e-05
- train_batch_size: 8
- eval_batch_size: 8
- seed: 42
- distributed_type: multi-GPU
- num_devices: 8
- gradient_accumulation_steps: 4
- total_train_batch_size: 256
- total_eval_batch_size: 64
- optimizer: Use OptimizerNames.ADAMW_TORCH with betas=(0.9,0.999) and epsilon=1e-08 and optimizer_args=No additional optimizer arguments
- lr_scheduler_type: cosine
- lr_scheduler_warmup_ratio: 0.1
- num_epochs: 1

### Training results

| Training Loss | Epoch  | Step | Validation Loss |
|:-------------:|:------:|:----:|:---------------:|
| 0.4759        | 0.9967 | 149  | 1.3609          |


### Framework versions

- Transformers 4.46.3
- Pytorch 2.3.1+cu121
- Datasets 3.1.0
- Tokenizers 0.20.3
","{""id"": ""klcsp/gemma7b-fft-coding-11-v1"", ""author"": ""klcsp"", ""sha"": ""d0733982ad06b8d5f493daf00d9032ca449453b8"", ""last_modified"": ""2024-11-22 01:39:48+00:00"", ""created_at"": ""2024-11-22 01:13:28+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""trl"", ""sft"", ""generated_from_trainer"", ""conversational"", ""dataset:generator"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""license:gemma"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- generator\nlibrary_name: transformers\nlicense: gemma\ntags:\n- trl\n- sft\n- generated_from_trainer\nmodel-index:\n- name: gemma7b-fft-coding-11-v1\n  results: []"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": [{""name"": ""gemma7b-fft-coding-11-v1"", ""results"": []}], ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{% if messages[0]['role'] == 'user' or messages[0]['role'] == 'system' %}{{ bos_token }}{% endif %}{% for message in messages %}{{ '<|im_start|>' + message['role'] + '\n' + message['content'] + '<|im_end|>' + '\n' }}{% endfor %}{% if add_generation_prompt %}{{ '<|im_start|>assistant\n' }}{% elif messages[-1]['role'] == 'assistant' %}{{ eos_token }}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='eval_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='generation_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00001-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00002-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00003-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00004-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model.safetensors.index.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Nov21_20-02-18_main-fft-gemma-coding-0-0/events.out.tfevents.1732238015.main-fft-gemma-coding-0-0.545.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Nov21_20-02-18_main-fft-gemma-coding-0-0/events.out.tfevents.1732239425.main-fft-gemma-coding-0-0.545.1', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": {""parameters"": {""BF16"": 8537680896}, ""total"": 8537680896}, ""security_repo_status"": null, ""lastModified"": ""2024-11-22 01:39:48+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- generator\nlibrary_name: transformers\nlicense: gemma\ntags:\n- trl\n- sft\n- generated_from_trainer\nmodel-index:\n- name: gemma7b-fft-coding-11-v1\n  results: []"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""673fdab8816e3a7f88249997"", ""modelId"": ""klcsp/gemma7b-fft-coding-11-v1"", ""usedStorage"": 17109726711}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=klcsp/gemma7b-fft-coding-11-v1&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bklcsp%2Fgemma7b-fft-coding-11-v1%5D(%2Fklcsp%2Fgemma7b-fft-coding-11-v1)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
klcsp/gemma7b-fft-summarization-11-v1,"---
library_name: transformers
license: gemma
base_model: google/gemma-7b
tags:
- trl
- sft
- generated_from_trainer
datasets:
- generator
model-index:
- name: gemma7b-fft-summarization-11-v1
  results: []
---

<!-- This model card has been generated automatically according to the information the Trainer had access to. You
should probably proofread and complete it, then remove this comment. -->

# gemma7b-fft-summarization-11-v1

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the generator dataset.
It achieves the following results on the evaluation set:
- Loss: 2.7200

## Model description

More information needed

## Intended uses & limitations

More information needed

## Training and evaluation data

More information needed

## Training procedure

### Training hyperparameters

The following hyperparameters were used during training:
- learning_rate: 2e-05
- train_batch_size: 8
- eval_batch_size: 8
- seed: 42
- distributed_type: multi-GPU
- num_devices: 8
- gradient_accumulation_steps: 4
- total_train_batch_size: 256
- total_eval_batch_size: 64
- optimizer: Use OptimizerNames.ADAMW_TORCH with betas=(0.9,0.999) and epsilon=1e-08 and optimizer_args=No additional optimizer arguments
- lr_scheduler_type: cosine
- lr_scheduler_warmup_ratio: 0.1
- num_epochs: 1

### Training results

| Training Loss | Epoch  | Step | Validation Loss |
|:-------------:|:------:|:----:|:---------------:|
| 0.7827        | 0.9932 | 109  | 2.7200          |


### Framework versions

- Transformers 4.46.3
- Pytorch 2.3.1+cu121
- Datasets 3.1.0
- Tokenizers 0.20.3
","{""id"": ""klcsp/gemma7b-fft-summarization-11-v1"", ""author"": ""klcsp"", ""sha"": ""118ed2b8b74b52dde44ab91566ae5cb6557aa81e"", ""last_modified"": ""2024-11-22 03:20:28+00:00"", ""created_at"": ""2024-11-22 02:58:59+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""trl"", ""sft"", ""generated_from_trainer"", ""conversational"", ""dataset:generator"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""license:gemma"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- generator\nlibrary_name: transformers\nlicense: gemma\ntags:\n- trl\n- sft\n- generated_from_trainer\nmodel-index:\n- name: gemma7b-fft-summarization-11-v1\n  results: []"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": [{""name"": ""gemma7b-fft-summarization-11-v1"", ""results"": []}], ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{% if messages[0]['role'] == 'user' or messages[0]['role'] == 'system' %}{{ bos_token }}{% endif %}{% for message in messages %}{{ '<|im_start|>' + message['role'] + '\n' + message['content'] + '<|im_end|>' + '\n' }}{% endfor %}{% if add_generation_prompt %}{{ '<|im_start|>assistant\n' }}{% elif messages[-1]['role'] == 'assistant' %}{{ eos_token }}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='eval_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='generation_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00001-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00002-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00003-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00004-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model.safetensors.index.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Nov21_21-47-04_main-fft-mistral-coding-0-0/events.out.tfevents.1732244344.main-fft-mistral-coding-0-0.546.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Nov21_21-47-04_main-fft-mistral-coding-0-0/events.out.tfevents.1732245462.main-fft-mistral-coding-0-0.546.1', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": {""parameters"": {""BF16"": 8537680896}, ""total"": 8537680896}, ""security_repo_status"": null, ""lastModified"": ""2024-11-22 03:20:28+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- generator\nlibrary_name: transformers\nlicense: gemma\ntags:\n- trl\n- sft\n- generated_from_trainer\nmodel-index:\n- name: gemma7b-fft-summarization-11-v1\n  results: []"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""673ff373f2d0992e1f2fde13"", ""modelId"": ""klcsp/gemma7b-fft-summarization-11-v1"", ""usedStorage"": 17109725053}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=klcsp/gemma7b-fft-summarization-11-v1&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bklcsp%2Fgemma7b-fft-summarization-11-v1%5D(%2Fklcsp%2Fgemma7b-fft-summarization-11-v1)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
YingL19/5epoch_1e5_1124,"---
base_model: google/gemma-7b
library_name: transformers
model_name: 5epoch_1e5_1124
tags:
- generated_from_trainer
- trl
- sft
licence: license
---

# Model Card for 5epoch_1e5_1124

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b).
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""YingL19/5epoch_1e5_1124"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/vermouth319-san-jose-state-university/huggingface/runs/3axird6g)

This model was trained with SFT.

### Framework versions

- TRL: 0.12.1
- Transformers: 4.46.2
- Pytorch: 2.5.1+cu121
- Datasets: 3.1.0
- Tokenizers: 0.20.3

## Citations



Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""YingL19/5epoch_1e5_1124"", ""author"": ""YingL19"", ""sha"": ""6de866f28a30efe0b7064b094fd5c04632f66ccb"", ""last_modified"": ""2024-12-05 23:25:43+00:00"", ""created_at"": ""2024-11-25 01:29:54+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""generated_from_trainer"", ""trl"", ""sft"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": null, ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\nlibrary_name: transformers\nmodel_name: 5epoch_1e5_1124\ntags:\n- generated_from_trainer\n- trl\n- sft\nlicence: license"", ""widget_data"": null, ""model_index"": null, ""config"": {""tokenizer_config"": {""bos_token"": ""<bos>"", ""eos_token"": ""<eos>"", ""pad_token"": ""<eos>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModel"", ""custom_class"": null, ""pipeline_tag"": null, ""processor"": null}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='handler.py', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='requirements.txt', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Nov25_01-23-51_81c20e4cfeee/events.out.tfevents.1732497957.81c20e4cfeee.2861.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='sheldon_DB/.DS_Store', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='sheldon_DB/abf57a73-525f-41ae-b6e3-c851fe75ee4f/data_level0.bin', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='sheldon_DB/abf57a73-525f-41ae-b6e3-c851fe75ee4f/header.bin', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='sheldon_DB/abf57a73-525f-41ae-b6e3-c851fe75ee4f/length.bin', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='sheldon_DB/abf57a73-525f-41ae-b6e3-c851fe75ee4f/link_lists.bin', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='sheldon_DB/chroma.sqlite3', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2024-12-05 23:25:43+00:00"", ""cardData"": ""base_model: google/gemma-7b\nlibrary_name: transformers\nmodel_name: 5epoch_1e5_1124\ntags:\n- generated_from_trainer\n- trl\n- sft\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModel"", ""custom_class"": null, ""pipeline_tag"": null, ""processor"": null}, ""_id"": ""6743d31270ee90e92d0babfe"", ""modelId"": ""YingL19/5epoch_1e5_1124"", ""usedStorage"": 443793590}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=YingL19/5epoch_1e5_1124&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5BYingL19%2F5epoch_1e5_1124%5D(%2FYingL19%2F5epoch_1e5_1124)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
YingL19/gemma_10epoch_1e5_lincoln,"---
base_model: google/gemma-7b
library_name: transformers
model_name: gemma_10epoch_1e5_lincoln
tags:
- generated_from_trainer
- trl
- sft
licence: license
---

# Model Card for gemma_10epoch_1e5_lincoln

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b).
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""YingL19/gemma_10epoch_1e5_lincoln"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/ying-liu02-san-jose-state-university/huggingface/runs/nrm26w8h)

This model was trained with SFT.

### Framework versions

- TRL: 0.12.1
- Transformers: 4.46.2
- Pytorch: 2.5.1+cu121
- Datasets: 3.1.0
- Tokenizers: 0.20.3

## Citations



Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""YingL19/gemma_10epoch_1e5_lincoln"", ""author"": ""YingL19"", ""sha"": ""6ea2198460731561b99397da5c38315733943328"", ""last_modified"": ""2024-12-02 00:04:12+00:00"", ""created_at"": ""2024-12-02 00:03:55+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""generated_from_trainer"", ""trl"", ""sft"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": null, ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\nlibrary_name: transformers\nmodel_name: gemma_10epoch_1e5_lincoln\ntags:\n- generated_from_trainer\n- trl\n- sft\nlicence: license"", ""widget_data"": null, ""model_index"": null, ""config"": {""tokenizer_config"": {""bos_token"": ""<bos>"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModel"", ""custom_class"": null, ""pipeline_tag"": null, ""processor"": null}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Dec01_23-27-10_2956e34b089d/events.out.tfevents.1733095681.2956e34b089d.2968.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Dec01_23-35-50_2956e34b089d/events.out.tfevents.1733096157.2956e34b089d.2968.1', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Dec01_23-48-31_95e647db330a/events.out.tfevents.1733096920.95e647db330a.2474.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2024-12-02 00:04:12+00:00"", ""cardData"": ""base_model: google/gemma-7b\nlibrary_name: transformers\nmodel_name: gemma_10epoch_1e5_lincoln\ntags:\n- generated_from_trainer\n- trl\n- sft\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModel"", ""custom_class"": null, ""pipeline_tag"": null, ""processor"": null}, ""_id"": ""674cf96bbeb24e8a6d5e4bbe"", ""modelId"": ""YingL19/gemma_10epoch_1e5_lincoln"", ""usedStorage"": 438771860}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=YingL19/gemma_10epoch_1e5_lincoln&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5BYingL19%2Fgemma_10epoch_1e5_lincoln%5D(%2FYingL19%2Fgemma_10epoch_1e5_lincoln)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
YingL19/gemma_10epoch_1e5_lincoln1,"---
base_model: google/gemma-7b
library_name: transformers
model_name: gemma_10epoch_1e5_lincoln1
tags:
- generated_from_trainer
- trl
- sft
licence: license
---

# Model Card for gemma_10epoch_1e5_lincoln1

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b).
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""YingL19/gemma_10epoch_1e5_lincoln1"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/ying-liu02-san-jose-state-university/huggingface/runs/1vmwmmcx)

This model was trained with SFT.

### Framework versions

- TRL: 0.12.1
- Transformers: 4.46.2
- Pytorch: 2.5.1+cu121
- Datasets: 3.1.0
- Tokenizers: 0.20.3

## Citations



Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""YingL19/gemma_10epoch_1e5_lincoln1"", ""author"": ""YingL19"", ""sha"": ""b65a8d09b19350396faa33820a360ff6e91c3f3b"", ""last_modified"": ""2024-12-04 08:08:43+00:00"", ""created_at"": ""2024-12-02 01:22:44+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""generated_from_trainer"", ""trl"", ""sft"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": null, ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\nlibrary_name: transformers\nmodel_name: gemma_10epoch_1e5_lincoln1\ntags:\n- generated_from_trainer\n- trl\n- sft\nlicence: license"", ""widget_data"": null, ""model_index"": null, ""config"": {""tokenizer_config"": {""bos_token"": ""<bos>"", ""eos_token"": ""<eos>"", ""pad_token"": ""<eos>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModel"", ""custom_class"": null, ""pipeline_tag"": null, ""processor"": null}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='Lincoln_DB/chroma.sqlite3', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='Lincoln_DB/e8227d10-9905-4099-ab22-68db0c71e327/data_level0.bin', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='Lincoln_DB/e8227d10-9905-4099-ab22-68db0c71e327/header.bin', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='Lincoln_DB/e8227d10-9905-4099-ab22-68db0c71e327/length.bin', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='Lincoln_DB/e8227d10-9905-4099-ab22-68db0c71e327/link_lists.bin', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='handler.py', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='requirements.txt', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Dec02_01-10-12_69098491f29a/events.out.tfevents.1733101820.69098491f29a.2876.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2024-12-04 08:08:43+00:00"", ""cardData"": ""base_model: google/gemma-7b\nlibrary_name: transformers\nmodel_name: gemma_10epoch_1e5_lincoln1\ntags:\n- generated_from_trainer\n- trl\n- sft\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModel"", ""custom_class"": null, ""pipeline_tag"": null, ""processor"": null}, ""_id"": ""674d0be4df9b1f8db4ffed67"", ""modelId"": ""YingL19/gemma_10epoch_1e5_lincoln1"", ""usedStorage"": 443947130}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=YingL19/gemma_10epoch_1e5_lincoln1&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5BYingL19%2Fgemma_10epoch_1e5_lincoln1%5D(%2FYingL19%2Fgemma_10epoch_1e5_lincoln1)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
YingL19/gemma_10epoch_1e5_sherlock,"---
base_model: google/gemma-7b
library_name: transformers
model_name: gemma_10epoch_1e5_sherlock
tags:
- generated_from_trainer
- trl
- sft
licence: license
---

# Model Card for gemma_10epoch_1e5_sherlock

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b).
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""YingL19/gemma_10epoch_1e5_sherlock"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/ying-liu02-san-jose-state-university/huggingface/runs/ar3qxdtf)

This model was trained with SFT.

### Framework versions

- TRL: 0.12.1
- Transformers: 4.46.2
- Pytorch: 2.5.1+cu121
- Datasets: 3.1.0
- Tokenizers: 0.20.3

## Citations



Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""YingL19/gemma_10epoch_1e5_sherlock"", ""author"": ""YingL19"", ""sha"": ""6c753c061f6ac1f7e9c46cfb47d54658933f3b38"", ""last_modified"": ""2024-12-02 06:29:37+00:00"", ""created_at"": ""2024-12-02 06:29:06+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""generated_from_trainer"", ""trl"", ""sft"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": null, ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\nlibrary_name: transformers\nmodel_name: gemma_10epoch_1e5_sherlock\ntags:\n- generated_from_trainer\n- trl\n- sft\nlicence: license"", ""widget_data"": null, ""model_index"": null, ""config"": {""tokenizer_config"": {""bos_token"": ""<bos>"", ""eos_token"": ""<eos>"", ""pad_token"": ""<eos>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModel"", ""custom_class"": null, ""pipeline_tag"": null, ""processor"": null}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Dec02_06-16-07_3868a05241ea/events.out.tfevents.1733120177.3868a05241ea.1616.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2024-12-02 06:29:37+00:00"", ""cardData"": ""base_model: google/gemma-7b\nlibrary_name: transformers\nmodel_name: gemma_10epoch_1e5_sherlock\ntags:\n- generated_from_trainer\n- trl\n- sft\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModel"", ""custom_class"": null, ""pipeline_tag"": null, ""processor"": null}, ""_id"": ""674d53b2f82c6ffe5535e556"", ""modelId"": ""YingL19/gemma_10epoch_1e5_sherlock"", ""usedStorage"": 438755152}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=YingL19/gemma_10epoch_1e5_sherlock&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5BYingL19%2Fgemma_10epoch_1e5_sherlock%5D(%2FYingL19%2Fgemma_10epoch_1e5_sherlock)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
daphne604/EHR_Mort_DS_gemma-7b_PEFT,"---
base_model: google/gemma-7b
library_name: transformers
model_name: EHR_Mort_DS_gemma-7b_PEFT
tags:
- generated_from_trainer
- trl
- sft
licence: license
---

# Model Card for EHR_Mort_DS_gemma-7b_PEFT

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b).
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""daphne604/EHR_Mort_DS_gemma-7b_PEFT"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/starsss-daphne-anna-university/EHR_PEFT_local/runs/h0k99pmf)

This model was trained with SFT.

### Framework versions

- TRL: 0.12.1
- Transformers: 4.46.3
- Pytorch: 2.5.1
- Datasets: 3.1.0
- Tokenizers: 0.20.3

## Citations



Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin GallouÃ©dec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""daphne604/EHR_Mort_DS_gemma-7b_PEFT"", ""author"": ""daphne604"", ""sha"": ""9292e507bdd523122d8124cf43fbe5a3c4995a61"", ""last_modified"": ""2024-12-22 19:18:19+00:00"", ""created_at"": ""2024-12-22 19:01:55+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""safetensors"", ""generated_from_trainer"", ""trl"", ""sft"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": null, ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\nlibrary_name: transformers\nmodel_name: EHR_Mort_DS_gemma-7b_PEFT\ntags:\n- generated_from_trainer\n- trl\n- sft\nlicence: license"", ""widget_data"": null, ""model_index"": null, ""config"": {""tokenizer_config"": {""bos_token"": ""<bos>"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModel"", ""custom_class"": null, ""pipeline_tag"": null, ""processor"": null}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2024-12-22 19:18:19+00:00"", ""cardData"": ""base_model: google/gemma-7b\nlibrary_name: transformers\nmodel_name: EHR_Mort_DS_gemma-7b_PEFT\ntags:\n- generated_from_trainer\n- trl\n- sft\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModel"", ""custom_class"": null, ""pipeline_tag"": null, ""processor"": null}, ""_id"": ""67686223313268c381d85d27"", ""modelId"": ""daphne604/EHR_Mort_DS_gemma-7b_PEFT"", ""usedStorage"": 6725903425}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=daphne604/EHR_Mort_DS_gemma-7b_PEFT&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bdaphne604%2FEHR_Mort_DS_gemma-7b_PEFT%5D(%2Fdaphne604%2FEHR_Mort_DS_gemma-7b_PEFT)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
AmberYifan/Gemma-7b-sft-ultrachat,"---
base_model: google/gemma-7b
library_name: transformers
model_name: Gemma-7b-sft-ultrachat
tags:
- generated_from_trainer
- trl
- sft
licence: license
---

# Model Card for Gemma-7b-sft-ultrachat

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b).
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""AmberYifan/Gemma-7b-sft-ultrachat"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure



This model was trained with SFT.

### Framework versions

- TRL: 0.12.2
- Transformers: 4.46.3
- Pytorch: 2.5.1+cu118
- Datasets: 3.2.0
- Tokenizers: 0.20.3

## Citations



Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""AmberYifan/Gemma-7b-sft-ultrachat"", ""author"": ""AmberYifan"", ""sha"": ""925e16116f18de11179999887cef82a3e05ef4f7"", ""last_modified"": ""2025-01-12 02:55:45+00:00"", ""created_at"": ""2025-01-11 23:29:27+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 2, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""trl"", ""sft"", ""conversational"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\nlibrary_name: transformers\nmodel_name: Gemma-7b-sft-ultrachat\ntags:\n- generated_from_trainer\n- trl\n- sft\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{% for message in messages %}\n{% if message['role'] == 'user' %}\n{{ '<|user|>\n' + message['content'] + eos_token }}\n{% elif message['role'] == 'system' %}\n{{ '<|system|>\n' + message['content'] + eos_token }}\n{% elif message['role'] == 'assistant' %}\n{{ '<|assistant|>\n'  + message['content'] + eos_token }}\n{% endif %}\n{% if loop.last and add_generation_prompt %}\n{{ '<|assistant|>' }}\n{% endif %}\n{% endfor %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='generation_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00001-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00002-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00003-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00004-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model.safetensors.index.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan11_17-56-42_gilbreth-j001.rcac.purdue.edu/events.out.tfevents.1736638423.gilbreth-j001.rcac.purdue.edu.193404.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": {""parameters"": {""BF16"": 8537680896}, ""total"": 8537680896}, ""security_repo_status"": null, ""lastModified"": ""2025-01-12 02:55:45+00:00"", ""cardData"": ""base_model: google/gemma-7b\nlibrary_name: transformers\nmodel_name: Gemma-7b-sft-ultrachat\ntags:\n- generated_from_trainer\n- trl\n- sft\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""6782fed763ffb0435b3491cd"", ""modelId"": ""AmberYifan/Gemma-7b-sft-ultrachat"", ""usedStorage"": 17114145010}",1,https://huggingface.co/AmberYifan/Gemma-7b-sft-ultrachat-safeRLHF,1,"https://huggingface.co/mradermacher/Gemma-7b-sft-ultrachat-GGUF, https://huggingface.co/mradermacher/Gemma-7b-sft-ultrachat-i1-GGUF",2,,0,huggingface/InferenceSupport/discussions/new?title=AmberYifan/Gemma-7b-sft-ultrachat&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5BAmberYifan%2FGemma-7b-sft-ultrachat%5D(%2FAmberYifan%2FGemma-7b-sft-ultrachat)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
AmberYifan/Gemma-7b-sft-ultrachat-safeRLHF,"---
base_model: AmberYifan/Gemma-7b-sft-ultrachat
library_name: transformers
model_name: Gemma-7b-sft-ultrachat-safeRLHF
tags:
- generated_from_trainer
- trl
- sft
licence: license
---

# Model Card for Gemma-7b-sft-ultrachat-safeRLHF

This model is a fine-tuned version of [AmberYifan/Gemma-7b-sft-ultrachat](https://huggingface.co/AmberYifan/Gemma-7b-sft-ultrachat).
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""AmberYifan/Gemma-7b-sft-ultrachat-safeRLHF"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure



This model was trained with SFT.

### Framework versions

- TRL: 0.12.2
- Transformers: 4.46.3
- Pytorch: 2.5.1+cu118
- Datasets: 3.2.0
- Tokenizers: 0.20.3

## Citations



Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""AmberYifan/Gemma-7b-sft-ultrachat-safeRLHF"", ""author"": ""AmberYifan"", ""sha"": ""dd1e8d244903b6de0747c9429215fa541fdd1c17"", ""last_modified"": ""2025-01-12 04:52:23+00:00"", ""created_at"": ""2025-01-12 03:13:25+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 2, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""trl"", ""sft"", ""conversational"", ""base_model:AmberYifan/Gemma-7b-sft-ultrachat"", ""base_model:finetune:AmberYifan/Gemma-7b-sft-ultrachat"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: AmberYifan/Gemma-7b-sft-ultrachat\nlibrary_name: transformers\nmodel_name: Gemma-7b-sft-ultrachat-safeRLHF\ntags:\n- generated_from_trainer\n- trl\n- sft\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{% for message in messages %}\n{% if message['role'] == 'user' %}\n{{ '<|user|>\n' + message['content'] + eos_token }}\n{% elif message['role'] == 'system' %}\n{{ '<|system|>\n' + message['content'] + eos_token }}\n{% elif message['role'] == 'assistant' %}\n{{ '<|assistant|>\n'  + message['content'] + eos_token }}\n{% endif %}\n{% if loop.last and add_generation_prompt %}\n{{ '<|assistant|>' }}\n{% endif %}\n{% endfor %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='generation_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00001-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00002-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00003-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00004-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model.safetensors.index.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan11_21-56-34_gilbreth-j001.rcac.purdue.edu/events.out.tfevents.1736651619.gilbreth-j001.rcac.purdue.edu.11251.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": {""parameters"": {""BF16"": 8537680896}, ""total"": 8537680896}, ""security_repo_status"": null, ""lastModified"": ""2025-01-12 04:52:23+00:00"", ""cardData"": ""base_model: AmberYifan/Gemma-7b-sft-ultrachat\nlibrary_name: transformers\nmodel_name: Gemma-7b-sft-ultrachat-safeRLHF\ntags:\n- generated_from_trainer\n- trl\n- sft\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""678333556550f5a48b843a32"", ""modelId"": ""AmberYifan/Gemma-7b-sft-ultrachat-safeRLHF"", ""usedStorage"": 17114140389}",2,"https://huggingface.co/AmberYifan/Gemma-7B-sft-gen-dpo-10k, https://huggingface.co/AmberYifan/Gemma-7B-sft-spin-10k, https://huggingface.co/AmberYifan/Gemma-7B-sft-dpo-10k, https://huggingface.co/AmberYifan/Gemma-7B-sft-SPIN-Gemma-2-27B, https://huggingface.co/AmberYifan/Gemma-7B-sft-SPIN-gpt4o",5,"https://huggingface.co/mradermacher/Gemma-7b-sft-ultrachat-safeRLHF-GGUF, https://huggingface.co/mradermacher/Gemma-7b-sft-ultrachat-safeRLHF-i1-GGUF",2,,0,huggingface/InferenceSupport/discussions/new?title=AmberYifan/Gemma-7b-sft-ultrachat-safeRLHF&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5BAmberYifan%2FGemma-7b-sft-ultrachat-safeRLHF%5D(%2FAmberYifan%2FGemma-7b-sft-ultrachat-safeRLHF)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
AmberYifan/Gemma-7B-sft-gen-dpo-10k,"---
base_model: AmberYifan/Gemma-7b-sft-ultrachat-safeRLHF
library_name: transformers
model_name: Gemma-7B-sft-gen-dpo-10k
tags:
- generated_from_trainer
- trl
- dpo
licence: license
---

# Model Card for Gemma-7B-sft-gen-dpo-10k

This model is a fine-tuned version of [AmberYifan/Gemma-7b-sft-ultrachat-safeRLHF](https://huggingface.co/AmberYifan/Gemma-7b-sft-ultrachat-safeRLHF).
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""AmberYifan/Gemma-7B-sft-gen-dpo-10k"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/yifanwang/huggingface/runs/k8ru4b4w)

This model was trained with DPO, a method introduced in [Direct Preference Optimization: Your Language Model is Secretly a Reward Model](https://huggingface.co/papers/2305.18290).

### Framework versions

- TRL: 0.12.2
- Transformers: 4.46.3
- Pytorch: 2.5.1+cu118
- Datasets: 3.2.0
- Tokenizers: 0.20.3

## Citations

Cite DPO as:

```bibtex
@inproceedings{rafailov2023direct,
    title        = {{Direct Preference Optimization: Your Language Model is Secretly a Reward Model}},
    author       = {Rafael Rafailov and Archit Sharma and Eric Mitchell and Christopher D. Manning and Stefano Ermon and Chelsea Finn},
    year         = 2023,
    booktitle    = {Advances in Neural Information Processing Systems 36: Annual Conference on Neural Information Processing Systems 2023, NeurIPS 2023, New Orleans, LA, USA, December 10 - 16, 2023},
    url          = {http://papers.nips.cc/paper_files/paper/2023/hash/a85b405ed65c6477a4fe8302b5e06ce7-Abstract-Conference.html},
    editor       = {Alice Oh and Tristan Naumann and Amir Globerson and Kate Saenko and Moritz Hardt and Sergey Levine},
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""AmberYifan/Gemma-7B-sft-gen-dpo-10k"", ""author"": ""AmberYifan"", ""sha"": ""cfd6f73856966f9a3ba6b1bc8b9cdb106b4f6190"", ""last_modified"": ""2025-01-12 19:50:11+00:00"", ""created_at"": ""2025-01-12 18:15:07+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""trl"", ""dpo"", ""conversational"", ""arxiv:2305.18290"", ""base_model:AmberYifan/Gemma-7b-sft-ultrachat-safeRLHF"", ""base_model:finetune:AmberYifan/Gemma-7b-sft-ultrachat-safeRLHF"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: AmberYifan/Gemma-7b-sft-ultrachat-safeRLHF\nlibrary_name: transformers\nmodel_name: Gemma-7B-sft-gen-dpo-10k\ntags:\n- generated_from_trainer\n- trl\n- dpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{% for message in messages %}\n{% if message['role'] == 'user' %}\n{{ '<|user|>\n' + message['content'] + eos_token }}\n{% elif message['role'] == 'system' %}\n{{ '<|system|>\n' + message['content'] + eos_token }}\n{% elif message['role'] == 'assistant' %}\n{{ '<|assistant|>\n'  + message['content'] + eos_token }}\n{% endif %}\n{% if loop.last and add_generation_prompt %}\n{{ '<|assistant|>' }}\n{% endif %}\n{% endfor %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='generation_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/generation_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/global_step305/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/global_step305/bf16_zero_pp_rank_1_mp_rank_00_optim_states.pt', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/global_step305/bf16_zero_pp_rank_2_mp_rank_00_optim_states.pt', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/global_step305/bf16_zero_pp_rank_3_mp_rank_00_optim_states.pt', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/global_step305/zero_pp_rank_0_mp_rank_00_model_states.pt', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/global_step305/zero_pp_rank_1_mp_rank_00_model_states.pt', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/global_step305/zero_pp_rank_2_mp_rank_00_model_states.pt', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/global_step305/zero_pp_rank_3_mp_rank_00_model_states.pt', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/global_step610/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/global_step610/bf16_zero_pp_rank_1_mp_rank_00_optim_states.pt', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/global_step610/bf16_zero_pp_rank_2_mp_rank_00_optim_states.pt', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/global_step610/bf16_zero_pp_rank_3_mp_rank_00_optim_states.pt', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/global_step610/zero_pp_rank_0_mp_rank_00_model_states.pt', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/global_step610/zero_pp_rank_1_mp_rank_00_model_states.pt', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/global_step610/zero_pp_rank_2_mp_rank_00_model_states.pt', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/global_step610/zero_pp_rank_3_mp_rank_00_model_states.pt', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/global_step915/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/global_step915/bf16_zero_pp_rank_1_mp_rank_00_optim_states.pt', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/global_step915/bf16_zero_pp_rank_2_mp_rank_00_optim_states.pt', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/global_step915/bf16_zero_pp_rank_3_mp_rank_00_optim_states.pt', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/global_step915/zero_pp_rank_0_mp_rank_00_model_states.pt', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/global_step915/zero_pp_rank_1_mp_rank_00_model_states.pt', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/global_step915/zero_pp_rank_2_mp_rank_00_model_states.pt', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/global_step915/zero_pp_rank_3_mp_rank_00_model_states.pt', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/latest', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/model-00001-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/model-00002-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/model-00003-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/model-00004-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/model.safetensors.index.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/rng_state_0.pth', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/rng_state_1.pth', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/rng_state_2.pth', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/rng_state_3.pth', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/scheduler.pt', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/training_args.bin', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/zero_to_fp32.py', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00001-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00002-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00003-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00004-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model.safetensors.index.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": {""parameters"": {""BF16"": 8537680896}, ""total"": 8537680896}, ""security_repo_status"": null, ""lastModified"": ""2025-01-12 19:50:11+00:00"", ""cardData"": ""base_model: AmberYifan/Gemma-7b-sft-ultrachat-safeRLHF\nlibrary_name: transformers\nmodel_name: Gemma-7B-sft-gen-dpo-10k\ntags:\n- generated_from_trainer\n- trl\n- dpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""678406abfc7ff7562268688c"", ""modelId"": ""AmberYifan/Gemma-7B-sft-gen-dpo-10k"", ""usedStorage"": 256170948004}",3,,0,https://huggingface.co/mradermacher/Gemma-7B-sft-gen-dpo-10k-GGUF,1,,0,huggingface/InferenceSupport/discussions/new?title=AmberYifan/Gemma-7B-sft-gen-dpo-10k&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5BAmberYifan%2FGemma-7B-sft-gen-dpo-10k%5D(%2FAmberYifan%2FGemma-7B-sft-gen-dpo-10k)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
AmberYifan/Gemma-7B-sft-spin-10k,"---
base_model: AmberYifan/Gemma-7b-sft-ultrachat-safeRLHF
library_name: transformers
model_name: Gemma-7B-sft-spin-10k
tags:
- generated_from_trainer
- trl
- dpo
licence: license
---

# Model Card for Gemma-7B-sft-spin-10k

This model is a fine-tuned version of [AmberYifan/Gemma-7b-sft-ultrachat-safeRLHF](https://huggingface.co/AmberYifan/Gemma-7b-sft-ultrachat-safeRLHF).
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""AmberYifan/Gemma-7B-sft-spin-10k"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/yifanwang/huggingface/runs/kmg4htny)

This model was trained with DPO, a method introduced in [Direct Preference Optimization: Your Language Model is Secretly a Reward Model](https://huggingface.co/papers/2305.18290).

### Framework versions

- TRL: 0.12.2
- Transformers: 4.46.3
- Pytorch: 2.5.1+cu118
- Datasets: 3.2.0
- Tokenizers: 0.20.3

## Citations

Cite DPO as:

```bibtex
@inproceedings{rafailov2023direct,
    title        = {{Direct Preference Optimization: Your Language Model is Secretly a Reward Model}},
    author       = {Rafael Rafailov and Archit Sharma and Eric Mitchell and Christopher D. Manning and Stefano Ermon and Chelsea Finn},
    year         = 2023,
    booktitle    = {Advances in Neural Information Processing Systems 36: Annual Conference on Neural Information Processing Systems 2023, NeurIPS 2023, New Orleans, LA, USA, December 10 - 16, 2023},
    url          = {http://papers.nips.cc/paper_files/paper/2023/hash/a85b405ed65c6477a4fe8302b5e06ce7-Abstract-Conference.html},
    editor       = {Alice Oh and Tristan Naumann and Amir Globerson and Kate Saenko and Moritz Hardt and Sergey Levine},
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""AmberYifan/Gemma-7B-sft-spin-10k"", ""author"": ""AmberYifan"", ""sha"": ""d2a40ddc826d1bae64858f68a7277d86c43120e1"", ""last_modified"": ""2025-01-12 21:34:46+00:00"", ""created_at"": ""2025-01-12 19:57:14+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""trl"", ""dpo"", ""conversational"", ""arxiv:2305.18290"", ""base_model:AmberYifan/Gemma-7b-sft-ultrachat-safeRLHF"", ""base_model:finetune:AmberYifan/Gemma-7b-sft-ultrachat-safeRLHF"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: AmberYifan/Gemma-7b-sft-ultrachat-safeRLHF\nlibrary_name: transformers\nmodel_name: Gemma-7B-sft-spin-10k\ntags:\n- generated_from_trainer\n- trl\n- dpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{% for message in messages %}\n{% if message['role'] == 'user' %}\n{{ '<|user|>\n' + message['content'] + eos_token }}\n{% elif message['role'] == 'system' %}\n{{ '<|system|>\n' + message['content'] + eos_token }}\n{% elif message['role'] == 'assistant' %}\n{{ '<|assistant|>\n'  + message['content'] + eos_token }}\n{% endif %}\n{% if loop.last and add_generation_prompt %}\n{{ '<|assistant|>' }}\n{% endif %}\n{% endfor %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='generation_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/generation_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/global_step305/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/global_step305/bf16_zero_pp_rank_1_mp_rank_00_optim_states.pt', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/global_step305/bf16_zero_pp_rank_2_mp_rank_00_optim_states.pt', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/global_step305/bf16_zero_pp_rank_3_mp_rank_00_optim_states.pt', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/global_step305/zero_pp_rank_0_mp_rank_00_model_states.pt', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/global_step305/zero_pp_rank_1_mp_rank_00_model_states.pt', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/global_step305/zero_pp_rank_2_mp_rank_00_model_states.pt', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/global_step305/zero_pp_rank_3_mp_rank_00_model_states.pt', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/global_step610/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/global_step610/bf16_zero_pp_rank_1_mp_rank_00_optim_states.pt', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/global_step610/bf16_zero_pp_rank_2_mp_rank_00_optim_states.pt', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/global_step610/bf16_zero_pp_rank_3_mp_rank_00_optim_states.pt', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/global_step610/zero_pp_rank_0_mp_rank_00_model_states.pt', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/global_step610/zero_pp_rank_1_mp_rank_00_model_states.pt', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/global_step610/zero_pp_rank_2_mp_rank_00_model_states.pt', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/global_step610/zero_pp_rank_3_mp_rank_00_model_states.pt', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/global_step915/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/global_step915/bf16_zero_pp_rank_1_mp_rank_00_optim_states.pt', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/global_step915/bf16_zero_pp_rank_2_mp_rank_00_optim_states.pt', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/global_step915/bf16_zero_pp_rank_3_mp_rank_00_optim_states.pt', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/global_step915/zero_pp_rank_0_mp_rank_00_model_states.pt', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/global_step915/zero_pp_rank_1_mp_rank_00_model_states.pt', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/global_step915/zero_pp_rank_2_mp_rank_00_model_states.pt', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/global_step915/zero_pp_rank_3_mp_rank_00_model_states.pt', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/latest', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/model-00001-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/model-00002-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/model-00003-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/model-00004-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/model.safetensors.index.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/rng_state_0.pth', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/rng_state_1.pth', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/rng_state_2.pth', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/rng_state_3.pth', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/scheduler.pt', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/training_args.bin', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/zero_to_fp32.py', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00001-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00002-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00003-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00004-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model.safetensors.index.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": {""parameters"": {""BF16"": 8537680896}, ""total"": 8537680896}, ""security_repo_status"": null, ""lastModified"": ""2025-01-12 21:34:46+00:00"", ""cardData"": ""base_model: AmberYifan/Gemma-7b-sft-ultrachat-safeRLHF\nlibrary_name: transformers\nmodel_name: Gemma-7B-sft-spin-10k\ntags:\n- generated_from_trainer\n- trl\n- dpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67841e9a88796724ed6abc41"", ""modelId"": ""AmberYifan/Gemma-7B-sft-spin-10k"", ""usedStorage"": 256170948004}",3,,0,https://huggingface.co/mradermacher/Gemma-7B-sft-spin-10k-GGUF,1,,0,huggingface/InferenceSupport/discussions/new?title=AmberYifan/Gemma-7B-sft-spin-10k&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5BAmberYifan%2FGemma-7B-sft-spin-10k%5D(%2FAmberYifan%2FGemma-7B-sft-spin-10k)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
AmberYifan/Gemma-7B-sft-dpo-10k,"---
base_model: AmberYifan/Gemma-7b-sft-ultrachat-safeRLHF
library_name: transformers
model_name: Gemma-7B-sft-dpo-10k
tags:
- generated_from_trainer
- trl
- dpo
licence: license
---

# Model Card for Gemma-7B-sft-dpo-10k

This model is a fine-tuned version of [AmberYifan/Gemma-7b-sft-ultrachat-safeRLHF](https://huggingface.co/AmberYifan/Gemma-7b-sft-ultrachat-safeRLHF).
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""AmberYifan/Gemma-7B-sft-dpo-10k"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/yifanwang/huggingface/runs/vl0s4s85)

This model was trained with DPO, a method introduced in [Direct Preference Optimization: Your Language Model is Secretly a Reward Model](https://huggingface.co/papers/2305.18290).

### Framework versions

- TRL: 0.12.2
- Transformers: 4.46.3
- Pytorch: 2.5.1+cu118
- Datasets: 3.2.0
- Tokenizers: 0.20.3

## Citations

Cite DPO as:

```bibtex
@inproceedings{rafailov2023direct,
    title        = {{Direct Preference Optimization: Your Language Model is Secretly a Reward Model}},
    author       = {Rafael Rafailov and Archit Sharma and Eric Mitchell and Christopher D. Manning and Stefano Ermon and Chelsea Finn},
    year         = 2023,
    booktitle    = {Advances in Neural Information Processing Systems 36: Annual Conference on Neural Information Processing Systems 2023, NeurIPS 2023, New Orleans, LA, USA, December 10 - 16, 2023},
    url          = {http://papers.nips.cc/paper_files/paper/2023/hash/a85b405ed65c6477a4fe8302b5e06ce7-Abstract-Conference.html},
    editor       = {Alice Oh and Tristan Naumann and Amir Globerson and Kate Saenko and Moritz Hardt and Sergey Levine},
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""AmberYifan/Gemma-7B-sft-dpo-10k"", ""author"": ""AmberYifan"", ""sha"": ""99c8b96867ff541aa61ecd33a8287d8882a7c298"", ""last_modified"": ""2025-01-12 23:27:41+00:00"", ""created_at"": ""2025-01-12 21:41:51+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""trl"", ""dpo"", ""conversational"", ""arxiv:2305.18290"", ""base_model:AmberYifan/Gemma-7b-sft-ultrachat-safeRLHF"", ""base_model:finetune:AmberYifan/Gemma-7b-sft-ultrachat-safeRLHF"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: AmberYifan/Gemma-7b-sft-ultrachat-safeRLHF\nlibrary_name: transformers\nmodel_name: Gemma-7B-sft-dpo-10k\ntags:\n- generated_from_trainer\n- trl\n- dpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{% for message in messages %}\n{% if message['role'] == 'user' %}\n{{ '<|user|>\n' + message['content'] + eos_token }}\n{% elif message['role'] == 'system' %}\n{{ '<|system|>\n' + message['content'] + eos_token }}\n{% elif message['role'] == 'assistant' %}\n{{ '<|assistant|>\n'  + message['content'] + eos_token }}\n{% endif %}\n{% if loop.last and add_generation_prompt %}\n{{ '<|assistant|>' }}\n{% endif %}\n{% endfor %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='generation_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/generation_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/global_step305/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/global_step305/bf16_zero_pp_rank_1_mp_rank_00_optim_states.pt', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/global_step305/bf16_zero_pp_rank_2_mp_rank_00_optim_states.pt', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/global_step305/bf16_zero_pp_rank_3_mp_rank_00_optim_states.pt', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/global_step305/zero_pp_rank_0_mp_rank_00_model_states.pt', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/global_step305/zero_pp_rank_1_mp_rank_00_model_states.pt', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/global_step305/zero_pp_rank_2_mp_rank_00_model_states.pt', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/global_step305/zero_pp_rank_3_mp_rank_00_model_states.pt', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/global_step610/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/global_step610/bf16_zero_pp_rank_1_mp_rank_00_optim_states.pt', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/global_step610/bf16_zero_pp_rank_2_mp_rank_00_optim_states.pt', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/global_step610/bf16_zero_pp_rank_3_mp_rank_00_optim_states.pt', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/global_step610/zero_pp_rank_0_mp_rank_00_model_states.pt', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/global_step610/zero_pp_rank_1_mp_rank_00_model_states.pt', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/global_step610/zero_pp_rank_2_mp_rank_00_model_states.pt', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/global_step610/zero_pp_rank_3_mp_rank_00_model_states.pt', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/global_step915/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/global_step915/bf16_zero_pp_rank_1_mp_rank_00_optim_states.pt', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/global_step915/bf16_zero_pp_rank_2_mp_rank_00_optim_states.pt', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/global_step915/bf16_zero_pp_rank_3_mp_rank_00_optim_states.pt', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/global_step915/zero_pp_rank_0_mp_rank_00_model_states.pt', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/global_step915/zero_pp_rank_1_mp_rank_00_model_states.pt', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/global_step915/zero_pp_rank_2_mp_rank_00_model_states.pt', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/global_step915/zero_pp_rank_3_mp_rank_00_model_states.pt', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/latest', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/model-00001-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/model-00002-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/model-00003-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/model-00004-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/model.safetensors.index.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/rng_state_0.pth', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/rng_state_1.pth', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/rng_state_2.pth', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/rng_state_3.pth', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/scheduler.pt', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/training_args.bin', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/zero_to_fp32.py', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00001-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00002-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00003-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00004-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model.safetensors.index.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": {""parameters"": {""BF16"": 8537680896}, ""total"": 8537680896}, ""security_repo_status"": null, ""lastModified"": ""2025-01-12 23:27:41+00:00"", ""cardData"": ""base_model: AmberYifan/Gemma-7b-sft-ultrachat-safeRLHF\nlibrary_name: transformers\nmodel_name: Gemma-7B-sft-dpo-10k\ntags:\n- generated_from_trainer\n- trl\n- dpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""6784371f883142429f448b04"", ""modelId"": ""AmberYifan/Gemma-7B-sft-dpo-10k"", ""usedStorage"": 256170948004}",3,,0,https://huggingface.co/mradermacher/Gemma-7B-sft-dpo-10k-GGUF,1,,0,huggingface/InferenceSupport/discussions/new?title=AmberYifan/Gemma-7B-sft-dpo-10k&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5BAmberYifan%2FGemma-7B-sft-dpo-10k%5D(%2FAmberYifan%2FGemma-7B-sft-dpo-10k)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
AmberYifan/Gemma-7B-sft-SPIN-Gemma-2-27B,"---
base_model: AmberYifan/Gemma-7b-sft-ultrachat-safeRLHF
library_name: transformers
model_name: Gemma-7B-sft-SPIN-Gemma-2-27B
tags:
- generated_from_trainer
- trl
- dpo
licence: license
---

# Model Card for Gemma-7B-sft-SPIN-Gemma-2-27B

This model is a fine-tuned version of [AmberYifan/Gemma-7b-sft-ultrachat-safeRLHF](https://huggingface.co/AmberYifan/Gemma-7b-sft-ultrachat-safeRLHF).
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""AmberYifan/Gemma-7B-sft-SPIN-Gemma-2-27B"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/yifanwang/huggingface/runs/nw10j6ek)

This model was trained with DPO, a method introduced in [Direct Preference Optimization: Your Language Model is Secretly a Reward Model](https://huggingface.co/papers/2305.18290).

### Framework versions

- TRL: 0.12.2
- Transformers: 4.46.3
- Pytorch: 2.5.1+cu118
- Datasets: 3.2.0
- Tokenizers: 0.20.3

## Citations

Cite DPO as:

```bibtex
@inproceedings{rafailov2023direct,
    title        = {{Direct Preference Optimization: Your Language Model is Secretly a Reward Model}},
    author       = {Rafael Rafailov and Archit Sharma and Eric Mitchell and Christopher D. Manning and Stefano Ermon and Chelsea Finn},
    year         = 2023,
    booktitle    = {Advances in Neural Information Processing Systems 36: Annual Conference on Neural Information Processing Systems 2023, NeurIPS 2023, New Orleans, LA, USA, December 10 - 16, 2023},
    url          = {http://papers.nips.cc/paper_files/paper/2023/hash/a85b405ed65c6477a4fe8302b5e06ce7-Abstract-Conference.html},
    editor       = {Alice Oh and Tristan Naumann and Amir Globerson and Kate Saenko and Moritz Hardt and Sergey Levine},
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""AmberYifan/Gemma-7B-sft-SPIN-Gemma-2-27B"", ""author"": ""AmberYifan"", ""sha"": ""a81919563d591dd6332873d7aec689542b5e4f9f"", ""last_modified"": ""2025-01-13 01:57:16+00:00"", ""created_at"": ""2025-01-12 23:58:00+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""trl"", ""dpo"", ""conversational"", ""arxiv:2305.18290"", ""base_model:AmberYifan/Gemma-7b-sft-ultrachat-safeRLHF"", ""base_model:finetune:AmberYifan/Gemma-7b-sft-ultrachat-safeRLHF"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: AmberYifan/Gemma-7b-sft-ultrachat-safeRLHF\nlibrary_name: transformers\nmodel_name: Gemma-7B-sft-SPIN-Gemma-2-27B\ntags:\n- generated_from_trainer\n- trl\n- dpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{% for message in messages %}\n{% if message['role'] == 'user' %}\n{{ '<|user|>\n' + message['content'] + eos_token }}\n{% elif message['role'] == 'system' %}\n{{ '<|system|>\n' + message['content'] + eos_token }}\n{% elif message['role'] == 'assistant' %}\n{{ '<|assistant|>\n'  + message['content'] + eos_token }}\n{% endif %}\n{% if loop.last and add_generation_prompt %}\n{{ '<|assistant|>' }}\n{% endif %}\n{% endfor %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='generation_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/generation_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/global_step305/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/global_step305/bf16_zero_pp_rank_1_mp_rank_00_optim_states.pt', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/global_step305/bf16_zero_pp_rank_2_mp_rank_00_optim_states.pt', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/global_step305/bf16_zero_pp_rank_3_mp_rank_00_optim_states.pt', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/global_step305/zero_pp_rank_0_mp_rank_00_model_states.pt', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/global_step305/zero_pp_rank_1_mp_rank_00_model_states.pt', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/global_step305/zero_pp_rank_2_mp_rank_00_model_states.pt', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/global_step305/zero_pp_rank_3_mp_rank_00_model_states.pt', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/global_step610/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/global_step610/bf16_zero_pp_rank_1_mp_rank_00_optim_states.pt', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/global_step610/bf16_zero_pp_rank_2_mp_rank_00_optim_states.pt', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/global_step610/bf16_zero_pp_rank_3_mp_rank_00_optim_states.pt', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/global_step610/zero_pp_rank_0_mp_rank_00_model_states.pt', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/global_step610/zero_pp_rank_1_mp_rank_00_model_states.pt', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/global_step610/zero_pp_rank_2_mp_rank_00_model_states.pt', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/global_step610/zero_pp_rank_3_mp_rank_00_model_states.pt', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/global_step915/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/global_step915/bf16_zero_pp_rank_1_mp_rank_00_optim_states.pt', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/global_step915/bf16_zero_pp_rank_2_mp_rank_00_optim_states.pt', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/global_step915/bf16_zero_pp_rank_3_mp_rank_00_optim_states.pt', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/global_step915/zero_pp_rank_0_mp_rank_00_model_states.pt', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/global_step915/zero_pp_rank_1_mp_rank_00_model_states.pt', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/global_step915/zero_pp_rank_2_mp_rank_00_model_states.pt', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/global_step915/zero_pp_rank_3_mp_rank_00_model_states.pt', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/latest', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/model-00001-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/model-00002-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/model-00003-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/model-00004-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/model.safetensors.index.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/rng_state_0.pth', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/rng_state_1.pth', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/rng_state_2.pth', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/rng_state_3.pth', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/scheduler.pt', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/training_args.bin', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/zero_to_fp32.py', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00001-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00002-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00003-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00004-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model.safetensors.index.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": {""parameters"": {""BF16"": 8537680896}, ""total"": 8537680896}, ""security_repo_status"": null, ""lastModified"": ""2025-01-13 01:57:16+00:00"", ""cardData"": ""base_model: AmberYifan/Gemma-7b-sft-ultrachat-safeRLHF\nlibrary_name: transformers\nmodel_name: Gemma-7B-sft-SPIN-Gemma-2-27B\ntags:\n- generated_from_trainer\n- trl\n- dpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67845708183321c47a4bcfee"", ""modelId"": ""AmberYifan/Gemma-7B-sft-SPIN-Gemma-2-27B"", ""usedStorage"": 256170948004}",3,,0,"https://huggingface.co/mradermacher/Gemma-7B-sft-SPIN-Gemma-2-27B-GGUF, https://huggingface.co/mradermacher/Gemma-7B-sft-SPIN-Gemma-2-27B-i1-GGUF",2,,0,huggingface/InferenceSupport/discussions/new?title=AmberYifan/Gemma-7B-sft-SPIN-Gemma-2-27B&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5BAmberYifan%2FGemma-7B-sft-SPIN-Gemma-2-27B%5D(%2FAmberYifan%2FGemma-7B-sft-SPIN-Gemma-2-27B)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
AmberYifan/Gemma-7B-sft-SPIN-gpt4o,"---
base_model: AmberYifan/Gemma-7b-sft-ultrachat-safeRLHF
library_name: transformers
model_name: Gemma-7B-sft-SPIN-gpt4o
tags:
- generated_from_trainer
- trl
- dpo
licence: license
---

# Model Card for Gemma-7B-sft-SPIN-gpt4o

This model is a fine-tuned version of [AmberYifan/Gemma-7b-sft-ultrachat-safeRLHF](https://huggingface.co/AmberYifan/Gemma-7b-sft-ultrachat-safeRLHF).
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""AmberYifan/Gemma-7B-sft-SPIN-gpt4o"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/yifanwang/huggingface/runs/98t3c3rr)

This model was trained with DPO, a method introduced in [Direct Preference Optimization: Your Language Model is Secretly a Reward Model](https://huggingface.co/papers/2305.18290).

### Framework versions

- TRL: 0.12.2
- Transformers: 4.46.3
- Pytorch: 2.5.1+cu118
- Datasets: 3.2.0
- Tokenizers: 0.20.3

## Citations

Cite DPO as:

```bibtex
@inproceedings{rafailov2023direct,
    title        = {{Direct Preference Optimization: Your Language Model is Secretly a Reward Model}},
    author       = {Rafael Rafailov and Archit Sharma and Eric Mitchell and Christopher D. Manning and Stefano Ermon and Chelsea Finn},
    year         = 2023,
    booktitle    = {Advances in Neural Information Processing Systems 36: Annual Conference on Neural Information Processing Systems 2023, NeurIPS 2023, New Orleans, LA, USA, December 10 - 16, 2023},
    url          = {http://papers.nips.cc/paper_files/paper/2023/hash/a85b405ed65c6477a4fe8302b5e06ce7-Abstract-Conference.html},
    editor       = {Alice Oh and Tristan Naumann and Amir Globerson and Kate Saenko and Moritz Hardt and Sergey Levine},
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""AmberYifan/Gemma-7B-sft-SPIN-gpt4o"", ""author"": ""AmberYifan"", ""sha"": ""31869bfd0fc69ef83c6ec18705252f4c7adcded0"", ""last_modified"": ""2025-01-13 04:05:20+00:00"", ""created_at"": ""2025-01-13 02:06:00+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""trl"", ""dpo"", ""conversational"", ""arxiv:2305.18290"", ""base_model:AmberYifan/Gemma-7b-sft-ultrachat-safeRLHF"", ""base_model:finetune:AmberYifan/Gemma-7b-sft-ultrachat-safeRLHF"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: AmberYifan/Gemma-7b-sft-ultrachat-safeRLHF\nlibrary_name: transformers\nmodel_name: Gemma-7B-sft-SPIN-gpt4o\ntags:\n- generated_from_trainer\n- trl\n- dpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{% for message in messages %}\n{% if message['role'] == 'user' %}\n{{ '<|user|>\n' + message['content'] + eos_token }}\n{% elif message['role'] == 'system' %}\n{{ '<|system|>\n' + message['content'] + eos_token }}\n{% elif message['role'] == 'assistant' %}\n{{ '<|assistant|>\n'  + message['content'] + eos_token }}\n{% endif %}\n{% if loop.last and add_generation_prompt %}\n{{ '<|assistant|>' }}\n{% endif %}\n{% endfor %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='generation_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/generation_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/global_step305/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/global_step305/bf16_zero_pp_rank_1_mp_rank_00_optim_states.pt', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/global_step305/bf16_zero_pp_rank_2_mp_rank_00_optim_states.pt', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/global_step305/bf16_zero_pp_rank_3_mp_rank_00_optim_states.pt', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/global_step305/zero_pp_rank_0_mp_rank_00_model_states.pt', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/global_step305/zero_pp_rank_1_mp_rank_00_model_states.pt', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/global_step305/zero_pp_rank_2_mp_rank_00_model_states.pt', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/global_step305/zero_pp_rank_3_mp_rank_00_model_states.pt', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/global_step610/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/global_step610/bf16_zero_pp_rank_1_mp_rank_00_optim_states.pt', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/global_step610/bf16_zero_pp_rank_2_mp_rank_00_optim_states.pt', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/global_step610/bf16_zero_pp_rank_3_mp_rank_00_optim_states.pt', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/global_step610/zero_pp_rank_0_mp_rank_00_model_states.pt', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/global_step610/zero_pp_rank_1_mp_rank_00_model_states.pt', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/global_step610/zero_pp_rank_2_mp_rank_00_model_states.pt', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/global_step610/zero_pp_rank_3_mp_rank_00_model_states.pt', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/global_step915/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/global_step915/bf16_zero_pp_rank_1_mp_rank_00_optim_states.pt', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/global_step915/bf16_zero_pp_rank_2_mp_rank_00_optim_states.pt', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/global_step915/bf16_zero_pp_rank_3_mp_rank_00_optim_states.pt', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/global_step915/zero_pp_rank_0_mp_rank_00_model_states.pt', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/global_step915/zero_pp_rank_1_mp_rank_00_model_states.pt', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/global_step915/zero_pp_rank_2_mp_rank_00_model_states.pt', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/global_step915/zero_pp_rank_3_mp_rank_00_model_states.pt', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/latest', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/model-00001-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/model-00002-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/model-00003-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/model-00004-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/model.safetensors.index.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/rng_state_0.pth', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/rng_state_1.pth', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/rng_state_2.pth', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/rng_state_3.pth', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/scheduler.pt', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/training_args.bin', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='last-checkpoint/zero_to_fp32.py', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00001-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00002-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00003-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00004-of-00004.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model.safetensors.index.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": {""parameters"": {""BF16"": 8537680896}, ""total"": 8537680896}, ""security_repo_status"": null, ""lastModified"": ""2025-01-13 04:05:20+00:00"", ""cardData"": ""base_model: AmberYifan/Gemma-7b-sft-ultrachat-safeRLHF\nlibrary_name: transformers\nmodel_name: Gemma-7B-sft-SPIN-gpt4o\ntags:\n- generated_from_trainer\n- trl\n- dpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""678475082cff491fba767175"", ""modelId"": ""AmberYifan/Gemma-7B-sft-SPIN-gpt4o"", ""usedStorage"": 256170948004}",3,,0,https://huggingface.co/mradermacher/Gemma-7B-sft-SPIN-gpt4o-GGUF,1,,0,huggingface/InferenceSupport/discussions/new?title=AmberYifan/Gemma-7B-sft-SPIN-gpt4o&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5BAmberYifan%2FGemma-7B-sft-SPIN-gpt4o%5D(%2FAmberYifan%2FGemma-7B-sft-SPIN-gpt4o)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-orpo-noisy-4e-5,"---
base_model: google/gemma-7b
datasets:
- silviasapora/dpo_7k_noisy_10
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['silviasapora/dpo_7k_noisy_10']](https://huggingface.co/datasets/['silviasapora/dpo_7k_noisy_10']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-orpo-noisy-4e-5"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.13.0
- Transformers: 4.46.1
- Pytorch: 2.4.0
- Datasets: 3.1.0
- Tokenizers: 0.20.1

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-orpo-noisy-4e-5"", ""author"": ""silviasapora"", ""sha"": ""351ccf18b2f73cdaef179579511eb26a7330ebc3"", ""last_modified"": ""2025-01-23 19:55:30+00:00"", ""created_at"": ""2025-01-23 17:55:35+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:silviasapora/dpo_7k_noisy_10"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- silviasapora/dpo_7k_noisy_10\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan23_18-00-07_82272e4b10b1/events.out.tfevents.1737655224.82272e4b10b1.713.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-01-23 19:55:30+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- silviasapora/dpo_7k_noisy_10\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""6792829751fd9204fe29f0ab"", ""modelId"": ""silviasapora/gemma-7b-orpo-noisy-4e-5"", ""usedStorage"": 838779458}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-orpo-noisy-4e-5&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-orpo-noisy-4e-5%5D(%2Fsilviasapora%2Fgemma-7b-orpo-noisy-4e-5)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-borpo-noisy-6e-5,"---
base_model: google/gemma-7b
datasets:
- silviasapora/dpo_7k_noisy_10
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['silviasapora/dpo_7k_noisy_10']](https://huggingface.co/datasets/['silviasapora/dpo_7k_noisy_10']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-borpo-noisy-6e-5"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/cm8xb4wa) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.13.0
- Transformers: 4.46.1
- Pytorch: 2.4.0
- Datasets: 3.1.0
- Tokenizers: 0.20.1

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-borpo-noisy-6e-5"", ""author"": ""silviasapora"", ""sha"": ""6d6feb5f2c19fd51f27b7e61c2ed317ec03ead98"", ""last_modified"": ""2025-01-25 04:17:32+00:00"", ""created_at"": ""2025-01-23 19:39:39+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:silviasapora/dpo_7k_noisy_10"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- silviasapora/dpo_7k_noisy_10\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan23_19-24-39_82272e4b10b1/events.out.tfevents.1737660299.82272e4b10b1.1086.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan23_19-26-21_82272e4b10b1/events.out.tfevents.1737660445.82272e4b10b1.1272.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan23_19-34-51_82272e4b10b1/events.out.tfevents.1737660908.82272e4b10b1.1459.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan23_19-39-22_82272e4b10b1/events.out.tfevents.1737661181.82272e4b10b1.1645.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan23_19-52-21_82272e4b10b1/events.out.tfevents.1737661959.82272e4b10b1.1829.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan25_03-13-28_82272e4b10b1/events.out.tfevents.1737774842.82272e4b10b1.4274.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-01-25 04:17:32+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- silviasapora/dpo_7k_noisy_10\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67929afbfb4b03411a371fbd"", ""modelId"": ""silviasapora/gemma-7b-borpo-noisy-6e-5"", ""usedStorage"": 838807603}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-borpo-noisy-6e-5&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-borpo-noisy-6e-5%5D(%2Fsilviasapora%2Fgemma-7b-borpo-noisy-6e-5)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-borpo-shuffled-5e-5,"---
base_model: google/gemma-7b
datasets:
- silviasapora/argilla-mix-low
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['silviasapora/argilla-mix-low']](https://huggingface.co/datasets/['silviasapora/argilla-mix-low']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-borpo-shuffled-5e-5"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/qmpyc8el) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.13.0
- Transformers: 4.46.1
- Pytorch: 2.4.0
- Datasets: 3.1.0
- Tokenizers: 0.20.1

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-borpo-shuffled-5e-5"", ""author"": ""silviasapora"", ""sha"": ""9fb18166000bb99d9b6dec9c1255ab0195bf6e87"", ""last_modified"": ""2025-01-24 02:35:43+00:00"", ""created_at"": ""2025-01-23 19:55:03+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:silviasapora/argilla-mix-low"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- silviasapora/argilla-mix-low\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan23_19-54-45_82272e4b10b1/events.out.tfevents.1737662104.82272e4b10b1.2013.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan23_19-57-50_82272e4b10b1/events.out.tfevents.1737662297.82272e4b10b1.2213.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan23_20-19-39_82272e4b10b1/events.out.tfevents.1737663598.82272e4b10b1.2397.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan23_20-24-23_82272e4b10b1/events.out.tfevents.1737663881.82272e4b10b1.2581.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan23_20-28-00_82272e4b10b1/events.out.tfevents.1737664103.82272e4b10b1.2760.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan23_20-34-43_82272e4b10b1/events.out.tfevents.1737664504.82272e4b10b1.3237.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan24_00-31-09_82272e4b10b1/events.out.tfevents.1737678688.82272e4b10b1.1128.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-01-24 02:35:43+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- silviasapora/argilla-mix-low\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67929e9757b2fe2b1eccf0dc"", ""modelId"": ""silviasapora/gemma-7b-borpo-shuffled-5e-5"", ""usedStorage"": 838824277}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-borpo-shuffled-5e-5&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-borpo-shuffled-5e-5%5D(%2Fsilviasapora%2Fgemma-7b-borpo-shuffled-5e-5)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-borpo-noisy-5e-5,"---
base_model: google/gemma-7b
datasets:
- silviasapora/dpo_7k_noisy_10
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['silviasapora/dpo_7k_noisy_10']](https://huggingface.co/datasets/['silviasapora/dpo_7k_noisy_10']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-borpo-noisy-5e-5"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.13.0
- Transformers: 4.46.1
- Pytorch: 2.4.0
- Datasets: 3.1.0
- Tokenizers: 0.20.1

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-borpo-noisy-5e-5"", ""author"": ""silviasapora"", ""sha"": ""e246686af5bda3d5f44659e141e0eb21c6b1d37c"", ""last_modified"": ""2025-01-24 00:27:45+00:00"", ""created_at"": ""2025-01-23 20:39:08+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:silviasapora/dpo_7k_noisy_10"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- silviasapora/dpo_7k_noisy_10\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan23_20-38-51_82272e4b10b1/events.out.tfevents.1737664753.82272e4b10b1.194.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan23_22-14-25_82272e4b10b1/events.out.tfevents.1737670482.82272e4b10b1.568.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan23_22-15-15_82272e4b10b1/events.out.tfevents.1737670532.82272e4b10b1.750.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan23_22-30-56_82272e4b10b1/events.out.tfevents.1737671476.82272e4b10b1.936.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-01-24 00:27:45+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- silviasapora/dpo_7k_noisy_10\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""6792a8ecd931a18905b39233"", ""modelId"": ""silviasapora/gemma-7b-borpo-noisy-5e-5"", ""usedStorage"": 838835876}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-borpo-noisy-5e-5&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-borpo-noisy-5e-5%5D(%2Fsilviasapora%2Fgemma-7b-borpo-noisy-5e-5)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-orpo-noisy-5e-5,"---
base_model: google/gemma-7b
datasets:
- silviasapora/dpo_7k_noisy_10
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['silviasapora/dpo_7k_noisy_10']](https://huggingface.co/datasets/['silviasapora/dpo_7k_noisy_10']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-orpo-noisy-5e-5"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/nlvt2go3) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.13.0
- Transformers: 4.46.1
- Pytorch: 2.4.0
- Datasets: 3.1.0
- Tokenizers: 0.20.1

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-orpo-noisy-5e-5"", ""author"": ""silviasapora"", ""sha"": ""8e0af2ca4e6247e96e6c042ee75614ee6dd4e761"", ""last_modified"": ""2025-01-24 08:31:44+00:00"", ""created_at"": ""2025-01-24 06:35:54+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:silviasapora/dpo_7k_noisy_10"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- silviasapora/dpo_7k_noisy_10\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan24_06-35-36_82272e4b10b1/events.out.tfevents.1737700555.82272e4b10b1.2626.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-01-24 08:31:44+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- silviasapora/dpo_7k_noisy_10\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""679334caa4def0fec405ff7f"", ""modelId"": ""silviasapora/gemma-7b-orpo-noisy-5e-5"", ""usedStorage"": 838779471}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-orpo-noisy-5e-5&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-orpo-noisy-5e-5%5D(%2Fsilviasapora%2Fgemma-7b-orpo-noisy-5e-5)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-borpo-shuffled-6e-5,"---
base_model: google/gemma-7b
datasets:
- silviasapora/argilla-mix-low
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['silviasapora/argilla-mix-low']](https://huggingface.co/datasets/['silviasapora/argilla-mix-low']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-borpo-shuffled-6e-5"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/ybu7luf2) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.13.0
- Transformers: 4.46.1
- Pytorch: 2.4.0
- Datasets: 3.1.0
- Tokenizers: 0.20.1

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-borpo-shuffled-6e-5"", ""author"": ""silviasapora"", ""sha"": ""1b0b19d646097aa77e014498ffb61ac2de6442cb"", ""last_modified"": ""2025-01-25 05:26:45+00:00"", ""created_at"": ""2025-01-25 04:18:15+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:silviasapora/argilla-mix-low"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- silviasapora/argilla-mix-low\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan25_04-17-57_82272e4b10b1/events.out.tfevents.1737778696.82272e4b10b1.4898.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-01-25 05:26:45+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- silviasapora/argilla-mix-low\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""6794660718141b20c4c01aba"", ""modelId"": ""silviasapora/gemma-7b-borpo-shuffled-6e-5"", ""usedStorage"": 838785566}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-borpo-shuffled-6e-5&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-borpo-shuffled-6e-5%5D(%2Fsilviasapora%2Fgemma-7b-borpo-shuffled-6e-5)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-orpo-shuffled-6e-5,"---
base_model: google/gemma-7b
datasets:
- silviasapora/argilla-mix-low
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['silviasapora/argilla-mix-low']](https://huggingface.co/datasets/['silviasapora/argilla-mix-low']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-orpo-shuffled-6e-5"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/szgridhd) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.13.0
- Transformers: 4.46.1
- Pytorch: 2.4.0
- Datasets: 3.1.0
- Tokenizers: 0.20.1

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-orpo-shuffled-6e-5"", ""author"": ""silviasapora"", ""sha"": ""d83d258089ecda4593b734d473b750fff1ffe1fa"", ""last_modified"": ""2025-01-25 06:36:12+00:00"", ""created_at"": ""2025-01-25 05:27:28+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:silviasapora/argilla-mix-low"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- silviasapora/argilla-mix-low\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan25_05-27-09_82272e4b10b1/events.out.tfevents.1737782849.82272e4b10b1.5524.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-01-25 06:36:12+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- silviasapora/argilla-mix-low\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""6794764018141b20c4c5b3db"", ""modelId"": ""silviasapora/gemma-7b-orpo-shuffled-6e-5"", ""usedStorage"": 838785564}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-orpo-shuffled-6e-5&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-orpo-shuffled-6e-5%5D(%2Fsilviasapora%2Fgemma-7b-orpo-shuffled-6e-5)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-orpo-noisy-6e-5,"---
base_model: google/gemma-7b
datasets:
- silviasapora/dpo_7k_noisy_10
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['silviasapora/dpo_7k_noisy_10']](https://huggingface.co/datasets/['silviasapora/dpo_7k_noisy_10']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-orpo-noisy-6e-5"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/n7tdj845) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.13.0
- Transformers: 4.46.1
- Pytorch: 2.4.0
- Datasets: 3.1.0
- Tokenizers: 0.20.1

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-orpo-noisy-6e-5"", ""author"": ""silviasapora"", ""sha"": ""a4365b4394878ba276b1a8b6b2ad24af0a87e4ae"", ""last_modified"": ""2025-01-25 07:40:21+00:00"", ""created_at"": ""2025-01-25 06:36:55+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:silviasapora/dpo_7k_noisy_10"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- silviasapora/dpo_7k_noisy_10\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan25_06-36-37_82272e4b10b1/events.out.tfevents.1737787016.82272e4b10b1.6149.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-01-25 07:40:21+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- silviasapora/dpo_7k_noisy_10\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67948687aeb1a235ae43c5c8"", ""modelId"": ""silviasapora/gemma-7b-orpo-noisy-6e-5"", ""usedStorage"": 838779471}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-orpo-noisy-6e-5&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-orpo-noisy-6e-5%5D(%2Fsilviasapora%2Fgemma-7b-orpo-noisy-6e-5)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-borpo-noisy-5e-5-norm,"---
base_model: google/gemma-7b
datasets:
- silviasapora/dpo_7k_noisy_10
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['silviasapora/dpo_7k_noisy_10']](https://huggingface.co/datasets/['silviasapora/dpo_7k_noisy_10']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-borpo-noisy-5e-5-norm"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/fgpoejgs) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.13.0
- Transformers: 4.48.1
- Pytorch: 2.5.1
- Datasets: 3.2.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-borpo-noisy-5e-5-norm"", ""author"": ""silviasapora"", ""sha"": ""bdc4e6b95f7c682fc20782bf9672ab0cc61e81b3"", ""last_modified"": ""2025-01-26 20:29:50+00:00"", ""created_at"": ""2025-01-25 18:02:27+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:silviasapora/dpo_7k_noisy_10"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- silviasapora/dpo_7k_noisy_10\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan25_18-02-11_82272e4b10b1/events.out.tfevents.1737828148.82272e4b10b1.20035.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan25_21-59-47_82272e4b10b1/events.out.tfevents.1737842406.82272e4b10b1.21039.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan26_18-11-49_e967ea18ab86/events.out.tfevents.1737915121.e967ea18ab86.7889.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan26_18-13-11_e967ea18ab86/events.out.tfevents.1737915203.e967ea18ab86.8939.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-01-26 20:29:50+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- silviasapora/dpo_7k_noisy_10\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""679527333e8ddcbdcaa9eb08"", ""modelId"": ""silviasapora/gemma-7b-borpo-noisy-5e-5-norm"", ""usedStorage"": 3239213628}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-borpo-noisy-5e-5-norm&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-borpo-noisy-5e-5-norm%5D(%2Fsilviasapora%2Fgemma-7b-borpo-noisy-5e-5-norm)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-borpo-shuffled-1e-5-norm,"---
base_model: google/gemma-7b
datasets:
- silviasapora/argilla-mix-low
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['silviasapora/argilla-mix-low']](https://huggingface.co/datasets/['silviasapora/argilla-mix-low']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-borpo-shuffled-1e-5-norm"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/2g3juwqw) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.13.0
- Transformers: 4.48.1
- Pytorch: 2.5.1
- Datasets: 3.2.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-borpo-shuffled-1e-5-norm"", ""author"": ""silviasapora"", ""sha"": ""63c73e0c96ca9f118e8349f0c296c9305eff2408"", ""last_modified"": ""2025-01-25 21:19:48+00:00"", ""created_at"": ""2025-01-25 18:58:15+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 1, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:silviasapora/argilla-mix-low"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- silviasapora/argilla-mix-low\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan25_18-57-22_b8708497d66a/events.out.tfevents.1737831496.b8708497d66a.86449.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-01-25 21:19:48+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- silviasapora/argilla-mix-low\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""679534477534713f944c6ca1"", ""modelId"": ""silviasapora/gemma-7b-borpo-shuffled-1e-5-norm"", ""usedStorage"": 1638849127}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-borpo-shuffled-1e-5-norm&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-borpo-shuffled-1e-5-norm%5D(%2Fsilviasapora%2Fgemma-7b-borpo-shuffled-1e-5-norm)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-borpo-shuffled-5e-5-norm,"---
base_model: google/gemma-7b
datasets:
- silviasapora/argilla-mix-low
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['silviasapora/argilla-mix-low']](https://huggingface.co/datasets/['silviasapora/argilla-mix-low']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-borpo-shuffled-5e-5-norm"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/hjdjxiph) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.13.0
- Transformers: 4.48.1
- Pytorch: 2.5.1
- Datasets: 3.2.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-borpo-shuffled-5e-5-norm"", ""author"": ""silviasapora"", ""sha"": ""e7df4cf2739f1cec928a2daac4b2faca9b1b8215"", ""last_modified"": ""2025-01-27 21:20:07+00:00"", ""created_at"": ""2025-01-25 19:05:59+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:silviasapora/argilla-mix-low"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- silviasapora/argilla-mix-low\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan25_19-05-49_b8708497d66a/events.out.tfevents.1737831962.b8708497d66a.91622.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan25_19-05-49_b8708497d66a/events.out.tfevents.1737831963.b8708497d66a.91617.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan27_18-55-07_b4d476355ce0/events.out.tfevents.1738004161.b4d476355ce0.104907.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-01-27 21:20:07+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- silviasapora/argilla-mix-low\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""6795361739bf18bcca5771b4"", ""modelId"": ""silviasapora/gemma-7b-borpo-shuffled-5e-5-norm"", ""usedStorage"": 4839347606}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-borpo-shuffled-5e-5-norm&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-borpo-shuffled-5e-5-norm%5D(%2Fsilviasapora%2Fgemma-7b-borpo-shuffled-5e-5-norm)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-borpo-shuffled-7e-5-norm,"---
base_model: google/gemma-7b
datasets:
- silviasapora/argilla-mix-low
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['silviasapora/argilla-mix-low']](https://huggingface.co/datasets/['silviasapora/argilla-mix-low']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-borpo-shuffled-7e-5-norm"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/va2vrajx) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.13.0
- Transformers: 4.48.1
- Pytorch: 2.5.1
- Datasets: 3.2.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-borpo-shuffled-7e-5-norm"", ""author"": ""silviasapora"", ""sha"": ""6d0d88e58dda633d901ebf603d6bb6216917d390"", ""last_modified"": ""2025-01-25 21:27:13+00:00"", ""created_at"": ""2025-01-25 19:06:00+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 1, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:silviasapora/argilla-mix-low"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- silviasapora/argilla-mix-low\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan25_19-05-49_b8708497d66a/events.out.tfevents.1737831962.b8708497d66a.91619.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-01-25 21:27:13+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- silviasapora/argilla-mix-low\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""6795361846f22e87c86c4097"", ""modelId"": ""silviasapora/gemma-7b-borpo-shuffled-7e-5-norm"", ""usedStorage"": 1638849129}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-borpo-shuffled-7e-5-norm&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-borpo-shuffled-7e-5-norm%5D(%2Fsilviasapora%2Fgemma-7b-borpo-shuffled-7e-5-norm)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-borpo-noisy-1e-5-norm,"---
base_model: google/gemma-7b
datasets:
- silviasapora/dpo_7k_noisy_10
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['silviasapora/dpo_7k_noisy_10']](https://huggingface.co/datasets/['silviasapora/dpo_7k_noisy_10']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-borpo-noisy-1e-5-norm"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/7kgum8xr) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.13.0
- Transformers: 4.46.1
- Pytorch: 2.4.0
- Datasets: 3.1.0
- Tokenizers: 0.20.1

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-borpo-noisy-1e-5-norm"", ""author"": ""silviasapora"", ""sha"": ""0a1e809980647d8140ed51a6cf452d1aa367c873"", ""last_modified"": ""2025-01-25 21:58:22+00:00"", ""created_at"": ""2025-01-25 19:58:41+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:silviasapora/dpo_7k_noisy_10"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- silviasapora/dpo_7k_noisy_10\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan25_19-57-36_82272e4b10b1/events.out.tfevents.1737835122.82272e4b10b1.20539.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-01-25 21:58:22+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- silviasapora/dpo_7k_noisy_10\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""679542712ec68b4193a5af12"", ""modelId"": ""silviasapora/gemma-7b-borpo-noisy-1e-5-norm"", ""usedStorage"": 838779553}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-borpo-noisy-1e-5-norm&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-borpo-noisy-1e-5-norm%5D(%2Fsilviasapora%2Fgemma-7b-borpo-noisy-1e-5-norm)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-orpo-noisy-1e-5-norm,"---
base_model: google/gemma-7b
datasets:
- silviasapora/dpo_7k_noisy_10
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['silviasapora/dpo_7k_noisy_10']](https://huggingface.co/datasets/['silviasapora/dpo_7k_noisy_10']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-orpo-noisy-1e-5-norm"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/ytq75ba2) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.13.0
- Transformers: 4.48.1
- Pytorch: 2.5.1
- Datasets: 3.2.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-orpo-noisy-1e-5-norm"", ""author"": ""silviasapora"", ""sha"": ""59a0a56dc2cfa00ed5ac3c0ca57b3d0affd15466"", ""last_modified"": ""2025-01-25 23:34:14+00:00"", ""created_at"": ""2025-01-25 21:18:02+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:silviasapora/dpo_7k_noisy_10"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- silviasapora/dpo_7k_noisy_10\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan25_21-17-52_e967ea18ab86/events.out.tfevents.1737839883.e967ea18ab86.3499.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-01-25 23:34:14+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- silviasapora/dpo_7k_noisy_10\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""6795550aaaa2da41211659c0"", ""modelId"": ""silviasapora/gemma-7b-orpo-noisy-1e-5-norm"", ""usedStorage"": 1638843096}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-orpo-noisy-1e-5-norm&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-orpo-noisy-1e-5-norm%5D(%2Fsilviasapora%2Fgemma-7b-orpo-noisy-1e-5-norm)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-orpo-shuffled-1e-5-norm,"---
base_model: google/gemma-7b
datasets:
- silviasapora/argilla-mix-low
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['silviasapora/argilla-mix-low']](https://huggingface.co/datasets/['silviasapora/argilla-mix-low']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-orpo-shuffled-1e-5-norm"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/1ucj7mru) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.13.0
- Transformers: 4.48.1
- Pytorch: 2.5.1
- Datasets: 3.2.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-orpo-shuffled-1e-5-norm"", ""author"": ""silviasapora"", ""sha"": ""3456054dc99444400b67f9f50b5d1e7a5c2dd656"", ""last_modified"": ""2025-01-25 23:45:49+00:00"", ""created_at"": ""2025-01-25 21:22:07+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:silviasapora/argilla-mix-low"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- silviasapora/argilla-mix-low\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan25_21-21-16_b8708497d66a/events.out.tfevents.1737840130.b8708497d66a.163641.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-01-25 23:45:49+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- silviasapora/argilla-mix-low\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""679555ff5512d18930565baf"", ""modelId"": ""silviasapora/gemma-7b-orpo-shuffled-1e-5-norm"", ""usedStorage"": 1638849125}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-orpo-shuffled-1e-5-norm&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-orpo-shuffled-1e-5-norm%5D(%2Fsilviasapora%2Fgemma-7b-orpo-shuffled-1e-5-norm)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-orpo-noisy-5e-6-norm,"---
base_model: google/gemma-7b
datasets:
- silviasapora/dpo_7k_noisy_10
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['silviasapora/dpo_7k_noisy_10']](https://huggingface.co/datasets/['silviasapora/dpo_7k_noisy_10']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-orpo-noisy-5e-6-norm"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/737acx2r) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.13.0
- Transformers: 4.48.1
- Pytorch: 2.5.1
- Datasets: 3.2.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-orpo-noisy-5e-6-norm"", ""author"": ""silviasapora"", ""sha"": ""4a1074183e27696c7262de696cc1298f53051178"", ""last_modified"": ""2025-01-26 15:43:57+00:00"", ""created_at"": ""2025-01-25 21:34:46+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 2, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:silviasapora/dpo_7k_noisy_10"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- silviasapora/dpo_7k_noisy_10\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan25_21-34-36_e967ea18ab86/events.out.tfevents.1737840889.e967ea18ab86.4188.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan26_13-27-48_e967ea18ab86/events.out.tfevents.1737898079.e967ea18ab86.7161.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-01-26 15:43:57+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- silviasapora/dpo_7k_noisy_10\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""679558f64fccd4b951602f2b"", ""modelId"": ""silviasapora/gemma-7b-orpo-noisy-5e-6-norm"", ""usedStorage"": 3239089148}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-orpo-noisy-5e-6-norm&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-orpo-noisy-5e-6-norm%5D(%2Fsilviasapora%2Fgemma-7b-orpo-noisy-5e-6-norm)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-orpo-noisy-7e-5-norm,"---
base_model: google/gemma-7b
datasets:
- silviasapora/dpo_7k_noisy_10
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['silviasapora/dpo_7k_noisy_10']](https://huggingface.co/datasets/['silviasapora/dpo_7k_noisy_10']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-orpo-noisy-7e-5-norm"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/rds7ebnu) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.13.0
- Transformers: 4.48.1
- Pytorch: 2.5.1
- Datasets: 3.2.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-orpo-noisy-7e-5-norm"", ""author"": ""silviasapora"", ""sha"": ""59acbea4bc2392666de0e24991f26a28c6e69000"", ""last_modified"": ""2025-01-25 23:50:59+00:00"", ""created_at"": ""2025-01-25 21:34:47+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 3, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:silviasapora/dpo_7k_noisy_10"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- silviasapora/dpo_7k_noisy_10\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan25_21-34-37_e967ea18ab86/events.out.tfevents.1737840888.e967ea18ab86.4185.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-01-25 23:50:59+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- silviasapora/dpo_7k_noisy_10\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""679558f7e0bae7ff706e6ed2"", ""modelId"": ""silviasapora/gemma-7b-orpo-noisy-7e-5-norm"", ""usedStorage"": 1638843098}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-orpo-noisy-7e-5-norm&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-orpo-noisy-7e-5-norm%5D(%2Fsilviasapora%2Fgemma-7b-orpo-noisy-7e-5-norm)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-orpo-shuffled-7e-5-norm,"---
base_model: google/gemma-7b
datasets:
- silviasapora/argilla-mix-low
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['silviasapora/argilla-mix-low']](https://huggingface.co/datasets/['silviasapora/argilla-mix-low']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-orpo-shuffled-7e-5-norm"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/g01xa3im) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.13.0
- Transformers: 4.48.1
- Pytorch: 2.5.1
- Datasets: 3.2.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-orpo-shuffled-7e-5-norm"", ""author"": ""silviasapora"", ""sha"": ""fb8b32c7dadedaf0d6b17d93290d2890b5915602"", ""last_modified"": ""2025-01-26 00:00:27+00:00"", ""created_at"": ""2025-01-25 21:36:18+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 2, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:silviasapora/argilla-mix-low"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- silviasapora/argilla-mix-low\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan25_21-36-08_b8708497d66a/events.out.tfevents.1737840979.b8708497d66a.171798.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-01-26 00:00:27+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- silviasapora/argilla-mix-low\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""679559529638a73609d4003d"", ""modelId"": ""silviasapora/gemma-7b-orpo-shuffled-7e-5-norm"", ""usedStorage"": 1638849127}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-orpo-shuffled-7e-5-norm&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-orpo-shuffled-7e-5-norm%5D(%2Fsilviasapora%2Fgemma-7b-orpo-shuffled-7e-5-norm)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-orpo-shuffled-5e-5-norm,"---
base_model: google/gemma-7b
datasets:
- silviasapora/argilla-mix-low
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['silviasapora/argilla-mix-low']](https://huggingface.co/datasets/['silviasapora/argilla-mix-low']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-orpo-shuffled-5e-5-norm"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/kx8fonb2) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.13.0
- Transformers: 4.48.1
- Pytorch: 2.5.1
- Datasets: 3.2.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-orpo-shuffled-5e-5-norm"", ""author"": ""silviasapora"", ""sha"": ""a39488798e8eef9fdd49ba3d06d1135038d274c2"", ""last_modified"": ""2025-01-26 00:00:54+00:00"", ""created_at"": ""2025-01-25 21:36:18+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 1, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:silviasapora/argilla-mix-low"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- silviasapora/argilla-mix-low\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan25_21-36-08_b8708497d66a/events.out.tfevents.1737840980.b8708497d66a.171793.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan25_21-36-08_b8708497d66a/events.out.tfevents.1737840981.b8708497d66a.171797.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-01-26 00:00:54+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- silviasapora/argilla-mix-low\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67955952d4afc6fb1c0be91a"", ""modelId"": ""silviasapora/gemma-7b-orpo-shuffled-5e-5-norm"", ""usedStorage"": 3239225344}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-orpo-shuffled-5e-5-norm&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-orpo-shuffled-5e-5-norm%5D(%2Fsilviasapora%2Fgemma-7b-orpo-shuffled-5e-5-norm)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-orpo-noisy-5e-5-norm,"---
base_model: google/gemma-7b
datasets:
- silviasapora/dpo_7k_noisy_10
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['silviasapora/dpo_7k_noisy_10']](https://huggingface.co/datasets/['silviasapora/dpo_7k_noisy_10']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-orpo-noisy-5e-5-norm"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/uid4aign) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.13.0
- Transformers: 4.48.1
- Pytorch: 2.5.1
- Datasets: 3.2.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-orpo-noisy-5e-5-norm"", ""author"": ""silviasapora"", ""sha"": ""5d3bd9b12ef3cf10a175e04076decdb5a90dff0e"", ""last_modified"": ""2025-01-26 01:51:14+00:00"", ""created_at"": ""2025-01-25 23:35:18+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 3, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:silviasapora/dpo_7k_noisy_10"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- silviasapora/dpo_7k_noisy_10\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan25_23-35-08_e967ea18ab86/events.out.tfevents.1737848120.e967ea18ab86.5160.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-01-26 01:51:14+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- silviasapora/dpo_7k_noisy_10\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67957536b48d2ba1065f4bc1"", ""modelId"": ""silviasapora/gemma-7b-orpo-noisy-5e-5-norm"", ""usedStorage"": 1638843096}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-orpo-noisy-5e-5-norm&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-orpo-noisy-5e-5-norm%5D(%2Fsilviasapora%2Fgemma-7b-orpo-noisy-5e-5-norm)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-borpo-noisy-7e-5-norm,"---
base_model: google/gemma-7b
datasets:
- silviasapora/dpo_7k_noisy_10
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['silviasapora/dpo_7k_noisy_10']](https://huggingface.co/datasets/['silviasapora/dpo_7k_noisy_10']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-borpo-noisy-7e-5-norm"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/ak6yt8s0) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.13.0
- Transformers: 4.48.1
- Pytorch: 2.5.1
- Datasets: 3.2.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-borpo-noisy-7e-5-norm"", ""author"": ""silviasapora"", ""sha"": ""5950e3644c6fc66cf997afe1f39878a2ba3884fa"", ""last_modified"": ""2025-01-26 02:04:19+00:00"", ""created_at"": ""2025-01-25 23:50:09+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 3, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:silviasapora/dpo_7k_noisy_10"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- silviasapora/dpo_7k_noisy_10\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan25_23-49-59_b8708497d66a/events.out.tfevents.1737849012.b8708497d66a.200078.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-01-26 02:04:19+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- silviasapora/dpo_7k_noisy_10\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""679578b122990ae89be51850"", ""modelId"": ""silviasapora/gemma-7b-borpo-noisy-7e-5-norm"", ""usedStorage"": 1638843101}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-borpo-noisy-7e-5-norm&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-borpo-noisy-7e-5-norm%5D(%2Fsilviasapora%2Fgemma-7b-borpo-noisy-7e-5-norm)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-borpo-shuffled-5e-6-norm,"---
base_model: google/gemma-7b
datasets:
- silviasapora/argilla-mix-low
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['silviasapora/argilla-mix-low']](https://huggingface.co/datasets/['silviasapora/argilla-mix-low']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-borpo-shuffled-5e-6-norm"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/gidddsi5) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.13.0
- Transformers: 4.48.1
- Pytorch: 2.5.1
- Datasets: 3.2.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-borpo-shuffled-5e-6-norm"", ""author"": ""silviasapora"", ""sha"": ""fec4ea5f46663d1e13ab5be0e865b1d694ba1f46"", ""last_modified"": ""2025-01-26 15:04:15+00:00"", ""created_at"": ""2025-01-26 12:42:57+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 2, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:silviasapora/argilla-mix-low"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- silviasapora/argilla-mix-low\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan26_12-42-03_e967ea18ab86/events.out.tfevents.1737895379.e967ea18ab86.5760.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-01-26 15:04:15+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- silviasapora/argilla-mix-low\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67962dd1ecba76aee8af97be"", ""modelId"": ""silviasapora/gemma-7b-borpo-shuffled-5e-6-norm"", ""usedStorage"": 1638849128}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-borpo-shuffled-5e-6-norm&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-borpo-shuffled-5e-6-norm%5D(%2Fsilviasapora%2Fgemma-7b-borpo-shuffled-5e-6-norm)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-borpo-noisy-5e-6-norm,"---
base_model: google/gemma-7b
datasets:
- silviasapora/dpo_7k_noisy_10
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['silviasapora/dpo_7k_noisy_10']](https://huggingface.co/datasets/['silviasapora/dpo_7k_noisy_10']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-borpo-noisy-5e-6-norm"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/o3qvsr7s) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.13.0
- Transformers: 4.48.1
- Pytorch: 2.5.1
- Datasets: 3.2.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-borpo-noisy-5e-6-norm"", ""author"": ""silviasapora"", ""sha"": ""7e60038a8b3c6cdc271fc81c78d1ed9187b9e961"", ""last_modified"": ""2025-01-26 15:22:52+00:00"", ""created_at"": ""2025-01-26 13:08:33+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 3, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:silviasapora/dpo_7k_noisy_10"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- silviasapora/dpo_7k_noisy_10\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan26_13-07-43_e967ea18ab86/events.out.tfevents.1737896915.e967ea18ab86.6486.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-01-26 15:22:52+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- silviasapora/dpo_7k_noisy_10\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""679633d188cd7c02947eb261"", ""modelId"": ""silviasapora/gemma-7b-borpo-noisy-5e-6-norm"", ""usedStorage"": 1638843099}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-borpo-noisy-5e-6-norm&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-borpo-noisy-5e-6-norm%5D(%2Fsilviasapora%2Fgemma-7b-borpo-noisy-5e-6-norm)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-borpo-shuffled-5e-5-norm2,"---
base_model: google/gemma-7b
datasets:
- silviasapora/argilla-mix-low
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['silviasapora/argilla-mix-low']](https://huggingface.co/datasets/['silviasapora/argilla-mix-low']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-borpo-shuffled-5e-5-norm2"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/ohikmhmm) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.13.0
- Transformers: 4.48.1
- Pytorch: 2.5.1
- Datasets: 3.2.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-borpo-shuffled-5e-5-norm2"", ""author"": ""silviasapora"", ""sha"": ""c69daaaa7e5dbb0c5d14520101e080ef24ebf8ae"", ""last_modified"": ""2025-01-26 20:36:30+00:00"", ""created_at"": ""2025-01-26 18:12:00+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 3, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:silviasapora/argilla-mix-low"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- silviasapora/argilla-mix-low\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan26_18-11-49_e967ea18ab86/events.out.tfevents.1737915121.e967ea18ab86.7886.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan26_18-13-11_e967ea18ab86/events.out.tfevents.1737915203.e967ea18ab86.8936.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-01-26 20:36:30+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- silviasapora/argilla-mix-low\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67967af090859eaad7bc8e41"", ""modelId"": ""silviasapora/gemma-7b-borpo-shuffled-5e-5-norm2"", ""usedStorage"": 1638854655}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-borpo-shuffled-5e-5-norm2&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-borpo-shuffled-5e-5-norm2%5D(%2Fsilviasapora%2Fgemma-7b-borpo-shuffled-5e-5-norm2)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-borpo-shuffled-5e-5-norm-shuf,"---
base_model: google/gemma-7b
datasets:
- silviasapora/argilla-mix-low
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['silviasapora/argilla-mix-low']](https://huggingface.co/datasets/['silviasapora/argilla-mix-low']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-borpo-shuffled-5e-5-norm-shuf"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/jh5hp8n6) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.13.0
- Transformers: 4.48.1
- Pytorch: 2.5.1
- Datasets: 3.2.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-borpo-shuffled-5e-5-norm-shuf"", ""author"": ""silviasapora"", ""sha"": ""6fa8452644531dc70303b16bfb84b8cb532e5d3e"", ""last_modified"": ""2025-01-26 21:13:02+00:00"", ""created_at"": ""2025-01-26 18:15:48+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 2, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:silviasapora/argilla-mix-low"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- silviasapora/argilla-mix-low\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan26_18-15-38_e967ea18ab86/events.out.tfevents.1737915349.e967ea18ab86.9861.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan26_18-16-47_e967ea18ab86/events.out.tfevents.1737915419.e967ea18ab86.10395.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan26_18-49-02_e967ea18ab86/events.out.tfevents.1737917353.e967ea18ab86.11503.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-01-26 21:13:02+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- silviasapora/argilla-mix-low\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67967bd467fbbe1803d92b49"", ""modelId"": ""silviasapora/gemma-7b-borpo-shuffled-5e-5-norm-shuf"", ""usedStorage"": 1638872890}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-borpo-shuffled-5e-5-norm-shuf&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-borpo-shuffled-5e-5-norm-shuf%5D(%2Fsilviasapora%2Fgemma-7b-borpo-shuffled-5e-5-norm-shuf)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-borpo-noisy-7e-5-norm2,"---
base_model: google/gemma-7b
datasets:
- silviasapora/dpo_7k_noisy_10
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['silviasapora/dpo_7k_noisy_10']](https://huggingface.co/datasets/['silviasapora/dpo_7k_noisy_10']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-borpo-noisy-7e-5-norm2"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/i2kbz7ez) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.13.0
- Transformers: 4.48.1
- Pytorch: 2.5.1
- Datasets: 3.2.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-borpo-noisy-7e-5-norm2"", ""author"": ""silviasapora"", ""sha"": ""7ea4a04a05fcd2c5c9bed14ef6ffb4806cb8c3d3"", ""last_modified"": ""2025-01-26 20:35:09+00:00"", ""created_at"": ""2025-01-26 18:19:01+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 2, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:silviasapora/dpo_7k_noisy_10"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- silviasapora/dpo_7k_noisy_10\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan26_18-18-51_e967ea18ab86/events.out.tfevents.1737915543.e967ea18ab86.10928.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-01-26 20:35:09+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- silviasapora/dpo_7k_noisy_10\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67967c9518a4cf53cf588b9c"", ""modelId"": ""silviasapora/gemma-7b-borpo-noisy-7e-5-norm2"", ""usedStorage"": 1638843104}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-borpo-noisy-7e-5-norm2&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-borpo-noisy-7e-5-norm2%5D(%2Fsilviasapora%2Fgemma-7b-borpo-noisy-7e-5-norm2)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-borpo-noisy-1e-5-norm2,"---
base_model: google/gemma-7b
datasets:
- silviasapora/dpo_7k_noisy_10
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['silviasapora/dpo_7k_noisy_10']](https://huggingface.co/datasets/['silviasapora/dpo_7k_noisy_10']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-borpo-noisy-1e-5-norm2"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/30nmmu44) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.13.0
- Transformers: 4.48.1
- Pytorch: 2.5.1
- Datasets: 3.2.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-borpo-noisy-1e-5-norm2"", ""author"": ""silviasapora"", ""sha"": ""2044be1213cef829aeb03e7103869cb2c8f29326"", ""last_modified"": ""2025-01-26 20:38:46+00:00"", ""created_at"": ""2025-01-26 18:21:00+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 2, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:silviasapora/dpo_7k_noisy_10"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- silviasapora/dpo_7k_noisy_10\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan26_18-20-50_b8708497d66a/events.out.tfevents.1737915662.b8708497d66a.517553.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan26_18-22-47_b8708497d66a/events.out.tfevents.1737915779.b8708497d66a.519891.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-01-26 20:38:46+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- silviasapora/dpo_7k_noisy_10\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67967d0ca59233c1dda647c7"", ""modelId"": ""silviasapora/gemma-7b-borpo-noisy-1e-5-norm2"", ""usedStorage"": 1638848617}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-borpo-noisy-1e-5-norm2&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-borpo-noisy-1e-5-norm2%5D(%2Fsilviasapora%2Fgemma-7b-borpo-noisy-1e-5-norm2)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-borpo-noisy-5e-6-norm2,"---
base_model: google/gemma-7b
datasets:
- silviasapora/dpo_7k_noisy_10
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['silviasapora/dpo_7k_noisy_10']](https://huggingface.co/datasets/['silviasapora/dpo_7k_noisy_10']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-borpo-noisy-5e-6-norm2"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/6qp64s1w) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.13.0
- Transformers: 4.48.1
- Pytorch: 2.5.1
- Datasets: 3.2.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-borpo-noisy-5e-6-norm2"", ""author"": ""silviasapora"", ""sha"": ""bfa5ee3d97c210c8a9dfd91d09fcfc8ae3828c2f"", ""last_modified"": ""2025-01-26 20:38:19+00:00"", ""created_at"": ""2025-01-26 18:21:46+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 2, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:silviasapora/dpo_7k_noisy_10"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- silviasapora/dpo_7k_noisy_10\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan26_18-21-36_b8708497d66a/events.out.tfevents.1737915708.b8708497d66a.518578.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan26_18-22-47_b8708497d66a/events.out.tfevents.1737915779.b8708497d66a.519890.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-01-26 20:38:19+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- silviasapora/dpo_7k_noisy_10\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67967d3add74aca566693a8b"", ""modelId"": ""silviasapora/gemma-7b-borpo-noisy-5e-6-norm2"", ""usedStorage"": 1638848617}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-borpo-noisy-5e-6-norm2&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-borpo-noisy-5e-6-norm2%5D(%2Fsilviasapora%2Fgemma-7b-borpo-noisy-5e-6-norm2)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-borpo-noisy-5e-5-005-norm2,"---
base_model: google/gemma-7b
datasets:
- silviasapora/dpo_7k_noisy_10
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['silviasapora/dpo_7k_noisy_10']](https://huggingface.co/datasets/['silviasapora/dpo_7k_noisy_10']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-borpo-noisy-5e-5-005-norm2"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/p8p8dr5w) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.13.0
- Transformers: 4.48.1
- Pytorch: 2.5.1
- Datasets: 3.2.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-borpo-noisy-5e-5-005-norm2"", ""author"": ""silviasapora"", ""sha"": ""843524f6dfcd13a22524afa30bdb9d18d99e13e0"", ""last_modified"": ""2025-01-26 23:55:54+00:00"", ""created_at"": ""2025-01-26 21:40:18+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 2, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:silviasapora/dpo_7k_noisy_10"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- silviasapora/dpo_7k_noisy_10\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan26_21-39-38_e967ea18ab86/events.out.tfevents.1737927620.e967ea18ab86.12578.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-01-26 23:55:54+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- silviasapora/dpo_7k_noisy_10\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""6796abc25f80616a45f4d388"", ""modelId"": ""silviasapora/gemma-7b-borpo-noisy-5e-5-005-norm2"", ""usedStorage"": 1638843115}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-borpo-noisy-5e-5-005-norm2&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-borpo-noisy-5e-5-005-norm2%5D(%2Fsilviasapora%2Fgemma-7b-borpo-noisy-5e-5-005-norm2)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-borpo-noisy-5e-5-02-norm2,"---
base_model: google/gemma-7b
datasets:
- silviasapora/dpo_7k_noisy_10
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['silviasapora/dpo_7k_noisy_10']](https://huggingface.co/datasets/['silviasapora/dpo_7k_noisy_10']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-borpo-noisy-5e-5-02-norm2"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/c9nk8fmy) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.13.0
- Transformers: 4.48.1
- Pytorch: 2.5.1
- Datasets: 3.2.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-borpo-noisy-5e-5-02-norm2"", ""author"": ""silviasapora"", ""sha"": ""3f84642813d0dc70e2ce045b80ad2147576d5407"", ""last_modified"": ""2025-01-26 23:56:47+00:00"", ""created_at"": ""2025-01-26 21:40:18+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 2, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:silviasapora/dpo_7k_noisy_10"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- silviasapora/dpo_7k_noisy_10\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan26_21-39-39_e967ea18ab86/events.out.tfevents.1737927620.e967ea18ab86.12575.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-01-26 23:56:47+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- silviasapora/dpo_7k_noisy_10\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""6796abc27dbf69e4e3090391"", ""modelId"": ""silviasapora/gemma-7b-borpo-noisy-5e-5-02-norm2"", ""usedStorage"": 1638843111}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-borpo-noisy-5e-5-02-norm2&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-borpo-noisy-5e-5-02-norm2%5D(%2Fsilviasapora%2Fgemma-7b-borpo-noisy-5e-5-02-norm2)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-borpo-noisy-5e-5-04-norm2,"---
base_model: google/gemma-7b
datasets:
- silviasapora/dpo_7k_noisy_10
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['silviasapora/dpo_7k_noisy_10']](https://huggingface.co/datasets/['silviasapora/dpo_7k_noisy_10']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-borpo-noisy-5e-5-04-norm2"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/k8yno39e) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.13.0
- Transformers: 4.48.1
- Pytorch: 2.5.1
- Datasets: 3.2.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-borpo-noisy-5e-5-04-norm2"", ""author"": ""silviasapora"", ""sha"": ""c8958e8cb26f73b4ea45bb3d56044c27beec73f0"", ""last_modified"": ""2025-01-26 23:56:38+00:00"", ""created_at"": ""2025-01-26 21:40:18+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 2, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:silviasapora/dpo_7k_noisy_10"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- silviasapora/dpo_7k_noisy_10\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan26_21-39-39_e967ea18ab86/events.out.tfevents.1737927620.e967ea18ab86.12584.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-01-26 23:56:38+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- silviasapora/dpo_7k_noisy_10\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""6796abc2b48d2ba106c0c618"", ""modelId"": ""silviasapora/gemma-7b-borpo-noisy-5e-5-04-norm2"", ""usedStorage"": 1638843111}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-borpo-noisy-5e-5-04-norm2&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-borpo-noisy-5e-5-04-norm2%5D(%2Fsilviasapora%2Fgemma-7b-borpo-noisy-5e-5-04-norm2)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-borpo-noisy-5e-5-01-norm2,"---
base_model: google/gemma-7b
datasets:
- silviasapora/dpo_7k_noisy_10
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['silviasapora/dpo_7k_noisy_10']](https://huggingface.co/datasets/['silviasapora/dpo_7k_noisy_10']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-borpo-noisy-5e-5-01-norm2"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/hydk8g34) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.13.0
- Transformers: 4.48.1
- Pytorch: 2.5.1
- Datasets: 3.2.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-borpo-noisy-5e-5-01-norm2"", ""author"": ""silviasapora"", ""sha"": ""a4637770da1438a65afc8738c694cbc03a21dd56"", ""last_modified"": ""2025-01-26 23:56:50+00:00"", ""created_at"": ""2025-01-26 21:40:18+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 3, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:silviasapora/dpo_7k_noisy_10"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- silviasapora/dpo_7k_noisy_10\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan26_21-39-38_e967ea18ab86/events.out.tfevents.1737927620.e967ea18ab86.12581.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-01-26 23:56:50+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- silviasapora/dpo_7k_noisy_10\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""6796abc2bdc99911a9170597"", ""modelId"": ""silviasapora/gemma-7b-borpo-noisy-5e-5-01-norm2"", ""usedStorage"": 1638843111}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-borpo-noisy-5e-5-01-norm2&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-borpo-noisy-5e-5-01-norm2%5D(%2Fsilviasapora%2Fgemma-7b-borpo-noisy-5e-5-01-norm2)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-orpo-5e-5-norm2,"---
base_model: google/gemma-7b
datasets:
- argilla/dpo-mix-7k
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['argilla/dpo-mix-7k']](https://huggingface.co/datasets/['argilla/dpo-mix-7k']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-orpo-5e-5-norm2"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/msdssntf) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.13.0
- Transformers: 4.48.1
- Pytorch: 2.5.1
- Datasets: 3.2.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-orpo-5e-5-norm2"", ""author"": ""silviasapora"", ""sha"": ""3c6e6735d55b5c8fc8946cd3c663717990d17462"", ""last_modified"": ""2025-01-27 16:53:42+00:00"", ""created_at"": ""2025-01-27 14:36:24+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:argilla/dpo-mix-7k"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan27_14-35-29_b4d476355ce0/events.out.tfevents.1737988586.b4d476355ce0.92916.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan27_14-37-59_b4d476355ce0/events.out.tfevents.1737988691.b4d476355ce0.93930.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-01-27 16:53:42+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""679799e8b546b71300389790"", ""modelId"": ""silviasapora/gemma-7b-orpo-5e-5-norm2"", ""usedStorage"": 1638848575}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-orpo-5e-5-norm2&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-orpo-5e-5-norm2%5D(%2Fsilviasapora%2Fgemma-7b-orpo-5e-5-norm2)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-borpo-5e-5-04-norm2,"---
base_model: google/gemma-7b
datasets:
- argilla/dpo-mix-7k
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['argilla/dpo-mix-7k']](https://huggingface.co/datasets/['argilla/dpo-mix-7k']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-borpo-5e-5-04-norm2"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/h911s126) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.13.0
- Transformers: 4.48.1
- Pytorch: 2.5.1
- Datasets: 3.2.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-borpo-5e-5-04-norm2"", ""author"": ""silviasapora"", ""sha"": ""b2accdea70a832f0dd0299b1974b041788a2ccb0"", ""last_modified"": ""2025-01-27 16:54:04+00:00"", ""created_at"": ""2025-01-27 14:36:25+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:argilla/dpo-mix-7k"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan27_14-37-59_b4d476355ce0/events.out.tfevents.1737988691.b4d476355ce0.93927.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-01-27 16:54:04+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""679799e95e344b131b5bb6a5"", ""modelId"": ""silviasapora/gemma-7b-borpo-5e-5-04-norm2"", ""usedStorage"": 1638843093}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-borpo-5e-5-04-norm2&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-borpo-5e-5-04-norm2%5D(%2Fsilviasapora%2Fgemma-7b-borpo-5e-5-04-norm2)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-simpo-noisy-5e-5,"---
base_model: google/gemma-7b
datasets:
- silviasapora/dpo_7k_noisy_10
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['silviasapora/dpo_7k_noisy_10']](https://huggingface.co/datasets/['silviasapora/dpo_7k_noisy_10']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-simpo-noisy-5e-5"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/x11gsd3s) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.13.0
- Transformers: 4.48.1
- Pytorch: 2.5.1
- Datasets: 3.2.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-simpo-noisy-5e-5"", ""author"": ""silviasapora"", ""sha"": ""1ac50ea9e5d84c979c8d541bf94a485d97cde149"", ""last_modified"": ""2025-01-27 21:12:10+00:00"", ""created_at"": ""2025-01-27 18:55:59+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:silviasapora/dpo_7k_noisy_10"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- silviasapora/dpo_7k_noisy_10\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan27_18-55-07_b4d476355ce0/events.out.tfevents.1738004161.b4d476355ce0.104910.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-01-27 21:12:10+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- silviasapora/dpo_7k_noisy_10\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""6797d6bf056597ad8fd8ac5c"", ""modelId"": ""silviasapora/gemma-7b-simpo-noisy-5e-5"", ""usedStorage"": 1638843084}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-simpo-noisy-5e-5&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-simpo-noisy-5e-5%5D(%2Fsilviasapora%2Fgemma-7b-simpo-noisy-5e-5)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-simpo-basic-5e-5,"---
base_model: google/gemma-7b
datasets:
- argilla/dpo-mix-7k
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['argilla/dpo-mix-7k']](https://huggingface.co/datasets/['argilla/dpo-mix-7k']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-simpo-basic-5e-5"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/pb09p2zt) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.13.0
- Transformers: 4.48.1
- Pytorch: 2.5.1
- Datasets: 3.2.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-simpo-basic-5e-5"", ""author"": ""silviasapora"", ""sha"": ""9cec678426192fb0a4a65ac71124ebd9203e92a3"", ""last_modified"": ""2025-01-27 21:25:55+00:00"", ""created_at"": ""2025-01-27 19:09:26+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:argilla/dpo-mix-7k"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan27_19-09-16_b4d476355ce0/events.out.tfevents.1738004968.b4d476355ce0.106708.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan27_19-09-16_b4d476355ce0/events.out.tfevents.1738004969.b4d476355ce0.106711.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-01-27 21:25:55+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""6797d9e68c7a5e66d4f89afd"", ""modelId"": ""silviasapora/gemma-7b-simpo-basic-5e-5"", ""usedStorage"": 1638908428}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-simpo-basic-5e-5&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-simpo-basic-5e-5%5D(%2Fsilviasapora%2Fgemma-7b-simpo-basic-5e-5)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-leakyrelu-noisy-5e-5,"---
base_model: google/gemma-7b
datasets:
- silviasapora/dpo_7k_noisy_10
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['silviasapora/dpo_7k_noisy_10']](https://huggingface.co/datasets/['silviasapora/dpo_7k_noisy_10']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-leakyrelu-noisy-5e-5"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/inpu3s9e) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.13.0
- Transformers: 4.48.1
- Pytorch: 2.5.1
- Datasets: 3.2.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-leakyrelu-noisy-5e-5"", ""author"": ""silviasapora"", ""sha"": ""cdb78013eb0217aed9436a6da0c4d0aa804a5be5"", ""last_modified"": ""2025-01-28 00:38:59+00:00"", ""created_at"": ""2025-01-27 22:11:04+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:silviasapora/dpo_7k_noisy_10"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- silviasapora/dpo_7k_noisy_10\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan27_22-10-14_b4d476355ce0/events.out.tfevents.1738015866.b4d476355ce0.107874.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan27_22-20-01_b4d476355ce0/events.out.tfevents.1738016413.b4d476355ce0.109163.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan27_22-22-54_b4d476355ce0/events.out.tfevents.1738016585.b4d476355ce0.110558.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan27_22-22-59_b4d476355ce0/events.out.tfevents.1738016592.b4d476355ce0.110837.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-01-28 00:38:59+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- silviasapora/dpo_7k_noisy_10\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""679804781703797636351245"", ""modelId"": ""silviasapora/gemma-7b-leakyrelu-noisy-5e-5"", ""usedStorage"": 1638869763}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-leakyrelu-noisy-5e-5&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-leakyrelu-noisy-5e-5%5D(%2Fsilviasapora%2Fgemma-7b-leakyrelu-noisy-5e-5)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-softplus-noisy-5e-5,"---
base_model: google/gemma-7b
datasets:
- silviasapora/dpo_7k_noisy_10
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['silviasapora/dpo_7k_noisy_10']](https://huggingface.co/datasets/['silviasapora/dpo_7k_noisy_10']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-softplus-noisy-5e-5"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/bigctf3q) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.13.0
- Transformers: 4.48.1
- Pytorch: 2.5.1
- Datasets: 3.2.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-softplus-noisy-5e-5"", ""author"": ""silviasapora"", ""sha"": ""f37179bad0944c7cc4ba0464675b643556a0ec5e"", ""last_modified"": ""2025-01-28 00:38:46+00:00"", ""created_at"": ""2025-01-27 22:11:04+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:silviasapora/dpo_7k_noisy_10"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- silviasapora/dpo_7k_noisy_10\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan27_22-10-14_b4d476355ce0/events.out.tfevents.1738015866.b4d476355ce0.107871.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan27_22-22-53_b4d476355ce0/events.out.tfevents.1738016588.b4d476355ce0.110561.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-01-28 00:38:46+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- silviasapora/dpo_7k_noisy_10\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""679804788370e663d4f9c82b"", ""modelId"": ""silviasapora/gemma-7b-softplus-noisy-5e-5"", ""usedStorage"": 1638852824}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-softplus-noisy-5e-5&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-softplus-noisy-5e-5%5D(%2Fsilviasapora%2Fgemma-7b-softplus-noisy-5e-5)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-softplus-basic-5e-5,"---
base_model: google/gemma-7b
datasets:
- argilla/dpo-mix-7k
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['argilla/dpo-mix-7k']](https://huggingface.co/datasets/['argilla/dpo-mix-7k']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-softplus-basic-5e-5"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/xu25ngo6) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.13.0
- Transformers: 4.48.1
- Pytorch: 2.5.1
- Datasets: 3.2.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-softplus-basic-5e-5"", ""author"": ""silviasapora"", ""sha"": ""38e0cab6330c4707e29d24e2e46dbaf67b5285d3"", ""last_modified"": ""2025-01-28 01:07:39+00:00"", ""created_at"": ""2025-01-27 22:20:41+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:argilla/dpo-mix-7k"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan27_22-20-01_b4d476355ce0/events.out.tfevents.1738016442.b4d476355ce0.109166.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan27_22-22-58_b4d476355ce0/events.out.tfevents.1738016591.b4d476355ce0.110835.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan27_22-51-11_b4d476355ce0/events.out.tfevents.1738018283.b4d476355ce0.112738.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-01-28 01:07:39+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""679806b933e38f906add4ee3"", ""modelId"": ""silviasapora/gemma-7b-softplus-basic-5e-5"", ""usedStorage"": 1638864245}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-softplus-basic-5e-5&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-softplus-basic-5e-5%5D(%2Fsilviasapora%2Fgemma-7b-softplus-basic-5e-5)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-leakyrelu-basic-5e-5,"---
base_model: google/gemma-7b
datasets:
- argilla/dpo-mix-7k
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['argilla/dpo-mix-7k']](https://huggingface.co/datasets/['argilla/dpo-mix-7k']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-leakyrelu-basic-5e-5"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/opjw9h96) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.13.0
- Transformers: 4.48.1
- Pytorch: 2.5.1
- Datasets: 3.2.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-leakyrelu-basic-5e-5"", ""author"": ""silviasapora"", ""sha"": ""bdfefdc09230184398877c8d447dc05cd42464a3"", ""last_modified"": ""2025-01-28 01:07:10+00:00"", ""created_at"": ""2025-01-27 22:51:20+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:argilla/dpo-mix-7k"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan27_22-51-10_b4d476355ce0/events.out.tfevents.1738018282.b4d476355ce0.112741.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-01-28 01:07:10+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67980de8a59233c1dd121e10"", ""modelId"": ""silviasapora/gemma-7b-leakyrelu-basic-5e-5"", ""usedStorage"": 1638843096}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-leakyrelu-basic-5e-5&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-leakyrelu-basic-5e-5%5D(%2Fsilviasapora%2Fgemma-7b-leakyrelu-basic-5e-5)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-silvia-basic-5e-5-v4,"---
base_model: google/gemma-7b
datasets:
- argilla/dpo-mix-7k
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['argilla/dpo-mix-7k']](https://huggingface.co/datasets/['argilla/dpo-mix-7k']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-silvia-basic-5e-5-v4"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/0lavtiko) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.13.0
- Transformers: 4.48.1
- Pytorch: 2.5.1
- Datasets: 3.2.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-silvia-basic-5e-5-v4"", ""author"": ""silviasapora"", ""sha"": ""975be6751ee8f2dac3d7c66610a878e17fd0ca98"", ""last_modified"": ""2025-01-28 04:49:58+00:00"", ""created_at"": ""2025-01-28 01:30:44+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:argilla/dpo-mix-7k"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan28_01-30-34_b4d476355ce0/events.out.tfevents.1738027845.b4d476355ce0.114012.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan28_01-31-29_b4d476355ce0/events.out.tfevents.1738027900.b4d476355ce0.114551.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan28_01-32-40_b4d476355ce0/events.out.tfevents.1738027971.b4d476355ce0.115150.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan28_01-39-09_b4d476355ce0/events.out.tfevents.1738028361.b4d476355ce0.115686.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan28_01-41-12_b4d476355ce0/events.out.tfevents.1738028484.b4d476355ce0.116215.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan28_01-42-30_b4d476355ce0/events.out.tfevents.1738028562.b4d476355ce0.116803.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan28_01-57-58_b4d476355ce0/events.out.tfevents.1738029490.b4d476355ce0.120553.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan28_01-59-45_b4d476355ce0/events.out.tfevents.1738029598.b4d476355ce0.121628.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan28_02-00-55_b4d476355ce0/events.out.tfevents.1738029667.b4d476355ce0.122697.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan28_02-02-05_b4d476355ce0/events.out.tfevents.1738029736.b4d476355ce0.123760.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan28_02-05-17_b4d476355ce0/events.out.tfevents.1738029928.b4d476355ce0.124831.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan28_02-09-09_b4d476355ce0/events.out.tfevents.1738030161.b4d476355ce0.125900.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan28_02-11-22_b4d476355ce0/events.out.tfevents.1738030294.b4d476355ce0.127210.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan28_02-13-00_b4d476355ce0/events.out.tfevents.1738030392.b4d476355ce0.128147.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan28_02-13-00_b4d476355ce0/events.out.tfevents.1738030393.b4d476355ce0.128156.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-01-28 04:49:58+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""679833441d3cfd7ca5c7f2f8"", ""modelId"": ""silviasapora/gemma-7b-silvia-basic-5e-5-v4"", ""usedStorage"": 4839424123}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-silvia-basic-5e-5-v4&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-silvia-basic-5e-5-v4%5D(%2Fsilviasapora%2Fgemma-7b-silvia-basic-5e-5-v4)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-borpo-basic-5e-5-v4,"---
base_model: google/gemma-7b
datasets:
- argilla/dpo-mix-7k
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['argilla/dpo-mix-7k']](https://huggingface.co/datasets/['argilla/dpo-mix-7k']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-borpo-basic-5e-5-v4"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/p38ybp3t) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.13.0
- Transformers: 4.48.1
- Pytorch: 2.5.1
- Datasets: 3.2.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-borpo-basic-5e-5-v4"", ""author"": ""silviasapora"", ""sha"": ""ba321f46c4d00feac91fdd580461f3d6400de97b"", ""last_modified"": ""2025-01-28 04:49:26+00:00"", ""created_at"": ""2025-01-28 01:44:12+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:argilla/dpo-mix-7k"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan28_01-44-01_b4d476355ce0/events.out.tfevents.1738028653.b4d476355ce0.117329.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan28_01-47-21_b4d476355ce0/events.out.tfevents.1738028852.b4d476355ce0.117878.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan28_01-50-03_b4d476355ce0/events.out.tfevents.1738029014.b4d476355ce0.118422.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan28_01-52-35_b4d476355ce0/events.out.tfevents.1738029166.b4d476355ce0.118953.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan28_01-55-23_b4d476355ce0/events.out.tfevents.1738029335.b4d476355ce0.119494.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan28_01-57-20_b4d476355ce0/events.out.tfevents.1738029452.b4d476355ce0.120025.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan28_01-58-27_b4d476355ce0/events.out.tfevents.1738029519.b4d476355ce0.121088.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan28_02-00-15_b4d476355ce0/events.out.tfevents.1738029626.b4d476355ce0.122156.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan28_02-01-31_b4d476355ce0/events.out.tfevents.1738029702.b4d476355ce0.123227.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan28_02-04-24_b4d476355ce0/events.out.tfevents.1738029875.b4d476355ce0.124305.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan28_02-07-21_b4d476355ce0/events.out.tfevents.1738030054.b4d476355ce0.125370.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan28_02-09-51_b4d476355ce0/events.out.tfevents.1738030203.b4d476355ce0.126434.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan28_02-12-59_b4d476355ce0/events.out.tfevents.1738030392.b4d476355ce0.128150.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-01-28 04:49:26+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""6798366c8d5e385e466c1cd0"", ""modelId"": ""silviasapora/gemma-7b-borpo-basic-5e-5-v4"", ""usedStorage"": 1638902626}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-borpo-basic-5e-5-v4&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-borpo-basic-5e-5-v4%5D(%2Fsilviasapora%2Fgemma-7b-borpo-basic-5e-5-v4)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-leakyrelu-basic-5e-5-v4,"---
base_model: google/gemma-7b
datasets:
- argilla/dpo-mix-7k
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['argilla/dpo-mix-7k']](https://huggingface.co/datasets/['argilla/dpo-mix-7k']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-leakyrelu-basic-5e-5-v4"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/p8gz9vkl) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.13.0
- Transformers: 4.48.1
- Pytorch: 2.5.1
- Datasets: 3.2.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-leakyrelu-basic-5e-5-v4"", ""author"": ""silviasapora"", ""sha"": ""0b80fcc4c0fdcd9b3416ae9e3d3b83f393fdfb89"", ""last_modified"": ""2025-01-28 04:48:30+00:00"", ""created_at"": ""2025-01-28 02:13:10+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:argilla/dpo-mix-7k"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan28_02-13-00_b4d476355ce0/events.out.tfevents.1738030392.b4d476355ce0.128153.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-01-28 04:48:30+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67983d361ad4da8d8cd1cf2c"", ""modelId"": ""silviasapora/gemma-7b-leakyrelu-basic-5e-5-v4"", ""usedStorage"": 1638835721}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-leakyrelu-basic-5e-5-v4&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-leakyrelu-basic-5e-5-v4%5D(%2Fsilviasapora%2Fgemma-7b-leakyrelu-basic-5e-5-v4)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-borpo-basic-5e-5-1-v4,"---
base_model: google/gemma-7b
datasets:
- argilla/dpo-mix-7k
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['argilla/dpo-mix-7k']](https://huggingface.co/datasets/['argilla/dpo-mix-7k']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-borpo-basic-5e-5-1-v4"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/j5mown5x) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.13.0
- Transformers: 4.46.1
- Pytorch: 2.4.0
- Datasets: 3.1.0
- Tokenizers: 0.20.1

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-borpo-basic-5e-5-1-v4"", ""author"": ""silviasapora"", ""sha"": ""51e2e4781a8d0e252bf4179d5de06a24f3449da8"", ""last_modified"": ""2025-01-28 04:45:03+00:00"", ""created_at"": ""2025-01-28 02:43:29+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:argilla/dpo-mix-7k"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan28_02-41-42_82272e4b10b1/events.out.tfevents.1738032210.82272e4b10b1.112348.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-01-28 04:45:03+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67984451644160eb6e408c30"", ""modelId"": ""silviasapora/gemma-7b-borpo-basic-5e-5-1-v4"", ""usedStorage"": 838772169}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-borpo-basic-5e-5-1-v4&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-borpo-basic-5e-5-1-v4%5D(%2Fsilviasapora%2Fgemma-7b-borpo-basic-5e-5-1-v4)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-borpo-basic-5e-5-02-v4,"---
base_model: google/gemma-7b
datasets:
- argilla/dpo-mix-7k
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['argilla/dpo-mix-7k']](https://huggingface.co/datasets/['argilla/dpo-mix-7k']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-borpo-basic-5e-5-02-v4"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/pzcdy8pd) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.13.0
- Transformers: 4.46.1
- Pytorch: 2.4.0
- Datasets: 3.1.0
- Tokenizers: 0.20.1

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-borpo-basic-5e-5-02-v4"", ""author"": ""silviasapora"", ""sha"": ""2a2af0eb4c123114f52904235818f7e34770ceb1"", ""last_modified"": ""2025-01-28 04:44:18+00:00"", ""created_at"": ""2025-01-28 02:43:30+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:argilla/dpo-mix-7k"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan28_02-41-40_82272e4b10b1/events.out.tfevents.1738032211.82272e4b10b1.112345.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-01-28 04:44:18+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67984452c262e2373e53d1b3"", ""modelId"": ""silviasapora/gemma-7b-borpo-basic-5e-5-02-v4"", ""usedStorage"": 838772172}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-borpo-basic-5e-5-02-v4&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-borpo-basic-5e-5-02-v4%5D(%2Fsilviasapora%2Fgemma-7b-borpo-basic-5e-5-02-v4)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-simpo-basic-5e-5-02-v4,"---
base_model: google/gemma-7b
datasets:
- argilla/dpo-mix-7k
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['argilla/dpo-mix-7k']](https://huggingface.co/datasets/['argilla/dpo-mix-7k']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-simpo-basic-5e-5-02-v4"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/cwhthh19) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.13.0
- Transformers: 4.46.1
- Pytorch: 2.4.0
- Datasets: 3.1.0
- Tokenizers: 0.20.1

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-simpo-basic-5e-5-02-v4"", ""author"": ""silviasapora"", ""sha"": ""55336ec6bda75957bad0ae3c33cac23c87b67725"", ""last_modified"": ""2025-01-28 06:46:11+00:00"", ""created_at"": ""2025-01-28 04:45:45+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:argilla/dpo-mix-7k"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan28_04-45-26_82272e4b10b1/events.out.tfevents.1738039546.82272e4b10b1.113592.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-01-28 06:46:11+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""679860f9c383bf27f204551c"", ""modelId"": ""silviasapora/gemma-7b-simpo-basic-5e-5-02-v4"", ""usedStorage"": 838772172}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-simpo-basic-5e-5-02-v4&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-simpo-basic-5e-5-02-v4%5D(%2Fsilviasapora%2Fgemma-7b-simpo-basic-5e-5-02-v4)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-simpo-basic-5e-5-05-v4,"---
base_model: google/gemma-7b
datasets:
- argilla/dpo-mix-7k
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['argilla/dpo-mix-7k']](https://huggingface.co/datasets/['argilla/dpo-mix-7k']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-simpo-basic-5e-5-05-v4"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/pxe4o1bf) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.13.0
- Transformers: 4.46.1
- Pytorch: 2.4.0
- Datasets: 3.1.0
- Tokenizers: 0.20.1

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-simpo-basic-5e-5-05-v4"", ""author"": ""silviasapora"", ""sha"": ""ae764becf5f007588e1e8d565d3dc61fdb1382e6"", ""last_modified"": ""2025-01-28 06:46:29+00:00"", ""created_at"": ""2025-01-28 04:46:26+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:argilla/dpo-mix-7k"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan28_04-45-26_82272e4b10b1/events.out.tfevents.1738039587.82272e4b10b1.113589.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-01-28 06:46:29+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""679861228c6b6dc728b3574c"", ""modelId"": ""silviasapora/gemma-7b-simpo-basic-5e-5-05-v4"", ""usedStorage"": 838772172}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-simpo-basic-5e-5-05-v4&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-simpo-basic-5e-5-05-v4%5D(%2Fsilviasapora%2Fgemma-7b-simpo-basic-5e-5-05-v4)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-cpo-noisy-5e-5-v4,"---
base_model: google/gemma-7b
datasets:
- silviasapora/dpo_7k_noisy_10
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['silviasapora/dpo_7k_noisy_10']](https://huggingface.co/datasets/['silviasapora/dpo_7k_noisy_10']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-cpo-noisy-5e-5-v4"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/3xvloaz5) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.13.0
- Transformers: 4.48.1
- Pytorch: 2.5.1
- Datasets: 3.2.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-cpo-noisy-5e-5-v4"", ""author"": ""silviasapora"", ""sha"": ""2aab544691986ff6f24c6542c46368d506ff8fb5"", ""last_modified"": ""2025-01-28 07:25:30+00:00"", ""created_at"": ""2025-01-28 04:50:24+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:silviasapora/dpo_7k_noisy_10"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- silviasapora/dpo_7k_noisy_10\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan28_04-50-14_b4d476355ce0/events.out.tfevents.1738039826.b4d476355ce0.130405.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-01-28 07:25:30+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- silviasapora/dpo_7k_noisy_10\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""679862102ec68b4193849f6a"", ""modelId"": ""silviasapora/gemma-7b-cpo-noisy-5e-5-v4"", ""usedStorage"": 1638835703}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-cpo-noisy-5e-5-v4&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-cpo-noisy-5e-5-v4%5D(%2Fsilviasapora%2Fgemma-7b-cpo-noisy-5e-5-v4)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-softplus-basic-5e-5-v4,"---
base_model: google/gemma-7b
datasets:
- argilla/dpo-mix-7k
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['argilla/dpo-mix-7k']](https://huggingface.co/datasets/['argilla/dpo-mix-7k']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-softplus-basic-5e-5-v4"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/xzqo0dg2) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.13.0
- Transformers: 4.48.1
- Pytorch: 2.5.1
- Datasets: 3.2.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-softplus-basic-5e-5-v4"", ""author"": ""silviasapora"", ""sha"": ""53448fa1fd587b72127f06572d8a7562c502e46b"", ""last_modified"": ""2025-01-28 07:26:51+00:00"", ""created_at"": ""2025-01-28 04:50:25+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 1, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:argilla/dpo-mix-7k"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan28_04-50-14_b4d476355ce0/events.out.tfevents.1738039827.b4d476355ce0.130408.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-01-28 07:26:51+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""6798621111ed93b78a3a4071"", ""modelId"": ""silviasapora/gemma-7b-softplus-basic-5e-5-v4"", ""usedStorage"": 1638835718}",1,,0,https://huggingface.co/PrunaAI/silviasapora-gemma-7b-softplus-basic-5e-5-v4-GGUF-smashed,1,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-softplus-basic-5e-5-v4&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-softplus-basic-5e-5-v4%5D(%2Fsilviasapora%2Fgemma-7b-softplus-basic-5e-5-v4)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-borpo-noisy-5e-5-v4,"---
base_model: google/gemma-7b
datasets:
- silviasapora/dpo_7k_noisy_10
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['silviasapora/dpo_7k_noisy_10']](https://huggingface.co/datasets/['silviasapora/dpo_7k_noisy_10']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-borpo-noisy-5e-5-v4"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/xbdzzejw) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.13.0
- Transformers: 4.48.1
- Pytorch: 2.5.1
- Datasets: 3.2.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-borpo-noisy-5e-5-v4"", ""author"": ""silviasapora"", ""sha"": ""96b000f9c98704733c1bc74df95c6bf35a7154a9"", ""last_modified"": ""2025-01-28 07:25:37+00:00"", ""created_at"": ""2025-01-28 04:50:25+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:silviasapora/dpo_7k_noisy_10"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- silviasapora/dpo_7k_noisy_10\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan28_04-50-14_b4d476355ce0/events.out.tfevents.1738039827.b4d476355ce0.130411.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-01-28 07:25:37+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- silviasapora/dpo_7k_noisy_10\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67986211582fda525ae1a907"", ""modelId"": ""silviasapora/gemma-7b-borpo-noisy-5e-5-v4"", ""usedStorage"": 1638835709}",1,,0,https://huggingface.co/PrunaAI/silviasapora-gemma-7b-borpo-noisy-5e-5-v4-GGUF-smashed,1,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-borpo-noisy-5e-5-v4&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-borpo-noisy-5e-5-v4%5D(%2Fsilviasapora%2Fgemma-7b-borpo-noisy-5e-5-v4)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-simpo-basic-5e-5-v4,"---
base_model: google/gemma-7b
datasets:
- argilla/dpo-mix-7k
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['argilla/dpo-mix-7k']](https://huggingface.co/datasets/['argilla/dpo-mix-7k']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-simpo-basic-5e-5-v4"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/zkrd5fnp) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.13.0
- Transformers: 4.48.1
- Pytorch: 2.5.1
- Datasets: 3.2.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-simpo-basic-5e-5-v4"", ""author"": ""silviasapora"", ""sha"": ""dda812113590ab5806877ee05a785ae8b361c0e8"", ""last_modified"": ""2025-01-28 07:26:17+00:00"", ""created_at"": ""2025-01-28 04:50:26+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:argilla/dpo-mix-7k"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan28_04-50-14_b4d476355ce0/events.out.tfevents.1738039827.b4d476355ce0.130414.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-01-28 07:26:17+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67986212d8e2dcea3d18c45c"", ""modelId"": ""silviasapora/gemma-7b-simpo-basic-5e-5-v4"", ""usedStorage"": 1638835709}",1,,0,https://huggingface.co/PrunaAI/silviasapora-gemma-7b-simpo-basic-5e-5-v4-GGUF-smashed,1,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-simpo-basic-5e-5-v4&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-simpo-basic-5e-5-v4%5D(%2Fsilviasapora%2Fgemma-7b-simpo-basic-5e-5-v4)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-borpo-noisy-5e-5-1-v4,"---
base_model: google/gemma-7b
datasets:
- silviasapora/dpo_7k_noisy_10
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['silviasapora/dpo_7k_noisy_10']](https://huggingface.co/datasets/['silviasapora/dpo_7k_noisy_10']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-borpo-noisy-5e-5-1-v4"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/188lh0jv) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.13.0
- Transformers: 4.46.1
- Pytorch: 2.4.0
- Datasets: 3.1.0
- Tokenizers: 0.20.1

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-borpo-noisy-5e-5-1-v4"", ""author"": ""silviasapora"", ""sha"": ""2c9ffdad9f9842e00cdc842b19567013a8b0e0b7"", ""last_modified"": ""2025-01-28 08:51:44+00:00"", ""created_at"": ""2025-01-28 06:51:05+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:silviasapora/dpo_7k_noisy_10"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- silviasapora/dpo_7k_noisy_10\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan28_06-49-55_82272e4b10b1/events.out.tfevents.1738047066.82272e4b10b1.114607.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-01-28 08:51:44+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- silviasapora/dpo_7k_noisy_10\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67987e596a5023b9cbf62acf"", ""modelId"": ""silviasapora/gemma-7b-borpo-noisy-5e-5-1-v4"", ""usedStorage"": 838772169}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-borpo-noisy-5e-5-1-v4&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-borpo-noisy-5e-5-1-v4%5D(%2Fsilviasapora%2Fgemma-7b-borpo-noisy-5e-5-1-v4)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-borpo-noisy-5e-5-02-v4,"---
base_model: google/gemma-7b
datasets:
- silviasapora/dpo_7k_noisy_10
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['silviasapora/dpo_7k_noisy_10']](https://huggingface.co/datasets/['silviasapora/dpo_7k_noisy_10']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-borpo-noisy-5e-5-02-v4"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/dgumo6go) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.13.0
- Transformers: 4.46.1
- Pytorch: 2.4.0
- Datasets: 3.1.0
- Tokenizers: 0.20.1

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-borpo-noisy-5e-5-02-v4"", ""author"": ""silviasapora"", ""sha"": ""6af4ef71cfb34cddc566d82fbcb8e8357e21a131"", ""last_modified"": ""2025-01-28 08:51:05+00:00"", ""created_at"": ""2025-01-28 06:51:05+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:silviasapora/dpo_7k_noisy_10"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- silviasapora/dpo_7k_noisy_10\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan28_06-49-55_82272e4b10b1/events.out.tfevents.1738047066.82272e4b10b1.114610.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-01-28 08:51:05+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- silviasapora/dpo_7k_noisy_10\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67987e59e60ab66534a383a1"", ""modelId"": ""silviasapora/gemma-7b-borpo-noisy-5e-5-02-v4"", ""usedStorage"": 838772172}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-borpo-noisy-5e-5-02-v4&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-borpo-noisy-5e-5-02-v4%5D(%2Fsilviasapora%2Fgemma-7b-borpo-noisy-5e-5-02-v4)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-leakyrelu-noisy-5e-5-v4,"---
base_model: google/gemma-7b
datasets:
- silviasapora/dpo_7k_noisy_10
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['silviasapora/dpo_7k_noisy_10']](https://huggingface.co/datasets/['silviasapora/dpo_7k_noisy_10']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-leakyrelu-noisy-5e-5-v4"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/s2qpo7kl) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.13.0
- Transformers: 4.48.1
- Pytorch: 2.5.1
- Datasets: 3.2.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-leakyrelu-noisy-5e-5-v4"", ""author"": ""silviasapora"", ""sha"": ""ed481680488d07fd0095f3b7f161c11622183dc1"", ""last_modified"": ""2025-01-28 10:10:55+00:00"", ""created_at"": ""2025-01-28 07:35:24+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:silviasapora/dpo_7k_noisy_10"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- silviasapora/dpo_7k_noisy_10\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan28_07-35-14_b4d476355ce0/events.out.tfevents.1738049726.b4d476355ce0.132661.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-01-28 10:10:55+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- silviasapora/dpo_7k_noisy_10\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""679888bc056597ad8f05260f"", ""modelId"": ""silviasapora/gemma-7b-leakyrelu-noisy-5e-5-v4"", ""usedStorage"": 1638835721}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-leakyrelu-noisy-5e-5-v4&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-leakyrelu-noisy-5e-5-v4%5D(%2Fsilviasapora%2Fgemma-7b-leakyrelu-noisy-5e-5-v4)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-silvia-noisy-5e-5-v4,"---
base_model: google/gemma-7b
datasets:
- silviasapora/dpo_7k_noisy_10
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['silviasapora/dpo_7k_noisy_10']](https://huggingface.co/datasets/['silviasapora/dpo_7k_noisy_10']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-silvia-noisy-5e-5-v4"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/2bwmk7ex) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.13.0
- Transformers: 4.48.1
- Pytorch: 2.5.1
- Datasets: 3.2.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-silvia-noisy-5e-5-v4"", ""author"": ""silviasapora"", ""sha"": ""2da8ff858e5b427ba98fe24f2f95e81520def369"", ""last_modified"": ""2025-01-28 10:11:46+00:00"", ""created_at"": ""2025-01-28 07:35:24+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:silviasapora/dpo_7k_noisy_10"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- silviasapora/dpo_7k_noisy_10\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan28_07-35-14_b4d476355ce0/events.out.tfevents.1738049726.b4d476355ce0.132655.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-01-28 10:11:46+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- silviasapora/dpo_7k_noisy_10\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""679888bc3181d50cb2e78925"", ""modelId"": ""silviasapora/gemma-7b-silvia-noisy-5e-5-v4"", ""usedStorage"": 1638835712}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-silvia-noisy-5e-5-v4&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-silvia-noisy-5e-5-v4%5D(%2Fsilviasapora%2Fgemma-7b-silvia-noisy-5e-5-v4)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-softplus-noisy-5e-5-v4,"---
base_model: google/gemma-7b
datasets:
- silviasapora/dpo_7k_noisy_10
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['silviasapora/dpo_7k_noisy_10']](https://huggingface.co/datasets/['silviasapora/dpo_7k_noisy_10']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-softplus-noisy-5e-5-v4"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/l5ytho9h) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.13.0
- Transformers: 4.48.1
- Pytorch: 2.5.1
- Datasets: 3.2.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-softplus-noisy-5e-5-v4"", ""author"": ""silviasapora"", ""sha"": ""5c3d38f24b5a00fb96dd0b09505d2e513e4b5861"", ""last_modified"": ""2025-01-28 10:10:41+00:00"", ""created_at"": ""2025-01-28 07:35:25+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:silviasapora/dpo_7k_noisy_10"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- silviasapora/dpo_7k_noisy_10\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan28_07-35-14_b4d476355ce0/events.out.tfevents.1738049727.b4d476355ce0.132652.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-01-28 10:10:41+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- silviasapora/dpo_7k_noisy_10\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""679888bd11ed93b78a4386fd"", ""modelId"": ""silviasapora/gemma-7b-softplus-noisy-5e-5-v4"", ""usedStorage"": 1638835718}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-softplus-noisy-5e-5-v4&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-softplus-noisy-5e-5-v4%5D(%2Fsilviasapora%2Fgemma-7b-softplus-noisy-5e-5-v4)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-simpo-noisy-5e-5-v4,"---
base_model: google/gemma-7b
datasets:
- silviasapora/dpo_7k_noisy_10
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['silviasapora/dpo_7k_noisy_10']](https://huggingface.co/datasets/['silviasapora/dpo_7k_noisy_10']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-simpo-noisy-5e-5-v4"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/wo2585ge) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.13.0
- Transformers: 4.48.1
- Pytorch: 2.5.1
- Datasets: 3.2.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-simpo-noisy-5e-5-v4"", ""author"": ""silviasapora"", ""sha"": ""78c03854b2dddbb54c046bb33fa004db07bf4560"", ""last_modified"": ""2025-01-28 10:10:43+00:00"", ""created_at"": ""2025-01-28 07:35:53+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:silviasapora/dpo_7k_noisy_10"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- silviasapora/dpo_7k_noisy_10\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan28_07-35-14_b4d476355ce0/events.out.tfevents.1738049755.b4d476355ce0.132658.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-01-28 10:10:43+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- silviasapora/dpo_7k_noisy_10\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""679888d91397f127d1983e86"", ""modelId"": ""silviasapora/gemma-7b-simpo-noisy-5e-5-v4"", ""usedStorage"": 1638835709}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-simpo-noisy-5e-5-v4&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-simpo-noisy-5e-5-v4%5D(%2Fsilviasapora%2Fgemma-7b-simpo-noisy-5e-5-v4)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-borpo-shuffled-5e-5-01-v4,"---
base_model: google/gemma-7b
datasets:
- silviasapora/argilla-mix-low
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['silviasapora/argilla-mix-low']](https://huggingface.co/datasets/['silviasapora/argilla-mix-low']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-borpo-shuffled-5e-5-01-v4"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/p9coglm2) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.13.0
- Transformers: 4.46.1
- Pytorch: 2.4.0
- Datasets: 3.1.0
- Tokenizers: 0.20.1

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-borpo-shuffled-5e-5-01-v4"", ""author"": ""silviasapora"", ""sha"": ""adae71cb33c04286fbc16fbe11bf4e8776432b94"", ""last_modified"": ""2025-01-28 11:02:23+00:00"", ""created_at"": ""2025-01-28 08:53:39+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 1, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:silviasapora/argilla-mix-low"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- silviasapora/argilla-mix-low\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan28_08-52-35_82272e4b10b1/events.out.tfevents.1738054420.82272e4b10b1.115616.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-01-28 11:02:23+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- silviasapora/argilla-mix-low\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67989b1322990ae89bc287ad"", ""modelId"": ""silviasapora/gemma-7b-borpo-shuffled-5e-5-01-v4"", ""usedStorage"": 838777375}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-borpo-shuffled-5e-5-01-v4&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-borpo-shuffled-5e-5-01-v4%5D(%2Fsilviasapora%2Fgemma-7b-borpo-shuffled-5e-5-01-v4)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-borpo-shuffled-5e-5-02-v4,"---
base_model: google/gemma-7b
datasets:
- silviasapora/argilla-mix-low
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['silviasapora/argilla-mix-low']](https://huggingface.co/datasets/['silviasapora/argilla-mix-low']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-borpo-shuffled-5e-5-02-v4"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/z4z6adbp) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.13.0
- Transformers: 4.46.1
- Pytorch: 2.4.0
- Datasets: 3.1.0
- Tokenizers: 0.20.1

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-borpo-shuffled-5e-5-02-v4"", ""author"": ""silviasapora"", ""sha"": ""cde28f4e24c77febb8a226a8c8958eb9a12f127c"", ""last_modified"": ""2025-01-28 11:02:50+00:00"", ""created_at"": ""2025-01-28 08:53:39+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:silviasapora/argilla-mix-low"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- silviasapora/argilla-mix-low\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan28_08-52-35_82272e4b10b1/events.out.tfevents.1738054420.82272e4b10b1.115618.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-01-28 11:02:50+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- silviasapora/argilla-mix-low\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67989b1367fbbe1803688269"", ""modelId"": ""silviasapora/gemma-7b-borpo-shuffled-5e-5-02-v4"", ""usedStorage"": 838777375}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-borpo-shuffled-5e-5-02-v4&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-borpo-shuffled-5e-5-02-v4%5D(%2Fsilviasapora%2Fgemma-7b-borpo-shuffled-5e-5-02-v4)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-silvia-shuffled-5e-5-v4,"---
base_model: google/gemma-7b
datasets:
- silviasapora/argilla-mix-low
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['silviasapora/argilla-mix-low']](https://huggingface.co/datasets/['silviasapora/argilla-mix-low']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-silvia-shuffled-5e-5-v4"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/m1nvyswy) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.13.0
- Transformers: 4.48.1
- Pytorch: 2.5.1
- Datasets: 3.2.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-silvia-shuffled-5e-5-v4"", ""author"": ""silviasapora"", ""sha"": ""3e9ff09cbfb3b01358d6ca8eae2a7a7b9647c47d"", ""last_modified"": ""2025-01-28 13:11:00+00:00"", ""created_at"": ""2025-01-28 10:26:03+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:silviasapora/argilla-mix-low"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- silviasapora/argilla-mix-low\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan28_10-25-53_b4d476355ce0/events.out.tfevents.1738059965.b4d476355ce0.134889.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-01-28 13:11:00+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- silviasapora/argilla-mix-low\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""6798b0bb7162b6652e91ab00"", ""modelId"": ""silviasapora/gemma-7b-silvia-shuffled-5e-5-v4"", ""usedStorage"": 1638840915}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-silvia-shuffled-5e-5-v4&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-silvia-shuffled-5e-5-v4%5D(%2Fsilviasapora%2Fgemma-7b-silvia-shuffled-5e-5-v4)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-cpo-shuffled-5e-5-v4,"---
base_model: google/gemma-7b
datasets:
- silviasapora/argilla-mix-low
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['silviasapora/argilla-mix-low']](https://huggingface.co/datasets/['silviasapora/argilla-mix-low']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-cpo-shuffled-5e-5-v4"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/u8a2akb0) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.13.0
- Transformers: 4.48.1
- Pytorch: 2.5.1
- Datasets: 3.2.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-cpo-shuffled-5e-5-v4"", ""author"": ""silviasapora"", ""sha"": ""cc5581394fe0d5946face08958017a9ce1771b3d"", ""last_modified"": ""2025-01-28 13:11:33+00:00"", ""created_at"": ""2025-01-28 10:26:04+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:silviasapora/argilla-mix-low"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- silviasapora/argilla-mix-low\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan28_10-25-53_b4d476355ce0/events.out.tfevents.1738059965.b4d476355ce0.134898.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-01-28 13:11:33+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- silviasapora/argilla-mix-low\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""6798b0bc47f3dadd6aee2088"", ""modelId"": ""silviasapora/gemma-7b-cpo-shuffled-5e-5-v4"", ""usedStorage"": 1638840906}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-cpo-shuffled-5e-5-v4&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-cpo-shuffled-5e-5-v4%5D(%2Fsilviasapora%2Fgemma-7b-cpo-shuffled-5e-5-v4)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-borpo-shuffled-5e-5-v4,"---
base_model: google/gemma-7b
datasets:
- silviasapora/argilla-mix-low
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['silviasapora/argilla-mix-low']](https://huggingface.co/datasets/['silviasapora/argilla-mix-low']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-borpo-shuffled-5e-5-v4"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/6p3at5qg) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.13.0
- Transformers: 4.48.1
- Pytorch: 2.5.1
- Datasets: 3.2.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-borpo-shuffled-5e-5-v4"", ""author"": ""silviasapora"", ""sha"": ""f31a8f73a5c609b0b1d83852eaa9f83b9d322895"", ""last_modified"": ""2025-01-28 13:11:04+00:00"", ""created_at"": ""2025-01-28 10:26:04+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:silviasapora/argilla-mix-low"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- silviasapora/argilla-mix-low\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan28_10-25-53_b4d476355ce0/events.out.tfevents.1738059967.b4d476355ce0.134892.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-01-28 13:11:04+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- silviasapora/argilla-mix-low\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""6798b0bc9b6acafdcb72e4d9"", ""modelId"": ""silviasapora/gemma-7b-borpo-shuffled-5e-5-v4"", ""usedStorage"": 1638840912}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-borpo-shuffled-5e-5-v4&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-borpo-shuffled-5e-5-v4%5D(%2Fsilviasapora%2Fgemma-7b-borpo-shuffled-5e-5-v4)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-leakyrelu-shuffled-5e-5-v4,"---
base_model: google/gemma-7b
datasets:
- silviasapora/argilla-mix-low
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['silviasapora/argilla-mix-low']](https://huggingface.co/datasets/['silviasapora/argilla-mix-low']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-leakyrelu-shuffled-5e-5-v4"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/7hx2ufai) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.13.0
- Transformers: 4.48.1
- Pytorch: 2.5.1
- Datasets: 3.2.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-leakyrelu-shuffled-5e-5-v4"", ""author"": ""silviasapora"", ""sha"": ""c346983a3cd0badd12765019269e3d5fbd2323b1"", ""last_modified"": ""2025-01-28 13:10:21+00:00"", ""created_at"": ""2025-01-28 10:26:05+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:silviasapora/argilla-mix-low"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- silviasapora/argilla-mix-low\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan28_10-25-53_b4d476355ce0/events.out.tfevents.1738059966.b4d476355ce0.134895.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-01-28 13:10:21+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- silviasapora/argilla-mix-low\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""6798b0bdc601f04228c466b2"", ""modelId"": ""silviasapora/gemma-7b-leakyrelu-shuffled-5e-5-v4"", ""usedStorage"": 1638840924}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-leakyrelu-shuffled-5e-5-v4&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-leakyrelu-shuffled-5e-5-v4%5D(%2Fsilviasapora%2Fgemma-7b-leakyrelu-shuffled-5e-5-v4)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-borpo-shuffled-5e-5-04-v4,"---
base_model: google/gemma-7b
datasets:
- silviasapora/argilla-mix-low
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['silviasapora/argilla-mix-low']](https://huggingface.co/datasets/['silviasapora/argilla-mix-low']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-borpo-shuffled-5e-5-04-v4"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/m5s4setu) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.13.0
- Transformers: 4.46.1
- Pytorch: 2.4.0
- Datasets: 3.1.0
- Tokenizers: 0.20.1

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-borpo-shuffled-5e-5-04-v4"", ""author"": ""silviasapora"", ""sha"": ""2f0617605cdc0949a45d6d2c556e16a287f938a9"", ""last_modified"": ""2025-01-28 13:13:05+00:00"", ""created_at"": ""2025-01-28 11:04:15+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:silviasapora/argilla-mix-low"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- silviasapora/argilla-mix-low\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan28_11-03-15_82272e4b10b1/events.out.tfevents.1738062256.82272e4b10b1.116554.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-01-28 13:13:05+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- silviasapora/argilla-mix-low\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""6798b9af11ed93b78a508eac"", ""modelId"": ""silviasapora/gemma-7b-borpo-shuffled-5e-5-04-v4"", ""usedStorage"": 838777375}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-borpo-shuffled-5e-5-04-v4&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-borpo-shuffled-5e-5-04-v4%5D(%2Fsilviasapora%2Fgemma-7b-borpo-shuffled-5e-5-04-v4)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-softplus-shuffled-5e-5-v4,"---
base_model: google/gemma-7b
datasets:
- silviasapora/argilla-mix-low
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['silviasapora/argilla-mix-low']](https://huggingface.co/datasets/['silviasapora/argilla-mix-low']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-softplus-shuffled-5e-5-v4"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/dy86yedo) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.13.0
- Transformers: 4.48.1
- Pytorch: 2.5.1
- Datasets: 3.2.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-softplus-shuffled-5e-5-v4"", ""author"": ""silviasapora"", ""sha"": ""9e99d9400a4991fa230961c8e050790f7f3ba795"", ""last_modified"": ""2025-01-28 15:57:01+00:00"", ""created_at"": ""2025-01-28 13:11:59+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:silviasapora/argilla-mix-low"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- silviasapora/argilla-mix-low\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan28_13-11-49_b4d476355ce0/events.out.tfevents.1738069920.b4d476355ce0.136859.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-01-28 15:57:01+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- silviasapora/argilla-mix-low\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""6798d79f495916be7c6944ac"", ""modelId"": ""silviasapora/gemma-7b-softplus-shuffled-5e-5-v4"", ""usedStorage"": 1638840921}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-softplus-shuffled-5e-5-v4&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-softplus-shuffled-5e-5-v4%5D(%2Fsilviasapora%2Fgemma-7b-softplus-shuffled-5e-5-v4)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-simpo-shuffled-5e-5-v4,"---
base_model: google/gemma-7b
datasets:
- silviasapora/argilla-mix-low
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['silviasapora/argilla-mix-low']](https://huggingface.co/datasets/['silviasapora/argilla-mix-low']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-simpo-shuffled-5e-5-v4"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/6hx7jmi5) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.13.0
- Transformers: 4.48.1
- Pytorch: 2.5.1
- Datasets: 3.2.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-simpo-shuffled-5e-5-v4"", ""author"": ""silviasapora"", ""sha"": ""60737866d7cfafae27848a5a15db318c8b7ee7b2"", ""last_modified"": ""2025-01-28 15:56:14+00:00"", ""created_at"": ""2025-01-28 13:12:28+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:silviasapora/argilla-mix-low"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- silviasapora/argilla-mix-low\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan28_13-11-48_b4d476355ce0/events.out.tfevents.1738069949.b4d476355ce0.136856.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-01-28 15:56:14+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- silviasapora/argilla-mix-low\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""6798d7bc05c4a94ebd06f2a9"", ""modelId"": ""silviasapora/gemma-7b-simpo-shuffled-5e-5-v4"", ""usedStorage"": 1638840912}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-simpo-shuffled-5e-5-v4&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-simpo-shuffled-5e-5-v4%5D(%2Fsilviasapora%2Fgemma-7b-simpo-shuffled-5e-5-v4)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-cpo-basic-5e-5-v5,"---
base_model: google/gemma-7b
datasets:
- argilla/dpo-mix-7k
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['argilla/dpo-mix-7k']](https://huggingface.co/datasets/['argilla/dpo-mix-7k']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-cpo-basic-5e-5-v5"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/r72ldo9y) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.13.0
- Transformers: 4.46.1
- Pytorch: 2.4.0
- Datasets: 3.1.0
- Tokenizers: 0.20.1

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-cpo-basic-5e-5-v5"", ""author"": ""silviasapora"", ""sha"": ""e14b12daf9c289c97010b6558c4292324a334141"", ""last_modified"": ""2025-01-28 23:38:40+00:00"", ""created_at"": ""2025-01-28 20:04:34+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:argilla/dpo-mix-7k"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan28_20-04-14_414595abd3b3/events.out.tfevents.1738094676.414595abd3b3.14491.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan28_21-36-09_414595abd3b3/events.out.tfevents.1738100214.414595abd3b3.14990.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-01-28 23:38:40+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67993852993b3c2dfac1404e"", ""modelId"": ""silviasapora/gemma-7b-cpo-basic-5e-5-v5"", ""usedStorage"": 838811436}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-cpo-basic-5e-5-v5&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-cpo-basic-5e-5-v5%5D(%2Fsilviasapora%2Fgemma-7b-cpo-basic-5e-5-v5)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-cpo-noisy-5e-5-v5,"---
base_model: google/gemma-7b
datasets:
- silviasapora/dpo_7k_noisy_10
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['silviasapora/dpo_7k_noisy_10']](https://huggingface.co/datasets/['silviasapora/dpo_7k_noisy_10']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-cpo-noisy-5e-5-v5"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/45vtl6ay) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.13.0
- Transformers: 4.48.1
- Pytorch: 2.5.1
- Datasets: 3.2.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-cpo-noisy-5e-5-v5"", ""author"": ""silviasapora"", ""sha"": ""15fcdc7404f5d4073a33ab43a84e1f1577fbd119"", ""last_modified"": ""2025-01-28 23:03:22+00:00"", ""created_at"": ""2025-01-28 20:05:54+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:silviasapora/dpo_7k_noisy_10"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- silviasapora/dpo_7k_noisy_10\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan28_20-05-44_b4d476355ce0/events.out.tfevents.1738094756.b4d476355ce0.167249.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan28_20-22-46_b4d476355ce0/events.out.tfevents.1738095779.b4d476355ce0.168946.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-01-28 23:03:22+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- silviasapora/dpo_7k_noisy_10\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""679938a2c7c866e59b7b706c"", ""modelId"": ""silviasapora/gemma-7b-cpo-noisy-5e-5-v5"", ""usedStorage"": 1638845577}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-cpo-noisy-5e-5-v5&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-cpo-noisy-5e-5-v5%5D(%2Fsilviasapora%2Fgemma-7b-cpo-noisy-5e-5-v5)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-borpo-shuffled-5e-5-v5,"---
base_model: google/gemma-7b
datasets:
- silviasapora/argilla-mix-low
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['silviasapora/argilla-mix-low']](https://huggingface.co/datasets/['silviasapora/argilla-mix-low']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-borpo-shuffled-5e-5-v5"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/a7p09bfs) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.13.0
- Transformers: 4.48.1
- Pytorch: 2.5.1
- Datasets: 3.2.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-borpo-shuffled-5e-5-v5"", ""author"": ""silviasapora"", ""sha"": ""77a6b76f535ecc1c3d0c23f9fcc706333926a8b4"", ""last_modified"": ""2025-01-28 23:24:02+00:00"", ""created_at"": ""2025-01-28 20:13:38+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:silviasapora/argilla-mix-low"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- silviasapora/argilla-mix-low\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan28_20-12-33_593bafed1c64/events.out.tfevents.1738095221.593bafed1c64.6288.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan28_20-25-54_593bafed1c64/events.out.tfevents.1738095970.593bafed1c64.7204.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan28_20-31-26_593bafed1c64/events.out.tfevents.1738096303.593bafed1c64.8805.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-01-28 23:24:02+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- silviasapora/argilla-mix-low\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67993a72a50c5c94002feb8d"", ""modelId"": ""silviasapora/gemma-7b-borpo-shuffled-5e-5-v5"", ""usedStorage"": 1638855584}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-borpo-shuffled-5e-5-v5&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-borpo-shuffled-5e-5-v5%5D(%2Fsilviasapora%2Fgemma-7b-borpo-shuffled-5e-5-v5)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-borpo-basic-5e-5-v5,"---
base_model: google/gemma-7b
datasets:
- argilla/dpo-mix-7k
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['argilla/dpo-mix-7k']](https://huggingface.co/datasets/['argilla/dpo-mix-7k']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-borpo-basic-5e-5-v5"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/nfhuos2t) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.13.0
- Transformers: 4.48.1
- Pytorch: 2.5.1
- Datasets: 3.2.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-borpo-basic-5e-5-v5"", ""author"": ""silviasapora"", ""sha"": ""6c4a3acf9bb596d0d15dc73481c51ea984808b0e"", ""last_modified"": ""2025-01-28 22:58:27+00:00"", ""created_at"": ""2025-01-28 20:17:05+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:argilla/dpo-mix-7k"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan28_20-16-54_b4d476355ce0/events.out.tfevents.1738095426.b4d476355ce0.168132.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-01-28 22:58:27+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67993b41337290e981243664"", ""modelId"": ""silviasapora/gemma-7b-borpo-basic-5e-5-v5"", ""usedStorage"": 1638835709}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-borpo-basic-5e-5-v5&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-borpo-basic-5e-5-v5%5D(%2Fsilviasapora%2Fgemma-7b-borpo-basic-5e-5-v5)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-orpo-noisy-5e-5-v5,"---
base_model: google/gemma-7b
datasets:
- silviasapora/dpo_7k_noisy_10
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['silviasapora/dpo_7k_noisy_10']](https://huggingface.co/datasets/['silviasapora/dpo_7k_noisy_10']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-orpo-noisy-5e-5-v5"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/w7dql9hh) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.13.0
- Transformers: 4.48.1
- Pytorch: 2.5.1
- Datasets: 3.2.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-orpo-noisy-5e-5-v5"", ""author"": ""silviasapora"", ""sha"": ""e7228b61763988b325ec6c8aee5aa362760df4ff"", ""last_modified"": ""2025-01-28 23:02:26+00:00"", ""created_at"": ""2025-01-28 20:22:57+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:silviasapora/dpo_7k_noisy_10"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- silviasapora/dpo_7k_noisy_10\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan28_20-22-46_b4d476355ce0/events.out.tfevents.1738095779.b4d476355ce0.168949.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-01-28 23:02:26+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- silviasapora/dpo_7k_noisy_10\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67993ca153433a6b824722e5"", ""modelId"": ""silviasapora/gemma-7b-orpo-noisy-5e-5-v5"", ""usedStorage"": 1638835706}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-orpo-noisy-5e-5-v5&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-orpo-noisy-5e-5-v5%5D(%2Fsilviasapora%2Fgemma-7b-orpo-noisy-5e-5-v5)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-borpo-noisy-5e-5-v5,"---
base_model: google/gemma-7b
datasets:
- silviasapora/dpo_7k_noisy_10
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['silviasapora/dpo_7k_noisy_10']](https://huggingface.co/datasets/['silviasapora/dpo_7k_noisy_10']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-borpo-noisy-5e-5-v5"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/8x3zr5y9) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.13.0
- Transformers: 4.48.1
- Pytorch: 2.5.1
- Datasets: 3.2.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-borpo-noisy-5e-5-v5"", ""author"": ""silviasapora"", ""sha"": ""8b02247dbdf99f09bd9cc106b0dd1abd8b16cb81"", ""last_modified"": ""2025-01-28 23:03:08+00:00"", ""created_at"": ""2025-01-28 20:22:57+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:silviasapora/dpo_7k_noisy_10"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- silviasapora/dpo_7k_noisy_10\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan28_20-22-46_b4d476355ce0/events.out.tfevents.1738095778.b4d476355ce0.168952.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-01-28 23:03:08+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- silviasapora/dpo_7k_noisy_10\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67993ca1f0f3ced11f5cca9d"", ""modelId"": ""silviasapora/gemma-7b-borpo-noisy-5e-5-v5"", ""usedStorage"": 1638835709}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-borpo-noisy-5e-5-v5&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-borpo-noisy-5e-5-v5%5D(%2Fsilviasapora%2Fgemma-7b-borpo-noisy-5e-5-v5)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-orpo-shuffled-5e-5-v5,"---
base_model: google/gemma-7b
datasets:
- silviasapora/argilla-mix-low
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['silviasapora/argilla-mix-low']](https://huggingface.co/datasets/['silviasapora/argilla-mix-low']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-orpo-shuffled-5e-5-v5"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/srb7mwnt) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.13.0
- Transformers: 4.48.1
- Pytorch: 2.5.1
- Datasets: 3.2.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-orpo-shuffled-5e-5-v5"", ""author"": ""silviasapora"", ""sha"": ""97c5274471fc61d76d9d1e9b3dd4627bc1f13799"", ""last_modified"": ""2025-01-28 23:25:14+00:00"", ""created_at"": ""2025-01-28 20:26:07+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:silviasapora/argilla-mix-low"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- silviasapora/argilla-mix-low\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan28_20-25-54_593bafed1c64/events.out.tfevents.1738095969.593bafed1c64.7201.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan28_20-31-27_593bafed1c64/events.out.tfevents.1738096302.593bafed1c64.8807.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-01-28 23:25:14+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- silviasapora/argilla-mix-low\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67993d5ff5dd0b85311fb9b5"", ""modelId"": ""silviasapora/gemma-7b-orpo-shuffled-5e-5-v5"", ""usedStorage"": 1638847148}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-orpo-shuffled-5e-5-v5&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-orpo-shuffled-5e-5-v5%5D(%2Fsilviasapora%2Fgemma-7b-orpo-shuffled-5e-5-v5)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-cpo-shuffled-5e-5-v5,"---
base_model: google/gemma-7b
datasets:
- silviasapora/argilla-mix-low
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['silviasapora/argilla-mix-low']](https://huggingface.co/datasets/['silviasapora/argilla-mix-low']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-cpo-shuffled-5e-5-v5"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/h4u7kg6b) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.13.0
- Transformers: 4.48.1
- Pytorch: 2.5.1
- Datasets: 3.2.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-cpo-shuffled-5e-5-v5"", ""author"": ""silviasapora"", ""sha"": ""d87036c198733ff72abab26e2cf021ace6be8692"", ""last_modified"": ""2025-01-28 23:23:26+00:00"", ""created_at"": ""2025-01-28 20:31:41+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:silviasapora/argilla-mix-low"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- silviasapora/argilla-mix-low\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan28_20-31-27_593bafed1c64/events.out.tfevents.1738096303.593bafed1c64.8810.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-01-28 23:23:26+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- silviasapora/argilla-mix-low\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67993ead482020a2dac41505"", ""modelId"": ""silviasapora/gemma-7b-cpo-shuffled-5e-5-v5"", ""usedStorage"": 1638840905}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-cpo-shuffled-5e-5-v5&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-cpo-shuffled-5e-5-v5%5D(%2Fsilviasapora%2Fgemma-7b-cpo-shuffled-5e-5-v5)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-borpo-basic-5e-5-02-v5,"---
base_model: google/gemma-7b
datasets:
- argilla/dpo-mix-7k
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['argilla/dpo-mix-7k']](https://huggingface.co/datasets/['argilla/dpo-mix-7k']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-borpo-basic-5e-5-02-v5"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/bahokwr3) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.13.0
- Transformers: 4.48.1
- Pytorch: 2.5.1
- Datasets: 3.2.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-borpo-basic-5e-5-02-v5"", ""author"": ""silviasapora"", ""sha"": ""71b44c4e12e5ed62d420fba60e476a6c92c64030"", ""last_modified"": ""2025-01-29 15:18:51+00:00"", ""created_at"": ""2025-01-28 23:46:47+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:argilla/dpo-mix-7k"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + ' ' + message['content'] | trim + '<end_of_turn> ' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model '}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan28_23-46-07_b4d476355ce0/events.out.tfevents.1738108010.b4d476355ce0.178481.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan29_12-31-26_593bafed1c64/events.out.tfevents.1738153938.593bafed1c64.13764.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan29_12-33-15_593bafed1c64/events.out.tfevents.1738154011.593bafed1c64.14301.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan29_12-36-04_593bafed1c64/events.out.tfevents.1738154180.593bafed1c64.15361.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-01-29 15:18:51+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67996c67c7c866e59b891340"", ""modelId"": ""silviasapora/gemma-7b-borpo-basic-5e-5-02-v5"", ""usedStorage"": 3239088673}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-borpo-basic-5e-5-02-v5&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-borpo-basic-5e-5-02-v5%5D(%2Fsilviasapora%2Fgemma-7b-borpo-basic-5e-5-02-v5)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-orpo-basic-5e-5-05-v5,"---
base_model: google/gemma-7b
datasets:
- argilla/dpo-mix-7k
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['argilla/dpo-mix-7k']](https://huggingface.co/datasets/['argilla/dpo-mix-7k']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-orpo-basic-5e-5-05-v5"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/yeipla9e) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.13.0
- Transformers: 4.48.1
- Pytorch: 2.5.1
- Datasets: 3.2.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-orpo-basic-5e-5-05-v5"", ""author"": ""silviasapora"", ""sha"": ""629368e32dede77ce7d324c3b58aae8057bb4f6a"", ""last_modified"": ""2025-01-29 05:50:22+00:00"", ""created_at"": ""2025-01-29 01:39:45+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:argilla/dpo-mix-7k"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + ' ' + message['content'] | trim + '<end_of_turn> ' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model '}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan29_01-38-40_593bafed1c64/events.out.tfevents.1738114787.593bafed1c64.12077.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan29_03-08-08_593bafed1c64/events.out.tfevents.1738120103.593bafed1c64.183.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-01-29 05:50:22+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""679986e1270f8f4f7605e4a6"", ""modelId"": ""silviasapora/gemma-7b-orpo-basic-5e-5-05-v5"", ""usedStorage"": 1638865388}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-orpo-basic-5e-5-05-v5&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-orpo-basic-5e-5-05-v5%5D(%2Fsilviasapora%2Fgemma-7b-orpo-basic-5e-5-05-v5)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-silvia-shuffled-5e-5-05-v5,"---
base_model: google/gemma-7b
datasets:
- silviasapora/argilla-mix-low
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['silviasapora/argilla-mix-low']](https://huggingface.co/datasets/['silviasapora/argilla-mix-low']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-silvia-shuffled-5e-5-05-v5"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/ur9d6pk3) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.13.0
- Transformers: 4.48.1
- Pytorch: 2.5.1
- Datasets: 3.2.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-silvia-shuffled-5e-5-05-v5"", ""author"": ""silviasapora"", ""sha"": ""d6b002f9123a6bbf6860e895a0d87d3e8e5b0985"", ""last_modified"": ""2025-01-29 21:02:52+00:00"", ""created_at"": ""2025-01-29 01:59:27+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:silviasapora/argilla-mix-low"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- silviasapora/argilla-mix-low\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + ' ' + message['content'] | trim + '<end_of_turn> ' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model '}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan29_01-59-16_b4d476355ce0/events.out.tfevents.1738115969.b4d476355ce0.183531.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan29_02-34-50_b4d476355ce0/events.out.tfevents.1738118101.b4d476355ce0.188517.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan29_03-37-07_b4d476355ce0/events.out.tfevents.1738121839.b4d476355ce0.193202.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan29_04-08-10_b4d476355ce0/events.out.tfevents.1738123701.b4d476355ce0.193756.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan29_04-17-55_b4d476355ce0/events.out.tfevents.1738124287.b4d476355ce0.194993.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan29_04-44-06_b4d476355ce0/events.out.tfevents.1738125858.b4d476355ce0.196093.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan29_05-10-16_b4d476355ce0/events.out.tfevents.1738127428.b4d476355ce0.197189.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan29_05-18-57_b4d476355ce0/events.out.tfevents.1738127949.b4d476355ce0.198262.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan29_05-20-37_b4d476355ce0/events.out.tfevents.1738128049.b4d476355ce0.199321.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan29_10-42-58_414595abd3b3/events.out.tfevents.1738147464.414595abd3b3.21266.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan29_18-12-19_593bafed1c64/events.out.tfevents.1738174356.593bafed1c64.31031.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-01-29 21:02:52+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- silviasapora/argilla-mix-low\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67998b7f21d341f459a3efcf"", ""modelId"": ""silviasapora/gemma-7b-silvia-shuffled-5e-5-05-v5"", ""usedStorage"": 4039369516}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-silvia-shuffled-5e-5-05-v5&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-silvia-shuffled-5e-5-05-v5%5D(%2Fsilviasapora%2Fgemma-7b-silvia-shuffled-5e-5-05-v5)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-silvia-basic-5e-5-05-v5,"---
base_model: google/gemma-7b
datasets:
- argilla/dpo-mix-7k
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['argilla/dpo-mix-7k']](https://huggingface.co/datasets/['argilla/dpo-mix-7k']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-silvia-basic-5e-5-05-v5"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/n69btssx) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.13.0
- Transformers: 4.48.1
- Pytorch: 2.5.1
- Datasets: 3.2.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-v5"", ""author"": ""silviasapora"", ""sha"": ""6dbd912347f52d39bbc2ed75f8568ac8678883fd"", ""last_modified"": ""2025-01-29 08:01:09+00:00"", ""created_at"": ""2025-01-29 01:59:27+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:argilla/dpo-mix-7k"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + ' ' + message['content'] | trim + '<end_of_turn> ' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model '}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan29_01-59-17_b4d476355ce0/events.out.tfevents.1738115969.b4d476355ce0.183528.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan29_02-26-30_414595abd3b3/events.out.tfevents.1738117653.414595abd3b3.18743.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan29_03-02-43_b4d476355ce0/events.out.tfevents.1738119775.b4d476355ce0.191289.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan29_03-19-02_414595abd3b3/events.out.tfevents.1738120760.414595abd3b3.19249.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan29_03-23-59_b4d476355ce0/events.out.tfevents.1738121051.b4d476355ce0.191981.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan29_03-35-31_b4d476355ce0/events.out.tfevents.1738121743.b4d476355ce0.192529.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan29_04-09-34_b4d476355ce0/events.out.tfevents.1738123787.b4d476355ce0.194293.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan29_04-17-55_b4d476355ce0/events.out.tfevents.1738124287.b4d476355ce0.194990.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan29_04-30-29_414595abd3b3/events.out.tfevents.1738125048.414595abd3b3.19746.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan29_04-44-07_b4d476355ce0/events.out.tfevents.1738125859.b4d476355ce0.196096.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan29_05-10-16_b4d476355ce0/events.out.tfevents.1738127429.b4d476355ce0.197192.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan29_05-18-58_b4d476355ce0/events.out.tfevents.1738127949.b4d476355ce0.198265.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan29_05-20-37_b4d476355ce0/events.out.tfevents.1738128049.b4d476355ce0.199318.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-01-29 08:01:09+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67998b7ff619388895689810"", ""modelId"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-v5"", ""usedStorage"": 2439169966}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-silvia-basic-5e-5-05-v5&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-v5%5D(%2Fsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-v5)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-borpo-basic-5e-5-005-v5,"---
base_model: google/gemma-7b
datasets:
- argilla/dpo-mix-7k
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['argilla/dpo-mix-7k']](https://huggingface.co/datasets/['argilla/dpo-mix-7k']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-borpo-basic-5e-5-005-v5"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/w0e6oelu) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.13.0
- Transformers: 4.48.1
- Pytorch: 2.5.1
- Datasets: 3.2.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-borpo-basic-5e-5-005-v5"", ""author"": ""silviasapora"", ""sha"": ""96715a8df5828592104b6e4bce085dbd84ca692f"", ""last_modified"": ""2025-01-29 07:36:47+00:00"", ""created_at"": ""2025-01-29 04:53:42+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:argilla/dpo-mix-7k"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + ' ' + message['content'] | trim + '<end_of_turn> ' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model '}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan29_04-52-53_593bafed1c64/events.out.tfevents.1738126424.593bafed1c64.8579.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-01-29 07:36:47+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""6799b456f0f3ced11f7dc39a"", ""modelId"": ""silviasapora/gemma-7b-borpo-basic-5e-5-005-v5"", ""usedStorage"": 1638835722}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-borpo-basic-5e-5-005-v5&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-borpo-basic-5e-5-005-v5%5D(%2Fsilviasapora%2Fgemma-7b-borpo-basic-5e-5-005-v5)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-silvia-basic-5e-5-02-v5,"---
base_model: google/gemma-7b
datasets:
- argilla/dpo-mix-7k
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['argilla/dpo-mix-7k']](https://huggingface.co/datasets/['argilla/dpo-mix-7k']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-silvia-basic-5e-5-02-v5"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/n1z1yk2u) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.13.0
- Transformers: 4.46.1
- Pytorch: 2.4.0
- Datasets: 3.1.0
- Tokenizers: 0.20.1

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-silvia-basic-5e-5-02-v5"", ""author"": ""silviasapora"", ""sha"": ""72547b6e79be3d821f8240748e8f9f8a3f0a0ce4"", ""last_modified"": ""2025-01-29 08:37:59+00:00"", ""created_at"": ""2025-01-29 06:35:29+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:argilla/dpo-mix-7k"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + ' ' + message['content'] | trim + '<end_of_turn> ' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model '}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan29_06-33-53_414595abd3b3/events.out.tfevents.1738132530.414595abd3b3.20253.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-01-29 08:37:59+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""6799cc31fe3c29ec21a33b1a"", ""modelId"": ""silviasapora/gemma-7b-silvia-basic-5e-5-02-v5"", ""usedStorage"": 838772175}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-silvia-basic-5e-5-02-v5&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-silvia-basic-5e-5-02-v5%5D(%2Fsilviasapora%2Fgemma-7b-silvia-basic-5e-5-02-v5)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-borpo-basic-5e-5-01-v5,"---
base_model: google/gemma-7b
datasets:
- argilla/dpo-mix-7k
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['argilla/dpo-mix-7k']](https://huggingface.co/datasets/['argilla/dpo-mix-7k']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-borpo-basic-5e-5-01-v5"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/f4l3icyh) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.13.0
- Transformers: 4.48.1
- Pytorch: 2.5.1
- Datasets: 3.2.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-borpo-basic-5e-5-01-v5"", ""author"": ""silviasapora"", ""sha"": ""f9b0e48f2ba06c848cb02ee02fe8cf9da93fc9ed"", ""last_modified"": ""2025-01-29 10:21:07+00:00"", ""created_at"": ""2025-01-29 07:37:55+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:argilla/dpo-mix-7k"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + ' ' + message['content'] | trim + '<end_of_turn> ' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model '}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan29_07-37-06_593bafed1c64/events.out.tfevents.1738136277.593bafed1c64.9152.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-01-29 10:21:07+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""6799dad3d6f1e2e44854ea73"", ""modelId"": ""silviasapora/gemma-7b-borpo-basic-5e-5-01-v5"", ""usedStorage"": 1638835718}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-borpo-basic-5e-5-01-v5&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-borpo-basic-5e-5-01-v5%5D(%2Fsilviasapora%2Fgemma-7b-borpo-basic-5e-5-01-v5)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-silvia-basic-5e-5-01-v5,"---
base_model: google/gemma-7b
datasets:
- argilla/dpo-mix-7k
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['argilla/dpo-mix-7k']](https://huggingface.co/datasets/['argilla/dpo-mix-7k']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-silvia-basic-5e-5-01-v5"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/5bupopoy) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.13.0
- Transformers: 4.46.1
- Pytorch: 2.4.0
- Datasets: 3.1.0
- Tokenizers: 0.20.1

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-silvia-basic-5e-5-01-v5"", ""author"": ""silviasapora"", ""sha"": ""b137fe5e84c034319ed8dbf743f6a4f7f99842e0"", ""last_modified"": ""2025-01-29 10:42:29+00:00"", ""created_at"": ""2025-01-29 08:39:25+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:argilla/dpo-mix-7k"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + ' ' + message['content'] | trim + '<end_of_turn> ' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model '}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan29_08-38-24_414595abd3b3/events.out.tfevents.1738139966.414595abd3b3.20760.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-01-29 10:42:29+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""6799e93d59b5b8a2b491e354"", ""modelId"": ""silviasapora/gemma-7b-silvia-basic-5e-5-01-v5"", ""usedStorage"": 838772175}",1,,0,https://huggingface.co/PrunaAI/silviasapora-gemma-7b-silvia-basic-5e-5-01-v5-GGUF-smashed,1,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-silvia-basic-5e-5-01-v5&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-silvia-basic-5e-5-01-v5%5D(%2Fsilviasapora%2Fgemma-7b-silvia-basic-5e-5-01-v5)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-borpo-basic-5e-5-05-v5,"---
base_model: google/gemma-7b
datasets:
- argilla/dpo-mix-7k
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['argilla/dpo-mix-7k']](https://huggingface.co/datasets/['argilla/dpo-mix-7k']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-borpo-basic-5e-5-05-v5"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/c2sr02mk) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.13.0
- Transformers: 4.48.1
- Pytorch: 2.5.1
- Datasets: 3.2.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-borpo-basic-5e-5-05-v5"", ""author"": ""silviasapora"", ""sha"": ""b35adb11095a42f64a72ecc0b267a226fa28520f"", ""last_modified"": ""2025-01-29 18:01:58+00:00"", ""created_at"": ""2025-01-29 10:21:42+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:argilla/dpo-mix-7k"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + ' ' + message['content'] | trim + '<end_of_turn> ' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model '}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan29_10-21-29_593bafed1c64/events.out.tfevents.1738146104.593bafed1c64.9708.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan29_12-33-51_593bafed1c64/events.out.tfevents.1738154047.593bafed1c64.14831.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan29_15-19-09_593bafed1c64/events.out.tfevents.1738163966.593bafed1c64.27154.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-01-29 18:01:58+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""679a013675d613164c1a11dd"", ""modelId"": ""silviasapora/gemma-7b-borpo-basic-5e-5-05-v5"", ""usedStorage"": 1638886032}",1,,0,https://huggingface.co/PrunaAI/silviasapora-gemma-7b-borpo-basic-5e-5-05-v5-GGUF-smashed,1,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-borpo-basic-5e-5-05-v5&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-borpo-basic-5e-5-05-v5%5D(%2Fsilviasapora%2Fgemma-7b-borpo-basic-5e-5-05-v5)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-silvia-shuffled-5e-5-02-v5,"---
base_model: google/gemma-7b
datasets:
- silviasapora/argilla-mix-low
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['silviasapora/argilla-mix-low']](https://huggingface.co/datasets/['silviasapora/argilla-mix-low']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-silvia-shuffled-5e-5-02-v5"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/iisl3c1d) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.13.0
- Transformers: 4.46.1
- Pytorch: 2.4.0
- Datasets: 3.1.0
- Tokenizers: 0.20.1

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-silvia-shuffled-5e-5-02-v5"", ""author"": ""silviasapora"", ""sha"": ""92c66dc248fb7baebdeafb34a679cf4f57d4a58c"", ""last_modified"": ""2025-01-29 15:06:20+00:00"", ""created_at"": ""2025-01-29 12:55:30+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:silviasapora/argilla-mix-low"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- silviasapora/argilla-mix-low\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + ' ' + message['content'] | trim + '<end_of_turn> ' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model '}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan29_12-54-28_414595abd3b3/events.out.tfevents.1738155332.414595abd3b3.21879.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-01-29 15:06:20+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- silviasapora/argilla-mix-low\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""679a2542465967384ee4f914"", ""modelId"": ""silviasapora/gemma-7b-silvia-shuffled-5e-5-02-v5"", ""usedStorage"": 838777378}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-silvia-shuffled-5e-5-02-v5&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-silvia-shuffled-5e-5-02-v5%5D(%2Fsilviasapora%2Fgemma-7b-silvia-shuffled-5e-5-02-v5)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-borpo-shuffled-5e-5-05-v5,"---
base_model: google/gemma-7b
datasets:
- silviasapora/argilla-mix-low
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['silviasapora/argilla-mix-low']](https://huggingface.co/datasets/['silviasapora/argilla-mix-low']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-borpo-shuffled-5e-5-05-v5"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/hh5108d1) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.13.0
- Transformers: 4.48.1
- Pytorch: 2.5.1
- Datasets: 3.2.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-borpo-shuffled-5e-5-05-v5"", ""author"": ""silviasapora"", ""sha"": ""feb89201a65fa61633ec55d5285aad51c3935b4b"", ""last_modified"": ""2025-01-29 18:55:15+00:00"", ""created_at"": ""2025-01-29 14:25:56+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:silviasapora/argilla-mix-low"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- silviasapora/argilla-mix-low\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + ' ' + message['content'] | trim + '<end_of_turn> ' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model '}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan29_14-24-50_593bafed1c64/events.out.tfevents.1738160757.593bafed1c64.25978.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan29_16-04-19_593bafed1c64/events.out.tfevents.1738166675.593bafed1c64.28501.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-01-29 18:55:15+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- silviasapora/argilla-mix-low\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""679a3a74c33e59da38ab22dc"", ""modelId"": ""silviasapora/gemma-7b-borpo-shuffled-5e-5-05-v5"", ""usedStorage"": 1638881470}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-borpo-shuffled-5e-5-05-v5&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-borpo-shuffled-5e-5-05-v5%5D(%2Fsilviasapora%2Fgemma-7b-borpo-shuffled-5e-5-05-v5)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-slic-basic-5e-5-05-v5,"---
base_model: google/gemma-7b
datasets:
- argilla/dpo-mix-7k
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['argilla/dpo-mix-7k']](https://huggingface.co/datasets/['argilla/dpo-mix-7k']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-slic-basic-5e-5-05-v5"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/iod0j5dx) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.13.0
- Transformers: 4.46.1
- Pytorch: 2.4.0
- Datasets: 3.1.0
- Tokenizers: 0.20.1

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-slic-basic-5e-5-05-v5"", ""author"": ""silviasapora"", ""sha"": ""1edccecce629816e027835459f7af336b6a99def"", ""last_modified"": ""2025-01-30 18:02:36+00:00"", ""created_at"": ""2025-01-29 16:25:29+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:argilla/dpo-mix-7k"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + ' ' + message['content'] | trim + '<end_of_turn> ' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model '}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan29_16-25-12_414595abd3b3/events.out.tfevents.1738167930.414595abd3b3.23268.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan29_16-26-45_414595abd3b3/events.out.tfevents.1738168023.414595abd3b3.23887.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan29_16-29-07_414595abd3b3/events.out.tfevents.1738168166.414595abd3b3.25071.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan29_17-29-16_414595abd3b3/events.out.tfevents.1738171779.414595abd3b3.26541.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan29_18-01-26_414595abd3b3/events.out.tfevents.1738173730.414595abd3b3.27379.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan29_18-03-28_414595abd3b3/events.out.tfevents.1738173827.414595abd3b3.27860.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan29_18-04-25_414595abd3b3/events.out.tfevents.1738173883.414595abd3b3.28332.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan30_15-59-06_414595abd3b3/events.out.tfevents.1738252770.414595abd3b3.33035.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-01-30 18:02:36+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""679a56792bfbc7c847c2c849"", ""modelId"": ""silviasapora/gemma-7b-slic-basic-5e-5-05-v5"", ""usedStorage"": 1639013822}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-slic-basic-5e-5-05-v5&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-slic-basic-5e-5-05-v5%5D(%2Fsilviasapora%2Fgemma-7b-slic-basic-5e-5-05-v5)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-slic-shuffled-5e-5-05-v5,"---
base_model: google/gemma-7b
datasets:
- silviasapora/argilla-mix-low
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['silviasapora/argilla-mix-low']](https://huggingface.co/datasets/['silviasapora/argilla-mix-low']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-slic-shuffled-5e-5-05-v5"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/9v7v1wjj) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.13.0
- Transformers: 4.46.1
- Pytorch: 2.4.0
- Datasets: 3.1.0
- Tokenizers: 0.20.1

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-slic-shuffled-5e-5-05-v5"", ""author"": ""silviasapora"", ""sha"": ""f98090f2cbed6f5bd9136406d466105c47f4c156"", ""last_modified"": ""2025-01-29 20:17:11+00:00"", ""created_at"": ""2025-01-29 16:27:52+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:silviasapora/argilla-mix-low"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- silviasapora/argilla-mix-low\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + ' ' + message['content'] | trim + '<end_of_turn> ' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model '}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan29_16-27-34_414595abd3b3/events.out.tfevents.1738168073.414595abd3b3.24445.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan29_16-28-47_414595abd3b3/events.out.tfevents.1738168145.414595abd3b3.24917.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan29_16-32-05_414595abd3b3/events.out.tfevents.1738168348.414595abd3b3.25861.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan29_17-28-59_414595abd3b3/events.out.tfevents.1738171779.414595abd3b3.26387.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan29_18-06-43_414595abd3b3/events.out.tfevents.1738174021.414595abd3b3.28819.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-01-29 20:17:11+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- silviasapora/argilla-mix-low\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""679a5708dfc4ad408f2c0592"", ""modelId"": ""silviasapora/gemma-7b-slic-shuffled-5e-5-05-v5"", ""usedStorage"": 838836609}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-slic-shuffled-5e-5-05-v5&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-slic-shuffled-5e-5-05-v5%5D(%2Fsilviasapora%2Fgemma-7b-slic-shuffled-5e-5-05-v5)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-silvia-shuffled-5e-5-05-v6-08sftt,"---
base_model: google/gemma-7b
datasets:
- silviasapora/argilla-mix-low
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['silviasapora/argilla-mix-low']](https://huggingface.co/datasets/['silviasapora/argilla-mix-low']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-silvia-shuffled-5e-5-05-v6-08sftt"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/06tumc8r) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.13.0
- Transformers: 4.48.1
- Pytorch: 2.5.1
- Datasets: 3.2.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-silvia-shuffled-5e-5-05-v6-08sftt"", ""author"": ""silviasapora"", ""sha"": ""27474b8ca7d565d9b3044d1d6ae9c5f2522ab7c2"", ""last_modified"": ""2025-01-29 22:27:09+00:00"", ""created_at"": ""2025-01-29 19:36:16+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:silviasapora/argilla-mix-low"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- silviasapora/argilla-mix-low\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + ' ' + message['content'] | trim + '<end_of_turn> ' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model '}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan29_19-35-53_593bafed1c64/events.out.tfevents.1738179378.593bafed1c64.32843.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-01-29 22:27:09+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- silviasapora/argilla-mix-low\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""679a83308acd9f7b0c071281"", ""modelId"": ""silviasapora/gemma-7b-silvia-shuffled-5e-5-05-v6-08sftt"", ""usedStorage"": 1638844560}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-silvia-shuffled-5e-5-05-v6-08sftt&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-silvia-shuffled-5e-5-05-v6-08sftt%5D(%2Fsilviasapora%2Fgemma-7b-silvia-shuffled-5e-5-05-v6-08sftt)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-silvia-shuffled-5e-5-05-v6-1sftt,"---
base_model: google/gemma-7b
datasets:
- silviasapora/argilla-mix-low
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['silviasapora/argilla-mix-low']](https://huggingface.co/datasets/['silviasapora/argilla-mix-low']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-silvia-shuffled-5e-5-05-v6-1sftt"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/et5ungxj) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.13.0
- Transformers: 4.48.1
- Pytorch: 2.5.1
- Datasets: 3.2.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-silvia-shuffled-5e-5-05-v6-1sftt"", ""author"": ""silviasapora"", ""sha"": ""f68462e4981ae116c77ba8f107bb0d80b14725cd"", ""last_modified"": ""2025-01-29 22:30:01+00:00"", ""created_at"": ""2025-01-29 19:40:03+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:silviasapora/argilla-mix-low"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- silviasapora/argilla-mix-low\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + ' ' + message['content'] | trim + '<end_of_turn> ' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model '}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan29_19-39-40_593bafed1c64/events.out.tfevents.1738179606.593bafed1c64.33600.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-01-29 22:30:01+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- silviasapora/argilla-mix-low\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""679a84131f5daa58c07d7083"", ""modelId"": ""silviasapora/gemma-7b-silvia-shuffled-5e-5-05-v6-1sftt"", ""usedStorage"": 1638844557}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-silvia-shuffled-5e-5-05-v6-1sftt&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-silvia-shuffled-5e-5-05-v6-1sftt%5D(%2Fsilviasapora%2Fgemma-7b-silvia-shuffled-5e-5-05-v6-1sftt)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-slic-basic-5e-5-05-v5-1sftt-gamma10,"---
base_model: google/gemma-7b
datasets:
- argilla/dpo-mix-7k
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['argilla/dpo-mix-7k']](https://huggingface.co/datasets/['argilla/dpo-mix-7k']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-slic-basic-5e-5-05-v5-1sftt-gamma10"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/hmm7jfjo) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.13.0
- Transformers: 4.46.1
- Pytorch: 2.4.0
- Datasets: 3.1.0
- Tokenizers: 0.20.1

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-slic-basic-5e-5-05-v5-1sftt-gamma10"", ""author"": ""silviasapora"", ""sha"": ""5c3a9c7119d21e2fd9a5b08dd1c076033839aa81"", ""last_modified"": ""2025-01-30 22:31:13+00:00"", ""created_at"": ""2025-01-30 20:28:39+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:argilla/dpo-mix-7k"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + ' ' + message['content'] | trim + '<end_of_turn> ' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model '}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan30_20-28-22_414595abd3b3/events.out.tfevents.1738268920.414595abd3b3.35430.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-01-30 22:31:13+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""679be0f76510bc938eced2e7"", ""modelId"": ""silviasapora/gemma-7b-slic-basic-5e-5-05-v5-1sftt-gamma10"", ""usedStorage"": 838772211}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-slic-basic-5e-5-05-v5-1sftt-gamma10&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-slic-basic-5e-5-05-v5-1sftt-gamma10%5D(%2Fsilviasapora%2Fgemma-7b-slic-basic-5e-5-05-v5-1sftt-gamma10)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-silvia-basic-5e-5-05-v5-1sftt-gamma10,"---
base_model: google/gemma-7b
datasets:
- argilla/dpo-mix-7k
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['argilla/dpo-mix-7k']](https://huggingface.co/datasets/['argilla/dpo-mix-7k']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-silvia-basic-5e-5-05-v5-1sftt-gamma10"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/79522cp6) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.13.0
- Transformers: 4.46.1
- Pytorch: 2.4.0
- Datasets: 3.1.0
- Tokenizers: 0.20.1

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-v5-1sftt-gamma10"", ""author"": ""silviasapora"", ""sha"": ""7d99000122a3b77f91d6763b5ef1dfe9df5568b0"", ""last_modified"": ""2025-01-31 02:47:16+00:00"", ""created_at"": ""2025-01-31 00:44:40+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:argilla/dpo-mix-7k"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + ' ' + message['content'] | trim + '<end_of_turn> ' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model '}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan31_00-44-16_414595abd3b3/events.out.tfevents.1738284280.414595abd3b3.35939.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-01-31 02:47:16+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""679c1cf83046a3013dda2b26"", ""modelId"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-v5-1sftt-gamma10"", ""usedStorage"": 838772217}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-silvia-basic-5e-5-05-v5-1sftt-gamma10&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-v5-1sftt-gamma10%5D(%2Fsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-v5-1sftt-gamma10)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-silvia-basic-5e-5-05-v5-1sftt-gamma5,"---
base_model: google/gemma-7b
datasets:
- argilla/dpo-mix-7k
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['argilla/dpo-mix-7k']](https://huggingface.co/datasets/['argilla/dpo-mix-7k']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-silvia-basic-5e-5-05-v5-1sftt-gamma5"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/l88fi4pp) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.13.0
- Transformers: 4.46.1
- Pytorch: 2.4.0
- Datasets: 3.1.0
- Tokenizers: 0.20.1

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-v5-1sftt-gamma5"", ""author"": ""silviasapora"", ""sha"": ""dbb52aac814bff6453451c337520145b4fc0c616"", ""last_modified"": ""2025-01-31 08:34:41+00:00"", ""created_at"": ""2025-01-31 03:38:31+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:argilla/dpo-mix-7k"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + ' ' + message['content'] | trim + '<end_of_turn> ' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model '}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan31_03-38-13_414595abd3b3/events.out.tfevents.1738294712.414595abd3b3.38041.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan31_06-31-36_414595abd3b3/events.out.tfevents.1738305115.414595abd3b3.40138.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-01-31 08:34:41+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""679c45b724e702a242fc1f0d"", ""modelId"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-v5-1sftt-gamma5"", ""usedStorage"": 1638950635}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-silvia-basic-5e-5-05-v5-1sftt-gamma5&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-v5-1sftt-gamma5%5D(%2Fsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-v5-1sftt-gamma5)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-silvia-basic-5e-5-05-v5-05sftt-gamma5,"---
base_model: google/gemma-7b
datasets:
- argilla/dpo-mix-7k
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['argilla/dpo-mix-7k']](https://huggingface.co/datasets/['argilla/dpo-mix-7k']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-silvia-basic-5e-5-05-v5-05sftt-gamma5"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/g99scf6p) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.13.0
- Transformers: 4.46.1
- Pytorch: 2.4.0
- Datasets: 3.1.0
- Tokenizers: 0.20.1

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-v5-05sftt-gamma5"", ""author"": ""silviasapora"", ""sha"": ""85f5c39cc3b62523e59281d5cd0b8e5e41b5bc46"", ""last_modified"": ""2025-01-31 12:39:30+00:00"", ""created_at"": ""2025-01-31 10:37:17+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:argilla/dpo-mix-7k"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + ' ' + message['content'] | trim + '<end_of_turn> ' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model '}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Jan31_10-37-00_414595abd3b3/events.out.tfevents.1738319838.414595abd3b3.42525.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-01-31 12:39:30+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""679ca7dd3c89c62d32883eab"", ""modelId"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-v5-05sftt-gamma5"", ""usedStorage"": 838775468}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-silvia-basic-5e-5-05-v5-05sftt-gamma5&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-v5-05sftt-gamma5%5D(%2Fsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-v5-05sftt-gamma5)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp1,"---
base_model: google/gemma-7b
datasets:
- argilla/dpo-mix-7k
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['argilla/dpo-mix-7k']](https://huggingface.co/datasets/['argilla/dpo-mix-7k']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp1"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/dy83al4g) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.13.0
- Transformers: 4.48.1
- Pytorch: 2.5.1
- Datasets: 3.2.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp1"", ""author"": ""silviasapora"", ""sha"": ""f951f39c364ff9842abb4543c5c7ff5e0980bac6"", ""last_modified"": ""2025-02-27 00:00:31+00:00"", ""created_at"": ""2025-02-19 15:55:53+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 2, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:argilla/dpo-mix-7k"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + ' ' + message['content'] | trim + '<end_of_turn> ' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model '}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Feb19_15-54-31_e967ea18ab86/events.out.tfevents.1739980554.e967ea18ab86.1382.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Feb26_16-30-04_6df9d1e4444f/events.out.tfevents.1740587418.6df9d1e4444f.9336.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Feb26_21-17-07_e967ea18ab86/events.out.tfevents.1740604658.e967ea18ab86.241404.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Feb26_21-18-44_e967ea18ab86/events.out.tfevents.1740604737.e967ea18ab86.244669.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Feb26_21-20-14_e967ea18ab86/events.out.tfevents.1740604828.e967ea18ab86.247062.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-02-27 00:00:31+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67b5ff09194f0442be4be394"", ""modelId"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp1"", ""usedStorage"": 4839327557}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp1&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-vshp1%5D(%2Fsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-vshp1)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp0,"---
base_model: google/gemma-7b
datasets:
- argilla/dpo-mix-7k
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['argilla/dpo-mix-7k']](https://huggingface.co/datasets/['argilla/dpo-mix-7k']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp0"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/ug7b0chy) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.13.0
- Transformers: 4.48.1
- Pytorch: 2.5.1
- Datasets: 3.2.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp0"", ""author"": ""silviasapora"", ""sha"": ""86cc1c6f9f370554299057647692fc55ffbfef64"", ""last_modified"": ""2025-02-27 00:00:24+00:00"", ""created_at"": ""2025-02-19 15:55:53+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 2, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:argilla/dpo-mix-7k"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + ' ' + message['content'] | trim + '<end_of_turn> ' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model '}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Feb19_15-54-32_e967ea18ab86/events.out.tfevents.1739980555.e967ea18ab86.1378.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Feb26_00-14-00_425eae2e39a5/events.out.tfevents.1740528856.425eae2e39a5.1247.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Feb26_00-23-20_425eae2e39a5/events.out.tfevents.1740529415.425eae2e39a5.5280.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Feb26_00-24-16_425eae2e39a5/events.out.tfevents.1740529472.425eae2e39a5.6170.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Feb26_13-54-45_425eae2e39a5/events.out.tfevents.1740578101.425eae2e39a5.15240.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Feb26_15-01-22_425eae2e39a5/events.out.tfevents.1740582098.425eae2e39a5.21445.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Feb26_16-30-04_6df9d1e4444f/events.out.tfevents.1740587419.6df9d1e4444f.9335.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Feb26_21-17-07_e967ea18ab86/events.out.tfevents.1740604658.e967ea18ab86.241408.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Feb26_21-20-15_e967ea18ab86/events.out.tfevents.1740604828.e967ea18ab86.247056.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-02-27 00:00:24+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67b5ff0985107d2014993ab6"", ""modelId"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp0"", ""usedStorage"": 6439605177}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp0&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-vshp0%5D(%2Fsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-vshp0)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp3,"---
base_model: google/gemma-7b
datasets:
- argilla/dpo-mix-7k
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['argilla/dpo-mix-7k']](https://huggingface.co/datasets/['argilla/dpo-mix-7k']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp3"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/jy6upiud) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.13.0
- Transformers: 4.48.1
- Pytorch: 2.5.1
- Datasets: 3.2.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp3"", ""author"": ""silviasapora"", ""sha"": ""44a738d73d6d5ec05e5a2c5d7218fd21b955493c"", ""last_modified"": ""2025-02-27 02:40:43+00:00"", ""created_at"": ""2025-02-19 18:49:44+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 3, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:argilla/dpo-mix-7k"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + ' ' + message['content'] | trim + '<end_of_turn> ' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model '}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Feb19_18-49-32_e967ea18ab86/events.out.tfevents.1739990986.e967ea18ab86.2735.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Feb26_19-10-52_6df9d1e4444f/events.out.tfevents.1740597069.6df9d1e4444f.58580.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Feb26_21-17-07_e967ea18ab86/events.out.tfevents.1740604658.e967ea18ab86.241413.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Feb27_00-00-48_e967ea18ab86/events.out.tfevents.1740614480.e967ea18ab86.303331.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-02-27 02:40:43+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67b627c834a2d76785a896e4"", ""modelId"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp3"", ""usedStorage"": 4839321967}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp3&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-vshp3%5D(%2Fsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-vshp3)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp2,"---
base_model: google/gemma-7b
datasets:
- argilla/dpo-mix-7k
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['argilla/dpo-mix-7k']](https://huggingface.co/datasets/['argilla/dpo-mix-7k']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp2"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/4uyt69lx) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.13.0
- Transformers: 4.49.0
- Pytorch: 2.5.1
- Datasets: 3.2.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp2"", ""author"": ""silviasapora"", ""sha"": ""d259f99b54e35b13de65d9c3f7ef2909d1b0545f"", ""last_modified"": ""2025-02-26 21:51:29+00:00"", ""created_at"": ""2025-02-19 18:49:44+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 2, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:argilla/dpo-mix-7k"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + ' ' + message['content'] | trim + '<end_of_turn> ' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model '}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Feb19_18-49-31_e967ea18ab86/events.out.tfevents.1739990986.e967ea18ab86.2732.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Feb26_19-10-52_6df9d1e4444f/events.out.tfevents.1740597069.6df9d1e4444f.58577.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-02-26 21:51:29+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67b627c84f5db7d4bef7719f"", ""modelId"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp2"", ""usedStorage"": 3239074311}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp2&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-vshp2%5D(%2Fsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-vshp2)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp5,"---
base_model: google/gemma-7b
datasets:
- argilla/dpo-mix-7k
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['argilla/dpo-mix-7k']](https://huggingface.co/datasets/['argilla/dpo-mix-7k']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp5"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/ldc2lpf1) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.13.0
- Transformers: 4.48.1
- Pytorch: 2.5.1
- Datasets: 3.2.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp5"", ""author"": ""silviasapora"", ""sha"": ""558a811e38392c7511c8f122a37d3b220d705863"", ""last_modified"": ""2025-02-27 02:41:06+00:00"", ""created_at"": ""2025-02-19 21:32:21+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 3, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:argilla/dpo-mix-7k"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + ' ' + message['content'] | trim + '<end_of_turn> ' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model '}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Feb19_21-32-09_e967ea18ab86/events.out.tfevents.1740000743.e967ea18ab86.3843.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Feb26_21-51-50_6df9d1e4444f/events.out.tfevents.1740606726.6df9d1e4444f.92461.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Feb27_00-00-48_e967ea18ab86/events.out.tfevents.1740614472.e967ea18ab86.303328.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-02-27 02:41:06+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67b64de513df25808fcd22e7"", ""modelId"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp5"", ""usedStorage"": 4839316374}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp5&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-vshp5%5D(%2Fsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-vshp5)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp4,"---
base_model: google/gemma-7b
datasets:
- argilla/dpo-mix-7k
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['argilla/dpo-mix-7k']](https://huggingface.co/datasets/['argilla/dpo-mix-7k']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp4"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/cqk5n8k3) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.13.0
- Transformers: 4.48.1
- Pytorch: 2.5.1
- Datasets: 3.2.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp4"", ""author"": ""silviasapora"", ""sha"": ""5590ba9ca35e78a143949459087b0b2d2d40a251"", ""last_modified"": ""2025-02-27 02:41:27+00:00"", ""created_at"": ""2025-02-19 21:32:21+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 3, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:argilla/dpo-mix-7k"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + ' ' + message['content'] | trim + '<end_of_turn> ' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model '}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Feb19_21-32-09_e967ea18ab86/events.out.tfevents.1740000743.e967ea18ab86.3846.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Feb26_21-51-49_6df9d1e4444f/events.out.tfevents.1740606726.6df9d1e4444f.92458.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Feb27_00-00-48_e967ea18ab86/events.out.tfevents.1740614479.e967ea18ab86.303334.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-02-27 02:41:27+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67b64de52834a8690e96f610"", ""modelId"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp4"", ""usedStorage"": 4839316377}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp4&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-vshp4%5D(%2Fsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-vshp4)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp7,"---
base_model: google/gemma-7b
datasets:
- argilla/dpo-mix-7k
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['argilla/dpo-mix-7k']](https://huggingface.co/datasets/['argilla/dpo-mix-7k']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp7"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/unorn36d) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.13.0
- Transformers: 4.48.1
- Pytorch: 2.5.1
- Datasets: 3.2.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp7"", ""author"": ""silviasapora"", ""sha"": ""128c84791c807466caa76da28c0ee246beac69c5"", ""last_modified"": ""2025-02-27 05:21:43+00:00"", ""created_at"": ""2025-02-20 00:15:14+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 3, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:argilla/dpo-mix-7k"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + ' ' + message['content'] | trim + '<end_of_turn> ' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model '}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Feb20_00-15-02_e967ea18ab86/events.out.tfevents.1740010516.e967ea18ab86.4946.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Feb27_00-33-48_6df9d1e4444f/events.out.tfevents.1740616462.6df9d1e4444f.156246.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Feb27_02-41-44_e967ea18ab86/events.out.tfevents.1740624116.e967ea18ab86.337089.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-02-27 05:21:43+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67b67412ed945e53d07a5f4a"", ""modelId"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp7"", ""usedStorage"": 4839316378}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp7&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-vshp7%5D(%2Fsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-vshp7)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp6,"---
base_model: google/gemma-7b
datasets:
- argilla/dpo-mix-7k
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['argilla/dpo-mix-7k']](https://huggingface.co/datasets/['argilla/dpo-mix-7k']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp6"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/a2i5tdc1) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.13.0
- Transformers: 4.48.1
- Pytorch: 2.5.1
- Datasets: 3.2.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp6"", ""author"": ""silviasapora"", ""sha"": ""e20204968f8437e9f5447b33df40d99d66444d42"", ""last_modified"": ""2025-02-27 05:21:32+00:00"", ""created_at"": ""2025-02-20 00:15:15+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 4, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:argilla/dpo-mix-7k"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + ' ' + message['content'] | trim + '<end_of_turn> ' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model '}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Feb20_00-15-03_e967ea18ab86/events.out.tfevents.1740010517.e967ea18ab86.4943.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Feb27_00-33-46_6df9d1e4444f/events.out.tfevents.1740616462.6df9d1e4444f.156242.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Feb27_02-41-44_e967ea18ab86/events.out.tfevents.1740624118.e967ea18ab86.337083.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-02-27 05:21:32+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67b6741341a6811fc79ddbfb"", ""modelId"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp6"", ""usedStorage"": 4839316378}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp6&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-vshp6%5D(%2Fsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-vshp6)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp9,"---
base_model: google/gemma-7b
datasets:
- argilla/dpo-mix-7k
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['argilla/dpo-mix-7k']](https://huggingface.co/datasets/['argilla/dpo-mix-7k']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp9"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/sc8pgwzh) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.13.0
- Transformers: 4.48.1
- Pytorch: 2.5.1
- Datasets: 3.2.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp9"", ""author"": ""silviasapora"", ""sha"": ""1eec321b018d0ec1b4068dec64ed64d89bc8ad08"", ""last_modified"": ""2025-02-27 08:01:31+00:00"", ""created_at"": ""2025-02-20 03:03:01+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 3, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:argilla/dpo-mix-7k"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + ' ' + message['content'] | trim + '<end_of_turn> ' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model '}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Feb20_03-02-49_e967ea18ab86/events.out.tfevents.1740020583.e967ea18ab86.6045.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Feb27_03-15-14_6df9d1e4444f/events.out.tfevents.1740626134.6df9d1e4444f.166238.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Feb27_05-22-00_e967ea18ab86/events.out.tfevents.1740633734.e967ea18ab86.338795.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-02-27 08:01:31+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67b69b65e63619060fc35e8b"", ""modelId"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp9"", ""usedStorage"": 4839316379}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp9&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-vshp9%5D(%2Fsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-vshp9)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp8,"---
base_model: google/gemma-7b
datasets:
- argilla/dpo-mix-7k
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['argilla/dpo-mix-7k']](https://huggingface.co/datasets/['argilla/dpo-mix-7k']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp8"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/4wmia9gb) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.13.0
- Transformers: 4.49.0
- Pytorch: 2.5.1
- Datasets: 3.2.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp8"", ""author"": ""silviasapora"", ""sha"": ""cdd25022e316db75fed8f6209687a9256ad93eaf"", ""last_modified"": ""2025-02-27 05:56:25+00:00"", ""created_at"": ""2025-02-20 03:03:02+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 3, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:argilla/dpo-mix-7k"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + ' ' + message['content'] | trim + '<end_of_turn> ' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model '}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Feb20_03-02-49_e967ea18ab86/events.out.tfevents.1740020584.e967ea18ab86.6048.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Feb27_02-41-43_e967ea18ab86/events.out.tfevents.1740624117.e967ea18ab86.337086.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Feb27_03-15-14_6df9d1e4444f/events.out.tfevents.1740626134.6df9d1e4444f.166239.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-02-27 05:56:25+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67b69b66baad730d6437ef46"", ""modelId"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp8"", ""usedStorage"": 4839316375}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp8&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-vshp8%5D(%2Fsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-vshp8)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp10,"---
base_model: google/gemma-7b
datasets:
- argilla/dpo-mix-7k
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['argilla/dpo-mix-7k']](https://huggingface.co/datasets/['argilla/dpo-mix-7k']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp10"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/l8g8wl4d) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.13.0
- Transformers: 4.49.0
- Pytorch: 2.5.1
- Datasets: 3.2.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp10"", ""author"": ""silviasapora"", ""sha"": ""54a2cd017cab9f779a6facef95ca06d3b83946c6"", ""last_modified"": ""2025-02-27 08:48:28+00:00"", ""created_at"": ""2025-02-20 05:46:16+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 3, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:argilla/dpo-mix-7k"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + ' ' + message['content'] | trim + '<end_of_turn> ' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model '}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Feb20_05-46-03_e967ea18ab86/events.out.tfevents.1740030377.e967ea18ab86.7159.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Feb27_05-21-59_e967ea18ab86/events.out.tfevents.1740633733.e967ea18ab86.338800.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Feb27_06-08-25_6df9d1e4444f/events.out.tfevents.1740636521.6df9d1e4444f.167246.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-02-27 08:48:28+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67b6c1a8475309d4e9a6e03d"", ""modelId"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp10"", ""usedStorage"": 4839316388}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp10&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-vshp10%5D(%2Fsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-vshp10)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp11,"---
base_model: google/gemma-7b
datasets:
- argilla/dpo-mix-7k
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['argilla/dpo-mix-7k']](https://huggingface.co/datasets/['argilla/dpo-mix-7k']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp11"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/kl5exvqy) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.13.0
- Transformers: 4.49.0
- Pytorch: 2.5.1
- Datasets: 3.2.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp11"", ""author"": ""silviasapora"", ""sha"": ""75d453acdfa27450feea26f379e37fc72719e091"", ""last_modified"": ""2025-02-27 08:49:55+00:00"", ""created_at"": ""2025-02-20 05:46:16+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 3, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:argilla/dpo-mix-7k"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + ' ' + message['content'] | trim + '<end_of_turn> ' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model '}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Feb20_05-46-04_e967ea18ab86/events.out.tfevents.1740030378.e967ea18ab86.7155.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Feb27_05-21-59_e967ea18ab86/events.out.tfevents.1740633732.e967ea18ab86.338799.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Feb27_06-08-24_6df9d1e4444f/events.out.tfevents.1740636520.6df9d1e4444f.167243.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-02-27 08:49:55+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67b6c1a8cf1408b9b6e24653"", ""modelId"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp11"", ""usedStorage"": 4839316385}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp11&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-vshp11%5D(%2Fsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-vshp11)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp12,"---
base_model: google/gemma-7b
datasets:
- argilla/dpo-mix-7k
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['argilla/dpo-mix-7k']](https://huggingface.co/datasets/['argilla/dpo-mix-7k']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp12"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/s76b94il) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.13.0
- Transformers: 4.49.0
- Pytorch: 2.5.1
- Datasets: 3.2.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp12"", ""author"": ""silviasapora"", ""sha"": ""d4c4d6b70e5be0c1b6871a870cb5d7abed9044d2"", ""last_modified"": ""2025-02-27 11:30:04+00:00"", ""created_at"": ""2025-02-20 08:30:36+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 3, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:argilla/dpo-mix-7k"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + ' ' + message['content'] | trim + '<end_of_turn> ' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model '}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Feb20_08-30-24_e967ea18ab86/events.out.tfevents.1740040239.e967ea18ab86.8263.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Feb27_08-11-24_e967ea18ab86/events.out.tfevents.1740643898.e967ea18ab86.340474.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Feb27_08-50-14_6df9d1e4444f/events.out.tfevents.1740646230.6df9d1e4444f.168244.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-02-27 11:30:04+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67b6e82ca9195b31652e1c81"", ""modelId"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp12"", ""usedStorage"": 4839316388}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp12&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-vshp12%5D(%2Fsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-vshp12)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp13,"---
base_model: google/gemma-7b
datasets:
- argilla/dpo-mix-7k
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['argilla/dpo-mix-7k']](https://huggingface.co/datasets/['argilla/dpo-mix-7k']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp13"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/90o1ovfk) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.13.0
- Transformers: 4.49.0
- Pytorch: 2.5.1
- Datasets: 3.2.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp13"", ""author"": ""silviasapora"", ""sha"": ""a4e4e73aa8a6f38e0c087df2f23087ef82b373ec"", ""last_modified"": ""2025-02-27 11:30:54+00:00"", ""created_at"": ""2025-02-20 08:30:37+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 4, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:argilla/dpo-mix-7k"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + ' ' + message['content'] | trim + '<end_of_turn> ' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model '}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Feb20_08-30-24_e967ea18ab86/events.out.tfevents.1740040239.e967ea18ab86.8266.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Feb27_08-11-24_e967ea18ab86/events.out.tfevents.1740643897.e967ea18ab86.340478.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Feb27_08-50-14_6df9d1e4444f/events.out.tfevents.1740646230.6df9d1e4444f.168241.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-02-27 11:30:54+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67b6e82d1cca080042e805ae"", ""modelId"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp13"", ""usedStorage"": 4839316388}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp13&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-vshp13%5D(%2Fsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-vshp13)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp14,"---
base_model: google/gemma-7b
datasets:
- argilla/dpo-mix-7k
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['argilla/dpo-mix-7k']](https://huggingface.co/datasets/['argilla/dpo-mix-7k']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp14"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/3via6qvy) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.13.0
- Transformers: 4.49.0
- Pytorch: 2.5.1
- Datasets: 3.2.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp14"", ""author"": ""silviasapora"", ""sha"": ""9afd814570abbb35b4ab047898fe977c4ab54036"", ""last_modified"": ""2025-02-27 14:12:07+00:00"", ""created_at"": ""2025-02-20 11:13:09+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 3, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:argilla/dpo-mix-7k"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + ' ' + message['content'] | trim + '<end_of_turn> ' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model '}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Feb20_11-12-56_e967ea18ab86/events.out.tfevents.1740049991.e967ea18ab86.9239.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Feb27_08-11-24_e967ea18ab86/events.out.tfevents.1740643897.e967ea18ab86.340479.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Feb27_11-31-14_6df9d1e4444f/events.out.tfevents.1740655891.6df9d1e4444f.169180.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-02-27 14:12:07+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67b70e455599f718b33d0452"", ""modelId"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp14"", ""usedStorage"": 4839316385}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp14&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-vshp14%5D(%2Fsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-vshp14)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp15,"---
base_model: google/gemma-7b
datasets:
- argilla/dpo-mix-7k
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['argilla/dpo-mix-7k']](https://huggingface.co/datasets/['argilla/dpo-mix-7k']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp15"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/oyaz47jv) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.13.0
- Transformers: 4.48.1
- Pytorch: 2.5.1
- Datasets: 3.2.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp15"", ""author"": ""silviasapora"", ""sha"": ""df5598cc8d8eba83de00c20407c1e2d238cb7a31"", ""last_modified"": ""2025-02-27 13:31:09+00:00"", ""created_at"": ""2025-02-27 10:51:33+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 2, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:argilla/dpo-mix-7k"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + ' ' + message['content'] | trim + '<end_of_turn> ' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model '}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Feb27_10-51-21_e967ea18ab86/events.out.tfevents.1740653495.e967ea18ab86.342153.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-02-27 13:31:09+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67c043b530d06ae0c59a98b4"", ""modelId"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp15"", ""usedStorage"": 1638839110}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp15&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-vshp15%5D(%2Fsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-vshp15)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp17,"---
base_model: google/gemma-7b
datasets:
- argilla/dpo-mix-7k
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['argilla/dpo-mix-7k']](https://huggingface.co/datasets/['argilla/dpo-mix-7k']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp17"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/8u5inj0e) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.13.0
- Transformers: 4.48.1
- Pytorch: 2.5.1
- Datasets: 3.2.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp17"", ""author"": ""silviasapora"", ""sha"": ""1e85b1836e7bfb5acac67e2996c1079123b7bf67"", ""last_modified"": ""2025-02-27 13:31:09+00:00"", ""created_at"": ""2025-02-27 10:51:33+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 2, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:argilla/dpo-mix-7k"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + ' ' + message['content'] | trim + '<end_of_turn> ' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model '}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Feb27_10-51-21_e967ea18ab86/events.out.tfevents.1740653494.e967ea18ab86.342156.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-02-27 13:31:09+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67c043b53336813b39ef560a"", ""modelId"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp17"", ""usedStorage"": 1638839109}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp17&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-vshp17%5D(%2Fsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-vshp17)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp16,"---
base_model: google/gemma-7b
datasets:
- argilla/dpo-mix-7k
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['argilla/dpo-mix-7k']](https://huggingface.co/datasets/['argilla/dpo-mix-7k']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp16"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/lfkf2m77) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.13.0
- Transformers: 4.48.1
- Pytorch: 2.5.1
- Datasets: 3.2.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp16"", ""author"": ""silviasapora"", ""sha"": ""6d9fa468dd2ceb80b27340908afe5cb81dda21c0"", ""last_modified"": ""2025-02-27 13:31:31+00:00"", ""created_at"": ""2025-02-27 10:51:33+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 2, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:argilla/dpo-mix-7k"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + ' ' + message['content'] | trim + '<end_of_turn> ' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model '}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Feb27_10-51-21_e967ea18ab86/events.out.tfevents.1740653494.e967ea18ab86.342150.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-02-27 13:31:31+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67c043b5a44113fdda6c2dee"", ""modelId"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp16"", ""usedStorage"": 1638839110}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp16&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-vshp16%5D(%2Fsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-vshp16)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp19,"---
base_model: google/gemma-7b
datasets:
- argilla/dpo-mix-7k
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['argilla/dpo-mix-7k']](https://huggingface.co/datasets/['argilla/dpo-mix-7k']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp19"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/clu4ltsq) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.13.0
- Transformers: 4.48.1
- Pytorch: 2.5.1
- Datasets: 3.2.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp19"", ""author"": ""silviasapora"", ""sha"": ""3bedd4183633be9ac9e031919c71bb27e01d0744"", ""last_modified"": ""2025-02-27 16:14:55+00:00"", ""created_at"": ""2025-02-27 13:35:35+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 1, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:argilla/dpo-mix-7k"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + ' ' + message['content'] | trim + '<end_of_turn> ' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model '}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Feb27_13-35-24_e967ea18ab86/events.out.tfevents.1740663338.e967ea18ab86.343843.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-02-27 16:14:55+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67c06a27a4bb474653a0a83e"", ""modelId"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp19"", ""usedStorage"": 1638839112}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp19&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-vshp19%5D(%2Fsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-vshp19)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp18,"---
base_model: google/gemma-7b
datasets:
- argilla/dpo-mix-7k
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['argilla/dpo-mix-7k']](https://huggingface.co/datasets/['argilla/dpo-mix-7k']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp18"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/pe1md1ju) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.13.0
- Transformers: 4.48.1
- Pytorch: 2.5.1
- Datasets: 3.2.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp18"", ""author"": ""silviasapora"", ""sha"": ""1ced9b2a2ead1d613d3b202a5038289620e3fdec"", ""last_modified"": ""2025-02-27 16:14:39+00:00"", ""created_at"": ""2025-02-27 13:35:35+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 1, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:argilla/dpo-mix-7k"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + ' ' + message['content'] | trim + '<end_of_turn> ' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model '}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Feb27_13-35-24_e967ea18ab86/events.out.tfevents.1740663337.e967ea18ab86.343837.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-02-27 16:14:39+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67c06a27d1f37121ad2f0d39"", ""modelId"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp18"", ""usedStorage"": 1638839112}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp18&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-vshp18%5D(%2Fsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-vshp18)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp20,"---
base_model: google/gemma-7b
datasets:
- argilla/dpo-mix-7k
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['argilla/dpo-mix-7k']](https://huggingface.co/datasets/['argilla/dpo-mix-7k']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp20"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/c02gq3v6) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.13.0
- Transformers: 4.48.1
- Pytorch: 2.5.1
- Datasets: 3.2.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp20"", ""author"": ""silviasapora"", ""sha"": ""4291786bf038aa4fdef340c399ddc162359f8e58"", ""last_modified"": ""2025-02-27 16:13:48+00:00"", ""created_at"": ""2025-02-27 13:35:36+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 2, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:argilla/dpo-mix-7k"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + ' ' + message['content'] | trim + '<end_of_turn> ' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model '}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Feb27_13-35-24_e967ea18ab86/events.out.tfevents.1740663337.e967ea18ab86.343840.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-02-27 16:13:48+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67c06a28cda310c0876ac71e"", ""modelId"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp20"", ""usedStorage"": 1638839111}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp20&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-vshp20%5D(%2Fsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-vshp20)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp21,"---
base_model: google/gemma-7b
datasets:
- argilla/dpo-mix-7k
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['argilla/dpo-mix-7k']](https://huggingface.co/datasets/['argilla/dpo-mix-7k']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp21"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/ce2gtg9m) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.15.2
- Transformers: 4.49.0
- Pytorch: 2.4.0
- Datasets: 3.0.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp21"", ""author"": ""silviasapora"", ""sha"": ""b5159dff2bab2142c24cfcec6685be5b1330d3dd"", ""last_modified"": ""2025-03-26 06:32:50+00:00"", ""created_at"": ""2025-02-27 16:15:23+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 2, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:argilla/dpo-mix-7k"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + ' ' + message['content'] | trim + '<end_of_turn> ' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model '}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Feb27_16-15-12_e967ea18ab86/events.out.tfevents.1740672925.e967ea18ab86.396922.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Mar26_02-29-25_9600b3b70eda/events.out.tfevents.1742956222.9600b3b70eda.1854655.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Mar26_05-05-20_9600b3b70eda/events.out.tfevents.1742965576.9600b3b70eda.1876696.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-03-26 06:32:50+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67c08f9b01cef6d4b9858460"", ""modelId"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp21"", ""usedStorage"": 3239071779}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp21&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-vshp21%5D(%2Fsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-vshp21)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp23,"---
base_model: google/gemma-7b
datasets:
- argilla/dpo-mix-7k
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['argilla/dpo-mix-7k']](https://huggingface.co/datasets/['argilla/dpo-mix-7k']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp23"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/3mjn91os) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.15.2
- Transformers: 4.49.0
- Pytorch: 2.4.0
- Datasets: 3.0.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp23"", ""author"": ""silviasapora"", ""sha"": ""d131fd00a4c4f1556b4541b05fa90a852da2485a"", ""last_modified"": ""2025-03-26 08:00:30+00:00"", ""created_at"": ""2025-02-27 16:15:23+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 2, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:argilla/dpo-mix-7k"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + ' ' + message['content'] | trim + '<end_of_turn> ' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model '}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Feb27_16-15-11_e967ea18ab86/events.out.tfevents.1740672925.e967ea18ab86.396927.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Mar26_06-33-10_9600b3b70eda/events.out.tfevents.1742970847.9600b3b70eda.1878399.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-03-26 08:00:30+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67c08f9b62aa7ba43ad46901"", ""modelId"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp23"", ""usedStorage"": 3239066152}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp23&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-vshp23%5D(%2Fsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-vshp23)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp22,"---
base_model: google/gemma-7b
datasets:
- argilla/dpo-mix-7k
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['argilla/dpo-mix-7k']](https://huggingface.co/datasets/['argilla/dpo-mix-7k']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp22"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/iwd7o896) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.15.2
- Transformers: 4.49.0
- Pytorch: 2.4.0
- Datasets: 3.0.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp22"", ""author"": ""silviasapora"", ""sha"": ""71723a6e9b599e7a0bb0d5a62d0161532b552760"", ""last_modified"": ""2025-03-26 07:59:42+00:00"", ""created_at"": ""2025-02-27 16:15:24+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 2, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:argilla/dpo-mix-7k"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + ' ' + message['content'] | trim + '<end_of_turn> ' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model '}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Feb27_16-15-11_e967ea18ab86/events.out.tfevents.1740672925.e967ea18ab86.396926.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Mar26_06-33-06_9600b3b70eda/events.out.tfevents.1742970843.9600b3b70eda.1878402.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-03-26 07:59:42+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67c08f9ca43d7939d6def835"", ""modelId"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp22"", ""usedStorage"": 3239066153}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp22&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-vshp22%5D(%2Fsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-vshp22)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp26,"---
base_model: google/gemma-7b
datasets:
- argilla/dpo-mix-7k
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['argilla/dpo-mix-7k']](https://huggingface.co/datasets/['argilla/dpo-mix-7k']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp26"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/jaegmnut) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.15.2
- Transformers: 4.49.0
- Pytorch: 2.4.0
- Datasets: 3.0.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp26"", ""author"": ""silviasapora"", ""sha"": ""d9ed2b8348fe15a8426ad04c8f5bc823b43219a2"", ""last_modified"": ""2025-03-26 09:43:23+00:00"", ""created_at"": ""2025-02-27 19:10:35+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 2, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:argilla/dpo-mix-7k"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + ' ' + message['content'] | trim + '<end_of_turn> ' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model '}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Feb27_19-10-24_e967ea18ab86/events.out.tfevents.1740683436.e967ea18ab86.457048.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Mar26_08-16-26_9600b3b70eda/events.out.tfevents.1742977042.9600b3b70eda.1880110.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-03-26 09:43:23+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67c0b8ab5f49eb5f6ce9035e"", ""modelId"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp26"", ""usedStorage"": 3239066150}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp26&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-vshp26%5D(%2Fsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-vshp26)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp25,"---
base_model: google/gemma-7b
datasets:
- argilla/dpo-mix-7k
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['argilla/dpo-mix-7k']](https://huggingface.co/datasets/['argilla/dpo-mix-7k']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp25"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/rz5pm43f) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.15.2
- Transformers: 4.49.0
- Pytorch: 2.4.0
- Datasets: 3.0.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp25"", ""author"": ""silviasapora"", ""sha"": ""b30d581a747b3d0ad6e61fafdd4dc0eaf93342ca"", ""last_modified"": ""2025-03-26 09:42:36+00:00"", ""created_at"": ""2025-02-27 19:10:35+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 2, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:argilla/dpo-mix-7k"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + ' ' + message['content'] | trim + '<end_of_turn> ' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model '}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Feb27_19-10-24_e967ea18ab86/events.out.tfevents.1740683437.e967ea18ab86.457045.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Mar26_08-16-25_9600b3b70eda/events.out.tfevents.1742977041.9600b3b70eda.1880113.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-03-26 09:42:36+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67c0b8ab8589d8ecb7a1e560"", ""modelId"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp25"", ""usedStorage"": 3239066151}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp25&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-vshp25%5D(%2Fsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-vshp25)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp24,"---
base_model: google/gemma-7b
datasets:
- argilla/dpo-mix-7k
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['argilla/dpo-mix-7k']](https://huggingface.co/datasets/['argilla/dpo-mix-7k']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp24"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/gju0l4u0) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.15.2
- Transformers: 4.49.0
- Pytorch: 2.4.0
- Datasets: 3.0.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp24"", ""author"": ""silviasapora"", ""sha"": ""a1cc86129a1fd0fd95601c408ba0e982da297d45"", ""last_modified"": ""2025-03-26 08:00:29+00:00"", ""created_at"": ""2025-02-27 19:10:35+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 2, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:argilla/dpo-mix-7k"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + ' ' + message['content'] | trim + '<end_of_turn> ' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model '}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Feb27_19-10-24_e967ea18ab86/events.out.tfevents.1740683436.e967ea18ab86.457041.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Mar26_06-33-07_9600b3b70eda/events.out.tfevents.1742970843.9600b3b70eda.1878396.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-03-26 08:00:29+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67c0b8abdfcdc929048bdae5"", ""modelId"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp24"", ""usedStorage"": 3239066152}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp24&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-vshp24%5D(%2Fsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-vshp24)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp29,"---
base_model: google/gemma-7b
datasets:
- argilla/dpo-mix-7k
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['argilla/dpo-mix-7k']](https://huggingface.co/datasets/['argilla/dpo-mix-7k']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp29"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/9tkkclnw) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.13.0
- Transformers: 4.48.1
- Pytorch: 2.5.1
- Datasets: 3.2.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp29"", ""author"": ""silviasapora"", ""sha"": ""84da3e8dfb9c966695b758bef4b9d12693a05a54"", ""last_modified"": ""2025-02-28 00:45:03+00:00"", ""created_at"": ""2025-02-27 22:06:06+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 2, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:argilla/dpo-mix-7k"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + ' ' + message['content'] | trim + '<end_of_turn> ' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model '}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Feb27_22-05-55_e967ea18ab86/events.out.tfevents.1740693968.e967ea18ab86.458738.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-02-28 00:45:03+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67c0e1ce367d7a03e4dfd8dc"", ""modelId"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp29"", ""usedStorage"": 1638839111}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp29&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-vshp29%5D(%2Fsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-vshp29)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp28,"---
base_model: google/gemma-7b
datasets:
- argilla/dpo-mix-7k
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['argilla/dpo-mix-7k']](https://huggingface.co/datasets/['argilla/dpo-mix-7k']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp28"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/hwbve54x) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.15.2
- Transformers: 4.49.0
- Pytorch: 2.4.0
- Datasets: 3.0.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp28"", ""author"": ""silviasapora"", ""sha"": ""7b6cab231952c80cb12f4da6517dfe0262f25884"", ""last_modified"": ""2025-03-26 11:09:21+00:00"", ""created_at"": ""2025-02-27 22:06:06+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 5, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:argilla/dpo-mix-7k"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + ' ' + message['content'] | trim + '<end_of_turn> ' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model '}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Feb27_22-05-55_e967ea18ab86/events.out.tfevents.1740693968.e967ea18ab86.458743.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Mar26_09-43-52_9600b3b70eda/events.out.tfevents.1742982288.9600b3b70eda.1881551.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-03-26 11:09:21+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67c0e1ce6fee7b3bfea853f3"", ""modelId"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp28"", ""usedStorage"": 3239066152}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp28&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-vshp28%5D(%2Fsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-vshp28)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp27,"---
base_model: google/gemma-7b
datasets:
- argilla/dpo-mix-7k
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['argilla/dpo-mix-7k']](https://huggingface.co/datasets/['argilla/dpo-mix-7k']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp27"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/hwg3yin7) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.15.2
- Transformers: 4.49.0
- Pytorch: 2.4.0
- Datasets: 3.0.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp27"", ""author"": ""silviasapora"", ""sha"": ""96db67a7bf92f4738585c029edaa7a391483c497"", ""last_modified"": ""2025-03-26 09:43:37+00:00"", ""created_at"": ""2025-02-27 22:06:06+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 4, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:argilla/dpo-mix-7k"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + ' ' + message['content'] | trim + '<end_of_turn> ' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model '}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Feb27_22-05-55_e967ea18ab86/events.out.tfevents.1740693968.e967ea18ab86.458742.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Mar26_08-16-24_9600b3b70eda/events.out.tfevents.1742977044.9600b3b70eda.1880112.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-03-26 09:43:37+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67c0e1ceed965e5a9b201023"", ""modelId"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp27"", ""usedStorage"": 3239066152}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp27&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-vshp27%5D(%2Fsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-vshp27)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp30,"---
base_model: google/gemma-7b
datasets:
- argilla/dpo-mix-7k
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['argilla/dpo-mix-7k']](https://huggingface.co/datasets/['argilla/dpo-mix-7k']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp30"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/6ffpao0k) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.13.0
- Transformers: 4.48.1
- Pytorch: 2.5.1
- Datasets: 3.2.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp30"", ""author"": ""silviasapora"", ""sha"": ""ab2ec772ba8eef39283dfdde880815f3a30da033"", ""last_modified"": ""2025-02-28 03:27:03+00:00"", ""created_at"": ""2025-02-28 00:46:46+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 3, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:argilla/dpo-mix-7k"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + ' ' + message['content'] | trim + '<end_of_turn> ' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model '}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Feb28_00-46-34_e967ea18ab86/events.out.tfevents.1740703607.e967ea18ab86.460425.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-02-28 03:27:03+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67c107760fb3ba8025960c57"", ""modelId"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp30"", ""usedStorage"": 1638839112}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp30&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-vshp30%5D(%2Fsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-vshp30)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp31,"---
base_model: google/gemma-7b
datasets:
- argilla/dpo-mix-7k
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['argilla/dpo-mix-7k']](https://huggingface.co/datasets/['argilla/dpo-mix-7k']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp31"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/jr55dcz4) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.13.0
- Transformers: 4.48.1
- Pytorch: 2.5.1
- Datasets: 3.2.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp31"", ""author"": ""silviasapora"", ""sha"": ""92f03a80973ff662e1b9cddcc5edc8ca02d4c48b"", ""last_modified"": ""2025-02-28 03:27:13+00:00"", ""created_at"": ""2025-02-28 00:46:47+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 3, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:argilla/dpo-mix-7k"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + ' ' + message['content'] | trim + '<end_of_turn> ' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model '}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Feb28_00-46-35_e967ea18ab86/events.out.tfevents.1740703609.e967ea18ab86.460429.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-02-28 03:27:13+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67c107770cec1569edc47b3d"", ""modelId"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp31"", ""usedStorage"": 1638839112}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp31&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-vshp31%5D(%2Fsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-vshp31)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp32,"---
base_model: google/gemma-7b
datasets:
- argilla/dpo-mix-7k
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['argilla/dpo-mix-7k']](https://huggingface.co/datasets/['argilla/dpo-mix-7k']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp32"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/7n2crrns) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.13.0
- Transformers: 4.48.1
- Pytorch: 2.5.1
- Datasets: 3.2.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp32"", ""author"": ""silviasapora"", ""sha"": ""6ad14e77faec52875be20f59963202354236ceb7"", ""last_modified"": ""2025-02-28 03:26:45+00:00"", ""created_at"": ""2025-02-28 00:46:47+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 3, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:argilla/dpo-mix-7k"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + ' ' + message['content'] | trim + '<end_of_turn> ' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model '}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Feb28_00-46-35_e967ea18ab86/events.out.tfevents.1740703609.e967ea18ab86.460432.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-02-28 03:26:45+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67c107778212315f7f100eb7"", ""modelId"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp32"", ""usedStorage"": 1638839111}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp32&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-vshp32%5D(%2Fsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-vshp32)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp33,"---
base_model: google/gemma-7b
datasets:
- argilla/dpo-mix-7k
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['argilla/dpo-mix-7k']](https://huggingface.co/datasets/['argilla/dpo-mix-7k']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp33"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/mqf0ita4) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.13.0
- Transformers: 4.48.1
- Pytorch: 2.5.1
- Datasets: 3.2.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp33"", ""author"": ""silviasapora"", ""sha"": ""303f7c5953bb9011b24a964116cc39e02df6caba"", ""last_modified"": ""2025-02-28 06:07:54+00:00"", ""created_at"": ""2025-02-28 03:27:41+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 3, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:argilla/dpo-mix-7k"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + ' ' + message['content'] | trim + '<end_of_turn> ' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model '}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Feb28_03-27-29_e967ea18ab86/events.out.tfevents.1740713262.e967ea18ab86.462110.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-02-28 06:07:54+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67c12d2db77e3a3d35ab8119"", ""modelId"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp33"", ""usedStorage"": 1638839111}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp33&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-vshp33%5D(%2Fsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-vshp33)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp34,"---
base_model: google/gemma-7b
datasets:
- argilla/dpo-mix-7k
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['argilla/dpo-mix-7k']](https://huggingface.co/datasets/['argilla/dpo-mix-7k']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp34"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/8bo5mtq6) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.13.0
- Transformers: 4.48.1
- Pytorch: 2.5.1
- Datasets: 3.2.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp34"", ""author"": ""silviasapora"", ""sha"": ""3a9e5fef20a10f86b8aca26239e1a3354ecb6e78"", ""last_modified"": ""2025-02-28 06:08:05+00:00"", ""created_at"": ""2025-02-28 03:27:41+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 3, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:argilla/dpo-mix-7k"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + ' ' + message['content'] | trim + '<end_of_turn> ' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model '}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Feb28_03-27-30_e967ea18ab86/events.out.tfevents.1740713263.e967ea18ab86.462107.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-02-28 06:08:05+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67c12d2dfbd33379f3f09d66"", ""modelId"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp34"", ""usedStorage"": 1638839111}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp34&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-vshp34%5D(%2Fsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-vshp34)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp35,"---
base_model: google/gemma-7b
datasets:
- argilla/dpo-mix-7k
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['argilla/dpo-mix-7k']](https://huggingface.co/datasets/['argilla/dpo-mix-7k']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp35"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/xje0muur) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.13.0
- Transformers: 4.48.1
- Pytorch: 2.5.1
- Datasets: 3.2.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp35"", ""author"": ""silviasapora"", ""sha"": ""0554c009d220e6c749f989efef19429bc4d8bc9f"", ""last_modified"": ""2025-02-28 06:08:06+00:00"", ""created_at"": ""2025-02-28 03:27:43+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 3, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:argilla/dpo-mix-7k"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + ' ' + message['content'] | trim + '<end_of_turn> ' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model '}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Feb28_03-27-30_e967ea18ab86/events.out.tfevents.1740713264.e967ea18ab86.462113.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-02-28 06:08:06+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67c12d2fef9af7490253ef97"", ""modelId"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp35"", ""usedStorage"": 1638839110}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp35&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-vshp35%5D(%2Fsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-vshp35)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp37,"---
base_model: google/gemma-7b
datasets:
- argilla/dpo-mix-7k
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['argilla/dpo-mix-7k']](https://huggingface.co/datasets/['argilla/dpo-mix-7k']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp37"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/4m6tjhf0) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.13.0
- Transformers: 4.48.1
- Pytorch: 2.5.1
- Datasets: 3.2.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp37"", ""author"": ""silviasapora"", ""sha"": ""2a037c010d3c23f044bbe0aa6da460fe8bba5eec"", ""last_modified"": ""2025-02-28 08:57:43+00:00"", ""created_at"": ""2025-02-28 06:17:09+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 4, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:argilla/dpo-mix-7k"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + ' ' + message['content'] | trim + '<end_of_turn> ' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model '}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Feb28_06-16-58_e967ea18ab86/events.out.tfevents.1740723431.e967ea18ab86.463805.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-02-28 08:57:43+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67c154e5268a4a304053f304"", ""modelId"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp37"", ""usedStorage"": 1638839112}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp37&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-vshp37%5D(%2Fsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-vshp37)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp36,"---
base_model: google/gemma-7b
datasets:
- argilla/dpo-mix-7k
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['argilla/dpo-mix-7k']](https://huggingface.co/datasets/['argilla/dpo-mix-7k']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp36"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/uajdt6ve) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.13.0
- Transformers: 4.48.1
- Pytorch: 2.5.1
- Datasets: 3.2.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp36"", ""author"": ""silviasapora"", ""sha"": ""022a2c8a387a12a735e7d0375c16af9b639d95ba"", ""last_modified"": ""2025-02-28 08:57:35+00:00"", ""created_at"": ""2025-02-28 06:17:09+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 4, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:argilla/dpo-mix-7k"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + ' ' + message['content'] | trim + '<end_of_turn> ' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model '}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Feb28_06-16-58_e967ea18ab86/events.out.tfevents.1740723430.e967ea18ab86.463808.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-02-28 08:57:35+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67c154e5505a88e4a192b3bb"", ""modelId"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp36"", ""usedStorage"": 1638839112}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp36&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-vshp36%5D(%2Fsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-vshp36)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp38,"---
base_model: google/gemma-7b
datasets:
- argilla/dpo-mix-7k
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['argilla/dpo-mix-7k']](https://huggingface.co/datasets/['argilla/dpo-mix-7k']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp38"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/kx9lhisx) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.13.0
- Transformers: 4.48.1
- Pytorch: 2.5.1
- Datasets: 3.2.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp38"", ""author"": ""silviasapora"", ""sha"": ""05d4e208a490bb50cfa31c89cd551be77a8b86c3"", ""last_modified"": ""2025-02-28 08:55:58+00:00"", ""created_at"": ""2025-02-28 06:17:09+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 4, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:argilla/dpo-mix-7k"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + ' ' + message['content'] | trim + '<end_of_turn> ' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model '}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Feb28_06-16-57_e967ea18ab86/events.out.tfevents.1740723430.e967ea18ab86.463811.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-02-28 08:55:58+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67c154e5ca734e81b15c4500"", ""modelId"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp38"", ""usedStorage"": 1638839111}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp38&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-vshp38%5D(%2Fsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-vshp38)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp39,"---
base_model: google/gemma-7b
datasets:
- argilla/dpo-mix-7k
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['argilla/dpo-mix-7k']](https://huggingface.co/datasets/['argilla/dpo-mix-7k']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp39"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/an7gy5ip) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.13.0
- Transformers: 4.48.1
- Pytorch: 2.5.1
- Datasets: 3.2.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp39"", ""author"": ""silviasapora"", ""sha"": ""281a10ba7b88b763d599d167e9ab3f1b6d973782"", ""last_modified"": ""2025-02-28 11:45:41+00:00"", ""created_at"": ""2025-02-28 09:05:37+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 4, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:argilla/dpo-mix-7k"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + ' ' + message['content'] | trim + '<end_of_turn> ' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model '}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Feb28_09-05-25_e967ea18ab86/events.out.tfevents.1740733539.e967ea18ab86.465490.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-02-28 11:45:41+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67c17c612620d9e36b097836"", ""modelId"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp39"", ""usedStorage"": 1638839112}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp39&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-vshp39%5D(%2Fsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-vshp39)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp40,"---
base_model: google/gemma-7b
datasets:
- argilla/dpo-mix-7k
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['argilla/dpo-mix-7k']](https://huggingface.co/datasets/['argilla/dpo-mix-7k']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp40"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/wilfko8s) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.13.0
- Transformers: 4.48.1
- Pytorch: 2.5.1
- Datasets: 3.2.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp40"", ""author"": ""silviasapora"", ""sha"": ""c516e34d1227408196d604c8aaa4fa235e8c83a8"", ""last_modified"": ""2025-02-28 11:45:57+00:00"", ""created_at"": ""2025-02-28 09:05:37+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 4, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:argilla/dpo-mix-7k"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + ' ' + message['content'] | trim + '<end_of_turn> ' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model '}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Feb28_09-05-25_e967ea18ab86/events.out.tfevents.1740733538.e967ea18ab86.465494.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-02-28 11:45:57+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67c17c6136bce561da0ccd8c"", ""modelId"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp40"", ""usedStorage"": 1638839112}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp40&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-vshp40%5D(%2Fsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-vshp40)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp41,"---
base_model: google/gemma-7b
datasets:
- argilla/dpo-mix-7k
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['argilla/dpo-mix-7k']](https://huggingface.co/datasets/['argilla/dpo-mix-7k']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp41"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/0dw6izom) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.13.0
- Transformers: 4.48.1
- Pytorch: 2.5.1
- Datasets: 3.2.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp41"", ""author"": ""silviasapora"", ""sha"": ""0aea51a7651c88156412cf9aba9923831540a213"", ""last_modified"": ""2025-02-28 11:45:35+00:00"", ""created_at"": ""2025-02-28 09:05:38+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 4, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:argilla/dpo-mix-7k"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + ' ' + message['content'] | trim + '<end_of_turn> ' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model '}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Feb28_09-05-26_e967ea18ab86/events.out.tfevents.1740733539.e967ea18ab86.465496.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-02-28 11:45:35+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67c17c62cbe0681f4f510ab0"", ""modelId"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp41"", ""usedStorage"": 1638839111}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp41&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-vshp41%5D(%2Fsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-vshp41)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp43,"---
base_model: google/gemma-7b
datasets:
- argilla/dpo-mix-7k
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['argilla/dpo-mix-7k']](https://huggingface.co/datasets/['argilla/dpo-mix-7k']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp43"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/9v8m4yu9) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.13.0
- Transformers: 4.48.1
- Pytorch: 2.5.1
- Datasets: 3.2.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp43"", ""author"": ""silviasapora"", ""sha"": ""042ccac755f4104125421d3ddd75fb656204649c"", ""last_modified"": ""2025-02-28 14:27:14+00:00"", ""created_at"": ""2025-02-28 11:46:25+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 4, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:argilla/dpo-mix-7k"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + ' ' + message['content'] | trim + '<end_of_turn> ' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model '}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Feb28_11-46-14_e967ea18ab86/events.out.tfevents.1740743187.e967ea18ab86.467186.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-02-28 14:27:14+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67c1a21112a5c67e58f07b9e"", ""modelId"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp43"", ""usedStorage"": 1638839111}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp43&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-vshp43%5D(%2Fsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-vshp43)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp44,"---
base_model: google/gemma-7b
datasets:
- argilla/dpo-mix-7k
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['argilla/dpo-mix-7k']](https://huggingface.co/datasets/['argilla/dpo-mix-7k']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp44"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/uitckmw5) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.13.0
- Transformers: 4.48.1
- Pytorch: 2.5.1
- Datasets: 3.2.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp44"", ""author"": ""silviasapora"", ""sha"": ""47200ace5ff914133c9feaba80607dbddf2e0857"", ""last_modified"": ""2025-02-28 14:26:34+00:00"", ""created_at"": ""2025-02-28 11:46:25+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 4, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:argilla/dpo-mix-7k"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + ' ' + message['content'] | trim + '<end_of_turn> ' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model '}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Feb28_11-46-14_e967ea18ab86/events.out.tfevents.1740743187.e967ea18ab86.467190.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-02-28 14:26:34+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67c1a2116af90e3ee4007ecb"", ""modelId"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp44"", ""usedStorage"": 1638839110}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp44&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-vshp44%5D(%2Fsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-vshp44)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp42,"---
base_model: google/gemma-7b
datasets:
- argilla/dpo-mix-7k
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['argilla/dpo-mix-7k']](https://huggingface.co/datasets/['argilla/dpo-mix-7k']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp42"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/xaqk2g3o) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.13.0
- Transformers: 4.48.1
- Pytorch: 2.5.1
- Datasets: 3.2.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp42"", ""author"": ""silviasapora"", ""sha"": ""4fccbbe19880f518edb143459531f15885b5ec8c"", ""last_modified"": ""2025-02-28 14:26:34+00:00"", ""created_at"": ""2025-02-28 11:46:25+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 4, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:argilla/dpo-mix-7k"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + ' ' + message['content'] | trim + '<end_of_turn> ' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model '}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Feb28_11-46-13_e967ea18ab86/events.out.tfevents.1740743186.e967ea18ab86.467185.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-02-28 14:26:34+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67c1a21191a63c813caea0cf"", ""modelId"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp42"", ""usedStorage"": 1638839111}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-silvia-basic-5e-5-05-vshp42&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-vshp42%5D(%2Fsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-vshp42)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-sft-basic-5e-5-05-vshp0,"---
base_model: google/gemma-7b
datasets:
- argilla/dpo-mix-7k
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['argilla/dpo-mix-7k']](https://huggingface.co/datasets/['argilla/dpo-mix-7k']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-sft-basic-5e-5-05-vshp0"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/8ma47aar) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.15.2
- Transformers: 4.49.0
- Pytorch: 2.4.0
- Datasets: 3.0.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-sft-basic-5e-5-05-vshp0"", ""author"": ""silviasapora"", ""sha"": ""983752b501cda3b8ab23fe5b78c06b520e9c6db2"", ""last_modified"": ""2025-03-04 01:32:29+00:00"", ""created_at"": ""2025-03-03 20:53:07+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 3, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:argilla/dpo-mix-7k"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + ' ' + message['content'] | trim + '<end_of_turn> ' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model '}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Mar03_20-51-59_9600b3b70eda/events.out.tfevents.1741035188.9600b3b70eda.522466.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Mar03_21-10-11_9600b3b70eda/events.out.tfevents.1741036268.9600b3b70eda.532910.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Mar03_21-22-55_9600b3b70eda/events.out.tfevents.1741037032.9600b3b70eda.540182.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Mar03_23-08-56_9600b3b70eda/events.out.tfevents.1741043395.9600b3b70eda.601590.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Mar03_23-15-06_9600b3b70eda/events.out.tfevents.1741043763.9600b3b70eda.605396.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Mar04_00-13-04_9600b3b70eda/events.out.tfevents.1741047242.9600b3b70eda.636487.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-03-04 01:32:29+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67c616b3c5d8edee36a1c146"", ""modelId"": ""silviasapora/gemma-7b-sft-basic-5e-5-05-vshp0"", ""usedStorage"": 3239095778}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-sft-basic-5e-5-05-vshp0&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-sft-basic-5e-5-05-vshp0%5D(%2Fsilviasapora%2Fgemma-7b-sft-basic-5e-5-05-vshp0)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-silvia-basic-5e-5-05-vsh2p1,"---
base_model: google/gemma-7b
datasets:
- argilla/dpo-mix-7k
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['argilla/dpo-mix-7k']](https://huggingface.co/datasets/['argilla/dpo-mix-7k']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-silvia-basic-5e-5-05-vsh2p1"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/1alqc3k5) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.13.0
- Transformers: 4.48.1
- Pytorch: 2.5.1
- Datasets: 3.2.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-vsh2p1"", ""author"": ""silviasapora"", ""sha"": ""61668b8edcd3a63121f8cae0c89d73386c428f23"", ""last_modified"": ""2025-03-04 03:56:01+00:00"", ""created_at"": ""2025-03-04 01:16:50+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 1, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:argilla/dpo-mix-7k"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + ' ' + message['content'] | trim + '<end_of_turn> ' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model '}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Mar04_01-14-30_84b693e79a02/events.out.tfevents.1741051011.84b693e79a02.322155.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-03-04 03:56:01+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67c65482385598c69b50456a"", ""modelId"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-vsh2p1"", ""usedStorage"": 1638839111}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-silvia-basic-5e-5-05-vsh2p1&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-vsh2p1%5D(%2Fsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-vsh2p1)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-silvia-basic-5e-5-05-vsh2p0,"---
base_model: google/gemma-7b
datasets:
- argilla/dpo-mix-7k
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['argilla/dpo-mix-7k']](https://huggingface.co/datasets/['argilla/dpo-mix-7k']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-silvia-basic-5e-5-05-vsh2p0"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/sz7nt1pa) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.13.0
- Transformers: 4.48.1
- Pytorch: 2.5.1
- Datasets: 3.2.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-vsh2p0"", ""author"": ""silviasapora"", ""sha"": ""7b9a4885a7241cef96e87245ab25f0ff7b5e6523"", ""last_modified"": ""2025-03-04 03:55:42+00:00"", ""created_at"": ""2025-03-04 01:16:50+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 1, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:argilla/dpo-mix-7k"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + ' ' + message['content'] | trim + '<end_of_turn> ' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model '}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Mar04_01-14-30_84b693e79a02/events.out.tfevents.1741051011.84b693e79a02.322158.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-03-04 03:55:42+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67c65482936c61fb878c88cc"", ""modelId"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-vsh2p0"", ""usedStorage"": 1638839111}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-silvia-basic-5e-5-05-vsh2p0&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-vsh2p0%5D(%2Fsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-vsh2p0)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-silvia-basic-5e-5-05-vsh2p3,"---
base_model: google/gemma-7b
datasets:
- argilla/dpo-mix-7k
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['argilla/dpo-mix-7k']](https://huggingface.co/datasets/['argilla/dpo-mix-7k']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-silvia-basic-5e-5-05-vsh2p3"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/jj4asii3) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.13.0
- Transformers: 4.48.1
- Pytorch: 2.5.1
- Datasets: 3.2.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-vsh2p3"", ""author"": ""silviasapora"", ""sha"": ""b5ed404dcc03428e3bacb64ff1ae588d8eadfdd8"", ""last_modified"": ""2025-03-04 06:36:52+00:00"", ""created_at"": ""2025-03-04 03:57:06+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 1, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:argilla/dpo-mix-7k"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + ' ' + message['content'] | trim + '<end_of_turn> ' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model '}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Mar04_03-56-20_84b693e79a02/events.out.tfevents.1741060628.84b693e79a02.355592.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-03-04 06:36:52+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67c67a12806c89e23e90b301"", ""modelId"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-vsh2p3"", ""usedStorage"": 1638839112}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-silvia-basic-5e-5-05-vsh2p3&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-vsh2p3%5D(%2Fsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-vsh2p3)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-silvia-basic-5e-5-05-vsh2p2,"---
base_model: google/gemma-7b
datasets:
- argilla/dpo-mix-7k
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['argilla/dpo-mix-7k']](https://huggingface.co/datasets/['argilla/dpo-mix-7k']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-silvia-basic-5e-5-05-vsh2p2"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/h6oy0voo) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.13.0
- Transformers: 4.48.1
- Pytorch: 2.5.1
- Datasets: 3.2.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-vsh2p2"", ""author"": ""silviasapora"", ""sha"": ""cc6b0423a3f8ba32f990b28e324178726d266875"", ""last_modified"": ""2025-03-04 06:35:50+00:00"", ""created_at"": ""2025-03-04 03:57:06+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 1, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:argilla/dpo-mix-7k"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + ' ' + message['content'] | trim + '<end_of_turn> ' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model '}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Mar04_03-56-20_84b693e79a02/events.out.tfevents.1741060628.84b693e79a02.355591.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-03-04 06:35:50+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67c67a128601e5f217537f25"", ""modelId"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-vsh2p2"", ""usedStorage"": 1638839111}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-silvia-basic-5e-5-05-vsh2p2&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-vsh2p2%5D(%2Fsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-vsh2p2)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-silvia-basic-5e-5-05-vsh2p7,"---
base_model: google/gemma-7b
datasets:
- argilla/dpo-mix-7k
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['argilla/dpo-mix-7k']](https://huggingface.co/datasets/['argilla/dpo-mix-7k']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-silvia-basic-5e-5-05-vsh2p7"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/byqulp8k) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.13.0
- Transformers: 4.48.1
- Pytorch: 2.5.1
- Datasets: 3.2.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-vsh2p7"", ""author"": ""silviasapora"", ""sha"": ""50beb03ee4923ec462d521284eaca0321a3d78bc"", ""last_modified"": ""2025-03-04 14:17:00+00:00"", ""created_at"": ""2025-03-04 11:38:01+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 3, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:argilla/dpo-mix-7k"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + ' ' + message['content'] | trim + '<end_of_turn> ' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model '}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Mar04_11-37-19_84b693e79a02/events.out.tfevents.1741088282.84b693e79a02.2729.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-03-04 14:17:00+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67c6e61917ccb045a2e247f0"", ""modelId"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-vsh2p7"", ""usedStorage"": 1638839113}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-silvia-basic-5e-5-05-vsh2p7&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-vsh2p7%5D(%2Fsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-vsh2p7)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-silvia-basic-5e-5-05-vsh2p5,"---
base_model: google/gemma-7b
datasets:
- argilla/dpo-mix-7k
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['argilla/dpo-mix-7k']](https://huggingface.co/datasets/['argilla/dpo-mix-7k']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-silvia-basic-5e-5-05-vsh2p5"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/4upzfpf6) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.13.0
- Transformers: 4.48.1
- Pytorch: 2.5.1
- Datasets: 3.2.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-vsh2p5"", ""author"": ""silviasapora"", ""sha"": ""9b3d5c2c6ef62db0f42694d4f7627deca0d512c9"", ""last_modified"": ""2025-03-04 14:17:05+00:00"", ""created_at"": ""2025-03-04 11:38:01+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 3, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:argilla/dpo-mix-7k"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + ' ' + message['content'] | trim + '<end_of_turn> ' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model '}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Mar04_11-37-19_84b693e79a02/events.out.tfevents.1741088282.84b693e79a02.2723.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-03-04 14:17:05+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67c6e61949bdbb9aa3635b1f"", ""modelId"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-vsh2p5"", ""usedStorage"": 1638839112}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-silvia-basic-5e-5-05-vsh2p5&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-vsh2p5%5D(%2Fsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-vsh2p5)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-silvia-basic-5e-5-05-vsh2p4,"---
base_model: google/gemma-7b
datasets:
- argilla/dpo-mix-7k
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['argilla/dpo-mix-7k']](https://huggingface.co/datasets/['argilla/dpo-mix-7k']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-silvia-basic-5e-5-05-vsh2p4"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/j4uxb5dk) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.13.0
- Transformers: 4.48.1
- Pytorch: 2.5.1
- Datasets: 3.2.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-vsh2p4"", ""author"": ""silviasapora"", ""sha"": ""27662664b8a2e3538493d6a75bc7a81d2645d39e"", ""last_modified"": ""2025-03-04 14:16:19+00:00"", ""created_at"": ""2025-03-04 11:38:01+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 3, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:argilla/dpo-mix-7k"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + ' ' + message['content'] | trim + '<end_of_turn> ' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model '}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Mar04_11-37-19_84b693e79a02/events.out.tfevents.1741088282.84b693e79a02.2720.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-03-04 14:16:19+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67c6e61973ccab8486168b32"", ""modelId"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-vsh2p4"", ""usedStorage"": 1638839112}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-silvia-basic-5e-5-05-vsh2p4&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-vsh2p4%5D(%2Fsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-vsh2p4)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-silvia-basic-5e-5-05-vsh2p6,"---
base_model: google/gemma-7b
datasets:
- argilla/dpo-mix-7k
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['argilla/dpo-mix-7k']](https://huggingface.co/datasets/['argilla/dpo-mix-7k']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-silvia-basic-5e-5-05-vsh2p6"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/vzr457aw) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.13.0
- Transformers: 4.48.1
- Pytorch: 2.5.1
- Datasets: 3.2.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-vsh2p6"", ""author"": ""silviasapora"", ""sha"": ""552db278d824daa0930ba84401c338dc6d56c7ba"", ""last_modified"": ""2025-03-04 14:17:03+00:00"", ""created_at"": ""2025-03-04 11:38:01+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 3, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:argilla/dpo-mix-7k"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + ' ' + message['content'] | trim + '<end_of_turn> ' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model '}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Mar04_11-37-18_84b693e79a02/events.out.tfevents.1741088282.84b693e79a02.2726.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-03-04 14:17:03+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67c6e619c64b52e1e19c5027"", ""modelId"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-vsh2p6"", ""usedStorage"": 1638839112}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-silvia-basic-5e-5-05-vsh2p6&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-vsh2p6%5D(%2Fsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-vsh2p6)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-silvia-basic-5e-5-05-vsh2p11,"---
base_model: google/gemma-7b
datasets:
- argilla/dpo-mix-7k
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['argilla/dpo-mix-7k']](https://huggingface.co/datasets/['argilla/dpo-mix-7k']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-silvia-basic-5e-5-05-vsh2p11"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/jmyx9n2k) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.13.0
- Transformers: 4.48.1
- Pytorch: 2.5.1
- Datasets: 3.2.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-vsh2p11"", ""author"": ""silviasapora"", ""sha"": ""de1ad1e1fd0b85c94f9217b59c375e1795dc0156"", ""last_modified"": ""2025-03-04 16:57:11+00:00"", ""created_at"": ""2025-03-04 14:17:34+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 3, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:argilla/dpo-mix-7k"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + ' ' + message['content'] | trim + '<end_of_turn> ' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model '}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Mar04_14-17-22_84b693e79a02/events.out.tfevents.1741097855.84b693e79a02.5702.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-03-04 16:57:11+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67c70b7e09ff212bdeabba90"", ""modelId"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-vsh2p11"", ""usedStorage"": 1638839116}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-silvia-basic-5e-5-05-vsh2p11&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-vsh2p11%5D(%2Fsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-vsh2p11)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-silvia-basic-5e-5-05-vsh2p9,"---
base_model: google/gemma-7b
datasets:
- argilla/dpo-mix-7k
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['argilla/dpo-mix-7k']](https://huggingface.co/datasets/['argilla/dpo-mix-7k']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-silvia-basic-5e-5-05-vsh2p9"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/d9onh6x9) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.13.0
- Transformers: 4.48.1
- Pytorch: 2.5.1
- Datasets: 3.2.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-vsh2p9"", ""author"": ""silviasapora"", ""sha"": ""ae33faf25a4ef8bd9fd615ec4411b4a9e7b5da09"", ""last_modified"": ""2025-03-04 16:57:20+00:00"", ""created_at"": ""2025-03-04 14:17:34+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 4, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:argilla/dpo-mix-7k"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + ' ' + message['content'] | trim + '<end_of_turn> ' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model '}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Mar04_14-17-22_84b693e79a02/events.out.tfevents.1741097855.84b693e79a02.5696.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-03-04 16:57:20+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67c70b7e31f542b2796a586d"", ""modelId"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-vsh2p9"", ""usedStorage"": 1638839112}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-silvia-basic-5e-5-05-vsh2p9&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-vsh2p9%5D(%2Fsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-vsh2p9)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-silvia-basic-5e-5-05-vsh2p10,"---
base_model: google/gemma-7b
datasets:
- argilla/dpo-mix-7k
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['argilla/dpo-mix-7k']](https://huggingface.co/datasets/['argilla/dpo-mix-7k']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-silvia-basic-5e-5-05-vsh2p10"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/ap9uuuzw) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.13.0
- Transformers: 4.48.1
- Pytorch: 2.5.1
- Datasets: 3.2.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-vsh2p10"", ""author"": ""silviasapora"", ""sha"": ""fe87dc8c34080d34f7b21923cbb53af7d071a9f8"", ""last_modified"": ""2025-03-04 16:57:20+00:00"", ""created_at"": ""2025-03-04 14:17:34+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 4, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:argilla/dpo-mix-7k"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + ' ' + message['content'] | trim + '<end_of_turn> ' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model '}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Mar04_14-17-22_84b693e79a02/events.out.tfevents.1741097856.84b693e79a02.5700.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-03-04 16:57:20+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67c70b7e8ab29bba4f219f11"", ""modelId"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-vsh2p10"", ""usedStorage"": 1638839115}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-silvia-basic-5e-5-05-vsh2p10&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-vsh2p10%5D(%2Fsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-vsh2p10)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-silvia-basic-5e-5-05-vsh2p8,"---
base_model: google/gemma-7b
datasets:
- argilla/dpo-mix-7k
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['argilla/dpo-mix-7k']](https://huggingface.co/datasets/['argilla/dpo-mix-7k']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-silvia-basic-5e-5-05-vsh2p8"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/xgn8tlwt) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.13.0
- Transformers: 4.48.1
- Pytorch: 2.5.1
- Datasets: 3.2.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-vsh2p8"", ""author"": ""silviasapora"", ""sha"": ""6a7dc72687947608b9b2da33ca6917f9e3707257"", ""last_modified"": ""2025-03-04 16:57:04+00:00"", ""created_at"": ""2025-03-04 14:17:34+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 3, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:argilla/dpo-mix-7k"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + ' ' + message['content'] | trim + '<end_of_turn> ' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model '}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Mar04_14-17-23_84b693e79a02/events.out.tfevents.1741097856.84b693e79a02.5705.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-03-04 16:57:04+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67c70b7edd166fc1df166fb1"", ""modelId"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-vsh2p8"", ""usedStorage"": 1638839112}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-silvia-basic-5e-5-05-vsh2p8&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-vsh2p8%5D(%2Fsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-vsh2p8)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
MatteoKhan/MistralGemma-7B-Merged,"---
license: mit
language:
- en
base_model:
- mistralai/Mistral-7B-v0.1
- google/gemma-7b
library_name: transformers
tags:
- mergekit
- merged-model
- mistral
- gemma
- language-model
---

# 🚀 MistralGemma-Hybrid-7B: A Fusion of Power & Precision

## 📌 Overview
**MistralGemma-Hybrid-7B** is an **experimental hybrid language model** that blends the strengths of **Mistral-7B** and **Gemma-7B** using the **Spherical Linear Interpolation (slerp) merging technique**. Designed to optimize both efficiency and performance, this model offers robust text generation capabilities while leveraging the advantages of both parent models.

🔗 **Created by**: [Matteo Khan]  
🎓 **Affiliation**: Apprentice at TW3 Partners (Generative AI Research)  
📍 **License**: MIT  

🔗 [Connect with me on LinkedIn](https://www.linkedin.com/in/matteo-khan-a10309263/)  
🔗 [Model on Hugging Face](https://huggingface.co/YourProfile/MistralGemma-Hybrid-7B)  

## 🧠 Model Details
- **Model Type**: Hybrid Language Model (Merged)
- **Parent Models**:
  - [Mistral-7B-v0.1](https://huggingface.co/mistralai/Mistral-7B-v0.1)
  - [Gemma-7B](https://huggingface.co/google/gemma-7b)
- **Merging Technique**: Slerp Merge (MergeKit)

## 🎯 Intended Use
This model is intended for **research and experimentation** in hybrid model optimization. Potential applications include:
- ✅ Text Generation
- ✅ Conversational AI
- ✅ Creative Writing Assistance
- ✅ Exploration of Model Merging Effects

## ⚠️ Limitations & Considerations
While **MistralGemma-Hybrid-7B** offers enhanced capabilities, it also inherits limitations from its parent models:
- ❌ May generate **inaccurate or misleading** information
- ⚠️ Potential for **biased, offensive, or harmful** content
- 🔄 Merging may introduce **unpredictable behaviors**
- 📉 Performance may **vary across different tasks**

## 🔬 Merging Process & Configuration
This is **not a newly trained model**, but rather a merge of existing models using the following configuration:

```yaml
merge_method: slerp  # Using slerp instead of linear
dtype: float16
models:
  - model: ""mistralai/Mistral-7B-v0.1""
    parameters:
      weight: 0.5
  - model: ""google/gemma-7b""
    parameters:
      weight: 0.5

parameters:
  normalize: true
  int8_mask: false
  rescale: true  # Helps with different model scales

layers:
  - pattern: "".*""
    layer_range: [0, -1]
```

📊 **No formal evaluation** has been conducted yet. Users are encouraged to **benchmark and share feedback**!

## 🌍 Environmental Impact
By utilizing **model merging** rather than training from scratch, **MistralGemma-Hybrid-7B** significantly reduces computational and environmental costs.

## 🚀 How to Use
```python
from transformers import AutoModelForCausalLM, AutoTokenizer

model_name = ""YourProfile/MistralGemma-Hybrid-7B""
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForCausalLM.from_pretrained(model_name)

# Example usage
prompt = ""Write a short story about the future of AI.""
inputs = tokenizer(prompt, return_tensors=""pt"")
outputs = model.generate(**inputs, max_length=200)
response = tokenizer.decode(outputs[0], skip_special_tokens=True)
print(response)
```

**📝 Citation**
```bibtex
@misc{mistralgemma2025,
      title={MistralGemma: A Hybrid Open-Source Language Model},
      author={Your Name},
      year={2025},
      eprint={arXiv:XXXX.XXXXX},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
```

📩 **Feedback & Contact**: Reach out via [Hugging Face](https://huggingface.co/YourProfile).

🎉 **Happy Experimenting!** 🚀","{""id"": ""MatteoKhan/MistralGemma-7B-Merged"", ""author"": ""MatteoKhan"", ""sha"": ""e8f61f3939cf4b99d8dbc27373fb3cb2e4e535b4"", ""last_modified"": ""2025-03-04 15:13:46+00:00"", ""created_at"": ""2025-03-04 14:55:35+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 5, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""safetensors"", ""mistral"", ""text-generation"", ""mergekit"", ""merged-model"", ""gemma"", ""language-model"", ""en"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""license:mit"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model:\n- mistralai/Mistral-7B-v0.1\n- google/gemma-7b\nlanguage:\n- en\nlibrary_name: transformers\nlicense: mit\ntags:\n- mergekit\n- merged-model\n- mistral\n- gemma\n- language-model"", ""widget_data"": [{""text"": ""My name is Julien and I like to""}, {""text"": ""I like traveling by train because""}, {""text"": ""Paris is an amazing place to visit,""}, {""text"": ""Once upon a time,""}], ""model_index"": null, ""config"": {""architectures"": [""MistralForCausalLM""], ""model_type"": ""mistral"", ""tokenizer_config"": {""bos_token"": ""<s>"", ""eos_token"": ""</s>"", ""pad_token"": null, ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='generation_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00001-of-00003.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00002-of-00003.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00003-of-00003.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model.safetensors.index.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": {""parameters"": {""F16"": 7241732096}, ""total"": 7241732096}, ""security_repo_status"": null, ""lastModified"": ""2025-03-04 15:13:46+00:00"", ""cardData"": ""base_model:\n- mistralai/Mistral-7B-v0.1\n- google/gemma-7b\nlanguage:\n- en\nlibrary_name: transformers\nlicense: mit\ntags:\n- mergekit\n- merged-model\n- mistral\n- gemma\n- language-model"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67c714673a5f3766f86fb845"", ""modelId"": ""MatteoKhan/MistralGemma-7B-Merged"", ""usedStorage"": 14483991171}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=MatteoKhan/MistralGemma-7B-Merged&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5BMatteoKhan%2FMistralGemma-7B-Merged%5D(%2FMatteoKhan%2FMistralGemma-7B-Merged)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-sft-basic-5e-5-05-vsh3p4,"---
base_model: google/gemma-7b
datasets:
- argilla/dpo-mix-7k
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['argilla/dpo-mix-7k']](https://huggingface.co/datasets/['argilla/dpo-mix-7k']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-sft-basic-5e-5-05-vsh3p4"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/w35o198h) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.13.0
- Transformers: 4.48.1
- Pytorch: 2.5.1
- Datasets: 3.2.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-sft-basic-5e-5-05-vsh3p4"", ""author"": ""silviasapora"", ""sha"": ""715cfe82e86061d5318f7970a1759c66255754ac"", ""last_modified"": ""2025-03-10 15:56:36+00:00"", ""created_at"": ""2025-03-10 13:26:18+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 2, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:argilla/dpo-mix-7k"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + ' ' + message['content'] | trim + '<end_of_turn> ' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model '}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Mar10_13-25-51_84b693e79a02/events.out.tfevents.1741613180.84b693e79a02.31891.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Mar10_13-26-58_84b693e79a02/events.out.tfevents.1741613230.84b693e79a02.32983.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-03-10 15:56:36+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67cee87a461b6703138c0114"", ""modelId"": ""silviasapora/gemma-7b-sft-basic-5e-5-05-vsh3p4"", ""usedStorage"": 1638841437}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-sft-basic-5e-5-05-vsh3p4&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-sft-basic-5e-5-05-vsh3p4%5D(%2Fsilviasapora%2Fgemma-7b-sft-basic-5e-5-05-vsh3p4)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-silvia-basic-5e-5-05-vsh3p1,"---
base_model: google/gemma-7b
datasets:
- argilla/dpo-mix-7k
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['argilla/dpo-mix-7k']](https://huggingface.co/datasets/['argilla/dpo-mix-7k']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-silvia-basic-5e-5-05-vsh3p1"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/9s56k26a) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.13.0
- Transformers: 4.48.1
- Pytorch: 2.5.1
- Datasets: 3.2.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-vsh3p1"", ""author"": ""silviasapora"", ""sha"": ""cbfbdbd8ae0b2ae9703a45b1ddac67b982c92e06"", ""last_modified"": ""2025-03-11 01:27:18+00:00"", ""created_at"": ""2025-03-10 22:48:00+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 1, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:argilla/dpo-mix-7k"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + ' ' + message['content'] | trim + '<end_of_turn> ' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model '}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Mar10_22-47-46_84b693e79a02/events.out.tfevents.1741646882.84b693e79a02.157189.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-03-11 01:27:18+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67cf6c2062df312581ffe3e7"", ""modelId"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-vsh3p1"", ""usedStorage"": 1638835861}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-silvia-basic-5e-5-05-vsh3p1&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-vsh3p1%5D(%2Fsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-vsh3p1)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-silvia-basic-5e-5-05-vsh3p0,"---
base_model: google/gemma-7b
datasets:
- argilla/dpo-mix-7k
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['argilla/dpo-mix-7k']](https://huggingface.co/datasets/['argilla/dpo-mix-7k']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-silvia-basic-5e-5-05-vsh3p0"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/8e9p2425) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.13.0
- Transformers: 4.48.1
- Pytorch: 2.5.1
- Datasets: 3.2.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-vsh3p0"", ""author"": ""silviasapora"", ""sha"": ""455f96f13e01ab74b593dcd6289925c8ae169140"", ""last_modified"": ""2025-03-11 01:26:30+00:00"", ""created_at"": ""2025-03-10 22:48:07+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 1, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:argilla/dpo-mix-7k"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + ' ' + message['content'] | trim + '<end_of_turn> ' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model '}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Mar10_22-47-48_84b693e79a02/events.out.tfevents.1741646889.84b693e79a02.157192.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-03-11 01:26:30+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67cf6c27f2b1fe815dac909b"", ""modelId"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-vsh3p0"", ""usedStorage"": 1638835861}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-silvia-basic-5e-5-05-vsh3p0&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-vsh3p0%5D(%2Fsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-vsh3p0)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-silvia-basic-5e-5-05-vsh3p3,"---
base_model: google/gemma-7b
datasets:
- argilla/dpo-mix-7k
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['argilla/dpo-mix-7k']](https://huggingface.co/datasets/['argilla/dpo-mix-7k']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-silvia-basic-5e-5-05-vsh3p3"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/jkqsxm0q) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.13.0
- Transformers: 4.48.1
- Pytorch: 2.5.1
- Datasets: 3.2.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-vsh3p3"", ""author"": ""silviasapora"", ""sha"": ""d0361014a288d614339c929493ef3169a00cdb87"", ""last_modified"": ""2025-03-11 04:11:43+00:00"", ""created_at"": ""2025-03-11 01:32:41+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 1, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:argilla/dpo-mix-7k"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + ' ' + message['content'] | trim + '<end_of_turn> ' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model '}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Mar11_01-32-28_84b693e79a02/events.out.tfevents.1741656763.84b693e79a02.215984.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-03-11 04:11:43+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67cf92b94dac6ed12da98fc1"", ""modelId"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-vsh3p3"", ""usedStorage"": 1638835861}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-silvia-basic-5e-5-05-vsh3p3&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-vsh3p3%5D(%2Fsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-vsh3p3)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-silvia-basic-5e-5-05-vsh3p2,"---
base_model: google/gemma-7b
datasets:
- argilla/dpo-mix-7k
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['argilla/dpo-mix-7k']](https://huggingface.co/datasets/['argilla/dpo-mix-7k']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-silvia-basic-5e-5-05-vsh3p2"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/l2s9npqi) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.13.0
- Transformers: 4.48.1
- Pytorch: 2.5.1
- Datasets: 3.2.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-vsh3p2"", ""author"": ""silviasapora"", ""sha"": ""b1ef6b9bc5c7ac31d8fdf07f9d66c68bb5c11e9f"", ""last_modified"": ""2025-03-11 04:11:05+00:00"", ""created_at"": ""2025-03-11 01:32:42+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 1, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:argilla/dpo-mix-7k"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + ' ' + message['content'] | trim + '<end_of_turn> ' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model '}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Mar11_01-32-31_84b693e79a02/events.out.tfevents.1741656765.84b693e79a02.215987.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-03-11 04:11:05+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67cf92ba8a4265f365543ca9"", ""modelId"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-vsh3p2"", ""usedStorage"": 1638835861}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-silvia-basic-5e-5-05-vsh3p2&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-vsh3p2%5D(%2Fsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-vsh3p2)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-silvia-basic-5e-5-05-vsh3p4,"---
base_model: google/gemma-7b
datasets:
- argilla/dpo-mix-7k
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['argilla/dpo-mix-7k']](https://huggingface.co/datasets/['argilla/dpo-mix-7k']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-silvia-basic-5e-5-05-vsh3p4"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/9u7xexrr) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.13.0
- Transformers: 4.48.1
- Pytorch: 2.5.1
- Datasets: 3.2.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-vsh3p4"", ""author"": ""silviasapora"", ""sha"": ""b1a4bb0e875f6f14dd52e8f99f27cd844f5f3062"", ""last_modified"": ""2025-03-11 06:50:36+00:00"", ""created_at"": ""2025-03-11 04:12:14+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 1, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:argilla/dpo-mix-7k"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + ' ' + message['content'] | trim + '<end_of_turn> ' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model '}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Mar11_04-11-59_84b693e79a02/events.out.tfevents.1741666343.84b693e79a02.217219.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-03-11 06:50:36+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67cfb81eaec7809ab93e169b"", ""modelId"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-vsh3p4"", ""usedStorage"": 1638835861}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-silvia-basic-5e-5-05-vsh3p4&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-vsh3p4%5D(%2Fsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-vsh3p4)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-silvia-basic-5e-5-05-vsh3p5,"---
base_model: google/gemma-7b
datasets:
- argilla/dpo-mix-7k
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['argilla/dpo-mix-7k']](https://huggingface.co/datasets/['argilla/dpo-mix-7k']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-silvia-basic-5e-5-05-vsh3p5"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/3u34zpd6) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.13.0
- Transformers: 4.48.1
- Pytorch: 2.5.1
- Datasets: 3.2.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-vsh3p5"", ""author"": ""silviasapora"", ""sha"": ""01e5065984e75a7afe30c2d518b8afb312e8ee43"", ""last_modified"": ""2025-03-11 06:51:43+00:00"", ""created_at"": ""2025-03-11 04:12:19+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 1, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:argilla/dpo-mix-7k"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + ' ' + message['content'] | trim + '<end_of_turn> ' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model '}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Mar11_04-12-00_84b693e79a02/events.out.tfevents.1741666343.84b693e79a02.217215.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-03-11 06:51:43+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67cfb823c956b41df75d6f18"", ""modelId"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-vsh3p5"", ""usedStorage"": 1638835861}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-silvia-basic-5e-5-05-vsh3p5&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-vsh3p5%5D(%2Fsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-vsh3p5)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-silvia-basic-5e-5-05-vsh3p6,"---
base_model: google/gemma-7b
datasets:
- argilla/dpo-mix-7k
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['argilla/dpo-mix-7k']](https://huggingface.co/datasets/['argilla/dpo-mix-7k']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-silvia-basic-5e-5-05-vsh3p6"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/kryx58cm) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.13.0
- Transformers: 4.48.1
- Pytorch: 2.5.1
- Datasets: 3.2.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-vsh3p6"", ""author"": ""silviasapora"", ""sha"": ""09b2cc930754e033272f35c4abdd3c4c6d46b79f"", ""last_modified"": ""2025-03-11 09:30:41+00:00"", ""created_at"": ""2025-03-11 06:52:13+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 1, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:argilla/dpo-mix-7k"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + ' ' + message['content'] | trim + '<end_of_turn> ' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model '}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Mar11_06-52-00_84b693e79a02/events.out.tfevents.1741675936.84b693e79a02.218358.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-03-11 09:30:41+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67cfdd9dd929faaa6f055f9f"", ""modelId"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-vsh3p6"", ""usedStorage"": 1638835861}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-silvia-basic-5e-5-05-vsh3p6&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-vsh3p6%5D(%2Fsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-vsh3p6)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-silvia-basic-5e-5-05-vsh3p7,"---
base_model: google/gemma-7b
datasets:
- argilla/dpo-mix-7k
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['argilla/dpo-mix-7k']](https://huggingface.co/datasets/['argilla/dpo-mix-7k']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-silvia-basic-5e-5-05-vsh3p7"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/kp5vd4do) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.13.0
- Transformers: 4.48.1
- Pytorch: 2.5.1
- Datasets: 3.2.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-vsh3p7"", ""author"": ""silviasapora"", ""sha"": ""09d06112ab29a7056843e0e7ad78d66cda1daf20"", ""last_modified"": ""2025-03-11 09:31:25+00:00"", ""created_at"": ""2025-03-11 06:52:20+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 1, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:argilla/dpo-mix-7k"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + ' ' + message['content'] | trim + '<end_of_turn> ' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model '}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Mar11_06-52-03_84b693e79a02/events.out.tfevents.1741675942.84b693e79a02.218355.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-03-11 09:31:25+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67cfdda41d45a856e36e56bc"", ""modelId"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-vsh3p7"", ""usedStorage"": 1638835861}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-silvia-basic-5e-5-05-vsh3p7&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-vsh3p7%5D(%2Fsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-vsh3p7)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-silvia-basic-5e-5-05-vsh3p8,"---
base_model: google/gemma-7b
datasets:
- argilla/dpo-mix-7k
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['argilla/dpo-mix-7k']](https://huggingface.co/datasets/['argilla/dpo-mix-7k']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-silvia-basic-5e-5-05-vsh3p8"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/lfhwr1dq) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.13.0
- Transformers: 4.48.1
- Pytorch: 2.5.1
- Datasets: 3.2.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-vsh3p8"", ""author"": ""silviasapora"", ""sha"": ""dcf3401190a2d850d2c59c06cc65869422cc5cea"", ""last_modified"": ""2025-03-11 12:21:21+00:00"", ""created_at"": ""2025-03-11 09:43:13+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 2, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:argilla/dpo-mix-7k"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + ' ' + message['content'] | trim + '<end_of_turn> ' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model '}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Mar11_09-43-02_84b693e79a02/events.out.tfevents.1741686200.84b693e79a02.219347.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-03-11 12:21:21+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67d005b1f0da021b1ad6eae1"", ""modelId"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-vsh3p8"", ""usedStorage"": 1638835861}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-silvia-basic-5e-5-05-vsh3p8&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-vsh3p8%5D(%2Fsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-vsh3p8)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-cpo-basic-5e-5-005-vshp1,"---
base_model: google/gemma-7b
datasets:
- argilla/dpo-mix-7k
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['argilla/dpo-mix-7k']](https://huggingface.co/datasets/['argilla/dpo-mix-7k']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-cpo-basic-5e-5-005-vshp1"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/o2xzf46q) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.15.2
- Transformers: 4.49.0
- Pytorch: 2.4.0
- Datasets: 3.0.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-cpo-basic-5e-5-005-vshp1"", ""author"": ""silviasapora"", ""sha"": ""abc5457b5e858d971f771cea6f62959aabf7f0dd"", ""last_modified"": ""2025-03-26 19:58:44+00:00"", ""created_at"": ""2025-03-26 16:41:18+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 1, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:argilla/dpo-mix-7k"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Mar26_16-40-31_9600b3b70eda/events.out.tfevents.1743007295.9600b3b70eda.1982131.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Mar26_17-16-49_9600b3b70eda/events.out.tfevents.1743009498.9600b3b70eda.2004311.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Mar26_17-19-26_9600b3b70eda/events.out.tfevents.1743009657.9600b3b70eda.2007691.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Mar26_17-30-19_9600b3b70eda/events.out.tfevents.1743010315.9600b3b70eda.2015179.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Mar26_17-41-36_9600b3b70eda/events.out.tfevents.1743010952.9600b3b70eda.2022499.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Mar26_18-25-54_9600b3b70eda/events.out.tfevents.1743013609.9600b3b70eda.2046795.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-03-26 19:58:44+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67e42e2e85b605b5590a6e81"", ""modelId"": ""silviasapora/gemma-7b-cpo-basic-5e-5-005-vshp1"", ""usedStorage"": 1638869629}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-cpo-basic-5e-5-005-vshp1&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-cpo-basic-5e-5-005-vshp1%5D(%2Fsilviasapora%2Fgemma-7b-cpo-basic-5e-5-005-vshp1)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-slic-basic-5e-5-005-vshp3,"---
base_model: google/gemma-7b
datasets:
- argilla/dpo-mix-7k
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['argilla/dpo-mix-7k']](https://huggingface.co/datasets/['argilla/dpo-mix-7k']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-slic-basic-5e-5-005-vshp3"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/8h4nifrd) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.15.2
- Transformers: 4.49.0
- Pytorch: 2.4.0
- Datasets: 3.0.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-slic-basic-5e-5-005-vshp3"", ""author"": ""silviasapora"", ""sha"": ""9b6dae714a0a3164d3fbff3b833939f5833a04c8"", ""last_modified"": ""2025-03-26 19:58:09+00:00"", ""created_at"": ""2025-03-26 16:41:18+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 1, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:argilla/dpo-mix-7k"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Mar26_16-40-32_9600b3b70eda/events.out.tfevents.1743007294.9600b3b70eda.1982128.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Mar26_17-16-49_9600b3b70eda/events.out.tfevents.1743009500.9600b3b70eda.2004321.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Mar26_17-19-27_9600b3b70eda/events.out.tfevents.1743009657.9600b3b70eda.2007695.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Mar26_17-30-20_9600b3b70eda/events.out.tfevents.1743010316.9600b3b70eda.2015174.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Mar26_17-41-35_9600b3b70eda/events.out.tfevents.1743010952.9600b3b70eda.2022503.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Mar26_18-25-54_9600b3b70eda/events.out.tfevents.1743013610.9600b3b70eda.2046802.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-03-26 19:58:09+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67e42e2ecb0ea7cea9d7da5d"", ""modelId"": ""silviasapora/gemma-7b-slic-basic-5e-5-005-vshp3"", ""usedStorage"": 1638868924}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-slic-basic-5e-5-005-vshp3&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-slic-basic-5e-5-005-vshp3%5D(%2Fsilviasapora%2Fgemma-7b-slic-basic-5e-5-005-vshp3)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-silvia-basic-5e-5-005-vshp0,"---
base_model: google/gemma-7b
datasets:
- argilla/dpo-mix-7k
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['argilla/dpo-mix-7k']](https://huggingface.co/datasets/['argilla/dpo-mix-7k']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-silvia-basic-5e-5-005-vshp0"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/9t7e7wib) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.15.2
- Transformers: 4.49.0
- Pytorch: 2.4.0
- Datasets: 3.0.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-silvia-basic-5e-5-005-vshp0"", ""author"": ""silviasapora"", ""sha"": ""ed097de375c68cd490e2b452f8c60f83e8454537"", ""last_modified"": ""2025-03-26 19:58:04+00:00"", ""created_at"": ""2025-03-26 16:41:18+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 1, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:argilla/dpo-mix-7k"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Mar26_16-40-32_9600b3b70eda/events.out.tfevents.1743007295.9600b3b70eda.1982137.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Mar26_17-06-58_9600b3b70eda/events.out.tfevents.1743008874.9600b3b70eda.1997094.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Mar26_17-08-47_9600b3b70eda/events.out.tfevents.1743008983.9600b3b70eda.1998488.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Mar26_17-11-42_9600b3b70eda/events.out.tfevents.1743009152.9600b3b70eda.2000434.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Mar26_17-14-01_9600b3b70eda/events.out.tfevents.1743009331.9600b3b70eda.2002076.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Mar26_17-16-49_9600b3b70eda/events.out.tfevents.1743009499.9600b3b70eda.2004319.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Mar26_17-19-27_9600b3b70eda/events.out.tfevents.1743009657.9600b3b70eda.2007700.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Mar26_17-30-19_9600b3b70eda/events.out.tfevents.1743010315.9600b3b70eda.2015171.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Mar26_17-41-36_9600b3b70eda/events.out.tfevents.1743010952.9600b3b70eda.2022506.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Mar26_18-08-52_9600b3b70eda/events.out.tfevents.1743012588.9600b3b70eda.2037329.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Mar26_18-10-12_9600b3b70eda/events.out.tfevents.1743012668.9600b3b70eda.2038484.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Mar26_18-25-53_9600b3b70eda/events.out.tfevents.1743013609.9600b3b70eda.2046805.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-03-26 19:58:04+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67e42e2ee6c74a242a0d50d1"", ""modelId"": ""silviasapora/gemma-7b-silvia-basic-5e-5-005-vshp0"", ""usedStorage"": 1638909290}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-silvia-basic-5e-5-005-vshp0&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-silvia-basic-5e-5-005-vshp0%5D(%2Fsilviasapora%2Fgemma-7b-silvia-basic-5e-5-005-vshp0)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-orpo-basic-5e-5-005-vshp2,"---
base_model: google/gemma-7b
datasets:
- argilla/dpo-mix-7k
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['argilla/dpo-mix-7k']](https://huggingface.co/datasets/['argilla/dpo-mix-7k']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-orpo-basic-5e-5-005-vshp2"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/14fny1yp) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.15.2
- Transformers: 4.49.0
- Pytorch: 2.4.0
- Datasets: 3.0.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-orpo-basic-5e-5-005-vshp2"", ""author"": ""silviasapora"", ""sha"": ""537cb0330990d9ce9eab191abf0f39efd3a7f8a1"", ""last_modified"": ""2025-03-26 19:58:18+00:00"", ""created_at"": ""2025-03-26 16:41:20+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 1, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:argilla/dpo-mix-7k"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Mar26_16-40-32_9600b3b70eda/events.out.tfevents.1743007296.9600b3b70eda.1982134.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Mar26_17-16-48_9600b3b70eda/events.out.tfevents.1743009498.9600b3b70eda.2004315.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Mar26_17-19-26_9600b3b70eda/events.out.tfevents.1743009657.9600b3b70eda.2007697.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Mar26_17-30-19_9600b3b70eda/events.out.tfevents.1743010315.9600b3b70eda.2015178.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Mar26_17-41-35_9600b3b70eda/events.out.tfevents.1743010952.9600b3b70eda.2022509.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Mar26_18-25-53_9600b3b70eda/events.out.tfevents.1743013609.9600b3b70eda.2046792.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-03-26 19:58:18+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67e42e307094166a65883312"", ""modelId"": ""silviasapora/gemma-7b-orpo-basic-5e-5-005-vshp2"", ""usedStorage"": 1638869653}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-orpo-basic-5e-5-005-vshp2&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-orpo-basic-5e-5-005-vshp2%5D(%2Fsilviasapora%2Fgemma-7b-orpo-basic-5e-5-005-vshp2)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-silvia-basic-5e-5-05-v72,"---
base_model: google/gemma-7b
datasets:
- argilla/dpo-mix-7k
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['argilla/dpo-mix-7k']](https://huggingface.co/datasets/['argilla/dpo-mix-7k']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-silvia-basic-5e-5-05-v72"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/goqrcw2o) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.15.2
- Transformers: 4.49.0
- Pytorch: 2.4.0
- Datasets: 3.0.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-v72"", ""author"": ""silviasapora"", ""sha"": ""3c6aa34c405df945e8a71220b755d9dcf17776f2"", ""last_modified"": ""2025-03-26 23:03:40+00:00"", ""created_at"": ""2025-03-26 21:36:10+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 1, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:argilla/dpo-mix-7k"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Mar26_21-35-31_9600b3b70eda/events.out.tfevents.1743024986.9600b3b70eda.2145151.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-03-26 23:03:40+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67e4734a27e5e279ffdb5845"", ""modelId"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-v72"", ""usedStorage"": 1638823333}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-silvia-basic-5e-5-05-v72&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-v72%5D(%2Fsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-v72)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-silvia-basic-5e-5-05-v71,"---
base_model: google/gemma-7b
datasets:
- argilla/dpo-mix-7k
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['argilla/dpo-mix-7k']](https://huggingface.co/datasets/['argilla/dpo-mix-7k']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-silvia-basic-5e-5-05-v71"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/3wqp6xtp) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.15.2
- Transformers: 4.49.0
- Pytorch: 2.4.0
- Datasets: 3.0.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-v71"", ""author"": ""silviasapora"", ""sha"": ""ccafa615df690346c9a2900f12181e2eeebc0558"", ""last_modified"": ""2025-03-26 23:04:02+00:00"", ""created_at"": ""2025-03-26 21:36:10+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 1, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:argilla/dpo-mix-7k"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Mar26_21-35-31_9600b3b70eda/events.out.tfevents.1743024989.9600b3b70eda.2145158.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-03-26 23:04:02+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67e4734a28161b0a642087b9"", ""modelId"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-v71"", ""usedStorage"": 1638823333}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-silvia-basic-5e-5-05-v71&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-v71%5D(%2Fsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-v71)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-silvia-basic-5e-5-05-v70,"---
base_model: google/gemma-7b
datasets:
- argilla/dpo-mix-7k
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['argilla/dpo-mix-7k']](https://huggingface.co/datasets/['argilla/dpo-mix-7k']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-silvia-basic-5e-5-05-v70"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/i1dpoxy7) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.15.2
- Transformers: 4.49.0
- Pytorch: 2.4.0
- Datasets: 3.0.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-v70"", ""author"": ""silviasapora"", ""sha"": ""e6951ca88e8cfcfd89eab790451784ad55f345c3"", ""last_modified"": ""2025-03-26 23:03:04+00:00"", ""created_at"": ""2025-03-26 21:36:11+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 1, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:argilla/dpo-mix-7k"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Mar26_21-35-31_9600b3b70eda/events.out.tfevents.1743024987.9600b3b70eda.2145148.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-03-26 23:03:04+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67e4734b86f8bca1b4015589"", ""modelId"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-v70"", ""usedStorage"": 1638823333}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-silvia-basic-5e-5-05-v70&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-v70%5D(%2Fsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-v70)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-cpo-basic-5e-5-05-v70,N/A,N/A,1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-cpo-basic-5e-5-05-v70&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-cpo-basic-5e-5-05-v70%5D(%2Fsilviasapora%2Fgemma-7b-cpo-basic-5e-5-05-v70)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-orpo-basic-5e-5-05-v71,"---
base_model: google/gemma-7b
datasets:
- argilla/dpo-mix-7k
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['argilla/dpo-mix-7k']](https://huggingface.co/datasets/['argilla/dpo-mix-7k']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-orpo-basic-5e-5-05-v71"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/xtf8kauv) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.15.2
- Transformers: 4.49.0
- Pytorch: 2.4.0
- Datasets: 3.0.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-orpo-basic-5e-5-05-v71"", ""author"": ""silviasapora"", ""sha"": ""989d9c99707d180f70ac26b10a69ae30e7af281d"", ""last_modified"": ""2025-03-27 00:37:40+00:00"", ""created_at"": ""2025-03-26 23:08:27+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 1, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:argilla/dpo-mix-7k"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Mar26_23-07-48_9600b3b70eda/events.out.tfevents.1743030523.9600b3b70eda.2166304.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-03-27 00:37:40+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67e488ebc8f6a60e7fd2e85a"", ""modelId"": ""silviasapora/gemma-7b-orpo-basic-5e-5-05-v71"", ""usedStorage"": 1638823325}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-orpo-basic-5e-5-05-v71&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-orpo-basic-5e-5-05-v71%5D(%2Fsilviasapora%2Fgemma-7b-orpo-basic-5e-5-05-v71)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-silvia-basic-5e-5-05-v81,"---
base_model: google/gemma-7b
datasets:
- argilla/dpo-mix-7k
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['argilla/dpo-mix-7k']](https://huggingface.co/datasets/['argilla/dpo-mix-7k']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-silvia-basic-5e-5-05-v81"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/plugphya) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.15.2
- Transformers: 4.49.0
- Pytorch: 2.4.0
- Datasets: 3.0.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-v81"", ""author"": ""silviasapora"", ""sha"": ""55c821578df21096e49a27ad942d4330a7298998"", ""last_modified"": ""2025-03-27 00:38:33+00:00"", ""created_at"": ""2025-03-26 23:09:23+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 1, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:argilla/dpo-mix-7k"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Mar26_23-08-44_9600b3b70eda/events.out.tfevents.1743030580.9600b3b70eda.2166805.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-03-27 00:38:33+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67e489230427953dfec1b660"", ""modelId"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-v81"", ""usedStorage"": 1638823333}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-silvia-basic-5e-5-05-v81&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-v81%5D(%2Fsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-v81)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-silvia-basic-5e-5-05-v80,"---
base_model: google/gemma-7b
datasets:
- argilla/dpo-mix-7k
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['argilla/dpo-mix-7k']](https://huggingface.co/datasets/['argilla/dpo-mix-7k']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-silvia-basic-5e-5-05-v80"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/kv88fc0h) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.15.2
- Transformers: 4.49.0
- Pytorch: 2.4.0
- Datasets: 3.0.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-v80"", ""author"": ""silviasapora"", ""sha"": ""ea4365b74a83baf758c3f869bed050cb7229bea2"", ""last_modified"": ""2025-03-27 00:37:37+00:00"", ""created_at"": ""2025-03-26 23:09:24+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 1, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:argilla/dpo-mix-7k"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Mar26_23-08-44_9600b3b70eda/events.out.tfevents.1743030581.9600b3b70eda.2166802.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-03-27 00:37:37+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67e4892484ac4e09158cfafd"", ""modelId"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-v80"", ""usedStorage"": 1638823333}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-silvia-basic-5e-5-05-v80&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-v80%5D(%2Fsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-v80)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-silvia-basic-5e-5-05-v82,"---
base_model: google/gemma-7b
datasets:
- argilla/dpo-mix-7k
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['argilla/dpo-mix-7k']](https://huggingface.co/datasets/['argilla/dpo-mix-7k']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-silvia-basic-5e-5-05-v82"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/wid9go42) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.15.2
- Transformers: 4.49.0
- Pytorch: 2.4.0
- Datasets: 3.0.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-v82"", ""author"": ""silviasapora"", ""sha"": ""4f6dd8c246afadeaa9974336159afbe7461a97b8"", ""last_modified"": ""2025-03-27 00:38:15+00:00"", ""created_at"": ""2025-03-26 23:09:24+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 2, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:argilla/dpo-mix-7k"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Mar26_23-08-44_9600b3b70eda/events.out.tfevents.1743030581.9600b3b70eda.2166808.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-03-27 00:38:15+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67e48924ef72b1740ecc14c3"", ""modelId"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-v82"", ""usedStorage"": 1638823333}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-silvia-basic-5e-5-05-v82&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-v82%5D(%2Fsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-v82)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-slic-basic-5e-5-05-v72,"---
base_model: google/gemma-7b
datasets:
- argilla/dpo-mix-7k
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['argilla/dpo-mix-7k']](https://huggingface.co/datasets/['argilla/dpo-mix-7k']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-slic-basic-5e-5-05-v72"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/xxsuig1z) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.15.2
- Transformers: 4.49.0
- Pytorch: 2.4.0
- Datasets: 3.0.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-slic-basic-5e-5-05-v72"", ""author"": ""silviasapora"", ""sha"": ""41d6d0c534870853ba0c034f103b22a8719192a5"", ""last_modified"": ""2025-03-27 02:04:46+00:00"", ""created_at"": ""2025-03-27 00:38:36+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 1, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:argilla/dpo-mix-7k"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Mar27_00-37-56_9600b3b70eda/events.out.tfevents.1743035932.9600b3b70eda.2168589.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-03-27 02:04:46+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67e49e0c28d4a2a5c8d74d05"", ""modelId"": ""silviasapora/gemma-7b-slic-basic-5e-5-05-v72"", ""usedStorage"": 1638823325}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-slic-basic-5e-5-05-v72&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-slic-basic-5e-5-05-v72%5D(%2Fsilviasapora%2Fgemma-7b-slic-basic-5e-5-05-v72)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-silvia-basic-5e-5-05-v93,"---
base_model: google/gemma-7b
datasets:
- argilla/dpo-mix-7k
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['argilla/dpo-mix-7k']](https://huggingface.co/datasets/['argilla/dpo-mix-7k']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-silvia-basic-5e-5-05-v93"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/5gv47371) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.15.2
- Transformers: 4.49.0
- Pytorch: 2.4.0
- Datasets: 3.0.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-v93"", ""author"": ""silviasapora"", ""sha"": ""030546920ccf23a1f1e209905ac3fea9845b0700"", ""last_modified"": ""2025-03-27 04:52:17+00:00"", ""created_at"": ""2025-03-27 03:24:36+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 2, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:argilla/dpo-mix-7k"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Mar27_03-23-56_9600b3b70eda/events.out.tfevents.1743045893.9600b3b70eda.2264443.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-03-27 04:52:17+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67e4c4f4376c1c83804786a9"", ""modelId"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-v93"", ""usedStorage"": 1638823333}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-silvia-basic-5e-5-05-v93&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-v93%5D(%2Fsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-v93)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-silvia-basic-5e-5-05-v91,"---
base_model: google/gemma-7b
datasets:
- argilla/dpo-mix-7k
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['argilla/dpo-mix-7k']](https://huggingface.co/datasets/['argilla/dpo-mix-7k']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-silvia-basic-5e-5-05-v91"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/bb0idyjj) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.15.2
- Transformers: 4.49.0
- Pytorch: 2.4.0
- Datasets: 3.0.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-v91"", ""author"": ""silviasapora"", ""sha"": ""ee1bc126b84af796a793dfd95a2fe5c692e0ecb0"", ""last_modified"": ""2025-03-27 04:52:24+00:00"", ""created_at"": ""2025-03-27 03:24:36+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 1, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:argilla/dpo-mix-7k"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Mar27_03-23-57_9600b3b70eda/events.out.tfevents.1743045892.9600b3b70eda.2264440.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-03-27 04:52:24+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67e4c4f4e7e1e432cd24fd57"", ""modelId"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-v91"", ""usedStorage"": 1638823332}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-silvia-basic-5e-5-05-v91&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-v91%5D(%2Fsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-v91)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-silvia-basic-5e-5-05-v92,"---
base_model: google/gemma-7b
datasets:
- argilla/dpo-mix-7k
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['argilla/dpo-mix-7k']](https://huggingface.co/datasets/['argilla/dpo-mix-7k']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-silvia-basic-5e-5-05-v92"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/mp184fhf) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.15.2
- Transformers: 4.49.0
- Pytorch: 2.4.0
- Datasets: 3.0.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-v92"", ""author"": ""silviasapora"", ""sha"": ""8ad84384ca980d1125c7133320e8c0afb26407c4"", ""last_modified"": ""2025-03-27 04:52:06+00:00"", ""created_at"": ""2025-03-27 03:24:40+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 1, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:argilla/dpo-mix-7k"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Mar27_03-24-01_9600b3b70eda/events.out.tfevents.1743045897.9600b3b70eda.2264449.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-03-27 04:52:06+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67e4c4f8c866bf34938588c4"", ""modelId"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-v92"", ""usedStorage"": 1638823332}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-silvia-basic-5e-5-05-v92&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-v92%5D(%2Fsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-v92)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-silvia-basic-5e-5-05-v90,"---
base_model: google/gemma-7b
datasets:
- argilla/dpo-mix-7k
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['argilla/dpo-mix-7k']](https://huggingface.co/datasets/['argilla/dpo-mix-7k']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-silvia-basic-5e-5-05-v90"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/d0o7fpll) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.15.2
- Transformers: 4.49.0
- Pytorch: 2.4.0
- Datasets: 3.0.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-v90"", ""author"": ""silviasapora"", ""sha"": ""ebc69409e9cc639f20819bfa8ebfb3712ef5a99d"", ""last_modified"": ""2025-03-27 04:51:40+00:00"", ""created_at"": ""2025-03-27 03:24:51+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 1, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:argilla/dpo-mix-7k"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Mar27_03-24-11_9600b3b70eda/events.out.tfevents.1743045908.9600b3b70eda.2264452.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-03-27 04:51:40+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67e4c503748481a11952945d"", ""modelId"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-v90"", ""usedStorage"": 1638823332}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-silvia-basic-5e-5-05-v90&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-v90%5D(%2Fsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-v90)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-silvia-basic-5e-5-05-v96,"---
base_model: google/gemma-7b
datasets:
- argilla/dpo-mix-7k
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['argilla/dpo-mix-7k']](https://huggingface.co/datasets/['argilla/dpo-mix-7k']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-silvia-basic-5e-5-05-v96"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/053mihem) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.15.2
- Transformers: 4.49.0
- Pytorch: 2.4.0
- Datasets: 3.0.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-v96"", ""author"": ""silviasapora"", ""sha"": ""edeeea16831967aff97d95a7d8a3107fd09f3f08"", ""last_modified"": ""2025-03-27 06:29:20+00:00"", ""created_at"": ""2025-03-27 04:59:09+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 1, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:argilla/dpo-mix-7k"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Mar27_04-58-27_9600b3b70eda/events.out.tfevents.1743051564.9600b3b70eda.2269179.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-03-27 06:29:20+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67e4db1d2d7725a31e204a62"", ""modelId"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-v96"", ""usedStorage"": 1638823333}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-silvia-basic-5e-5-05-v96&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-v96%5D(%2Fsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-v96)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-silvia-basic-5e-5-05-v95,"---
base_model: google/gemma-7b
datasets:
- argilla/dpo-mix-7k
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['argilla/dpo-mix-7k']](https://huggingface.co/datasets/['argilla/dpo-mix-7k']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-silvia-basic-5e-5-05-v95"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/34gh14um) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.15.2
- Transformers: 4.49.0
- Pytorch: 2.4.0
- Datasets: 3.0.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-v95"", ""author"": ""silviasapora"", ""sha"": ""94c89d2d54c50d341db7238d207c9372f54a1be7"", ""last_modified"": ""2025-03-27 06:30:13+00:00"", ""created_at"": ""2025-03-27 04:59:09+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 1, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:argilla/dpo-mix-7k"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Mar27_04-58-27_9600b3b70eda/events.out.tfevents.1743051563.9600b3b70eda.2269182.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-03-27 06:30:13+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67e4db1db23526964ee545d9"", ""modelId"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-v95"", ""usedStorage"": 1638823333}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-silvia-basic-5e-5-05-v95&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-v95%5D(%2Fsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-v95)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-silvia-basic-5e-5-05-v97,"---
base_model: google/gemma-7b
datasets:
- argilla/dpo-mix-7k
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['argilla/dpo-mix-7k']](https://huggingface.co/datasets/['argilla/dpo-mix-7k']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-silvia-basic-5e-5-05-v97"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/h5wdmr5r) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.15.2
- Transformers: 4.49.0
- Pytorch: 2.4.0
- Datasets: 3.0.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-v97"", ""author"": ""silviasapora"", ""sha"": ""692bb35d9d8d74a36332267a8cf913dfea5d325a"", ""last_modified"": ""2025-03-27 06:29:54+00:00"", ""created_at"": ""2025-03-27 04:59:09+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 1, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:argilla/dpo-mix-7k"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Mar27_04-58-27_9600b3b70eda/events.out.tfevents.1743051565.9600b3b70eda.2269172.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-03-27 06:29:54+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67e4db1de7e1e432cd2d7e0d"", ""modelId"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-v97"", ""usedStorage"": 1638823333}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-silvia-basic-5e-5-05-v97&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-v97%5D(%2Fsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-v97)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-silvia-basic-5e-5-05-v94,"---
base_model: google/gemma-7b
datasets:
- argilla/dpo-mix-7k
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['argilla/dpo-mix-7k']](https://huggingface.co/datasets/['argilla/dpo-mix-7k']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-silvia-basic-5e-5-05-v94"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/xemsudl5) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.15.2
- Transformers: 4.49.0
- Pytorch: 2.4.0
- Datasets: 3.0.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-v94"", ""author"": ""silviasapora"", ""sha"": ""bab94e4a95e6dedbc2d91f80ed156b3a2b07041d"", ""last_modified"": ""2025-03-27 06:29:30+00:00"", ""created_at"": ""2025-03-27 04:59:09+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 2, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:argilla/dpo-mix-7k"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Mar27_04-58-27_9600b3b70eda/events.out.tfevents.1743051564.9600b3b70eda.2269177.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-03-27 06:29:30+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67e4db1de7e1e432cd2d7e10"", ""modelId"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-v94"", ""usedStorage"": 1638823333}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-silvia-basic-5e-5-05-v94&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-v94%5D(%2Fsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-v94)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-silvia-basic-5e-5-05-v911,"---
base_model: google/gemma-7b
datasets:
- argilla/dpo-mix-7k
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['argilla/dpo-mix-7k']](https://huggingface.co/datasets/['argilla/dpo-mix-7k']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-silvia-basic-5e-5-05-v911"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/u4pr5ftq) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.15.2
- Transformers: 4.49.0
- Pytorch: 2.4.0
- Datasets: 3.0.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-v911"", ""author"": ""silviasapora"", ""sha"": ""29328d44d559f3b3e818e1b7f8aaced8e98db021"", ""last_modified"": ""2025-03-27 08:03:25+00:00"", ""created_at"": ""2025-03-27 06:31:08+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 1, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:argilla/dpo-mix-7k"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Mar27_06-30-28_9600b3b70eda/events.out.tfevents.1743057085.9600b3b70eda.2271482.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-03-27 08:03:25+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67e4f0ac6d47bc4578d88812"", ""modelId"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-v911"", ""usedStorage"": 1638823337}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-silvia-basic-5e-5-05-v911&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-v911%5D(%2Fsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-v911)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-silvia-basic-5e-5-05-v98,"---
base_model: google/gemma-7b
datasets:
- argilla/dpo-mix-7k
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['argilla/dpo-mix-7k']](https://huggingface.co/datasets/['argilla/dpo-mix-7k']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-silvia-basic-5e-5-05-v98"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/oonohbib) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.15.2
- Transformers: 4.49.0
- Pytorch: 2.4.0
- Datasets: 3.0.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-v98"", ""author"": ""silviasapora"", ""sha"": ""d18463ea05e6b43c68f36ee294ebdb7e03752cfc"", ""last_modified"": ""2025-03-27 08:02:44+00:00"", ""created_at"": ""2025-03-27 06:31:08+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 1, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:argilla/dpo-mix-7k"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Mar27_06-30-29_9600b3b70eda/events.out.tfevents.1743057086.9600b3b70eda.2271476.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-03-27 08:02:44+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67e4f0ac7ee0e311e3d57e0e"", ""modelId"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-v98"", ""usedStorage"": 1638823333}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-silvia-basic-5e-5-05-v98&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-v98%5D(%2Fsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-v98)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-silvia-basic-5e-5-05-v99,"---
base_model: google/gemma-7b
datasets:
- argilla/dpo-mix-7k
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['argilla/dpo-mix-7k']](https://huggingface.co/datasets/['argilla/dpo-mix-7k']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-silvia-basic-5e-5-05-v99"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/g3fc7h7x) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.15.2
- Transformers: 4.49.0
- Pytorch: 2.4.0
- Datasets: 3.0.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-v99"", ""author"": ""silviasapora"", ""sha"": ""facb2dfd4581adb436fff2676250797e9caaa5a8"", ""last_modified"": ""2025-03-27 08:02:59+00:00"", ""created_at"": ""2025-03-27 06:31:08+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 1, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:argilla/dpo-mix-7k"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Mar27_06-30-29_9600b3b70eda/events.out.tfevents.1743057084.9600b3b70eda.2271479.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-03-27 08:02:59+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67e4f0acdad3dee127dc7818"", ""modelId"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-v99"", ""usedStorage"": 1638823334}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-silvia-basic-5e-5-05-v99&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-v99%5D(%2Fsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-v99)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-silvia-basic-5e-5-05-v910,"---
base_model: google/gemma-7b
datasets:
- argilla/dpo-mix-7k
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['argilla/dpo-mix-7k']](https://huggingface.co/datasets/['argilla/dpo-mix-7k']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-silvia-basic-5e-5-05-v910"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/gd19z9dd) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.15.2
- Transformers: 4.49.0
- Pytorch: 2.4.0
- Datasets: 3.0.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-v910"", ""author"": ""silviasapora"", ""sha"": ""1cc63de7def3eff9f9a170eccfeed9fa4c6a8e0f"", ""last_modified"": ""2025-03-27 08:03:03+00:00"", ""created_at"": ""2025-03-27 06:31:09+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 1, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:argilla/dpo-mix-7k"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Mar27_06-30-29_9600b3b70eda/events.out.tfevents.1743057085.9600b3b70eda.2271473.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-03-27 08:03:03+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67e4f0adfe1f5acc6819adf4"", ""modelId"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-v910"", ""usedStorage"": 1638823337}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-silvia-basic-5e-5-05-v910&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-v910%5D(%2Fsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-v910)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-silvia-basic-5e-5-05-v914,"---
base_model: google/gemma-7b
datasets:
- argilla/dpo-mix-7k
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['argilla/dpo-mix-7k']](https://huggingface.co/datasets/['argilla/dpo-mix-7k']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-silvia-basic-5e-5-05-v914"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/cav0pi2s) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.15.2
- Transformers: 4.49.0
- Pytorch: 2.4.0
- Datasets: 3.0.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-v914"", ""author"": ""silviasapora"", ""sha"": ""8fe94ccf7ffdc46b7f6692e6984c4e52973c4490"", ""last_modified"": ""2025-03-27 09:34:07+00:00"", ""created_at"": ""2025-03-27 08:04:21+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 1, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:argilla/dpo-mix-7k"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Mar27_08-03-41_9600b3b70eda/events.out.tfevents.1743062677.9600b3b70eda.2273746.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-03-27 09:34:07+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67e50685311bea06dc547ed7"", ""modelId"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-v914"", ""usedStorage"": 1638823336}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-silvia-basic-5e-5-05-v914&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-v914%5D(%2Fsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-v914)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-silvia-basic-5e-5-05-v915,"---
base_model: google/gemma-7b
datasets:
- argilla/dpo-mix-7k
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['argilla/dpo-mix-7k']](https://huggingface.co/datasets/['argilla/dpo-mix-7k']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-silvia-basic-5e-5-05-v915"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/q03nhd6l) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.15.2
- Transformers: 4.49.0
- Pytorch: 2.4.0
- Datasets: 3.0.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-v915"", ""author"": ""silviasapora"", ""sha"": ""0cd8baeaeb13cb5e090bb0b68b51ed0c01845b4d"", ""last_modified"": ""2025-03-27 09:33:56+00:00"", ""created_at"": ""2025-03-27 08:04:21+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 2, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:argilla/dpo-mix-7k"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Mar27_08-03-41_9600b3b70eda/events.out.tfevents.1743062678.9600b3b70eda.2273754.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-03-27 09:33:56+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67e50685dad3dee127e44115"", ""modelId"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-v915"", ""usedStorage"": 1638823337}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-silvia-basic-5e-5-05-v915&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-v915%5D(%2Fsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-v915)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-silvia-basic-5e-5-05-v912,"---
base_model: google/gemma-7b
datasets:
- argilla/dpo-mix-7k
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['argilla/dpo-mix-7k']](https://huggingface.co/datasets/['argilla/dpo-mix-7k']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-silvia-basic-5e-5-05-v912"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/neem8bhv) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.15.2
- Transformers: 4.49.0
- Pytorch: 2.4.0
- Datasets: 3.0.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-v912"", ""author"": ""silviasapora"", ""sha"": ""09ae079c2f97dc96306d8c49a9d2ed770222eeec"", ""last_modified"": ""2025-03-27 09:33:43+00:00"", ""created_at"": ""2025-03-27 08:04:22+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 1, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:argilla/dpo-mix-7k"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Mar27_08-03-42_9600b3b70eda/events.out.tfevents.1743062678.9600b3b70eda.2273751.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-03-27 09:33:43+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67e50686f7e084e54fd79d0f"", ""modelId"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-v912"", ""usedStorage"": 1638823336}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-silvia-basic-5e-5-05-v912&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-v912%5D(%2Fsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-v912)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-silvia-basic-5e-5-05-v913,"---
base_model: google/gemma-7b
datasets:
- argilla/dpo-mix-7k
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['argilla/dpo-mix-7k']](https://huggingface.co/datasets/['argilla/dpo-mix-7k']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-silvia-basic-5e-5-05-v913"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/n2cv0y0l) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.15.2
- Transformers: 4.49.0
- Pytorch: 2.4.0
- Datasets: 3.0.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-v913"", ""author"": ""silviasapora"", ""sha"": ""f5501aebad581a8eb1e51345227a88f928406205"", ""last_modified"": ""2025-03-27 09:33:47+00:00"", ""created_at"": ""2025-03-27 08:04:23+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 3, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:argilla/dpo-mix-7k"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Mar27_08-03-42_9600b3b70eda/events.out.tfevents.1743062680.9600b3b70eda.2273748.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-03-27 09:33:47+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67e50687f591b36d7e042c82"", ""modelId"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-v913"", ""usedStorage"": 1638823336}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-silvia-basic-5e-5-05-v913&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-v913%5D(%2Fsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-v913)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-silvia-basic-5e-5-05-v917,"---
base_model: google/gemma-7b
datasets:
- argilla/dpo-mix-7k
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['argilla/dpo-mix-7k']](https://huggingface.co/datasets/['argilla/dpo-mix-7k']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-silvia-basic-5e-5-05-v917"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/q54t1qjm) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.15.2
- Transformers: 4.49.0
- Pytorch: 2.4.0
- Datasets: 3.0.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-v917"", ""author"": ""silviasapora"", ""sha"": ""3132ac39f3337da217485ab97c739b23cce196a9"", ""last_modified"": ""2025-03-27 11:01:33+00:00"", ""created_at"": ""2025-03-27 09:35:03+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 1, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:argilla/dpo-mix-7k"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Mar27_09-34-23_9600b3b70eda/events.out.tfevents.1743068119.9600b3b70eda.2275760.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-03-27 11:01:33+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67e51bc7672b3d9c9cd81af1"", ""modelId"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-v917"", ""usedStorage"": 1638823337}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-silvia-basic-5e-5-05-v917&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-v917%5D(%2Fsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-v917)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-silvia-basic-5e-5-05-v916,"---
base_model: google/gemma-7b
datasets:
- argilla/dpo-mix-7k
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['argilla/dpo-mix-7k']](https://huggingface.co/datasets/['argilla/dpo-mix-7k']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-silvia-basic-5e-5-05-v916"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/caqm8v1h) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.15.2
- Transformers: 4.49.0
- Pytorch: 2.4.0
- Datasets: 3.0.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-v916"", ""author"": ""silviasapora"", ""sha"": ""d8feb036ae8a5c98f75235aff7da6d47e97cfb9d"", ""last_modified"": ""2025-03-27 11:00:48+00:00"", ""created_at"": ""2025-03-27 09:35:03+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 1, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:argilla/dpo-mix-7k"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Mar27_09-34-23_9600b3b70eda/events.out.tfevents.1743068119.9600b3b70eda.2275763.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-03-27 11:00:48+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67e51bc7dad3dee127eb41ee"", ""modelId"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-v916"", ""usedStorage"": 1638823337}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-silvia-basic-5e-5-05-v916&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-v916%5D(%2Fsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-v916)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-silvia-basic-5e-5-05-v101,"---
base_model: google/gemma-7b
datasets:
- argilla/dpo-mix-7k
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['argilla/dpo-mix-7k']](https://huggingface.co/datasets/['argilla/dpo-mix-7k']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-silvia-basic-5e-5-05-v101"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/y9fmfgtz) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.15.2
- Transformers: 4.49.0
- Pytorch: 2.4.0
- Datasets: 3.0.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-v101"", ""author"": ""silviasapora"", ""sha"": ""abbd1cd8caa433694a2557015187d9d343c11957"", ""last_modified"": ""2025-03-27 15:50:02+00:00"", ""created_at"": ""2025-03-27 14:18:43+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 1, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:argilla/dpo-mix-7k"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Mar27_14-18-03_9600b3b70eda/events.out.tfevents.1743085140.9600b3b70eda.2354366.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-03-27 15:50:02+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67e55e4397f25fb6c98400f2"", ""modelId"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-v101"", ""usedStorage"": 1638823337}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-silvia-basic-5e-5-05-v101&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-v101%5D(%2Fsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-v101)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-silvia-basic-5e-5-05-v102,"---
base_model: google/gemma-7b
datasets:
- argilla/dpo-mix-7k
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['argilla/dpo-mix-7k']](https://huggingface.co/datasets/['argilla/dpo-mix-7k']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-silvia-basic-5e-5-05-v102"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/5er9r9bx) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.15.2
- Transformers: 4.49.0
- Pytorch: 2.4.0
- Datasets: 3.0.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-v102"", ""author"": ""silviasapora"", ""sha"": ""349e32c9cb9c79e5e7fd8bfc00a7bca7cfd6c3a8"", ""last_modified"": ""2025-03-27 15:49:48+00:00"", ""created_at"": ""2025-03-27 14:18:43+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 4, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:argilla/dpo-mix-7k"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Mar27_14-18-03_9600b3b70eda/events.out.tfevents.1743085139.9600b3b70eda.2354371.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-03-27 15:49:48+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67e55e43ab98d9f7b7665c66"", ""modelId"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-v102"", ""usedStorage"": 1638823337}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-silvia-basic-5e-5-05-v102&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-v102%5D(%2Fsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-v102)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-silvia-basic-5e-5-05-v103,"---
base_model: google/gemma-7b
datasets:
- argilla/dpo-mix-7k
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['argilla/dpo-mix-7k']](https://huggingface.co/datasets/['argilla/dpo-mix-7k']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-silvia-basic-5e-5-05-v103"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/1w5v54us) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.15.2
- Transformers: 4.49.0
- Pytorch: 2.4.0
- Datasets: 3.0.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-v103"", ""author"": ""silviasapora"", ""sha"": ""e6ef70eaf36705005204da7835243878d6487251"", ""last_modified"": ""2025-03-27 15:50:29+00:00"", ""created_at"": ""2025-03-27 14:18:43+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 2, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:argilla/dpo-mix-7k"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Mar27_14-18-03_9600b3b70eda/events.out.tfevents.1743085140.9600b3b70eda.2354374.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-03-27 15:50:29+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67e55e43da477db93d1acaf2"", ""modelId"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-v103"", ""usedStorage"": 1638823337}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-silvia-basic-5e-5-05-v103&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-v103%5D(%2Fsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-v103)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-silvia-basic-5e-5-05-v100,"---
base_model: google/gemma-7b
datasets:
- argilla/dpo-mix-7k
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['argilla/dpo-mix-7k']](https://huggingface.co/datasets/['argilla/dpo-mix-7k']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-silvia-basic-5e-5-05-v100"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/km3r00g4) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.15.2
- Transformers: 4.49.0
- Pytorch: 2.4.0
- Datasets: 3.0.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-v100"", ""author"": ""silviasapora"", ""sha"": ""36f5dc57170596d92d32dc7bd3ce3301cb7cd43c"", ""last_modified"": ""2025-03-27 15:49:40+00:00"", ""created_at"": ""2025-03-27 14:18:45+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 1, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:argilla/dpo-mix-7k"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Mar27_14-18-04_9600b3b70eda/events.out.tfevents.1743085141.9600b3b70eda.2354368.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-03-27 15:49:40+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67e55e45e97a73cc74197256"", ""modelId"": ""silviasapora/gemma-7b-silvia-basic-5e-5-05-v100"", ""usedStorage"": 1638823337}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-silvia-basic-5e-5-05-v100&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-v100%5D(%2Fsilviasapora%2Fgemma-7b-silvia-basic-5e-5-05-v100)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-silvia_cpo-basic-5e-5-05-v110,"---
base_model: google/gemma-7b
datasets:
- argilla/dpo-mix-7k
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['argilla/dpo-mix-7k']](https://huggingface.co/datasets/['argilla/dpo-mix-7k']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-silvia_cpo-basic-5e-5-05-v110"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/l4qhl28y) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.15.2
- Transformers: 4.49.0
- Pytorch: 2.5.1
- Datasets: 3.1.0
- Tokenizers: 0.21.1

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-silvia_cpo-basic-5e-5-05-v110"", ""author"": ""silviasapora"", ""sha"": ""e8b2ae0b85027dee60812fe165db3d2da99daaa2"", ""last_modified"": ""2025-03-28 05:02:57+00:00"", ""created_at"": ""2025-03-28 00:52:27+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 1, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:argilla/dpo-mix-7k"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Mar28_00-49-52_414595abd3b3/events.out.tfevents.1743123148.414595abd3b3.3819761.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Mar28_02-25-59_414595abd3b3/events.out.tfevents.1743128837.414595abd3b3.3857804.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Mar28_03-14-44_414595abd3b3/events.out.tfevents.1743131763.414595abd3b3.3879695.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Mar28_03-20-48_414595abd3b3/events.out.tfevents.1743132124.414595abd3b3.3884367.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-03-28 05:02:57+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67e5f2cb8f0b013732253e62"", ""modelId"": ""silviasapora/gemma-7b-silvia_cpo-basic-5e-5-05-v110"", ""usedStorage"": 1638967084}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-silvia_cpo-basic-5e-5-05-v110&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-silvia_cpo-basic-5e-5-05-v110%5D(%2Fsilviasapora%2Fgemma-7b-silvia_cpo-basic-5e-5-05-v110)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-silvia_cpo-basic-5e-5-05-v111,"---
base_model: google/gemma-7b
datasets:
- argilla/dpo-mix-7k
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['argilla/dpo-mix-7k']](https://huggingface.co/datasets/['argilla/dpo-mix-7k']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-silvia_cpo-basic-5e-5-05-v111"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/pd0y3es9) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.15.2
- Transformers: 4.49.0
- Pytorch: 2.5.1
- Datasets: 3.1.0
- Tokenizers: 0.21.1

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-silvia_cpo-basic-5e-5-05-v111"", ""author"": ""silviasapora"", ""sha"": ""6a16bbb1b50714fafcb9349cba80b78ffb28d743"", ""last_modified"": ""2025-03-28 06:44:00+00:00"", ""created_at"": ""2025-03-28 02:17:31+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 1, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:argilla/dpo-mix-7k"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Mar28_02-16-36_414595abd3b3/events.out.tfevents.1743128273.414595abd3b3.3852531.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Mar28_03-16-35_414595abd3b3/events.out.tfevents.1743131871.414595abd3b3.3881087.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Mar28_05-03-29_414595abd3b3/events.out.tfevents.1743138284.414595abd3b3.3890672.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-03-28 06:44:00+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67e606bb94611ae7affc555b"", ""modelId"": ""silviasapora/gemma-7b-silvia_cpo-basic-5e-5-05-v111"", ""usedStorage"": 838783038}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-silvia_cpo-basic-5e-5-05-v111&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-silvia_cpo-basic-5e-5-05-v111%5D(%2Fsilviasapora%2Fgemma-7b-silvia_cpo-basic-5e-5-05-v111)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-silvia_cpo-basic-5e-5-05-v112,"---
base_model: google/gemma-7b
datasets:
- argilla/dpo-mix-7k
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['argilla/dpo-mix-7k']](https://huggingface.co/datasets/['argilla/dpo-mix-7k']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-silvia_cpo-basic-5e-5-05-v112"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/xiyrsk87) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.15.2
- Transformers: 4.49.0
- Pytorch: 2.5.1
- Datasets: 3.1.0
- Tokenizers: 0.21.1

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-silvia_cpo-basic-5e-5-05-v112"", ""author"": ""silviasapora"", ""sha"": ""128b14d051ecbe86b6412ea116f58b4a43242c9e"", ""last_modified"": ""2025-03-28 08:27:06+00:00"", ""created_at"": ""2025-03-28 03:19:15+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 1, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:argilla/dpo-mix-7k"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Mar28_03-18-20_414595abd3b3/events.out.tfevents.1743131976.414595abd3b3.3882400.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Mar28_06-44-48_414595abd3b3/events.out.tfevents.1743144367.414595abd3b3.3891260.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-03-28 08:27:06+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67e615338cc44b1744c433f4"", ""modelId"": ""silviasapora/gemma-7b-silvia_cpo-basic-5e-5-05-v112"", ""usedStorage"": 838777403}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-silvia_cpo-basic-5e-5-05-v112&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-silvia_cpo-basic-5e-5-05-v112%5D(%2Fsilviasapora%2Fgemma-7b-silvia_cpo-basic-5e-5-05-v112)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-silvia_cpo-basic-5e-5-05-v113,"---
base_model: google/gemma-7b
datasets:
- argilla/dpo-mix-7k
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['argilla/dpo-mix-7k']](https://huggingface.co/datasets/['argilla/dpo-mix-7k']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-silvia_cpo-basic-5e-5-05-v113"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/cexrxayd) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.15.2
- Transformers: 4.49.0
- Pytorch: 2.5.1
- Datasets: 3.1.0
- Tokenizers: 0.21.1

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-silvia_cpo-basic-5e-5-05-v113"", ""author"": ""silviasapora"", ""sha"": ""ccab9557e59c05af2f48af7c2d3a5ef027a05472"", ""last_modified"": ""2025-03-28 10:11:03+00:00"", ""created_at"": ""2025-03-28 08:29:08+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 1, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:argilla/dpo-mix-7k"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Mar28_08-28-11_414595abd3b3/events.out.tfevents.1743150571.414595abd3b3.3891849.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-03-28 10:11:03+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67e65dd4470f96a3028864a7"", ""modelId"": ""silviasapora/gemma-7b-silvia_cpo-basic-5e-5-05-v113"", ""usedStorage"": 838771768}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-silvia_cpo-basic-5e-5-05-v113&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-silvia_cpo-basic-5e-5-05-v113%5D(%2Fsilviasapora%2Fgemma-7b-silvia_cpo-basic-5e-5-05-v113)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-silvia_cpo-basic-5e-5-05-v114,"---
base_model: google/gemma-7b
datasets:
- argilla/dpo-mix-7k
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['argilla/dpo-mix-7k']](https://huggingface.co/datasets/['argilla/dpo-mix-7k']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-silvia_cpo-basic-5e-5-05-v114"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/ne816bk0) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.15.2
- Transformers: 4.49.0
- Pytorch: 2.5.1
- Datasets: 3.1.0
- Tokenizers: 0.21.1

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-silvia_cpo-basic-5e-5-05-v114"", ""author"": ""silviasapora"", ""sha"": ""744e17e402eeeb4795ed9a3ed3c5acc0e46203a9"", ""last_modified"": ""2025-03-28 11:55:19+00:00"", ""created_at"": ""2025-03-28 10:13:08+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 1, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:argilla/dpo-mix-7k"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Mar28_10-12-09_414595abd3b3/events.out.tfevents.1743156811.414595abd3b3.3892436.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-03-28 11:55:19+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67e67634b2bcc810d0e765d3"", ""modelId"": ""silviasapora/gemma-7b-silvia_cpo-basic-5e-5-05-v114"", ""usedStorage"": 838771768}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-silvia_cpo-basic-5e-5-05-v114&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-silvia_cpo-basic-5e-5-05-v114%5D(%2Fsilviasapora%2Fgemma-7b-silvia_cpo-basic-5e-5-05-v114)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-silvia_cpo-basic-5e-5-05-v115,"---
base_model: google/gemma-7b
datasets:
- argilla/dpo-mix-7k
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['argilla/dpo-mix-7k']](https://huggingface.co/datasets/['argilla/dpo-mix-7k']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-silvia_cpo-basic-5e-5-05-v115"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/8d9p9npm) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.15.2
- Transformers: 4.49.0
- Pytorch: 2.5.1
- Datasets: 3.1.0
- Tokenizers: 0.21.1

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-silvia_cpo-basic-5e-5-05-v115"", ""author"": ""silviasapora"", ""sha"": ""83ccff6ca07ed838d1c0ba45c0cb523000664c18"", ""last_modified"": ""2025-03-28 13:40:52+00:00"", ""created_at"": ""2025-03-28 11:57:54+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 1, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:argilla/dpo-mix-7k"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Mar28_11-56-56_414595abd3b3/events.out.tfevents.1743163096.414595abd3b3.3914026.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-03-28 13:40:52+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67e68ec266db64fc656ad83e"", ""modelId"": ""silviasapora/gemma-7b-silvia_cpo-basic-5e-5-05-v115"", ""usedStorage"": 838771768}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-silvia_cpo-basic-5e-5-05-v115&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-silvia_cpo-basic-5e-5-05-v115%5D(%2Fsilviasapora%2Fgemma-7b-silvia_cpo-basic-5e-5-05-v115)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-cpo-basic-5e-5-05-v110,"---
base_model: google/gemma-7b
datasets:
- argilla/dpo-mix-7k
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['argilla/dpo-mix-7k']](https://huggingface.co/datasets/['argilla/dpo-mix-7k']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-cpo-basic-5e-5-05-v110"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/1961c57m) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.15.2
- Transformers: 4.49.0
- Pytorch: 2.5.1
- Datasets: 3.1.0
- Tokenizers: 0.21.1

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-cpo-basic-5e-5-05-v110"", ""author"": ""silviasapora"", ""sha"": ""6a2bcbc3d5f00f907a8b57445b4df8c640ab77a1"", ""last_modified"": ""2025-03-28 15:24:04+00:00"", ""created_at"": ""2025-03-28 13:43:10+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 1, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:argilla/dpo-mix-7k"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Mar28_13-41-53_414595abd3b3/events.out.tfevents.1743169394.414595abd3b3.3962550.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-03-28 15:24:04+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67e6a76e368c3e7cdf1136e3"", ""modelId"": ""silviasapora/gemma-7b-cpo-basic-5e-5-05-v110"", ""usedStorage"": 838771677}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-cpo-basic-5e-5-05-v110&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-cpo-basic-5e-5-05-v110%5D(%2Fsilviasapora%2Fgemma-7b-cpo-basic-5e-5-05-v110)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-orpo-basic-5e-5-05-v111,"---
base_model: google/gemma-7b
datasets:
- argilla/dpo-mix-7k
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['argilla/dpo-mix-7k']](https://huggingface.co/datasets/['argilla/dpo-mix-7k']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-orpo-basic-5e-5-05-v111"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/j13noj6r) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.15.2
- Transformers: 4.49.0
- Pytorch: 2.5.1
- Datasets: 3.1.0
- Tokenizers: 0.21.1

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-orpo-basic-5e-5-05-v111"", ""author"": ""silviasapora"", ""sha"": ""be3ae1bb3fc9eedd1134fd5aea28c774043217da"", ""last_modified"": ""2025-03-28 17:05:04+00:00"", ""created_at"": ""2025-03-28 15:25:48+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 1, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:argilla/dpo-mix-7k"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Mar28_15-24-35_414595abd3b3/events.out.tfevents.1743175553.414595abd3b3.3995383.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-03-28 17:05:04+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67e6bf7c112b7d94746159d9"", ""modelId"": ""silviasapora/gemma-7b-orpo-basic-5e-5-05-v111"", ""usedStorage"": 838771745}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-orpo-basic-5e-5-05-v111&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-orpo-basic-5e-5-05-v111%5D(%2Fsilviasapora%2Fgemma-7b-orpo-basic-5e-5-05-v111)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-silvia_cpo-basic_long-5e-5-05-v120,"---
base_model: google/gemma-7b
datasets:
- argilla/ultrafeedback-binarized-preferences-cleaned
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['argilla/ultrafeedback-binarized-preferences-cleaned']](https://huggingface.co/datasets/['argilla/ultrafeedback-binarized-preferences-cleaned']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-silvia_cpo-basic_long-5e-5-05-v120"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/zif11v4b) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.15.2
- Transformers: 4.49.0
- Pytorch: 2.5.1
- Datasets: 3.1.0
- Tokenizers: 0.21.1

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-silvia_cpo-basic_long-5e-5-05-v120"", ""author"": ""silviasapora"", ""sha"": ""67195f33e3dad69842189e235b52b7c0bf117b92"", ""last_modified"": ""2025-03-29 01:20:14+00:00"", ""created_at"": ""2025-03-28 20:36:00+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 2, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:argilla/ultrafeedback-binarized-preferences-cleaned"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/ultrafeedback-binarized-preferences-cleaned\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Mar28_20-29-52_414595abd3b3/events.out.tfevents.1743194390.414595abd3b3.4122651.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Mar28_20-42-24_414595abd3b3/events.out.tfevents.1743195143.414595abd3b3.4130042.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-03-29 01:20:14+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/ultrafeedback-binarized-preferences-cleaned\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67e7083049f9ab0a66ec8eb3"", ""modelId"": ""silviasapora/gemma-7b-silvia_cpo-basic_long-5e-5-05-v120"", ""usedStorage"": 838862763}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-silvia_cpo-basic_long-5e-5-05-v120&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-silvia_cpo-basic_long-5e-5-05-v120%5D(%2Fsilviasapora%2Fgemma-7b-silvia_cpo-basic_long-5e-5-05-v120)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-cpo-basic_long-5e-5-05-v120,"---
base_model: google/gemma-7b
datasets:
- argilla/ultrafeedback-binarized-preferences-cleaned
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['argilla/ultrafeedback-binarized-preferences-cleaned']](https://huggingface.co/datasets/['argilla/ultrafeedback-binarized-preferences-cleaned']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-cpo-basic_long-5e-5-05-v120"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/n8x4azrl) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.15.2
- Transformers: 4.49.0
- Pytorch: 2.5.1
- Datasets: 3.1.0
- Tokenizers: 0.21.1

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-cpo-basic_long-5e-5-05-v120"", ""author"": ""silviasapora"", ""sha"": ""363bc7fce7c17fe90f75680fe74d23b51b3eaac4"", ""last_modified"": ""2025-03-29 01:07:52+00:00"", ""created_at"": ""2025-03-28 20:36:24+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 1, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:argilla/ultrafeedback-binarized-preferences-cleaned"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/ultrafeedback-binarized-preferences-cleaned\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Mar28_20-30-31_414595abd3b3/events.out.tfevents.1743194424.414595abd3b3.4123451.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-03-29 01:07:52+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/ultrafeedback-binarized-preferences-cleaned\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67e7084889169d39ca6492bd"", ""modelId"": ""silviasapora/gemma-7b-cpo-basic_long-5e-5-05-v120"", ""usedStorage"": 838857086}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-cpo-basic_long-5e-5-05-v120&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-cpo-basic_long-5e-5-05-v120%5D(%2Fsilviasapora%2Fgemma-7b-cpo-basic_long-5e-5-05-v120)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-silvia_cpo-basic_long-5e-5-05-v130,"---
base_model: google/gemma-7b
datasets:
- argilla/ultrafeedback-binarized-preferences-cleaned
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['argilla/ultrafeedback-binarized-preferences-cleaned']](https://huggingface.co/datasets/['argilla/ultrafeedback-binarized-preferences-cleaned']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-silvia_cpo-basic_long-5e-5-05-v130"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/sg8irbn5) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.15.2
- Transformers: 4.49.0
- Pytorch: 2.5.1
- Datasets: 3.1.0
- Tokenizers: 0.21.1

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-silvia_cpo-basic_long-5e-5-05-v130"", ""author"": ""silviasapora"", ""sha"": ""bc1e97ea0dbe7cea2c1d1c74ce715d9936265c2c"", ""last_modified"": ""2025-03-29 15:10:39+00:00"", ""created_at"": ""2025-03-29 01:41:59+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 1, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:argilla/ultrafeedback-binarized-preferences-cleaned"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/ultrafeedback-binarized-preferences-cleaned\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Mar29_01-35-52_414595abd3b3/events.out.tfevents.1743212756.414595abd3b3.4143610.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-03-29 15:10:39+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/ultrafeedback-binarized-preferences-cleaned\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67e74fe7d2970ea02cf14d61"", ""modelId"": ""silviasapora/gemma-7b-silvia_cpo-basic_long-5e-5-05-v130"", ""usedStorage"": 839120523}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-silvia_cpo-basic_long-5e-5-05-v130&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-silvia_cpo-basic_long-5e-5-05-v130%5D(%2Fsilviasapora%2Fgemma-7b-silvia_cpo-basic_long-5e-5-05-v130)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-cpo-basic_long-5e-5-05-v130,"---
base_model: google/gemma-7b
datasets:
- argilla/ultrafeedback-binarized-preferences-cleaned
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['argilla/ultrafeedback-binarized-preferences-cleaned']](https://huggingface.co/datasets/['argilla/ultrafeedback-binarized-preferences-cleaned']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-cpo-basic_long-5e-5-05-v130"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/1mu0kwve) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.15.2
- Transformers: 4.49.0
- Pytorch: 2.5.1
- Datasets: 3.1.0
- Tokenizers: 0.21.1

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-cpo-basic_long-5e-5-05-v130"", ""author"": ""silviasapora"", ""sha"": ""dcf38cadf67563b32f501bed216402e93f835256"", ""last_modified"": ""2025-03-29 15:06:48+00:00"", ""created_at"": ""2025-03-29 01:42:15+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 1, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:argilla/ultrafeedback-binarized-preferences-cleaned"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/ultrafeedback-binarized-preferences-cleaned\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Mar29_01-36-22_414595abd3b3/events.out.tfevents.1743212780.414595abd3b3.4144093.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-03-29 15:06:48+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/ultrafeedback-binarized-preferences-cleaned\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67e74ff7c655d64ca814e0ab"", ""modelId"": ""silviasapora/gemma-7b-cpo-basic_long-5e-5-05-v130"", ""usedStorage"": 839120496}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-cpo-basic_long-5e-5-05-v130&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-cpo-basic_long-5e-5-05-v130%5D(%2Fsilviasapora%2Fgemma-7b-cpo-basic_long-5e-5-05-v130)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-silvia_cpo-basic_long-5e-5-025-v130,"---
base_model: google/gemma-7b
datasets:
- argilla/ultrafeedback-binarized-preferences-cleaned
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['argilla/ultrafeedback-binarized-preferences-cleaned']](https://huggingface.co/datasets/['argilla/ultrafeedback-binarized-preferences-cleaned']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-silvia_cpo-basic_long-5e-5-025-v130"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/7ndzjfmm) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.15.2
- Transformers: 4.49.0
- Pytorch: 2.5.1
- Datasets: 3.1.0
- Tokenizers: 0.21.1

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-silvia_cpo-basic_long-5e-5-025-v130"", ""author"": ""silviasapora"", ""sha"": ""158f53eb0f883b831bd2c1fb1a6bbbef639e9a94"", ""last_modified"": ""2025-03-29 17:11:13+00:00"", ""created_at"": ""2025-03-29 02:03:57+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 1, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:argilla/ultrafeedback-binarized-preferences-cleaned"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/ultrafeedback-binarized-preferences-cleaned\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Mar29_01-56-56_df3303997c95/events.out.tfevents.1743213904.df3303997c95.179.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-03-29 17:11:13+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/ultrafeedback-binarized-preferences-cleaned\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67e7550d385025c2deabc497"", ""modelId"": ""silviasapora/gemma-7b-silvia_cpo-basic_long-5e-5-025-v130"", ""usedStorage"": 21647516145}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-silvia_cpo-basic_long-5e-5-025-v130&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-silvia_cpo-basic_long-5e-5-025-v130%5D(%2Fsilviasapora%2Fgemma-7b-silvia_cpo-basic_long-5e-5-025-v130)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-cpo-basic_long-5e-5-025-v130,"---
base_model: google/gemma-7b
datasets:
- argilla/ultrafeedback-binarized-preferences-cleaned
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['argilla/ultrafeedback-binarized-preferences-cleaned']](https://huggingface.co/datasets/['argilla/ultrafeedback-binarized-preferences-cleaned']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-cpo-basic_long-5e-5-025-v130"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/v9zyy23m) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.15.2
- Transformers: 4.49.0
- Pytorch: 2.6.0+cu126
- Datasets: 3.4.1
- Tokenizers: 0.21.1

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-cpo-basic_long-5e-5-025-v130"", ""author"": ""silviasapora"", ""sha"": ""a532343c56f099ae31a1b5111aafb2958b83c31d"", ""last_modified"": ""2025-03-29 19:00:20+00:00"", ""created_at"": ""2025-03-29 02:05:33+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 1, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:argilla/ultrafeedback-binarized-preferences-cleaned"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/ultrafeedback-binarized-preferences-cleaned\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Mar29_02-00-10_fc2764183e1d/events.out.tfevents.1743214121.fc2764183e1d.1247.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-03-29 19:00:20+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/ultrafeedback-binarized-preferences-cleaned\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67e7556de260dc6b0f356fbd"", ""modelId"": ""silviasapora/gemma-7b-cpo-basic_long-5e-5-025-v130"", ""usedStorage"": 43249228728}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-cpo-basic_long-5e-5-025-v130&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-cpo-basic_long-5e-5-025-v130%5D(%2Fsilviasapora%2Fgemma-7b-cpo-basic_long-5e-5-025-v130)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-sft-basic-5e-5-00-v130,"---
base_model: google/gemma-7b
datasets:
- argilla/dpo-mix-7k
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['argilla/dpo-mix-7k']](https://huggingface.co/datasets/['argilla/dpo-mix-7k']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-sft-basic-5e-5-00-v130"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/molx1s8g) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.15.2
- Transformers: 4.49.0
- Pytorch: 2.5.1
- Datasets: 3.1.0
- Tokenizers: 0.21.1

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-sft-basic-5e-5-00-v130"", ""author"": ""silviasapora"", ""sha"": ""0bf65a05314bcb880547cec12cba2a4c7407d387"", ""last_modified"": ""2025-03-29 18:19:37+00:00"", ""created_at"": ""2025-03-29 17:02:04+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 1, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:argilla/dpo-mix-7k"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Mar29_17-01-08_414595abd3b3/events.out.tfevents.1743267748.414595abd3b3.82953.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Mar29_17-04-41_414595abd3b3/events.out.tfevents.1743267958.414595abd3b3.85062.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Mar29_17-08-16_414595abd3b3/events.out.tfevents.1743268172.414595abd3b3.87545.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-03-29 18:19:37+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67e8278cb012e2a5baf39161"", ""modelId"": ""silviasapora/gemma-7b-sft-basic-5e-5-00-v130"", ""usedStorage"": 2439062095}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-sft-basic-5e-5-00-v130&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-sft-basic-5e-5-00-v130%5D(%2Fsilviasapora%2Fgemma-7b-sft-basic-5e-5-00-v130)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-silvia_cpo-basic_long-5e-5-025-v131,"---
base_model: google/gemma-7b
datasets:
- argilla/ultrafeedback-binarized-preferences-cleaned
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['argilla/ultrafeedback-binarized-preferences-cleaned']](https://huggingface.co/datasets/['argilla/ultrafeedback-binarized-preferences-cleaned']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-silvia_cpo-basic_long-5e-5-025-v131"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/b4qfv9l8) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.15.2
- Transformers: 4.49.0
- Pytorch: 2.5.1
- Datasets: 3.1.0
- Tokenizers: 0.21.1

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-silvia_cpo-basic_long-5e-5-025-v131"", ""author"": ""silviasapora"", ""sha"": ""6bcb7da56e6b01c4aa18b42db44f7881d66dce32"", ""last_modified"": ""2025-03-30 08:44:15+00:00"", ""created_at"": ""2025-03-29 17:16:57+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 1, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:argilla/ultrafeedback-binarized-preferences-cleaned"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/ultrafeedback-binarized-preferences-cleaned\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Mar29_17-11-58_df3303997c95/events.out.tfevents.1743268812.df3303997c95.828.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Mar29_17-30-25_df3303997c95/events.out.tfevents.1743269923.df3303997c95.1588.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-03-30 08:44:15+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/ultrafeedback-binarized-preferences-cleaned\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67e82b095060844ab59b09ed"", ""modelId"": ""silviasapora/gemma-7b-silvia_cpo-basic_long-5e-5-025-v131"", ""usedStorage"": 21647523983}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-silvia_cpo-basic_long-5e-5-025-v131&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-silvia_cpo-basic_long-5e-5-025-v131%5D(%2Fsilviasapora%2Fgemma-7b-silvia_cpo-basic_long-5e-5-025-v131)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-silvia_cpo-basic_capibara-5e-5-01-v131,"---
base_model: google/gemma-7b
datasets:
- argilla/distilabel-capybara-dpo-7k-binarized
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['argilla/distilabel-capybara-dpo-7k-binarized']](https://huggingface.co/datasets/['argilla/distilabel-capybara-dpo-7k-binarized']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-silvia_cpo-basic_capibara-5e-5-01-v131"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/57dnfbi1) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.15.2
- Transformers: 4.49.0
- Pytorch: 2.5.1
- Datasets: 3.1.0
- Tokenizers: 0.21.1

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-silvia_cpo-basic_capibara-5e-5-01-v131"", ""author"": ""silviasapora"", ""sha"": ""8aa880740abfbae9897ce0a686a987ba1fdd3a58"", ""last_modified"": ""2025-03-29 22:03:41+00:00"", ""created_at"": ""2025-03-29 20:47:51+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 1, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:argilla/distilabel-capybara-dpo-7k-binarized"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/distilabel-capybara-dpo-7k-binarized\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Mar29_20-46-52_414595abd3b3/events.out.tfevents.1743281291.414595abd3b3.217748.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-03-29 22:03:41+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/distilabel-capybara-dpo-7k-binarized\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67e85c7719c696060cb4614c"", ""modelId"": ""silviasapora/gemma-7b-silvia_cpo-basic_capibara-5e-5-01-v131"", ""usedStorage"": 1638891477}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-silvia_cpo-basic_capibara-5e-5-01-v131&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-silvia_cpo-basic_capibara-5e-5-01-v131%5D(%2Fsilviasapora%2Fgemma-7b-silvia_cpo-basic_capibara-5e-5-01-v131)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-silvia_cpo-basic_capibara-5e-5-01-v132,"---
base_model: google/gemma-7b
datasets:
- argilla/distilabel-capybara-dpo-7k-binarized
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['argilla/distilabel-capybara-dpo-7k-binarized']](https://huggingface.co/datasets/['argilla/distilabel-capybara-dpo-7k-binarized']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-silvia_cpo-basic_capibara-5e-5-01-v132"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/mej0m8zp) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.15.2
- Transformers: 4.49.0
- Pytorch: 2.5.1
- Datasets: 3.1.0
- Tokenizers: 0.21.1

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-silvia_cpo-basic_capibara-5e-5-01-v132"", ""author"": ""silviasapora"", ""sha"": ""65dad3f951de676ef89681edd9cd08599eebb805"", ""last_modified"": ""2025-03-29 23:22:21+00:00"", ""created_at"": ""2025-03-29 22:05:12+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 1, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:argilla/distilabel-capybara-dpo-7k-binarized"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/distilabel-capybara-dpo-7k-binarized\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Mar29_22-04-12_414595abd3b3/events.out.tfevents.1743285931.414595abd3b3.226494.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-03-29 23:22:21+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/distilabel-capybara-dpo-7k-binarized\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67e86e985060844ab5aae33a"", ""modelId"": ""silviasapora/gemma-7b-silvia_cpo-basic_capibara-5e-5-01-v132"", ""usedStorage"": 1638891477}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-silvia_cpo-basic_capibara-5e-5-01-v132&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-silvia_cpo-basic_capibara-5e-5-01-v132%5D(%2Fsilviasapora%2Fgemma-7b-silvia_cpo-basic_capibara-5e-5-01-v132)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-silvia_cpo-basic_capibara-5e-5-025-v133,"---
base_model: google/gemma-7b
datasets:
- argilla/distilabel-capybara-dpo-7k-binarized
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['argilla/distilabel-capybara-dpo-7k-binarized']](https://huggingface.co/datasets/['argilla/distilabel-capybara-dpo-7k-binarized']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-silvia_cpo-basic_capibara-5e-5-025-v133"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/vwf1jef0) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.15.2
- Transformers: 4.49.0
- Pytorch: 2.5.1
- Datasets: 3.1.0
- Tokenizers: 0.21.1

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-silvia_cpo-basic_capibara-5e-5-025-v133"", ""author"": ""silviasapora"", ""sha"": ""71637fa251c9b32edf5d7cc91f84ac710811b76c"", ""last_modified"": ""2025-03-30 00:40:10+00:00"", ""created_at"": ""2025-03-29 23:23:52+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 1, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:argilla/distilabel-capybara-dpo-7k-binarized"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/distilabel-capybara-dpo-7k-binarized\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Mar29_23-22-52_414595abd3b3/events.out.tfevents.1743290652.414595abd3b3.227071.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-03-30 00:40:10+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/distilabel-capybara-dpo-7k-binarized\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67e88108c06ef4cda3939639"", ""modelId"": ""silviasapora/gemma-7b-silvia_cpo-basic_capibara-5e-5-025-v133"", ""usedStorage"": 1638891485}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-silvia_cpo-basic_capibara-5e-5-025-v133&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-silvia_cpo-basic_capibara-5e-5-025-v133%5D(%2Fsilviasapora%2Fgemma-7b-silvia_cpo-basic_capibara-5e-5-025-v133)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-cpo-basic_capibara-5e-5-01-v131,"---
base_model: google/gemma-7b
datasets:
- argilla/distilabel-capybara-dpo-7k-binarized
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['argilla/distilabel-capybara-dpo-7k-binarized']](https://huggingface.co/datasets/['argilla/distilabel-capybara-dpo-7k-binarized']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-cpo-basic_capibara-5e-5-01-v131"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/2o2zed7q) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.15.2
- Transformers: 4.49.0
- Pytorch: 2.6.0+cu126
- Datasets: 3.4.1
- Tokenizers: 0.21.1

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-cpo-basic_capibara-5e-5-01-v131"", ""author"": ""silviasapora"", ""sha"": ""e6f4046f5f0421961e0a8f7084a913277e435711"", ""last_modified"": ""2025-03-30 01:43:02+00:00"", ""created_at"": ""2025-03-30 00:10:01+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 1, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:argilla/distilabel-capybara-dpo-7k-binarized"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/distilabel-capybara-dpo-7k-binarized\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Mar30_00-09-06_fc2764183e1d/events.out.tfevents.1743293419.fc2764183e1d.12692.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-03-30 01:43:02+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/distilabel-capybara-dpo-7k-binarized\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67e88bd93bae8267eeede022"", ""modelId"": ""silviasapora/gemma-7b-cpo-basic_capibara-5e-5-01-v131"", ""usedStorage"": 3239018333}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-cpo-basic_capibara-5e-5-01-v131&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-cpo-basic_capibara-5e-5-01-v131%5D(%2Fsilviasapora%2Fgemma-7b-cpo-basic_capibara-5e-5-01-v131)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-sft-dpo-basic-5e-7-001-v131,"---
base_model: google/gemma-7b
library_name: transformers
model_name: gemma-7b-sft-dpo-basic-5e-7-001-v131
tags:
- generated_from_trainer
- trl
- dpo
licence: license
---

# Model Card for gemma-7b-sft-dpo-basic-5e-7-001-v131

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b).
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-sft-dpo-basic-5e-7-001-v131"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/pvlzaphr) 


This model was trained with DPO, a method introduced in [Direct Preference Optimization: Your Language Model is Secretly a Reward Model](https://huggingface.co/papers/2305.18290).

### Framework versions

- TRL: 0.15.2
- Transformers: 4.49.0
- Pytorch: 2.6.0+cu126
- Datasets: 3.4.1
- Tokenizers: 0.21.1

## Citations

Cite DPO as:

```bibtex
@inproceedings{rafailov2023direct,
    title        = {{Direct Preference Optimization: Your Language Model is Secretly a Reward Model}},
    author       = {Rafael Rafailov and Archit Sharma and Eric Mitchell and Christopher D. Manning and Stefano Ermon and Chelsea Finn},
    year         = 2023,
    booktitle    = {Advances in Neural Information Processing Systems 36: Annual Conference on Neural Information Processing Systems 2023, NeurIPS 2023, New Orleans, LA, USA, December 10 - 16, 2023},
    url          = {http://papers.nips.cc/paper_files/paper/2023/hash/a85b405ed65c6477a4fe8302b5e06ce7-Abstract-Conference.html},
    editor       = {Alice Oh and Tristan Naumann and Amir Globerson and Kate Saenko and Moritz Hardt and Sergey Levine},
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-sft-dpo-basic-5e-7-001-v131"", ""author"": ""silviasapora"", ""sha"": ""7951ccd2b1dffbb2531934085f9ebda0b1e625e5"", ""last_modified"": ""2025-03-30 01:23:40+00:00"", ""created_at"": ""2025-03-30 00:21:08+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""generated_from_trainer"", ""trl"", ""dpo"", ""arxiv:2305.18290"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": null, ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\nlibrary_name: transformers\nmodel_name: gemma-7b-sft-dpo-basic-5e-7-001-v131\ntags:\n- generated_from_trainer\n- trl\n- dpo\nlicence: license"", ""widget_data"": null, ""model_index"": null, ""config"": {""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModel"", ""custom_class"": null, ""pipeline_tag"": null, ""processor"": null}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Mar30_00-18-58_fc2764183e1d/events.out.tfevents.1743294095.fc2764183e1d.13582.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-03-30 01:23:40+00:00"", ""cardData"": ""base_model: google/gemma-7b\nlibrary_name: transformers\nmodel_name: gemma-7b-sft-dpo-basic-5e-7-001-v131\ntags:\n- generated_from_trainer\n- trl\n- dpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModel"", ""custom_class"": null, ""pipeline_tag"": null, ""processor"": null}, ""_id"": ""67e88e743745a0c5dde0b90d"", ""modelId"": ""silviasapora/gemma-7b-sft-dpo-basic-5e-7-001-v131"", ""usedStorage"": 1638801370}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-sft-dpo-basic-5e-7-001-v131&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-sft-dpo-basic-5e-7-001-v131%5D(%2Fsilviasapora%2Fgemma-7b-sft-dpo-basic-5e-7-001-v131)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-silvia_cpo-basic_capibara-5e-5-025-v134,"---
base_model: google/gemma-7b
datasets:
- argilla/distilabel-capybara-dpo-7k-binarized
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['argilla/distilabel-capybara-dpo-7k-binarized']](https://huggingface.co/datasets/['argilla/distilabel-capybara-dpo-7k-binarized']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-silvia_cpo-basic_capibara-5e-5-025-v134"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/269cqzww) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.15.2
- Transformers: 4.49.0
- Pytorch: 2.5.1
- Datasets: 3.1.0
- Tokenizers: 0.21.1

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-silvia_cpo-basic_capibara-5e-5-025-v134"", ""author"": ""silviasapora"", ""sha"": ""43e21828b32a9e42fd0619c93d3fc05697b717f6"", ""last_modified"": ""2025-03-30 01:57:33+00:00"", ""created_at"": ""2025-03-30 00:41:44+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 1, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:argilla/distilabel-capybara-dpo-7k-binarized"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/distilabel-capybara-dpo-7k-binarized\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Mar30_00-40-44_414595abd3b3/events.out.tfevents.1743295321.414595abd3b3.289299.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-03-30 01:57:33+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/distilabel-capybara-dpo-7k-binarized\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67e8934854cc82de7b69f506"", ""modelId"": ""silviasapora/gemma-7b-silvia_cpo-basic_capibara-5e-5-025-v134"", ""usedStorage"": 1638891485}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-silvia_cpo-basic_capibara-5e-5-025-v134&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-silvia_cpo-basic_capibara-5e-5-025-v134%5D(%2Fsilviasapora%2Fgemma-7b-silvia_cpo-basic_capibara-5e-5-025-v134)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-sft-dpo-basic-5e-7-005-v132,"---
base_model: google/gemma-7b
library_name: transformers
model_name: gemma-7b-sft-dpo-basic-5e-7-005-v132
tags:
- generated_from_trainer
- trl
- dpo
licence: license
---

# Model Card for gemma-7b-sft-dpo-basic-5e-7-005-v132

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b).
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-sft-dpo-basic-5e-7-005-v132"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/83bbps47) 


This model was trained with DPO, a method introduced in [Direct Preference Optimization: Your Language Model is Secretly a Reward Model](https://huggingface.co/papers/2305.18290).

### Framework versions

- TRL: 0.15.2
- Transformers: 4.49.0
- Pytorch: 2.6.0+cu126
- Datasets: 3.4.1
- Tokenizers: 0.21.1

## Citations

Cite DPO as:

```bibtex
@inproceedings{rafailov2023direct,
    title        = {{Direct Preference Optimization: Your Language Model is Secretly a Reward Model}},
    author       = {Rafael Rafailov and Archit Sharma and Eric Mitchell and Christopher D. Manning and Stefano Ermon and Chelsea Finn},
    year         = 2023,
    booktitle    = {Advances in Neural Information Processing Systems 36: Annual Conference on Neural Information Processing Systems 2023, NeurIPS 2023, New Orleans, LA, USA, December 10 - 16, 2023},
    url          = {http://papers.nips.cc/paper_files/paper/2023/hash/a85b405ed65c6477a4fe8302b5e06ce7-Abstract-Conference.html},
    editor       = {Alice Oh and Tristan Naumann and Amir Globerson and Kate Saenko and Moritz Hardt and Sergey Levine},
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-sft-dpo-basic-5e-7-005-v132"", ""author"": ""silviasapora"", ""sha"": ""36118e1f8066f53b2c960bcbc829114d9d1b88a4"", ""last_modified"": ""2025-03-30 02:28:18+00:00"", ""created_at"": ""2025-03-30 01:26:28+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""generated_from_trainer"", ""trl"", ""dpo"", ""arxiv:2305.18290"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": null, ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\nlibrary_name: transformers\nmodel_name: gemma-7b-sft-dpo-basic-5e-7-005-v132\ntags:\n- generated_from_trainer\n- trl\n- dpo\nlicence: license"", ""widget_data"": null, ""model_index"": null, ""config"": {""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModel"", ""custom_class"": null, ""pipeline_tag"": null, ""processor"": null}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Mar30_02-24-15_fc2764183e1d/events.out.tfevents.1743298002.fc2764183e1d.13900.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-03-30 02:28:18+00:00"", ""cardData"": ""base_model: google/gemma-7b\nlibrary_name: transformers\nmodel_name: gemma-7b-sft-dpo-basic-5e-7-005-v132\ntags:\n- generated_from_trainer\n- trl\n- dpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModel"", ""custom_class"": null, ""pipeline_tag"": null, ""processor"": null}, ""_id"": ""67e89dc43aaec19343bb4844"", ""modelId"": ""silviasapora/gemma-7b-sft-dpo-basic-5e-7-005-v132"", ""usedStorage"": 1638801370}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-sft-dpo-basic-5e-7-005-v132&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-sft-dpo-basic-5e-7-005-v132%5D(%2Fsilviasapora%2Fgemma-7b-sft-dpo-basic-5e-7-005-v132)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-cpo-basic_capibara-5e-5-025-v132,"---
base_model: google/gemma-7b
datasets:
- argilla/distilabel-capybara-dpo-7k-binarized
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['argilla/distilabel-capybara-dpo-7k-binarized']](https://huggingface.co/datasets/['argilla/distilabel-capybara-dpo-7k-binarized']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-cpo-basic_capibara-5e-5-025-v132"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/wwqbbebp) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.15.2
- Transformers: 4.49.0
- Pytorch: 2.6.0+cu126
- Datasets: 3.4.1
- Tokenizers: 0.21.1

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-cpo-basic_capibara-5e-5-025-v132"", ""author"": ""silviasapora"", ""sha"": ""02576571aabeab374c32434989cbe2e5b02156eb"", ""last_modified"": ""2025-03-30 06:36:45+00:00"", ""created_at"": ""2025-03-30 01:44:42+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 2, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:argilla/distilabel-capybara-dpo-7k-binarized"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/distilabel-capybara-dpo-7k-binarized\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Mar30_02-43-44_fc2764183e1d/events.out.tfevents.1743299102.fc2764183e1d.14219.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-03-30 06:36:45+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/distilabel-capybara-dpo-7k-binarized\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67e8a20a4579bd815899dae5"", ""modelId"": ""silviasapora/gemma-7b-cpo-basic_capibara-5e-5-025-v132"", ""usedStorage"": 12840622655}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-cpo-basic_capibara-5e-5-025-v132&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-cpo-basic_capibara-5e-5-025-v132%5D(%2Fsilviasapora%2Fgemma-7b-cpo-basic_capibara-5e-5-025-v132)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-orpo-basic_capibara-5e-5-025-v140,"---
base_model: google/gemma-7b
datasets:
- argilla/distilabel-capybara-dpo-7k-binarized
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['argilla/distilabel-capybara-dpo-7k-binarized']](https://huggingface.co/datasets/['argilla/distilabel-capybara-dpo-7k-binarized']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-orpo-basic_capibara-5e-5-025-v140"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/uf48hszj) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.16.0
- Transformers: 4.50.3
- Pytorch: 2.5.1
- Datasets: 3.3.2
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-orpo-basic_capibara-5e-5-025-v140"", ""author"": ""silviasapora"", ""sha"": ""374dd9cccf887934e8d599c26c27d2e79afc2aee"", ""last_modified"": ""2025-03-30 23:00:58+00:00"", ""created_at"": ""2025-03-30 21:52:38+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 1, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:argilla/distilabel-capybara-dpo-7k-binarized"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/distilabel-capybara-dpo-7k-binarized\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Mar30_21-50-37_425eae2e39a5/events.out.tfevents.1743371560.425eae2e39a5.8222.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Mar30_22-06-46_425eae2e39a5/events.out.tfevents.1743372478.425eae2e39a5.17133.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-03-30 23:00:58+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/distilabel-capybara-dpo-7k-binarized\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67e9bd26b8fad374d0898111"", ""modelId"": ""silviasapora/gemma-7b-orpo-basic_capibara-5e-5-025-v140"", ""usedStorage"": 3239028305}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-orpo-basic_capibara-5e-5-025-v140&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-orpo-basic_capibara-5e-5-025-v140%5D(%2Fsilviasapora%2Fgemma-7b-orpo-basic_capibara-5e-5-025-v140)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-silvia_cpo-basic_capibara-5e-5-025-v140,"---
base_model: google/gemma-7b
datasets:
- argilla/distilabel-capybara-dpo-7k-binarized
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['argilla/distilabel-capybara-dpo-7k-binarized']](https://huggingface.co/datasets/['argilla/distilabel-capybara-dpo-7k-binarized']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-silvia_cpo-basic_capibara-5e-5-025-v140"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/i8u805jy) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.16.0
- Transformers: 4.50.3
- Pytorch: 2.5.1
- Datasets: 3.3.2
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-silvia_cpo-basic_capibara-5e-5-025-v140"", ""author"": ""silviasapora"", ""sha"": ""076e93ba66271ac178173dbc2b7daa5f13588ccc"", ""last_modified"": ""2025-03-30 23:55:28+00:00"", ""created_at"": ""2025-03-30 23:02:12+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 3, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:argilla/distilabel-capybara-dpo-7k-binarized"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/distilabel-capybara-dpo-7k-binarized\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Mar30_23-01-23_425eae2e39a5/events.out.tfevents.1743375745.425eae2e39a5.46398.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-03-30 23:55:28+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/distilabel-capybara-dpo-7k-binarized\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67e9cd745aeb74b76dc6b5fb"", ""modelId"": ""silviasapora/gemma-7b-silvia_cpo-basic_capibara-5e-5-025-v140"", ""usedStorage"": 3239018339}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-silvia_cpo-basic_capibara-5e-5-025-v140&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-silvia_cpo-basic_capibara-5e-5-025-v140%5D(%2Fsilviasapora%2Fgemma-7b-silvia_cpo-basic_capibara-5e-5-025-v140)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-silvia_cpo-basic_capibara-5e-5-025-v141,"---
base_model: google/gemma-7b
datasets:
- argilla/distilabel-capybara-dpo-7k-binarized
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['argilla/distilabel-capybara-dpo-7k-binarized']](https://huggingface.co/datasets/['argilla/distilabel-capybara-dpo-7k-binarized']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-silvia_cpo-basic_capibara-5e-5-025-v141"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/dxv3pmn7) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.16.0
- Transformers: 4.50.3
- Pytorch: 2.5.1
- Datasets: 3.3.2
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-silvia_cpo-basic_capibara-5e-5-025-v141"", ""author"": ""silviasapora"", ""sha"": ""687dda112e7bab27f719e3425f2e7203f1c880b6"", ""last_modified"": ""2025-03-31 01:03:57+00:00"", ""created_at"": ""2025-03-31 00:10:32+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 2, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:argilla/distilabel-capybara-dpo-7k-binarized"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/distilabel-capybara-dpo-7k-binarized\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Mar31_00-09-45_425eae2e39a5/events.out.tfevents.1743379846.425eae2e39a5.82792.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-03-31 01:03:57+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/distilabel-capybara-dpo-7k-binarized\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67e9dd78715b22bc183b3431"", ""modelId"": ""silviasapora/gemma-7b-silvia_cpo-basic_capibara-5e-5-025-v141"", ""usedStorage"": 3239018339}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-silvia_cpo-basic_capibara-5e-5-025-v141&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-silvia_cpo-basic_capibara-5e-5-025-v141%5D(%2Fsilviasapora%2Fgemma-7b-silvia_cpo-basic_capibara-5e-5-025-v141)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-silvia_cpo-basic_capibara-5e-5-025-v142,"---
base_model: google/gemma-7b
datasets:
- argilla/distilabel-capybara-dpo-7k-binarized
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['argilla/distilabel-capybara-dpo-7k-binarized']](https://huggingface.co/datasets/['argilla/distilabel-capybara-dpo-7k-binarized']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-silvia_cpo-basic_capibara-5e-5-025-v142"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/uw5dlyvl) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.16.0
- Transformers: 4.50.3
- Pytorch: 2.5.1
- Datasets: 3.3.2
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-silvia_cpo-basic_capibara-5e-5-025-v142"", ""author"": ""silviasapora"", ""sha"": ""fc7f1e8979c3d07c082471c93edffdb7b1cde0ff"", ""last_modified"": ""2025-03-31 01:58:30+00:00"", ""created_at"": ""2025-03-31 01:05:07+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 2, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:argilla/distilabel-capybara-dpo-7k-binarized"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/distilabel-capybara-dpo-7k-binarized\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Mar31_01-04-20_425eae2e39a5/events.out.tfevents.1743383124.425eae2e39a5.111887.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-03-31 01:58:30+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/distilabel-capybara-dpo-7k-binarized\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67e9ea43c655d64ca8b1f62c"", ""modelId"": ""silviasapora/gemma-7b-silvia_cpo-basic_capibara-5e-5-025-v142"", ""usedStorage"": 3239018339}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-silvia_cpo-basic_capibara-5e-5-025-v142&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-silvia_cpo-basic_capibara-5e-5-025-v142%5D(%2Fsilviasapora%2Fgemma-7b-silvia_cpo-basic_capibara-5e-5-025-v142)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-cpo-basic_capibara-5e-5-025-v140,"---
base_model: google/gemma-7b
datasets:
- argilla/distilabel-capybara-dpo-7k-binarized
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['argilla/distilabel-capybara-dpo-7k-binarized']](https://huggingface.co/datasets/['argilla/distilabel-capybara-dpo-7k-binarized']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-cpo-basic_capibara-5e-5-025-v140"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/yp3j3t49) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.16.0
- Transformers: 4.50.3
- Pytorch: 2.5.1
- Datasets: 3.3.2
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-cpo-basic_capibara-5e-5-025-v140"", ""author"": ""silviasapora"", ""sha"": ""9b0bcf72aa42d610b9cbedffa0deba3aa5c44138"", ""last_modified"": ""2025-03-31 04:21:47+00:00"", ""created_at"": ""2025-03-31 03:28:24+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 2, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:argilla/distilabel-capybara-dpo-7k-binarized"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/distilabel-capybara-dpo-7k-binarized\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Mar31_03-27-35_425eae2e39a5/events.out.tfevents.1743391719.425eae2e39a5.197281.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-03-31 04:21:47+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/distilabel-capybara-dpo-7k-binarized\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67ea0bd81754667f8e6a8516"", ""modelId"": ""silviasapora/gemma-7b-cpo-basic_capibara-5e-5-025-v140"", ""usedStorage"": 3239018283}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-cpo-basic_capibara-5e-5-025-v140&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-cpo-basic_capibara-5e-5-025-v140%5D(%2Fsilviasapora%2Fgemma-7b-cpo-basic_capibara-5e-5-025-v140)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-orpo-basic-5e-5-05-v140,"---
base_model: google/gemma-7b
datasets:
- argilla/dpo-mix-7k
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['argilla/dpo-mix-7k']](https://huggingface.co/datasets/['argilla/dpo-mix-7k']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-orpo-basic-5e-5-05-v140"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/r51uz5sz) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.16.0
- Transformers: 4.50.3
- Pytorch: 2.5.1
- Datasets: 3.3.2
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-orpo-basic-5e-5-05-v140"", ""author"": ""silviasapora"", ""sha"": ""6d0b763164891dc6fd2d781a9687b71cf910f376"", ""last_modified"": ""2025-03-31 05:36:51+00:00"", ""created_at"": ""2025-03-31 04:28:31+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 3, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:argilla/dpo-mix-7k"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Mar31_04-27-37_425eae2e39a5/events.out.tfevents.1743395328.425eae2e39a5.230150.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-03-31 05:36:51+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67ea19eff5380cbbea8522af"", ""modelId"": ""silviasapora/gemma-7b-orpo-basic-5e-5-05-v140"", ""usedStorage"": 6439482151}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-orpo-basic-5e-5-05-v140&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-orpo-basic-5e-5-05-v140%5D(%2Fsilviasapora%2Fgemma-7b-orpo-basic-5e-5-05-v140)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-slic-basic-5e-5-05-v140,"---
base_model: google/gemma-7b
datasets:
- argilla/dpo-mix-7k
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['argilla/dpo-mix-7k']](https://huggingface.co/datasets/['argilla/dpo-mix-7k']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-slic-basic-5e-5-05-v140"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/f7c2m4yo) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.16.0
- Transformers: 4.50.3
- Pytorch: 2.5.1
- Datasets: 3.3.2
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-slic-basic-5e-5-05-v140"", ""author"": ""silviasapora"", ""sha"": ""82469fa1317b6e7676dad3e0bf57add20d1f9ed4"", ""last_modified"": ""2025-03-31 06:49:26+00:00"", ""created_at"": ""2025-03-31 05:41:42+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 2, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:argilla/dpo-mix-7k"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Mar31_05-40-58_425eae2e39a5/events.out.tfevents.1743399722.425eae2e39a5.269315.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-03-31 06:49:26+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/dpo-mix-7k\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67ea2b166887b70da579a44f"", ""modelId"": ""silviasapora/gemma-7b-slic-basic-5e-5-05-v140"", ""usedStorage"": 6439482151}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-slic-basic-5e-5-05-v140&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-slic-basic-5e-5-05-v140%5D(%2Fsilviasapora%2Fgemma-7b-slic-basic-5e-5-05-v140)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-slic-basic_capibara-5e-5-025-v140,"---
base_model: google/gemma-7b
datasets:
- argilla/distilabel-capybara-dpo-7k-binarized
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['argilla/distilabel-capybara-dpo-7k-binarized']](https://huggingface.co/datasets/['argilla/distilabel-capybara-dpo-7k-binarized']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-slic-basic_capibara-5e-5-025-v140"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/gwjmw0nw) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.16.0
- Transformers: 4.50.3
- Pytorch: 2.5.1
- Datasets: 3.3.2
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-slic-basic_capibara-5e-5-025-v140"", ""author"": ""silviasapora"", ""sha"": ""4233afd78f5a961a9a3bf78df1d15d48491c941a"", ""last_modified"": ""2025-03-31 07:43:16+00:00"", ""created_at"": ""2025-03-31 06:50:43+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 2, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:argilla/distilabel-capybara-dpo-7k-binarized"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/distilabel-capybara-dpo-7k-binarized\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Mar31_06-49-45_425eae2e39a5/events.out.tfevents.1743403859.425eae2e39a5.283549.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-03-31 07:43:16+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/distilabel-capybara-dpo-7k-binarized\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67ea3b43b3a87cc3bc7af217"", ""modelId"": ""silviasapora/gemma-7b-slic-basic_capibara-5e-5-025-v140"", ""usedStorage"": 3239018291}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-slic-basic_capibara-5e-5-025-v140&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-slic-basic_capibara-5e-5-025-v140%5D(%2Fsilviasapora%2Fgemma-7b-slic-basic_capibara-5e-5-025-v140)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-silvia_cpo-basic_capibara-5e-5-025-v150,"---
base_model: google/gemma-7b
datasets:
- argilla/distilabel-capybara-dpo-7k-binarized
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['argilla/distilabel-capybara-dpo-7k-binarized']](https://huggingface.co/datasets/['argilla/distilabel-capybara-dpo-7k-binarized']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-silvia_cpo-basic_capibara-5e-5-025-v150"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/wyrt8myx) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.16.0
- Transformers: 4.50.3
- Pytorch: 2.5.1
- Datasets: 3.3.2
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-silvia_cpo-basic_capibara-5e-5-025-v150"", ""author"": ""silviasapora"", ""sha"": ""fb55e5f2fc405952a74813596c2134c9faeead0a"", ""last_modified"": ""2025-03-31 12:47:20+00:00"", ""created_at"": ""2025-03-31 11:13:14+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 1, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:argilla/distilabel-capybara-dpo-7k-binarized"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/distilabel-capybara-dpo-7k-binarized\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Mar31_11-12-09_425eae2e39a5/events.out.tfevents.1743419606.425eae2e39a5.326851.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-03-31 12:47:20+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/distilabel-capybara-dpo-7k-binarized\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67ea78ca5efb3c1d5ec3eec0"", ""modelId"": ""silviasapora/gemma-7b-silvia_cpo-basic_capibara-5e-5-025-v150"", ""usedStorage"": 3239018339}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-silvia_cpo-basic_capibara-5e-5-025-v150&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-silvia_cpo-basic_capibara-5e-5-025-v150%5D(%2Fsilviasapora%2Fgemma-7b-silvia_cpo-basic_capibara-5e-5-025-v150)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-silvia_cpo-basic_capibara-5e-5-025-v151,"---
base_model: google/gemma-7b
datasets:
- argilla/distilabel-capybara-dpo-7k-binarized
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['argilla/distilabel-capybara-dpo-7k-binarized']](https://huggingface.co/datasets/['argilla/distilabel-capybara-dpo-7k-binarized']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-silvia_cpo-basic_capibara-5e-5-025-v151"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/mw5gj0gs) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.16.0
- Transformers: 4.50.3
- Pytorch: 2.5.1
- Datasets: 3.3.2
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-silvia_cpo-basic_capibara-5e-5-025-v151"", ""author"": ""silviasapora"", ""sha"": ""a2bcb6cc08640d6fba6e52e2a0743de0ae2e5377"", ""last_modified"": ""2025-03-31 14:22:48+00:00"", ""created_at"": ""2025-03-31 12:48:30+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 1, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:argilla/distilabel-capybara-dpo-7k-binarized"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/distilabel-capybara-dpo-7k-binarized\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Mar31_12-47-40_425eae2e39a5/events.out.tfevents.1743425322.425eae2e39a5.330594.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-03-31 14:22:48+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/distilabel-capybara-dpo-7k-binarized\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67ea8f1eca885da6d566d3fe"", ""modelId"": ""silviasapora/gemma-7b-silvia_cpo-basic_capibara-5e-5-025-v151"", ""usedStorage"": 3239018339}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-silvia_cpo-basic_capibara-5e-5-025-v151&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-silvia_cpo-basic_capibara-5e-5-025-v151%5D(%2Fsilviasapora%2Fgemma-7b-silvia_cpo-basic_capibara-5e-5-025-v151)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-sft-basic_capibara-5e-5-000-v131,N/A,N/A,1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-sft-basic_capibara-5e-5-000-v131&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-sft-basic_capibara-5e-5-000-v131%5D(%2Fsilviasapora%2Fgemma-7b-sft-basic_capibara-5e-5-000-v131)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
silviasapora/gemma-7b-sft-basic_capibara-5e-5-000-v133,"---
base_model: google/gemma-7b
datasets:
- argilla/distilabel-capybara-dpo-7k-binarized
library_name: transformers
model_name: google/gemma-7b
tags:
- generated_from_trainer
- alignment-handbook
- trl
- orpo
licence: license
---

# Model Card for google/gemma-7b

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b) on the [['argilla/distilabel-capybara-dpo-7k-binarized']](https://huggingface.co/datasets/['argilla/distilabel-capybara-dpo-7k-binarized']) dataset.
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""silviasapora/gemma-7b-sft-basic_capibara-5e-5-000-v133"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

[<img src=""https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-28.svg"" alt=""Visualize in Weights & Biases"" width=""150"" height=""24""/>](https://wandb.ai/silvias/huggingface/runs/oyswjcmp) 


This model was trained with ORPO, a method introduced in [ORPO: Monolithic Preference Optimization without Reference Model](https://huggingface.co/papers/2403.07691).

### Framework versions

- TRL: 0.16.1
- Transformers: 4.50.3
- Pytorch: 2.5.1
- Datasets: 3.2.0
- Tokenizers: 0.21.0

## Citations

Cite ORPO as:

```bibtex
@article{hong2024orpo,
    title        = {{ORPO: Monolithic Preference Optimization without Reference Model}},
    author       = {Jiwoo Hong and Noah Lee and James Thorne},
    year         = 2024,
    eprint       = {arXiv:2403.07691}
}
```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""silviasapora/gemma-7b-sft-basic_capibara-5e-5-000-v133"", ""author"": ""silviasapora"", ""sha"": ""840293c7a00213821b6cb3b285b553ae3bfc4b3e"", ""last_modified"": ""2025-04-04 23:29:17+00:00"", ""created_at"": ""2025-04-04 22:25:17+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 1, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""tensorboard"", ""safetensors"", ""gemma"", ""text-generation"", ""generated_from_trainer"", ""alignment-handbook"", ""trl"", ""orpo"", ""conversational"", ""dataset:argilla/distilabel-capybara-dpo-7k-binarized"", ""arxiv:2403.07691"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/distilabel-capybara-dpo-7k-binarized\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""GemmaForCausalLM""], ""model_type"": ""gemma"", ""tokenizer_config"": {""bos_token"": ""<bos>"", ""chat_template"": ""{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n' + message['content'] | trim + '<end_of_turn>\n' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n'}}{% endif %}"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='all_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='runs/Apr04_22-24-24_84b693e79a02/events.out.tfevents.1743805530.84b693e79a02.204365.0', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='train_results.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='trainer_state.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-04-04 23:29:17+00:00"", ""cardData"": ""base_model: google/gemma-7b\ndatasets:\n- argilla/distilabel-capybara-dpo-7k-binarized\nlibrary_name: transformers\nmodel_name: google/gemma-7b\ntags:\n- generated_from_trainer\n- alignment-handbook\n- trl\n- orpo\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67f05c4d56ef544a3d42b187"", ""modelId"": ""silviasapora/gemma-7b-sft-basic_capibara-5e-5-000-v133"", ""usedStorage"": 3239010875}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=silviasapora/gemma-7b-sft-basic_capibara-5e-5-000-v133&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsilviasapora%2Fgemma-7b-sft-basic_capibara-5e-5-000-v133%5D(%2Fsilviasapora%2Fgemma-7b-sft-basic_capibara-5e-5-000-v133)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,
selincildam/medical-assistant-gemma,"---
base_model: google/gemma-7b
library_name: transformers
model_name: medical-assistant-gemma
tags:
- generated_from_trainer
- trl
- sft
licence: license
---

# Model Card for medical-assistant-gemma

This model is a fine-tuned version of [google/gemma-7b](https://huggingface.co/google/gemma-7b).
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = ""If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?""
generator = pipeline(""text-generation"", model=""selincildam/medical-assistant-gemma"", device=""cuda"")
output = generator([{""role"": ""user"", ""content"": question}], max_new_tokens=128, return_full_text=False)[0]
print(output[""generated_text""])
```

## Training procedure

 


This model was trained with SFT.

### Framework versions

- TRL: 0.16.1
- Transformers: 4.52.0.dev0
- Pytorch: 2.5.1+cu124
- Datasets: 3.5.0
- Tokenizers: 0.21.0

## Citations



Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallouédec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/huggingface/trl}}
}
```","{""id"": ""selincildam/medical-assistant-gemma"", ""author"": ""selincildam"", ""sha"": ""eba2f81440e00df8d84db3ce54a364e4a188f867"", ""last_modified"": ""2025-04-14 21:38:08+00:00"", ""created_at"": ""2025-04-14 18:30:44+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""safetensors"", ""generated_from_trainer"", ""trl"", ""sft"", ""base_model:google/gemma-7b"", ""base_model:finetune:google/gemma-7b"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": null, ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: google/gemma-7b\nlibrary_name: transformers\nmodel_name: medical-assistant-gemma\ntags:\n- generated_from_trainer\n- trl\n- sft\nlicence: license"", ""widget_data"": null, ""model_index"": null, ""config"": {""tokenizer_config"": {""bos_token"": ""<bos>"", ""eos_token"": ""<eos>"", ""pad_token"": ""<pad>"", ""unk_token"": ""<unk>"", ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModel"", ""custom_class"": null, ""pipeline_tag"": null, ""processor"": null}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='adapter_model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.model', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='training_args.bin', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-04-14 21:38:08+00:00"", ""cardData"": ""base_model: google/gemma-7b\nlibrary_name: transformers\nmodel_name: medical-assistant-gemma\ntags:\n- generated_from_trainer\n- trl\n- sft\nlicence: license"", ""transformersInfo"": {""auto_model"": ""AutoModel"", ""custom_class"": null, ""pipeline_tag"": null, ""processor"": null}, ""_id"": ""67fd54545651c6a77fcbda2f"", ""modelId"": ""selincildam/medical-assistant-gemma"", ""usedStorage"": 167202148}",1,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=selincildam/medical-assistant-gemma&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bselincildam%2Fmedical-assistant-gemma%5D(%2Fselincildam%2Fmedical-assistant-gemma)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1,,

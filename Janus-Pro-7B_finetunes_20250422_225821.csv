model_id,card,metadata,depth,children,children_count,adapters,adapters_count,quantized,quantized_count,merges,merges_count,spaces,spaces_count
deepseek-ai/Janus-Pro-7B,"---
license: mit
license_name: deepseek
license_link: LICENSE
pipeline_tag: any-to-any
library_name: transformers
tags:
- muiltimodal
- text-to-image
- unified-model
---

## 1. Introduction

Janus-Pro is a novel autoregressive framework that unifies multimodal understanding and generation. 
It addresses the limitations of previous approaches by decoupling visual encoding into separate pathways, while still utilizing a single, unified transformer architecture for processing. The decoupling not only alleviates the conflict between the visual encoder’s roles in understanding and generation, but also enhances the framework’s flexibility. 
Janus-Pro surpasses previous unified model and matches or exceeds the performance of task-specific models. 
The simplicity, high flexibility, and effectiveness of Janus-Pro make it a strong candidate for next-generation unified multimodal models.

[**Github Repository**](https://github.com/deepseek-ai/Janus)

<div align=""center"">
<img alt=""image"" src=""janus_pro_teaser1.png"" style=""width:90%;"">
</div>

<div align=""center"">
<img alt=""image"" src=""janus_pro_teaser2.png"" style=""width:90%;"">
</div>


### 2. Model Summary

Janus-Pro is a unified understanding and generation MLLM, which decouples visual encoding for multimodal understanding and generation. 
Janus-Pro is constructed based on the DeepSeek-LLM-1.5b-base/DeepSeek-LLM-7b-base.

For multimodal understanding, it uses the [SigLIP-L](https://huggingface.co/timm/ViT-L-16-SigLIP-384) as the vision encoder, which supports 384 x 384 image input. For image generation, Janus-Pro uses the tokenizer from [here](https://github.com/FoundationVision/LlamaGen) with a downsample rate of 16.



## 3. Quick Start

Please refer to [**Github Repository**](https://github.com/deepseek-ai/Janus)


## 4. License

This code repository is licensed under [the MIT License](https://github.com/deepseek-ai/DeepSeek-LLM/blob/HEAD/LICENSE-CODE). The use of Janus-Pro models is subject to [DeepSeek Model License](https://github.com/deepseek-ai/DeepSeek-LLM/blob/HEAD/LICENSE-MODEL).
## 5. Citation

```
@article{chen2025janus,
  title={Janus-Pro: Unified Multimodal Understanding and Generation with Data and Model Scaling},
  author={Chen, Xiaokang and Wu, Zhiyu and Liu, Xingchao and Pan, Zizheng and Liu, Wen and Xie, Zhenda and Yu, Xingkai and Ruan, Chong},
  journal={arXiv preprint arXiv:2501.17811},
  year={2025}
}
```

## 6. Contact

If you have any questions, please raise an issue or contact us at [service@deepseek.com](mailto:service@deepseek.com).","{""id"": ""deepseek-ai/Janus-Pro-7B"", ""author"": ""deepseek-ai"", ""sha"": ""5c3eb3fb2a3b61094328465ba61fcd4272090d67"", ""last_modified"": ""2025-02-01 08:00:16+00:00"", ""created_at"": ""2025-01-26 12:05:50+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 235631, ""downloads_all_time"": null, ""likes"": 3344, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""pytorch"", ""multi_modality"", ""muiltimodal"", ""text-to-image"", ""unified-model"", ""any-to-any"", ""arxiv:2501.17811"", ""license:mit"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""any-to-any"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""library_name: transformers\nlicense: mit\nlicense_name: deepseek\nlicense_link: LICENSE\npipeline_tag: any-to-any\ntags:\n- muiltimodal\n- text-to-image\n- unified-model"", ""widget_data"": null, ""model_index"": null, ""config"": {""model_type"": ""multi_modality"", ""tokenizer_config"": {""bos_token"": ""<\uff5cbegin\u2581of\u2581sentence\uff5c>"", ""eos_token"": ""<\uff5cend\u2581of\u2581sentence\uff5c>"", ""pad_token"": null, ""unk_token"": null, ""use_default_system_prompt"": true}}, ""transformers_info"": {""auto_model"": ""AutoModel"", ""custom_class"": null, ""pipeline_tag"": null, ""processor"": null}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='janus_pro_teaser1.png', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='janus_pro_teaser2.png', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='preprocessor_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='processor_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='pytorch_model-00001-of-00002.bin', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='pytorch_model-00002-of-00002.bin', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='pytorch_model.bin.index.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)""], ""spaces"": [""deepseek-ai/Janus-Pro-7B"", ""AP123/Janus-Pro-7b"", ""LLMhacker/DeepseekJanusPro-Image"", ""blanchon/JanusPro"", ""VIDraft/Deepseek-Multimodal"", ""Bils/DeepseekJanusPro-Image"", ""ginigen/Janus-Pro-7B"", ""mkozak/Janus-Pro-7b"", ""omninexus/deepseek-vision"", ""AnonTnf/DeepseekJanusPro-Image"", ""shakuur/meme"", ""unography/Janus-Pro-7b"", ""awacke1/Janus-Pro-Frens"", ""luigi12345/AutoMultimodal"", ""ChrisOrr/Janus-Pro-7b-playground"", ""zx2323/xxxkk"", ""WILLIAMPIRES/empatikosprime"", ""ijohn07/Janus-Pro-7B"", ""BasqueLabs/Janus-Pro-7B"", ""d-delaurier/Jarvis"", ""WANGIII/Janus-Pro-7B"", ""Mohansai2004/test"", ""Dnldmhy/Janus-Pro-7B"", ""mido09/Janus-Pro-7B"", ""karouswissem/captionnn"", ""Moka51/januss"", ""Moka51/Janus-Pro-7B"", ""DHEIVER/pdf-analyzer"", ""cjgall/deepseek-janus-pro-7b"", ""andrewharp/Janus"", ""thehellyouare/testing"", ""bobocloud/Janus-Pro-7B"", ""hf-sun/ningDSApp"", ""BOSSHuggingFace/J-P"", ""Badger123t/Janus-Pro-7B"", ""roxky/Janus-Pro-7B"", ""lissank/Janus-Pro-7B"", ""LLMhacker/Janus-Pro-7B-0205"", ""scout306/Janus-Pro-7B"", ""creaturebot/Janus-Pro-7B"", ""wincrash33/test-model2"", ""wfustc/Deepseek_JanusPro_7B"", ""ferferefer/AutoMultimodal"", ""youssefch1012/Janus-Pro-7B"", ""ivanrhs/food-explorer"", ""Hatman/deepseek-janus"", ""NikhilJoson/Multimodal_Chat_JanusPro"", ""WesanCZE/Mistral7b-assistant"", ""imnop001/deepseek-ai"", ""PabloTJ/palindroms"", ""luigi12345/Deepseek-Multimodal"", ""IvanNeg/Janus-Pro-7B-Demo""], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-02-01 08:00:16+00:00"", ""cardData"": ""library_name: transformers\nlicense: mit\nlicense_name: deepseek\nlicense_link: LICENSE\npipeline_tag: any-to-any\ntags:\n- muiltimodal\n- text-to-image\n- unified-model"", ""transformersInfo"": {""auto_model"": ""AutoModel"", ""custom_class"": null, ""pipeline_tag"": null, ""processor"": null}, ""_id"": ""6796251e22990ae89b1f60f1"", ""modelId"": ""deepseek-ai/Janus-Pro-7B"", ""usedStorage"": 29685770369}",0,"https://huggingface.co/wnma3mz/Janus-Pro-7B-LM, https://huggingface.co/masterthor90/DarkDevil, https://huggingface.co/MISHANM/deepseek-ai_janus-Pro-7B-fp16, https://huggingface.co/Helen0811/test_repo, https://huggingface.co/Kevein/MakeIdea, https://huggingface.co/wnma3mz/Janus-Pro-7B, https://huggingface.co/ErenMil/sofa, https://huggingface.co/tulsikopoi/NepAI, https://huggingface.co/MatiVexx/Roxi, https://huggingface.co/GgDamn/Testees, https://huggingface.co/elmasryamr/King, https://huggingface.co/Vito13/Death, https://huggingface.co/Ferhat591/Kumsal, https://huggingface.co/Smartph90/Activities, https://huggingface.co/Vezel/Data, https://huggingface.co/Mandeepmk/Try, https://huggingface.co/vilho/gtyfr65, https://huggingface.co/komalkaur/aysha, https://huggingface.co/Alvarose/Snchezzz, https://huggingface.co/Dbandz/Elon657, https://huggingface.co/Kilichnuyy/CHIKIPIKI, https://huggingface.co/LulSteph/ScriptWriter, https://huggingface.co/trancoso-cc/gibberish-detector, https://huggingface.co/Ammihammi/camile_vero, https://huggingface.co/Vinayak9000/DHAIRYA, https://huggingface.co/mlmecham/watch-your-toes",26,"https://huggingface.co/fibonacciai/Persian-llm-fibonacci-1-7b-chat.P1_0, https://huggingface.co/Zeariaya/DeepSeek, https://huggingface.co/jasongarrison/JesusBro, https://huggingface.co/JacobLasher/pro, https://huggingface.co/astredia/lary, https://huggingface.co/SombreroCat/SombrerO1.0",6,"https://huggingface.co/wnma3mz/Janus-Pro-7B-LM-4bit, https://huggingface.co/wnma3mz/Janus-Pro-7B-4bit",2,,0,"AP123/Janus-Pro-7b, AnonTnf/DeepseekJanusPro-Image, Bils/DeepseekJanusPro-Image, LLMhacker/DeepseekJanusPro-Image, VIDraft/Deepseek-Multimodal, deepseek-ai/Janus-Pro-7B, ginigen/Janus-Pro-7B, huggingface/InferenceSupport/discussions/51, mkozak/Janus-Pro-7b, omninexus/deepseek-vision, shakuur/meme, unography/Janus-Pro-7b, zx2323/xxxkk",13
wnma3mz/Janus-Pro-7B-LM,"---
license: mit
license_name: deepseek
license_link: LICENSE
pipeline_tag: text-generation
library_name: transformers
base_model:
  - deepseek-ai/Janus-Pro-7B
tags:
  - chat
---

This model is derived from https://huggingface.co/deepseek-ai/Janus-Pro-7B and the main modifications are as follows

- bin files are updated to safetensors
- Add chat_template

`4bit` refers to quantifying the LLM part to 4 bits.

`LM` means that it contains only the language model part.

## Quick Start

In Macos (Apple silicon), use [mlx](https://github.com/ml-explore/mlx) framework https://github.com/wnma3mz/tLLM

```bash
tllm.server --model_path $MODEL_PATH --hostname localhost --is_local --client_size 1
```

`$MODEL_PATH` like `wnma3mz/Janus-Pro-1B-4bit`","{""id"": ""wnma3mz/Janus-Pro-7B-LM"", ""author"": ""wnma3mz"", ""sha"": ""85523dd0aa71f94d95e521b0b3e3bd296feef991"", ""last_modified"": ""2025-01-30 05:36:10+00:00"", ""created_at"": ""2025-01-28 12:34:18+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 30, ""downloads_all_time"": null, ""likes"": 1, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""pytorch"", ""safetensors"", ""llama"", ""text-generation"", ""chat"", ""conversational"", ""base_model:deepseek-ai/Janus-Pro-7B"", ""base_model:finetune:deepseek-ai/Janus-Pro-7B"", ""license:mit"", ""autotrain_compatible"", ""text-generation-inference"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model:\n- deepseek-ai/Janus-Pro-7B\nlibrary_name: transformers\nlicense: mit\nlicense_name: deepseek\nlicense_link: LICENSE\npipeline_tag: text-generation\ntags:\n- chat"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""LlamaForCausalLM""], ""model_type"": ""llama"", ""tokenizer_config"": {""bos_token"": ""<\uff5cbegin\u2581of\u2581sentence\uff5c>"", ""eos_token"": ""<\uff5cend\u2581of\u2581sentence\uff5c>"", ""pad_token"": null, ""chat_template"": ""{% if not add_generation_prompt is defined %}{% set add_generation_prompt = false %}{% endif %}{% set ns = namespace(is_first=false, is_tool=false, is_output_first=true, system_prompt='') %}{%- for message in messages %}{%- if message['role'] == 'system' %}{% set ns.system_prompt = message['content'] %}{%- endif %}{%- endfor %}{{ns.system_prompt}}{%- for message in messages %}{%- if message['role'] == 'user' %}{{'<|User|>: ' + message['content'] + '\\n\\n'}}{%- endif %}{%- if message['role'] == 'assistant' and message['content'] is not none %}{% set content = message['content'] %}{% if '</think>' in content %}{% set content = content.split('</think>')[-1] %}{% endif %}{{'<|Assistant|>: ' + content + '<\uff5cend\u2581of\u2581sentence\uff5c>'}}{%- endif %}{%- endfor -%}{% if add_generation_prompt %}{{'<|Assistant|>: '}}{% endif %}"", ""unk_token"": null, ""use_default_system_prompt"": true}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='preprocessor_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='processor_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='pytorch_model.bin.index.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='test_conv.py', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": {""parameters"": {""F16"": 6910365696}, ""total"": 6910365696}, ""security_repo_status"": null, ""lastModified"": ""2025-01-30 05:36:10+00:00"", ""cardData"": ""base_model:\n- deepseek-ai/Janus-Pro-7B\nlibrary_name: transformers\nlicense: mit\nlicense_name: deepseek\nlicense_link: LICENSE\npipeline_tag: text-generation\ntags:\n- chat"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""6798ceca7b3a8e8418b0ed21"", ""modelId"": ""wnma3mz/Janus-Pro-7B-LM"", ""usedStorage"": 13820763056}",1,,0,,0,"https://huggingface.co/mradermacher/Janus-Pro-7B-LM-GGUF, https://huggingface.co/mradermacher/Janus-Pro-7B-LM-i1-GGUF",2,,0,huggingface/InferenceSupport/discussions/new?title=wnma3mz/Janus-Pro-7B-LM&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bwnma3mz%2FJanus-Pro-7B-LM%5D(%2Fwnma3mz%2FJanus-Pro-7B-LM)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1
masterthor90/DarkDevil,"---
license: wtfpl
base_model:
- deepseek-ai/Janus-Pro-7B
---","{""id"": ""masterthor90/DarkDevil"", ""author"": ""masterthor90"", ""sha"": ""03d87cc2c3b866680ad9ddae761294e9745a9570"", ""last_modified"": ""2025-01-29 05:49:26+00:00"", ""created_at"": ""2025-01-29 05:48:24+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 1, ""library_name"": null, ""gguf"": null, ""inference"": null, ""tags"": [""base_model:deepseek-ai/Janus-Pro-7B"", ""base_model:finetune:deepseek-ai/Janus-Pro-7B"", ""license:wtfpl"", ""region:us""], ""pipeline_tag"": null, ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model:\n- deepseek-ai/Janus-Pro-7B\nlicense: wtfpl"", ""widget_data"": null, ""model_index"": null, ""config"": null, ""transformers_info"": null, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-01-29 05:49:26+00:00"", ""cardData"": ""base_model:\n- deepseek-ai/Janus-Pro-7B\nlicense: wtfpl"", ""transformersInfo"": null, ""_id"": ""6799c12844032a6b51eddd71"", ""modelId"": ""masterthor90/DarkDevil"", ""usedStorage"": 0}",1,,0,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=masterthor90/DarkDevil&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bmasterthor90%2FDarkDevil%5D(%2Fmasterthor90%2FDarkDevil)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1
MISHANM/deepseek-ai_janus-Pro-7B-fp16,"---
base_model:
- deepseek-ai/Janus-Pro-7B
---
  
  
# MISHANM/deepseek-ai_janus-Pro-7B-fp16
  
The MISHANM/deepseek-ai_janus-Pro-7B-fp16 model is the multimodal understanding and image generation model . It is designed to generate Image to text and high-quality images from textual prompts.  
  
## Model Details  
1. Language: English
2. Tasks: Imgae to Text & Text to  Image Generation
  
### Model Example output  
  
This is the model inference output:   
  
![image/png](https://cdn-uploads.huggingface.co/production/uploads/66851b2c4461866b07738832/5RotptYgkmhInup-jseVz.png)



![image/png](https://cdn-uploads.huggingface.co/production/uploads/66851b2c4461866b07738832/u7ms70_UQnq64Ze_EKtzF.png)


 ## How to Get Started with the Model  

```shell
git clone https://github.com/deepseek-ai/Janus.git
cd Janus
pip install -e .
```

## Use the code below to get started with the model. 

### Multimodal Understanding(Image to Text). 

Using Gradio
  
```python  
import gradio as gr
import torch
from transformers import AutoModelForCausalLM
from janus.models import MultiModalityCausalLM, VLChatProcessor
from janus.utils.io import load_pil_images
import base64
from io import BytesIO

def pil_image_to_base64(pil_image):
    buffered = BytesIO()
    pil_image.save(buffered, format=""PNG"")
    img_str = base64.b64encode(buffered.getvalue()).decode(""utf-8"")
    return f""data:image/png;base64,{img_str}""

# Initialize the processor and model
model_path = ""MISHANM/deepseek-ai_janus-Pro-7B-fp16""
vl_chat_processor: VLChatProcessor = VLChatProcessor.from_pretrained(model_path)
tokenizer = vl_chat_processor.tokenizer

vl_gpt: MultiModalityCausalLM = AutoModelForCausalLM.from_pretrained(
    model_path, trust_remote_code=True
)
vl_gpt = vl_gpt.to(torch.bfloat16).cuda().eval()

def multimodal_understanding(image, question):
    # Convert PIL Image to base64 string
    image_base64 = pil_image_to_base64(image)

    # Prepare the conversation
    conversation = [
        {
            ""role"": ""<|User|>"",
            ""content"": f""<image_placeholder>\n{question}"",
            ""images"": [image_base64], 
        },
        {""role"": ""<|Assistant|>"", ""content"": """"},
    ]

    # Load images and prepare inputs
    pil_images = load_pil_images(conversation)
    prepare_inputs = vl_chat_processor(
        conversations=conversation, images=pil_images, force_batchify=True
    ).to(vl_gpt.device)

    # Run image encoder to get the image embeddings
    inputs_embeds = vl_gpt.prepare_inputs_embeds(**prepare_inputs)

    # Run the model to get the response
    outputs = vl_gpt.language_model.generate(
        inputs_embeds=inputs_embeds,
        attention_mask=prepare_inputs.attention_mask,
        pad_token_id=tokenizer.eos_token_id,
        bos_token_id=tokenizer.bos_token_id,
        eos_token_id=tokenizer.eos_token_id,
        max_new_tokens=512,
        do_sample=False,
        use_cache=True,
    )

    answer = tokenizer.decode(outputs[0].cpu().tolist(), skip_special_tokens=True)
    return answer

# Gradio interface
interface = gr.Interface(
    fn=multimodal_understanding,
    inputs=[gr.Image(type=""pil""), gr.Textbox(lines=2, placeholder=""Enter your question here..."")],
    outputs=""text"",
    title=""Multimodal Understanding "",
    description=""Upload an image and ask a question about it.""
)

interface.launch(share=True)

```


### Text to Image Generation. 
  
```python  
import os
import gradio as gr
import PIL.Image
import torch
import numpy as np
from transformers import AutoModelForCausalLM
from janus.models import MultiModalityCausalLM, VLChatProcessor

# Initialize the processor and model
model_path = ""MISHANM/deepseek-ai_janus-Pro-7B-fp16""
vl_chat_processor: VLChatProcessor = VLChatProcessor.from_pretrained(model_path)
tokenizer = vl_chat_processor.tokenizer

vl_gpt: MultiModalityCausalLM = AutoModelForCausalLM.from_pretrained(
    model_path, trust_remote_code=True
)
vl_gpt = vl_gpt.to(torch.bfloat16).cuda().eval()

@torch.inference_mode()
def generate_image(prompt_text, parallel_size=1):
    # Prepare the conversation
    conversation = [
        {
            ""role"": ""<|User|>"",
            ""content"": prompt_text,
        },
        {""role"": ""<|Assistant|>"", ""content"": """"},
    ]

    sft_format = vl_chat_processor.apply_sft_template_for_multi_turn_prompts(
        conversations=conversation,
        sft_format=vl_chat_processor.sft_format,
        system_prompt="""",
    )
    prompt = sft_format + vl_chat_processor.image_start_tag

    input_ids = vl_chat_processor.tokenizer.encode(prompt)
    input_ids = torch.LongTensor(input_ids)

    tokens = torch.zeros((parallel_size*2, len(input_ids)), dtype=torch.int).cuda()
    for i in range(parallel_size*2):
        tokens[i, :] = input_ids
        if i % 2 != 0:
            tokens[i, 1:-1] = vl_chat_processor.pad_id

    inputs_embeds = vl_gpt.language_model.get_input_embeddings()(tokens)

    image_token_num_per_image = 576
    img_size = 384
    patch_size = 16
    generated_tokens = torch.zeros((parallel_size, image_token_num_per_image), dtype=torch.int).cuda()

    for i in range(image_token_num_per_image):
        outputs = vl_gpt.language_model.model(inputs_embeds=inputs_embeds, use_cache=True, past_key_values=outputs.past_key_values if i != 0 else None)
        hidden_states = outputs.last_hidden_state

        logits = vl_gpt.gen_head(hidden_states[:, -1, :])
        logit_cond = logits[0::2, :]
        logit_uncond = logits[1::2, :]

        cfg_weight = 5
        logits = logit_uncond + cfg_weight * (logit_cond-logit_uncond)
        probs = torch.softmax(logits, dim=-1)

        next_token = torch.multinomial(probs, num_samples=1)
        generated_tokens[:, i] = next_token.squeeze(dim=-1)

        next_token = torch.cat([next_token.unsqueeze(dim=1), next_token.unsqueeze(dim=1)], dim=1).view(-1)
        img_embeds = vl_gpt.prepare_gen_img_embeds(next_token)
        inputs_embeds = img_embeds.unsqueeze(dim=1)

    dec = vl_gpt.gen_vision_model.decode_code(generated_tokens.to(dtype=torch.int), shape=[parallel_size, 8, img_size//patch_size, img_size//patch_size])
    dec = dec.to(torch.float32).cpu().numpy().transpose(0, 2, 3, 1)

    dec = np.clip((dec + 1) / 2 * 255, 0, 255)

    visual_img = np.zeros((parallel_size, img_size, img_size, 3), dtype=np.uint8)
    visual_img[:, :, :] = dec

    return PIL.Image.fromarray(visual_img[0])

# Create Gradio interface
interface = gr.Interface(
    fn=generate_image,
    inputs=gr.Textbox(lines=2, placeholder=""Enter your prompt here...""),
    outputs=""image"",
    title=""Text-to-Image Generation"",
    description=""Enter a text prompt to generate an image.""
)

interface.launch(share=True)

 

```
## Uses  
  
### Direct Use  
  
The model is designed to convert images into text and text into images based on textual descriptions. It is useful for creative projects, content creation, and artistic exploration  
### Out-of-Scope Use  
  
The model is not designed to generate images containing explicit or harmful content. It may also struggle with highly abstract or nonsensical prompts.  
## Bias, Risks, and Limitations  
  
The model may inherit biases from its training data, potentially producing stereotypical or biased images based on the given prompts.

### Recommendations  
  
Users should be mindful of potential biases and limitations. It is advisable to review the generated content for accuracy and appropriateness.
## Citation Information
```
@misc{MISHANM/deepseek-ai_janus-Pro-7B-fp16,
  author = {Mishan Maurya},
  title = {Introducing Image to Text & Text to Image Generation model},
  year = {2025},
  publisher = {Hugging Face},
  journal = {Hugging Face repository},
  
}
```","{""id"": ""MISHANM/deepseek-ai_janus-Pro-7B-fp16"", ""author"": ""MISHANM"", ""sha"": ""c589f5b81185629c98f530f2b10d94090ffce913"", ""last_modified"": ""2025-02-13 18:05:01+00:00"", ""created_at"": ""2025-02-02 04:52:15+00:00"", ""private"": false, ""gated"": ""auto"", ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 2, ""library_name"": null, ""gguf"": null, ""inference"": null, ""tags"": [""safetensors"", ""multi_modality"", ""base_model:deepseek-ai/Janus-Pro-7B"", ""base_model:finetune:deepseek-ai/Janus-Pro-7B"", ""region:us""], ""pipeline_tag"": null, ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model:\n- deepseek-ai/Janus-Pro-7B"", ""widget_data"": null, ""model_index"": null, ""config"": {""architectures"": [""MultiModalityCausalLM""], ""model_type"": ""multi_modality"", ""tokenizer_config"": {""bos_token"": ""<\uff5cbegin\u2581of\u2581sentence\uff5c>"", ""eos_token"": ""<\uff5cend\u2581of\u2581sentence\uff5c>"", ""pad_token"": ""<\uff5c\u2581pad\u2581\uff5c>"", ""unk_token"": null, ""use_default_system_prompt"": true}}, ""transformers_info"": null, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00001-of-00003.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00002-of-00003.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00003-of-00003.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model.safetensors.index.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='preprocessor_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='processor_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": {""parameters"": {""F16"": 7420434059}, ""total"": 7420434059}, ""security_repo_status"": null, ""lastModified"": ""2025-02-13 18:05:01+00:00"", ""cardData"": ""base_model:\n- deepseek-ai/Janus-Pro-7B"", ""transformersInfo"": null, ""_id"": ""679ef9ff4c75fbb0e54f02c8"", ""modelId"": ""MISHANM/deepseek-ai_janus-Pro-7B-fp16"", ""usedStorage"": 14840985702}",1,,0,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=MISHANM/deepseek-ai_janus-Pro-7B-fp16&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5BMISHANM%2Fdeepseek-ai_janus-Pro-7B-fp16%5D(%2FMISHANM%2Fdeepseek-ai_janus-Pro-7B-fp16)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1
Helen0811/test_repo,"---
license: apache-2.0
datasets:
- open-r1/OpenR1-Math-220k
language:
- aa
metrics:
- cer
base_model:
- deepseek-ai/Janus-Pro-7B
new_version: deepseek-ai/DeepSeek-R1-Distill-Qwen-32B
pipeline_tag: text-classification
library_name: fairseq
tags:
- biology
---","{""id"": ""Helen0811/test_repo"", ""author"": ""Helen0811"", ""sha"": ""1bbef6cffd97891da54b8fc0cc573c102e404caf"", ""last_modified"": ""2025-02-14 10:00:34+00:00"", ""created_at"": ""2025-02-12 08:13:48+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 1, ""library_name"": ""fairseq"", ""gguf"": null, ""inference"": null, ""tags"": [""fairseq"", ""biology"", ""text-classification"", ""aa"", ""dataset:open-r1/OpenR1-Math-220k"", ""base_model:deepseek-ai/Janus-Pro-7B"", ""base_model:finetune:deepseek-ai/Janus-Pro-7B"", ""license:apache-2.0"", ""region:us""], ""pipeline_tag"": ""text-classification"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model:\n- deepseek-ai/Janus-Pro-7B\ndatasets:\n- open-r1/OpenR1-Math-220k\nlanguage:\n- aa\nlibrary_name: fairseq\nlicense: apache-2.0\nmetrics:\n- cer\npipeline_tag: text-classification\ntags:\n- biology\nnew_version: deepseek-ai/DeepSeek-R1-Distill-Qwen-32B"", ""widget_data"": null, ""model_index"": null, ""config"": null, ""transformers_info"": null, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-02-14 10:00:34+00:00"", ""cardData"": ""base_model:\n- deepseek-ai/Janus-Pro-7B\ndatasets:\n- open-r1/OpenR1-Math-220k\nlanguage:\n- aa\nlibrary_name: fairseq\nlicense: apache-2.0\nmetrics:\n- cer\npipeline_tag: text-classification\ntags:\n- biology\nnew_version: deepseek-ai/DeepSeek-R1-Distill-Qwen-32B"", ""transformersInfo"": null, ""_id"": ""67ac583cdb449af327d8a585"", ""modelId"": ""Helen0811/test_repo"", ""usedStorage"": 0}",1,,0,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=Helen0811/test_repo&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5BHelen0811%2Ftest_repo%5D(%2FHelen0811%2Ftest_repo)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1
Kevein/MakeIdea,"---
license: cc-by-sa-4.0
datasets:
- fka/awesome-chatgpt-prompts
language:
- en
metrics:
- bertscore
base_model:
- deepseek-ai/Janus-Pro-7B
new_version: deepseek-ai/Janus-Pro-7B
pipeline_tag: question-answering
library_name: fasttext
tags:
- All
---","{""id"": ""Kevein/MakeIdea"", ""author"": ""Kevein"", ""sha"": ""1f06ffaaedba870eb465ab30329c7da05738b09a"", ""last_modified"": ""2025-02-17 12:32:08+00:00"", ""created_at"": ""2025-02-17 12:24:04+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 1, ""library_name"": ""fasttext"", ""gguf"": null, ""inference"": null, ""tags"": [""fasttext"", ""All"", ""question-answering"", ""en"", ""dataset:fka/awesome-chatgpt-prompts"", ""base_model:deepseek-ai/Janus-Pro-7B"", ""base_model:finetune:deepseek-ai/Janus-Pro-7B"", ""license:cc-by-sa-4.0"", ""region:us""], ""pipeline_tag"": ""question-answering"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model:\n- deepseek-ai/Janus-Pro-7B\ndatasets:\n- fka/awesome-chatgpt-prompts\nlanguage:\n- en\nlibrary_name: fasttext\nlicense: cc-by-sa-4.0\nmetrics:\n- bertscore\npipeline_tag: question-answering\ntags:\n- All\nnew_version: deepseek-ai/Janus-Pro-7B"", ""widget_data"": [{""text"": ""Where do I live?"", ""context"": ""My name is Wolfgang and I live in Berlin""}, {""text"": ""Where do I live?"", ""context"": ""My name is Sarah and I live in London""}, {""text"": ""What's my name?"", ""context"": ""My name is Clara and I live in Berkeley.""}, {""text"": ""Which name is also used to describe the Amazon rainforest in English?"", ""context"": ""The Amazon rainforest (Portuguese: Floresta Amaz\u00f4nica or Amaz\u00f4nia; Spanish: Selva Amaz\u00f3nica, Amazon\u00eda or usually Amazonia; French: For\u00eat amazonienne; Dutch: Amazoneregenwoud), also known in English as Amazonia or the Amazon Jungle, is a moist broadleaf forest that covers most of the Amazon basin of South America. This basin encompasses 7,000,000 square kilometres (2,700,000 sq mi), of which 5,500,000 square kilometres (2,100,000 sq mi) are covered by the rainforest. This region includes territory belonging to nine nations. The majority of the forest is contained within Brazil, with 60% of the rainforest, followed by Peru with 13%, Colombia with 10%, and with minor amounts in Venezuela, Ecuador, Bolivia, Guyana, Suriname and French Guiana. States or departments in four nations contain \""Amazonas\"" in their names. The Amazon represents over half of the planet's remaining rainforests, and comprises the largest and most biodiverse tract of tropical rainforest in the world, with an estimated 390 billion individual trees divided into 16,000 species.""}], ""model_index"": null, ""config"": null, ""transformers_info"": null, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-02-17 12:32:08+00:00"", ""cardData"": ""base_model:\n- deepseek-ai/Janus-Pro-7B\ndatasets:\n- fka/awesome-chatgpt-prompts\nlanguage:\n- en\nlibrary_name: fasttext\nlicense: cc-by-sa-4.0\nmetrics:\n- bertscore\npipeline_tag: question-answering\ntags:\n- All\nnew_version: deepseek-ai/Janus-Pro-7B"", ""transformersInfo"": null, ""_id"": ""67b32a645ecdaf799ddb3fe6"", ""modelId"": ""Kevein/MakeIdea"", ""usedStorage"": 0}",1,,0,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=Kevein/MakeIdea&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5BKevein%2FMakeIdea%5D(%2FKevein%2FMakeIdea)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1
wnma3mz/Janus-Pro-7B,"---
license: mit
license_name: deepseek
license_link: LICENSE
pipeline_tag: any-to-any
library_name: mlx
base_model:
- deepseek-ai/Janus-Pro-7B
tags:
- chat
---

This model is derived from https://huggingface.co/deepseek-ai/Janus-Pro-7B and the main modifications are as follows

- bin files are updated to safetensors
- Add chat_template

`4bit` mainly refers to quantifying the LLM part to 4 bits.

## Quick Start

In Macos (Apple silicon), use [mlx](https://github.com/ml-explore/mlx) framework https://github.com/wnma3mz/tLLM

```bash
tllm.server --model_path $MODEL_PATH
```

`$MODEL_PATH` like `wnma3mz/Janus-Pro-1B-4bit`","{""id"": ""wnma3mz/Janus-Pro-7B"", ""author"": ""wnma3mz"", ""sha"": ""4a90e88c036a2e57df285b3e98f867a2c996ab19"", ""last_modified"": ""2025-02-01 13:02:15+00:00"", ""created_at"": ""2025-01-30 06:22:31+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 30, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""mlx"", ""gguf"": null, ""inference"": null, ""tags"": [""mlx"", ""safetensors"", ""chat"", ""any-to-any"", ""base_model:deepseek-ai/Janus-Pro-7B"", ""base_model:finetune:deepseek-ai/Janus-Pro-7B"", ""license:mit"", ""region:us""], ""pipeline_tag"": ""any-to-any"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model:\n- deepseek-ai/Janus-Pro-7B\nlibrary_name: mlx\nlicense: mit\nlicense_name: deepseek\nlicense_link: LICENSE\npipeline_tag: any-to-any\ntags:\n- chat"", ""widget_data"": null, ""model_index"": null, ""config"": {""architectures"": [""JanusProConditionalGeneration""], ""tokenizer_config"": {""bos_token"": ""<\uff5cbegin\u2581of\u2581sentence\uff5c>"", ""eos_token"": ""<\uff5cend\u2581of\u2581sentence\uff5c>"", ""pad_token"": null, ""unk_token"": null, ""chat_template"": ""{% if not add_generation_prompt is defined %}{% set add_generation_prompt = false %}{% endif %}{% set ns = namespace(is_first=false, is_tool=false, is_output_first=true, system_prompt='You are a helpful language and vision assistant. You are able to understand the visual content that the user provides, and assist the user with a variety of tasks using natural language.') %}{%- for message in messages %}{%- if message['role'] == 'system' %}{% set ns.system_prompt = message['content'] %}{% break %}{%- endif %}{%- endfor %}{{ns.system_prompt}}{% if ns.system_prompt %}{{'\n\n'}}{% endif %}{%- for message in messages %}{%- if message['role'] == 'user' %}{{'<|User|>: ' + message['content'] + '\n\n'}}{%- endif %}{%- if message['role'] == 'assistant' and message['content'] is not none %}{% set content = message['content'] %}{% if '</think>' in content %}{% set content = content.split('</think>')[-1] %}{% endif %}{{'<|Assistant|>: ' + content}}{% if add_generation_prompt or '</think>' in content %}{{'<\uff5cend of sentence\uff5c>'}}{% endif %}{%- endif %}{%- endfor -%}{% if add_generation_prompt %}{{'<|Assistant|>:'}}{% endif %}"", ""use_default_system_prompt"": true}}, ""transformers_info"": null, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00001-of-00002.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00002-of-00002.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model.safetensors.index.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='preprocessor_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='processor_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": {""parameters"": {""F16"": 7420434059}, ""total"": 7420434059}, ""security_repo_status"": null, ""lastModified"": ""2025-02-01 13:02:15+00:00"", ""cardData"": ""base_model:\n- deepseek-ai/Janus-Pro-7B\nlibrary_name: mlx\nlicense: mit\nlicense_name: deepseek\nlicense_link: LICENSE\npipeline_tag: any-to-any\ntags:\n- chat"", ""transformersInfo"": null, ""_id"": ""679b1aa77423010f80bfeb02"", ""modelId"": ""wnma3mz/Janus-Pro-7B"", ""usedStorage"": 14840985726}",1,,0,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=wnma3mz/Janus-Pro-7B&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bwnma3mz%2FJanus-Pro-7B%5D(%2Fwnma3mz%2FJanus-Pro-7B)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1
ErenMil/sofa,"---
license: openrail
language:
- en
metrics:
- bleu
base_model:
- deepseek-ai/Janus-Pro-7B
new_version: deepseek-ai/Janus-Pro-7B
pipeline_tag: text-generation
library_name: asteroid
---","{""id"": ""ErenMil/sofa"", ""author"": ""ErenMil"", ""sha"": ""0b5f97948ba3bdf5c67836eaf2473eb05186d1d4"", ""last_modified"": ""2025-01-30 16:56:18+00:00"", ""created_at"": ""2025-01-30 16:52:33+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""asteroid"", ""gguf"": null, ""inference"": null, ""tags"": [""asteroid"", ""text-generation"", ""en"", ""base_model:deepseek-ai/Janus-Pro-7B"", ""base_model:finetune:deepseek-ai/Janus-Pro-7B"", ""license:openrail"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model:\n- deepseek-ai/Janus-Pro-7B\nlanguage:\n- en\nlibrary_name: asteroid\nlicense: openrail\nmetrics:\n- bleu\npipeline_tag: text-generation\nnew_version: deepseek-ai/Janus-Pro-7B"", ""widget_data"": [{""text"": ""My name is Julien and I like to""}, {""text"": ""I like traveling by train because""}, {""text"": ""Paris is an amazing place to visit,""}, {""text"": ""Once upon a time,""}], ""model_index"": null, ""config"": null, ""transformers_info"": null, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-01-30 16:56:18+00:00"", ""cardData"": ""base_model:\n- deepseek-ai/Janus-Pro-7B\nlanguage:\n- en\nlibrary_name: asteroid\nlicense: openrail\nmetrics:\n- bleu\npipeline_tag: text-generation\nnew_version: deepseek-ai/Janus-Pro-7B"", ""transformersInfo"": null, ""_id"": ""679bae515ac87ae960edde28"", ""modelId"": ""ErenMil/sofa"", ""usedStorage"": 0}",1,,0,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=ErenMil/sofa&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5BErenMil%2Fsofa%5D(%2FErenMil%2Fsofa)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1
tulsikopoi/NepAI,"---
license: openrail
datasets:
- NovaSky-AI/Sky-T1_data_17k
language:
- ne
metrics:
- accuracy
- bertscore
- bleu
- bleurt
base_model:
- deepseek-ai/Janus-Pro-7B
new_version: deepseek-ai/DeepSeek-R1
pipeline_tag: image-to-video
library_name: fasttext
tags:
- not-for-all-audiences
---","{""id"": ""tulsikopoi/NepAI"", ""author"": ""tulsikopoi"", ""sha"": ""f3805b2d256459822bccaf648719d2fff0417ea5"", ""last_modified"": ""2025-01-31 07:54:06+00:00"", ""created_at"": ""2025-01-31 07:51:22+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""fasttext"", ""gguf"": null, ""inference"": null, ""tags"": [""fasttext"", ""not-for-all-audiences"", ""image-to-video"", ""ne"", ""dataset:NovaSky-AI/Sky-T1_data_17k"", ""base_model:deepseek-ai/Janus-Pro-7B"", ""base_model:finetune:deepseek-ai/Janus-Pro-7B"", ""license:openrail"", ""region:us""], ""pipeline_tag"": ""image-to-video"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model:\n- deepseek-ai/Janus-Pro-7B\ndatasets:\n- NovaSky-AI/Sky-T1_data_17k\nlanguage:\n- ne\nlibrary_name: fasttext\nlicense: openrail\nmetrics:\n- accuracy\n- bertscore\n- bleu\n- bleurt\npipeline_tag: image-to-video\ntags:\n- not-for-all-audiences\nnew_version: deepseek-ai/DeepSeek-R1"", ""widget_data"": null, ""model_index"": null, ""config"": null, ""transformers_info"": null, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-01-31 07:54:06+00:00"", ""cardData"": ""base_model:\n- deepseek-ai/Janus-Pro-7B\ndatasets:\n- NovaSky-AI/Sky-T1_data_17k\nlanguage:\n- ne\nlibrary_name: fasttext\nlicense: openrail\nmetrics:\n- accuracy\n- bertscore\n- bleu\n- bleurt\npipeline_tag: image-to-video\ntags:\n- not-for-all-audiences\nnew_version: deepseek-ai/DeepSeek-R1"", ""transformersInfo"": null, ""_id"": ""679c80fa6da6fbd8df0384fb"", ""modelId"": ""tulsikopoi/NepAI"", ""usedStorage"": 0}",1,,0,,0,,0,,0,,0
MatiVexx/Roxi,"---
base_model:
- deepseek-ai/Janus-Pro-7B
new_version: deepseek-ai/DeepSeek-R1
pipeline_tag: unconditional-image-generation
license: artistic-2.0
datasets:
- amaye15/NSFW
language:
- pl
metrics:
- character
library_name: fastai
---","{""id"": ""MatiVexx/Roxi"", ""author"": ""MatiVexx"", ""sha"": ""67970beaa74c96a0f7e5541ef5f2d0d5a535afbd"", ""last_modified"": ""2025-02-06 09:02:40+00:00"", ""created_at"": ""2025-02-06 08:58:47+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""fastai"", ""gguf"": null, ""inference"": null, ""tags"": [""fastai"", ""unconditional-image-generation"", ""pl"", ""dataset:amaye15/NSFW"", ""base_model:deepseek-ai/Janus-Pro-7B"", ""base_model:finetune:deepseek-ai/Janus-Pro-7B"", ""license:artistic-2.0"", ""region:us""], ""pipeline_tag"": ""unconditional-image-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model:\n- deepseek-ai/Janus-Pro-7B\ndatasets:\n- amaye15/NSFW\nlanguage:\n- pl\nlibrary_name: fastai\nlicense: artistic-2.0\nmetrics:\n- character\npipeline_tag: unconditional-image-generation\nnew_version: deepseek-ai/DeepSeek-R1"", ""widget_data"": null, ""model_index"": null, ""config"": null, ""transformers_info"": null, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-02-06 09:02:40+00:00"", ""cardData"": ""base_model:\n- deepseek-ai/Janus-Pro-7B\ndatasets:\n- amaye15/NSFW\nlanguage:\n- pl\nlibrary_name: fastai\nlicense: artistic-2.0\nmetrics:\n- character\npipeline_tag: unconditional-image-generation\nnew_version: deepseek-ai/DeepSeek-R1"", ""transformersInfo"": null, ""_id"": ""67a479c70f4436115b3c5eca"", ""modelId"": ""MatiVexx/Roxi"", ""usedStorage"": 0}",1,,0,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=MatiVexx/Roxi&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5BMatiVexx%2FRoxi%5D(%2FMatiVexx%2FRoxi)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1
GgDamn/Testees,"---
license: apache-2.0
datasets:
- ServiceNow-AI/R1-Distill-SFT
- fka/awesome-chatgpt-prompts
- bespokelabs/Bespoke-Stratos-17k
language:
- ru
- en
base_model:
- deepseek-ai/Janus-Pro-7B
---","{""id"": ""GgDamn/Testees"", ""author"": ""GgDamn"", ""sha"": ""28d6b613a62db8d4f9c420dac573a6646bf13970"", ""last_modified"": ""2025-02-06 14:57:23+00:00"", ""created_at"": ""2025-02-06 14:51:43+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": null, ""gguf"": null, ""inference"": null, ""tags"": [""ru"", ""en"", ""dataset:ServiceNow-AI/R1-Distill-SFT"", ""dataset:fka/awesome-chatgpt-prompts"", ""dataset:bespokelabs/Bespoke-Stratos-17k"", ""base_model:deepseek-ai/Janus-Pro-7B"", ""base_model:finetune:deepseek-ai/Janus-Pro-7B"", ""license:apache-2.0"", ""region:us""], ""pipeline_tag"": null, ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model:\n- deepseek-ai/Janus-Pro-7B\ndatasets:\n- ServiceNow-AI/R1-Distill-SFT\n- fka/awesome-chatgpt-prompts\n- bespokelabs/Bespoke-Stratos-17k\nlanguage:\n- ru\n- en\nlicense: apache-2.0"", ""widget_data"": null, ""model_index"": null, ""config"": null, ""transformers_info"": null, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-02-06 14:57:23+00:00"", ""cardData"": ""base_model:\n- deepseek-ai/Janus-Pro-7B\ndatasets:\n- ServiceNow-AI/R1-Distill-SFT\n- fka/awesome-chatgpt-prompts\n- bespokelabs/Bespoke-Stratos-17k\nlanguage:\n- ru\n- en\nlicense: apache-2.0"", ""transformersInfo"": null, ""_id"": ""67a4cc7fe494133c65efc82c"", ""modelId"": ""GgDamn/Testees"", ""usedStorage"": 0}",1,,0,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=GgDamn/Testees&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5BGgDamn%2FTestees%5D(%2FGgDamn%2FTestees)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1
elmasryamr/King,"---
license: afl-3.0
language:
- ar
- en
metrics:
- character
base_model:
- deepseek-ai/Janus-Pro-7B
pipeline_tag: question-answering
---","{""id"": ""elmasryamr/King"", ""author"": ""elmasryamr"", ""sha"": ""f1e902ed944f4aabeb457857b7b2cd837a845101"", ""last_modified"": ""2025-02-08 13:41:09+00:00"", ""created_at"": ""2025-02-08 13:17:41+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": null, ""gguf"": null, ""inference"": null, ""tags"": [""question-answering"", ""ar"", ""en"", ""base_model:deepseek-ai/Janus-Pro-7B"", ""base_model:finetune:deepseek-ai/Janus-Pro-7B"", ""license:afl-3.0"", ""region:us""], ""pipeline_tag"": ""question-answering"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model:\n- deepseek-ai/Janus-Pro-7B\nlanguage:\n- ar\n- en\nlicense: afl-3.0\nmetrics:\n- character\npipeline_tag: question-answering"", ""widget_data"": [{""text"": ""\u0623\u064a\u0646 \u0623\u0633\u0643\u0646\u061f"", ""context"": ""\u0625\u0633\u0645\u064a \u0645\u062d\u0645\u062f \u0648\u0623\u0633\u0643\u0646 \u0641\u064a \u0628\u064a\u0631\u0648\u062a""}, {""text"": ""\u0623\u064a\u0646 \u0623\u0633\u0643\u0646\u061f"", ""context"": ""\u0625\u0633\u0645\u064a \u0633\u0627\u0631\u0647 \u0648\u0623\u0633\u0643\u0646 \u0641\u064a \u0644\u0646\u062f\u0646""}, {""text"": ""\u0645\u0627 \u0627\u0633\u0645\u064a\u061f"", ""context"": ""\u0627\u0633\u0645\u064a \u0633\u0639\u064a\u062f \u0648\u0623\u0633\u0643\u0646 \u0641\u064a \u062d\u064a\u0641\u0627.""}, {""text"": ""\u0645\u0627 \u0644\u0642\u0628 \u062e\u0627\u0644\u062f \u0628\u0646 \u0627\u0644\u0648\u0644\u064a\u062f \u0628\u0627\u0644\u0639\u0631\u0628\u064a\u0629\u061f"", ""context"": ""\u062e\u0627\u0644\u062f \u0628\u0646 \u0627\u0644\u0648\u0644\u064a\u062f \u0645\u0646 \u0623\u0628\u0637\u0627\u0644 \u0648\u0642\u0627\u062f\u0629 \u0627\u0644\u0641\u062a\u062d \u0627\u0644\u0625\u0633\u0644\u0627\u0645\u064a \u0648\u0642\u062f \u062a\u062d\u062f\u062b\u062a \u0639\u0646\u0647 \u0627\u0644\u0644\u063a\u0627\u062a \u0627\u0644\u0625\u0646\u062c\u0644\u064a\u0632\u064a\u0629 \u0648\u0627\u0644\u0641\u0631\u0646\u0633\u064a\u0629 \u0648\u0627\u0644\u0625\u0633\u0628\u0627\u0646\u064a\u0629 \u0648\u0644\u0642\u0628 \u0628\u0633\u064a\u0641 \u0627\u0644\u0644\u0647 \u0627\u0644\u0645\u0633\u0644\u0648\u0644.""}], ""model_index"": null, ""config"": null, ""transformers_info"": null, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-02-08 13:41:09+00:00"", ""cardData"": ""base_model:\n- deepseek-ai/Janus-Pro-7B\nlanguage:\n- ar\n- en\nlicense: afl-3.0\nmetrics:\n- character\npipeline_tag: question-answering"", ""transformersInfo"": null, ""_id"": ""67a75975f9aa0ba571ed69e4"", ""modelId"": ""elmasryamr/King"", ""usedStorage"": 0}",1,,0,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=elmasryamr/King&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Belmasryamr%2FKing%5D(%2Felmasryamr%2FKing)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1
Vito13/Death,"---
license: openrail
datasets:
- simplescaling/s1K
metrics:
- bleu
- brier_score
base_model:
- deepseek-ai/Janus-Pro-7B
new_version: deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B
pipeline_tag: zero-shot-classification
library_name: fastai
tags:
- legal
- code
- text-generation-inference
---","{""id"": ""Vito13/Death"", ""author"": ""Vito13"", ""sha"": ""e10bb6911df16569bababefb6da4aa3ce0f019d4"", ""last_modified"": ""2025-02-15 11:51:26+00:00"", ""created_at"": ""2025-02-15 11:43:45+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""fastai"", ""gguf"": null, ""inference"": null, ""tags"": [""fastai"", ""legal"", ""code"", ""text-generation-inference"", ""zero-shot-classification"", ""dataset:simplescaling/s1K"", ""base_model:deepseek-ai/Janus-Pro-7B"", ""base_model:finetune:deepseek-ai/Janus-Pro-7B"", ""license:openrail"", ""region:us""], ""pipeline_tag"": ""zero-shot-classification"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model:\n- deepseek-ai/Janus-Pro-7B\ndatasets:\n- simplescaling/s1K\nlibrary_name: fastai\nlicense: openrail\nmetrics:\n- bleu\n- brier_score\npipeline_tag: zero-shot-classification\ntags:\n- legal\n- code\n- text-generation-inference\nnew_version: deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B"", ""widget_data"": [{""text"": ""I have a problem with my iphone that needs to be resolved asap!"", ""candidate_labels"": ""urgent, not urgent, phone, tablet, computer"", ""multi_class"": true}, {""text"": ""Last week I upgraded my iOS version and ever since then my phone has been overheating whenever I use your app."", ""candidate_labels"": ""mobile, website, billing, account access"", ""multi_class"": false}, {""text"": ""A new model offers an explanation for how the Galilean satellites formed around the solar system\u2019s largest world. Konstantin Batygin did not set out to solve one of the solar system\u2019s most puzzling mysteries when he went for a run up a hill in Nice, France. Dr. Batygin, a Caltech researcher, best known for his contributions to the search for the solar system\u2019s missing \u201cPlanet Nine,\u201d spotted a beer bottle. At a steep, 20 degree grade, he wondered why it wasn\u2019t rolling down the hill. He realized there was a breeze at his back holding the bottle in place. Then he had a thought that would only pop into the mind of a theoretical astrophysicist: \u201cOh! This is how Europa formed.\u201d Europa is one of Jupiter\u2019s four large Galilean moons. And in a paper published Monday in the Astrophysical Journal, Dr. Batygin and a co-author, Alessandro Morbidelli, a planetary scientist at the C\u00f4te d\u2019Azur Observatory in France, present a theory explaining how some moons form around gas giants like Jupiter and Saturn, suggesting that millimeter-sized grains of hail produced during the solar system\u2019s formation became trapped around these massive worlds, taking shape one at a time into the potentially habitable moons we know today."", ""candidate_labels"": ""space & cosmos, scientific discovery, microbiology, robots, archeology"", ""multi_class"": true}], ""model_index"": null, ""config"": null, ""transformers_info"": null, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-02-15 11:51:26+00:00"", ""cardData"": ""base_model:\n- deepseek-ai/Janus-Pro-7B\ndatasets:\n- simplescaling/s1K\nlibrary_name: fastai\nlicense: openrail\nmetrics:\n- bleu\n- brier_score\npipeline_tag: zero-shot-classification\ntags:\n- legal\n- code\n- text-generation-inference\nnew_version: deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B"", ""transformersInfo"": null, ""_id"": ""67b07df1d2ee8e627d574ac4"", ""modelId"": ""Vito13/Death"", ""usedStorage"": 0}",1,,0,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=Vito13/Death&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5BVito13%2FDeath%5D(%2FVito13%2FDeath)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1
Ferhat591/Kumsal,"---
license: apache-2.0
metrics:
- cer
base_model:
- deepseek-ai/Janus-Pro-7B
new_version: deepseek-ai/DeepSeek-R1
---","{""id"": ""Ferhat591/Kumsal"", ""author"": ""Ferhat591"", ""sha"": ""eec8df84c6fbbae0a2a6fbac440fc12300a90a10"", ""last_modified"": ""2025-02-16 17:51:04+00:00"", ""created_at"": ""2025-02-16 17:49:40+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": null, ""gguf"": null, ""inference"": null, ""tags"": [""base_model:deepseek-ai/Janus-Pro-7B"", ""base_model:finetune:deepseek-ai/Janus-Pro-7B"", ""license:apache-2.0"", ""region:us""], ""pipeline_tag"": null, ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model:\n- deepseek-ai/Janus-Pro-7B\nlicense: apache-2.0\nmetrics:\n- cer\nnew_version: deepseek-ai/DeepSeek-R1"", ""widget_data"": null, ""model_index"": null, ""config"": null, ""transformers_info"": null, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-02-16 17:51:04+00:00"", ""cardData"": ""base_model:\n- deepseek-ai/Janus-Pro-7B\nlicense: apache-2.0\nmetrics:\n- cer\nnew_version: deepseek-ai/DeepSeek-R1"", ""transformersInfo"": null, ""_id"": ""67b22534d6fb180091a41025"", ""modelId"": ""Ferhat591/Kumsal"", ""usedStorage"": 0}",1,,0,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=Ferhat591/Kumsal&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5BFerhat591%2FKumsal%5D(%2FFerhat591%2FKumsal)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1
Smartph90/Activities,"---
license: apache-2.0
datasets:
- fka/awesome-chatgpt-prompts
language:
- am
metrics:
- accuracy
base_model:
- deepseek-ai/Janus-Pro-7B
new_version: deepseek-ai/DeepSeek-V3
pipeline_tag: token-classification
library_name: flair
tags:
- biology
---","{""id"": ""Smartph90/Activities"", ""author"": ""Smartph90"", ""sha"": ""13c19fab32aa6d2762a00bffde529cc3aa58b5e6"", ""last_modified"": ""2025-02-17 23:31:27+00:00"", ""created_at"": ""2025-02-17 23:26:47+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""flair"", ""gguf"": null, ""inference"": null, ""tags"": [""flair"", ""biology"", ""token-classification"", ""am"", ""dataset:fka/awesome-chatgpt-prompts"", ""base_model:deepseek-ai/Janus-Pro-7B"", ""base_model:finetune:deepseek-ai/Janus-Pro-7B"", ""license:apache-2.0"", ""region:us""], ""pipeline_tag"": ""token-classification"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model:\n- deepseek-ai/Janus-Pro-7B\ndatasets:\n- fka/awesome-chatgpt-prompts\nlanguage:\n- am\nlibrary_name: flair\nlicense: apache-2.0\nmetrics:\n- accuracy\npipeline_tag: token-classification\ntags:\n- biology\nnew_version: deepseek-ai/DeepSeek-V3"", ""widget_data"": null, ""model_index"": null, ""config"": null, ""transformers_info"": null, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-02-17 23:31:27+00:00"", ""cardData"": ""base_model:\n- deepseek-ai/Janus-Pro-7B\ndatasets:\n- fka/awesome-chatgpt-prompts\nlanguage:\n- am\nlibrary_name: flair\nlicense: apache-2.0\nmetrics:\n- accuracy\npipeline_tag: token-classification\ntags:\n- biology\nnew_version: deepseek-ai/DeepSeek-V3"", ""transformersInfo"": null, ""_id"": ""67b3c5b73770f4f5d68dec77"", ""modelId"": ""Smartph90/Activities"", ""usedStorage"": 0}",1,,0,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=Smartph90/Activities&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5BSmartph90%2FActivities%5D(%2FSmartph90%2FActivities)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1
Vezel/Data,"---
license: mit
datasets:
- FreedomIntelligence/medical-o1-reasoning-SFT
language:
- en
- ur
- ar
- hi
metrics:
- accuracy
base_model:
- deepseek-ai/Janus-Pro-7B
new_version: deepseek-ai/DeepSeek-R1-Distill-Qwen-32B
pipeline_tag: translation
library_name: diffusers
tags:
- art
- audio
---","{""id"": ""Vezel/Data"", ""author"": ""Vezel"", ""sha"": ""43acd5a99e01494d295f8ec713393152a30b28ae"", ""last_modified"": ""2025-02-18 06:08:39+00:00"", ""created_at"": ""2025-02-18 06:06:56+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""diffusers"", ""gguf"": null, ""inference"": null, ""tags"": [""diffusers"", ""art"", ""audio"", ""translation"", ""en"", ""ur"", ""ar"", ""hi"", ""dataset:FreedomIntelligence/medical-o1-reasoning-SFT"", ""base_model:deepseek-ai/Janus-Pro-7B"", ""base_model:finetune:deepseek-ai/Janus-Pro-7B"", ""license:mit"", ""region:us""], ""pipeline_tag"": ""translation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model:\n- deepseek-ai/Janus-Pro-7B\ndatasets:\n- FreedomIntelligence/medical-o1-reasoning-SFT\nlanguage:\n- en\n- ur\n- ar\n- hi\nlibrary_name: diffusers\nlicense: mit\nmetrics:\n- accuracy\npipeline_tag: translation\ntags:\n- art\n- audio\nnew_version: deepseek-ai/DeepSeek-R1-Distill-Qwen-32B"", ""widget_data"": [{""text"": ""My name is Wolfgang and I live in Berlin""}, {""text"": ""My name is Sarah and I live in London""}], ""model_index"": null, ""config"": null, ""transformers_info"": null, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-02-18 06:08:39+00:00"", ""cardData"": ""base_model:\n- deepseek-ai/Janus-Pro-7B\ndatasets:\n- FreedomIntelligence/medical-o1-reasoning-SFT\nlanguage:\n- en\n- ur\n- ar\n- hi\nlibrary_name: diffusers\nlicense: mit\nmetrics:\n- accuracy\npipeline_tag: translation\ntags:\n- art\n- audio\nnew_version: deepseek-ai/DeepSeek-R1-Distill-Qwen-32B"", ""transformersInfo"": null, ""_id"": ""67b423809ec69437260f6a03"", ""modelId"": ""Vezel/Data"", ""usedStorage"": 0}",1,,0,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=Vezel/Data&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5BVezel%2FData%5D(%2FVezel%2FData)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1
Mandeepmk/Try,"---
license: apache-2.0
language:
- en
metrics:
- bleu
base_model:
- deepseek-ai/Janus-Pro-7B
pipeline_tag: table-question-answering
library_name: allennlp
tags:
- chemistry
---","{""id"": ""Mandeepmk/Try"", ""author"": ""Mandeepmk"", ""sha"": ""f66fd62aa15bc46f9e0becbebe4c6c8482f8b397"", ""last_modified"": ""2025-02-18 15:48:10+00:00"", ""created_at"": ""2025-02-18 15:45:35+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""allennlp"", ""gguf"": null, ""inference"": null, ""tags"": [""allennlp"", ""chemistry"", ""table-question-answering"", ""en"", ""base_model:deepseek-ai/Janus-Pro-7B"", ""base_model:finetune:deepseek-ai/Janus-Pro-7B"", ""license:apache-2.0"", ""region:us""], ""pipeline_tag"": ""table-question-answering"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model:\n- deepseek-ai/Janus-Pro-7B\nlanguage:\n- en\nlibrary_name: allennlp\nlicense: apache-2.0\nmetrics:\n- bleu\npipeline_tag: table-question-answering\ntags:\n- chemistry"", ""widget_data"": [{""text"": ""How many stars does the transformers repository have?"", ""table"": {""Repository"": [""Transformers"", ""Datasets"", ""Tokenizers""], ""Stars"": [36542, 4512, 3934], ""Contributors"": [651, 77, 34], ""Programming language"": [""Python"", ""Python"", ""Rust, Python and NodeJS""]}}], ""model_index"": null, ""config"": null, ""transformers_info"": null, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-02-18 15:48:10+00:00"", ""cardData"": ""base_model:\n- deepseek-ai/Janus-Pro-7B\nlanguage:\n- en\nlibrary_name: allennlp\nlicense: apache-2.0\nmetrics:\n- bleu\npipeline_tag: table-question-answering\ntags:\n- chemistry"", ""transformersInfo"": null, ""_id"": ""67b4ab1f823a72a38c8bc376"", ""modelId"": ""Mandeepmk/Try"", ""usedStorage"": 0}",1,,0,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=Mandeepmk/Try&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5BMandeepmk%2FTry%5D(%2FMandeepmk%2FTry)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1
vilho/gtyfr65,"---
license: apache-2.0
datasets:
- open-r1/OpenR1-Math-220k
language:
- fi
base_model:
- deepseek-ai/Janus-Pro-7B
pipeline_tag: text-generation
tags:
- chemistry
---","{""id"": ""vilho/gtyfr65"", ""author"": ""vilho"", ""sha"": ""e8029ed11754497b615a5035d99aa35d7a7a3ef7"", ""last_modified"": ""2025-02-19 09:32:05+00:00"", ""created_at"": ""2025-02-19 09:30:49+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": null, ""gguf"": null, ""inference"": null, ""tags"": [""chemistry"", ""text-generation"", ""fi"", ""dataset:open-r1/OpenR1-Math-220k"", ""base_model:deepseek-ai/Janus-Pro-7B"", ""base_model:finetune:deepseek-ai/Janus-Pro-7B"", ""license:apache-2.0"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model:\n- deepseek-ai/Janus-Pro-7B\ndatasets:\n- open-r1/OpenR1-Math-220k\nlanguage:\n- fi\nlicense: apache-2.0\npipeline_tag: text-generation\ntags:\n- chemistry"", ""widget_data"": null, ""model_index"": null, ""config"": null, ""transformers_info"": null, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-02-19 09:32:05+00:00"", ""cardData"": ""base_model:\n- deepseek-ai/Janus-Pro-7B\ndatasets:\n- open-r1/OpenR1-Math-220k\nlanguage:\n- fi\nlicense: apache-2.0\npipeline_tag: text-generation\ntags:\n- chemistry"", ""transformersInfo"": null, ""_id"": ""67b5a4c94adadc05e7f48ab8"", ""modelId"": ""vilho/gtyfr65"", ""usedStorage"": 0}",1,,0,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=vilho/gtyfr65&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bvilho%2Fgtyfr65%5D(%2Fvilho%2Fgtyfr65)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1
komalkaur/aysha,"---
license: apache-2.0
datasets:
- fka/awesome-chatgpt-prompts
language:
- en
metrics:
- accuracy
base_model:
- deepseek-ai/Janus-Pro-7B
new_version: deepseek-ai/DeepSeek-R1
pipeline_tag: text-classification
library_name: flair
---","{""id"": ""komalkaur/aysha"", ""author"": ""komalkaur"", ""sha"": ""146be0954e7d364d863c7a590574207833bdac02"", ""last_modified"": ""2025-02-19 14:18:04+00:00"", ""created_at"": ""2025-02-19 14:16:33+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""flair"", ""gguf"": null, ""inference"": null, ""tags"": [""flair"", ""text-classification"", ""en"", ""dataset:fka/awesome-chatgpt-prompts"", ""base_model:deepseek-ai/Janus-Pro-7B"", ""base_model:finetune:deepseek-ai/Janus-Pro-7B"", ""license:apache-2.0"", ""region:us""], ""pipeline_tag"": ""text-classification"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model:\n- deepseek-ai/Janus-Pro-7B\ndatasets:\n- fka/awesome-chatgpt-prompts\nlanguage:\n- en\nlibrary_name: flair\nlicense: apache-2.0\nmetrics:\n- accuracy\npipeline_tag: text-classification\nnew_version: deepseek-ai/DeepSeek-R1"", ""widget_data"": [{""text"": ""I like you. I love you""}], ""model_index"": null, ""config"": null, ""transformers_info"": null, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-02-19 14:18:04+00:00"", ""cardData"": ""base_model:\n- deepseek-ai/Janus-Pro-7B\ndatasets:\n- fka/awesome-chatgpt-prompts\nlanguage:\n- en\nlibrary_name: flair\nlicense: apache-2.0\nmetrics:\n- accuracy\npipeline_tag: text-classification\nnew_version: deepseek-ai/DeepSeek-R1"", ""transformersInfo"": null, ""_id"": ""67b5e7c1ed945e53d058d33b"", ""modelId"": ""komalkaur/aysha"", ""usedStorage"": 0}",1,,0,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=komalkaur/aysha&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bkomalkaur%2Faysha%5D(%2Fkomalkaur%2Faysha)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1
Alvarose/Snchezzz,"---
license: apache-2.0
base_model:
- deepseek-ai/Janus-Pro-7B
pipeline_tag: table-question-answering
tags:
- finance
---","{""id"": ""Alvarose/Snchezzz"", ""author"": ""Alvarose"", ""sha"": ""42a4fd3c297072404b63331ceba0074c0219f8f6"", ""last_modified"": ""2025-02-19 15:38:37+00:00"", ""created_at"": ""2025-02-19 15:37:31+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": null, ""gguf"": null, ""inference"": null, ""tags"": [""finance"", ""table-question-answering"", ""base_model:deepseek-ai/Janus-Pro-7B"", ""base_model:finetune:deepseek-ai/Janus-Pro-7B"", ""license:apache-2.0"", ""region:us""], ""pipeline_tag"": ""table-question-answering"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model:\n- deepseek-ai/Janus-Pro-7B\nlicense: apache-2.0\npipeline_tag: table-question-answering\ntags:\n- finance"", ""widget_data"": [{""text"": ""How many stars does the transformers repository have?"", ""table"": {""Repository"": [""Transformers"", ""Datasets"", ""Tokenizers""], ""Stars"": [36542, 4512, 3934], ""Contributors"": [651, 77, 34], ""Programming language"": [""Python"", ""Python"", ""Rust, Python and NodeJS""]}}], ""model_index"": null, ""config"": null, ""transformers_info"": null, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-02-19 15:38:37+00:00"", ""cardData"": ""base_model:\n- deepseek-ai/Janus-Pro-7B\nlicense: apache-2.0\npipeline_tag: table-question-answering\ntags:\n- finance"", ""transformersInfo"": null, ""_id"": ""67b5fabb0d42b3520de31d25"", ""modelId"": ""Alvarose/Snchezzz"", ""usedStorage"": 0}",1,,0,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=Alvarose/Snchezzz&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5BAlvarose%2FSnchezzz%5D(%2FAlvarose%2FSnchezzz)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1
Dbandz/Elon657,"---
license: apache-2.0
datasets:
- fka/awesome-chatgpt-prompts
language:
- ak
metrics:
- bertscore
base_model:
- deepseek-ai/Janus-Pro-7B
new_version: deepseek-ai/Janus-Pro-7B
pipeline_tag: question-answering
library_name: allennlp
---","{""id"": ""Dbandz/Elon657"", ""author"": ""Dbandz"", ""sha"": ""86b60c15ff513a67234f856bca4ba9378b7e55f0"", ""last_modified"": ""2025-02-22 09:41:17+00:00"", ""created_at"": ""2025-02-22 09:39:52+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""allennlp"", ""gguf"": null, ""inference"": null, ""tags"": [""allennlp"", ""question-answering"", ""ak"", ""dataset:fka/awesome-chatgpt-prompts"", ""base_model:deepseek-ai/Janus-Pro-7B"", ""base_model:finetune:deepseek-ai/Janus-Pro-7B"", ""license:apache-2.0"", ""region:us""], ""pipeline_tag"": ""question-answering"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model:\n- deepseek-ai/Janus-Pro-7B\ndatasets:\n- fka/awesome-chatgpt-prompts\nlanguage:\n- ak\nlibrary_name: allennlp\nlicense: apache-2.0\nmetrics:\n- bertscore\npipeline_tag: question-answering\nnew_version: deepseek-ai/Janus-Pro-7B"", ""widget_data"": null, ""model_index"": null, ""config"": null, ""transformers_info"": null, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-02-22 09:41:17+00:00"", ""cardData"": ""base_model:\n- deepseek-ai/Janus-Pro-7B\ndatasets:\n- fka/awesome-chatgpt-prompts\nlanguage:\n- ak\nlibrary_name: allennlp\nlicense: apache-2.0\nmetrics:\n- bertscore\npipeline_tag: question-answering\nnew_version: deepseek-ai/Janus-Pro-7B"", ""transformersInfo"": null, ""_id"": ""67b99b6857f0429b94e8faed"", ""modelId"": ""Dbandz/Elon657"", ""usedStorage"": 0}",1,,0,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=Dbandz/Elon657&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5BDbandz%2FElon657%5D(%2FDbandz%2FElon657)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1
Kilichnuyy/CHIKIPIKI,"---
license: apache-2.0
datasets:
- fka/awesome-chatgpt-prompts
- open-thoughts/OpenThoughts-114k
language:
- ru
- en
metrics:
- accuracy
base_model:
- deepseek-ai/Janus-Pro-7B
new_version: deepseek-ai/DeepSeek-R1
pipeline_tag: question-answering
library_name: fastai
tags:
- not-for-all-audiences
---","{""id"": ""Kilichnuyy/CHIKIPIKI"", ""author"": ""Kilichnuyy"", ""sha"": ""0370b5da15d037616b485471a7ad0f2c13d353e2"", ""last_modified"": ""2025-02-27 19:18:20+00:00"", ""created_at"": ""2025-02-27 19:16:50+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""fastai"", ""gguf"": null, ""inference"": null, ""tags"": [""fastai"", ""not-for-all-audiences"", ""question-answering"", ""ru"", ""en"", ""dataset:fka/awesome-chatgpt-prompts"", ""dataset:open-thoughts/OpenThoughts-114k"", ""base_model:deepseek-ai/Janus-Pro-7B"", ""base_model:finetune:deepseek-ai/Janus-Pro-7B"", ""license:apache-2.0"", ""region:us""], ""pipeline_tag"": ""question-answering"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model:\n- deepseek-ai/Janus-Pro-7B\ndatasets:\n- fka/awesome-chatgpt-prompts\n- open-thoughts/OpenThoughts-114k\nlanguage:\n- ru\n- en\nlibrary_name: fastai\nlicense: apache-2.0\nmetrics:\n- accuracy\npipeline_tag: question-answering\ntags:\n- not-for-all-audiences\nnew_version: deepseek-ai/DeepSeek-R1"", ""widget_data"": [{""text"": ""\u0413\u0434\u0435 \u0436\u0438\u0432\u0443?"", ""context"": ""\u041c\u0435\u043d\u044f \u0437\u043e\u0432\u0443\u0442 \u0412\u043e\u043b\u044c\u0444\u0433\u0430\u043d\u0433 \u0438 \u044f \u0436\u0438\u0432\u0443 \u0432 \u0411\u0435\u0440\u043b\u0438\u043d\u0435""}], ""model_index"": null, ""config"": null, ""transformers_info"": null, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-02-27 19:18:20+00:00"", ""cardData"": ""base_model:\n- deepseek-ai/Janus-Pro-7B\ndatasets:\n- fka/awesome-chatgpt-prompts\n- open-thoughts/OpenThoughts-114k\nlanguage:\n- ru\n- en\nlibrary_name: fastai\nlicense: apache-2.0\nmetrics:\n- accuracy\npipeline_tag: question-answering\ntags:\n- not-for-all-audiences\nnew_version: deepseek-ai/DeepSeek-R1"", ""transformersInfo"": null, ""_id"": ""67c0ba2201cef6d4b990792d"", ""modelId"": ""Kilichnuyy/CHIKIPIKI"", ""usedStorage"": 0}",1,,0,,0,,0,,0,,0
LulSteph/ScriptWriter,"---
license: creativeml-openrail-m
datasets:
- FreedomIntelligence/medical-o1-reasoning-SFT
- fka/awesome-chatgpt-prompts
- open-thoughts/OpenThoughts-114k
language:
- en
base_model:
- deepseek-ai/Janus-Pro-7B
- perplexity-ai/r1-1776
new_version: microsoft/OmniParser-v2.0
pipeline_tag: question-answering
tags:
- not-for-all-audiences
---
# Model Card for Model ID

<!-- Provide a quick summary of what the model is/does. -->

This modelcard aims to be a base template for new models. It has been generated using [this raw template](https://github.com/huggingface/huggingface_hub/blob/main/src/huggingface_hub/templates/modelcard_template.md?plain=1).

## Model Details

### Model Description

<!-- Provide a longer summary of what this model is. -->



- **Developed by:** [More Information Needed]
- **Funded by [optional]:** [More Information Needed]
- **Shared by [optional]:** [More Information Needed]
- **Model type:** [More Information Needed]
- **Language(s) (NLP):** [More Information Needed]
- **License:** [More Information Needed]
- **Finetuned from model [optional]:** [More Information Needed]

### Model Sources [optional]

<!-- Provide the basic links for the model. -->

- **Repository:** [More Information Needed]
- **Paper [optional]:** [More Information Needed]
- **Demo [optional]:** [More Information Needed]

## Uses

<!-- Address questions around how the model is intended to be used, including the foreseeable users of the model and those affected by the model. -->

### Direct Use

<!-- This section is for the model use without fine-tuning or plugging into a larger ecosystem/app. -->

[More Information Needed]

### Downstream Use [optional]

<!-- This section is for the model use when fine-tuned for a task, or when plugged into a larger ecosystem/app -->

[More Information Needed]

### Out-of-Scope Use

<!-- This section addresses misuse, malicious use, and uses that the model will not work well for. -->

[More Information Needed]

## Bias, Risks, and Limitations

<!-- This section is meant to convey both technical and sociotechnical limitations. -->

[More Information Needed]

### Recommendations

<!-- This section is meant to convey recommendations with respect to the bias, risk, and technical limitations. -->

Users (both direct and downstream) should be made aware of the risks, biases and limitations of the model. More information needed for further recommendations.

## How to Get Started with the Model

Use the code below to get started with the model.

[More Information Needed]

## Training Details

### Training Data

<!-- This should link to a Dataset Card, perhaps with a short stub of information on what the training data is all about as well as documentation related to data pre-processing or additional filtering. -->

[More Information Needed]

### Training Procedure

<!-- This relates heavily to the Technical Specifications. Content here should link to that section when it is relevant to the training procedure. -->

#### Preprocessing [optional]

[More Information Needed]


#### Training Hyperparameters

- **Training regime:** [More Information Needed] <!--fp32, fp16 mixed precision, bf16 mixed precision, bf16 non-mixed precision, fp16 non-mixed precision, fp8 mixed precision -->

#### Speeds, Sizes, Times [optional]

<!-- This section provides information about throughput, start/end time, checkpoint size if relevant, etc. -->

[More Information Needed]

## Evaluation

<!-- This section describes the evaluation protocols and provides the results. -->

### Testing Data, Factors & Metrics

#### Testing Data

<!-- This should link to a Dataset Card if possible. -->

[More Information Needed]

#### Factors

<!-- These are the things the evaluation is disaggregating by, e.g., subpopulations or domains. -->

[More Information Needed]

#### Metrics

<!-- These are the evaluation metrics being used, ideally with a description of why. -->

[More Information Needed]

### Results

[More Information Needed]

#### Summary



## Model Examination [optional]

<!-- Relevant interpretability work for the model goes here -->

[More Information Needed]

## Environmental Impact

<!-- Total emissions (in grams of CO2eq) and additional considerations, such as electricity usage, go here. Edit the suggested text below accordingly -->

Carbon emissions can be estimated using the [Machine Learning Impact calculator](https://mlco2.github.io/impact#compute) presented in [Lacoste et al. (2019)](https://arxiv.org/abs/1910.09700).

- **Hardware Type:** [More Information Needed]
- **Hours used:** [More Information Needed]
- **Cloud Provider:** [More Information Needed]
- **Compute Region:** [More Information Needed]
- **Carbon Emitted:** [More Information Needed]

## Technical Specifications [optional]

### Model Architecture and Objective

[More Information Needed]

### Compute Infrastructure

[More Information Needed]

#### Hardware

[More Information Needed]

#### Software

[More Information Needed]

## Citation [optional]

<!-- If there is a paper or blog post introducing the model, the APA and Bibtex information for that should go in this section. -->

**BibTeX:**

[More Information Needed]

**APA:**

[More Information Needed]

## Glossary [optional]

<!-- If relevant, include terms and calculations in this section that can help readers understand the model or model card. -->

[More Information Needed]

## More Information [optional]

[More Information Needed]

## Model Card Authors [optional]

[More Information Needed]

## Model Card Contact

[More Information Needed]","{""id"": ""LulSteph/ScriptWriter"", ""author"": ""LulSteph"", ""sha"": ""b1528b00e15c276fe8036c23ec3658355f02567c"", ""last_modified"": ""2025-02-27 19:25:59+00:00"", ""created_at"": ""2025-02-27 19:21:39+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": null, ""gguf"": null, ""inference"": null, ""tags"": [""not-for-all-audiences"", ""question-answering"", ""en"", ""dataset:FreedomIntelligence/medical-o1-reasoning-SFT"", ""dataset:fka/awesome-chatgpt-prompts"", ""dataset:open-thoughts/OpenThoughts-114k"", ""arxiv:1910.09700"", ""base_model:deepseek-ai/Janus-Pro-7B"", ""base_model:finetune:deepseek-ai/Janus-Pro-7B"", ""license:creativeml-openrail-m"", ""region:us""], ""pipeline_tag"": ""question-answering"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model:\n- deepseek-ai/Janus-Pro-7B\n- perplexity-ai/r1-1776\ndatasets:\n- FreedomIntelligence/medical-o1-reasoning-SFT\n- fka/awesome-chatgpt-prompts\n- open-thoughts/OpenThoughts-114k\nlanguage:\n- en\nlicense: creativeml-openrail-m\npipeline_tag: question-answering\ntags:\n- not-for-all-audiences\nnew_version: microsoft/OmniParser-v2.0"", ""widget_data"": [{""text"": ""Where do I live?"", ""context"": ""My name is Wolfgang and I live in Berlin""}, {""text"": ""Where do I live?"", ""context"": ""My name is Sarah and I live in London""}, {""text"": ""What's my name?"", ""context"": ""My name is Clara and I live in Berkeley.""}, {""text"": ""Which name is also used to describe the Amazon rainforest in English?"", ""context"": ""The Amazon rainforest (Portuguese: Floresta Amaz\u00f4nica or Amaz\u00f4nia; Spanish: Selva Amaz\u00f3nica, Amazon\u00eda or usually Amazonia; French: For\u00eat amazonienne; Dutch: Amazoneregenwoud), also known in English as Amazonia or the Amazon Jungle, is a moist broadleaf forest that covers most of the Amazon basin of South America. This basin encompasses 7,000,000 square kilometres (2,700,000 sq mi), of which 5,500,000 square kilometres (2,100,000 sq mi) are covered by the rainforest. This region includes territory belonging to nine nations. The majority of the forest is contained within Brazil, with 60% of the rainforest, followed by Peru with 13%, Colombia with 10%, and with minor amounts in Venezuela, Ecuador, Bolivia, Guyana, Suriname and French Guiana. States or departments in four nations contain \""Amazonas\"" in their names. The Amazon represents over half of the planet's remaining rainforests, and comprises the largest and most biodiverse tract of tropical rainforest in the world, with an estimated 390 billion individual trees divided into 16,000 species.""}], ""model_index"": null, ""config"": null, ""transformers_info"": null, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-02-27 19:25:59+00:00"", ""cardData"": ""base_model:\n- deepseek-ai/Janus-Pro-7B\n- perplexity-ai/r1-1776\ndatasets:\n- FreedomIntelligence/medical-o1-reasoning-SFT\n- fka/awesome-chatgpt-prompts\n- open-thoughts/OpenThoughts-114k\nlanguage:\n- en\nlicense: creativeml-openrail-m\npipeline_tag: question-answering\ntags:\n- not-for-all-audiences\nnew_version: microsoft/OmniParser-v2.0"", ""transformersInfo"": null, ""_id"": ""67c0bb4360f914064b7c5a41"", ""modelId"": ""LulSteph/ScriptWriter"", ""usedStorage"": 0}",1,,0,,0,,0,,0,,0
trancoso-cc/gibberish-detector,"---
tags:
- autonlp
language: en
widget:
- text: I love Machine Learning!
datasets:
- madhurjindal/autonlp-data-Gibberish-Detector
co2_eq_emissions: 5.527544460835904
license: mit
metrics:
- bertscore
base_model:
- deepseek-ai/Janus-Pro-7B
new_version: deepseek-ai/DeepSeek-V3
library_name: transformers
---

# Problem Description
The ability to process and understand user input is crucial for various applications, such as chatbots or downstream tasks. However, a common challenge faced in such systems is the presence of gibberish or nonsensical input. To address this problem, we present a project focused on developing a gibberish detector for the English language.
The primary goal of this project is to classify user input as either **gibberish** or **non-gibberish**, enabling more accurate and meaningful interactions with the system. We also aim to enhance the overall performance and user experience of chatbots and other systems that rely on user input.

>## What is Gibberish?
Gibberish refers to **nonsensical or meaningless language or text** that lacks coherence or any discernible meaning. It can be characterized by a combination of random words, nonsensical phrases, grammatical errors, or syntactical abnormalities that prevent the communication from conveying a clear and understandable message. Gibberish can vary in intensity, ranging from simple noise with no meaningful words to sentences that may appear superficially correct but lack coherence or logical structure when examined closely. Detecting and identifying gibberish is essential in various contexts, such as **natural language processing**, **chatbot systems**, **spam filtering**, and **language-based security measures**, to ensure effective communication and accurate processing of user inputs.

## Label Description
Thus, we break down the problem into 4 categories:

1. **Noise:** Gibberish at the zero level where even the different constituents of the input phrase (words) do not hold any meaning independently.  
   *For example: `dfdfer fgerfow2e0d qsqskdsd djksdnfkff swq.`*
   
2. **Word Salad:** Gibberish at level 1 where words make sense independently, but when looked at the bigger picture (the phrase) any meaning is not depicted.  
   *For example: `22 madhur old punjab pickle chennai`*

3. **Mild gibberish:** Gibberish at level 2 where there is a part of the sentence that has grammatical errors, word sense errors, or any syntactical abnormalities, which leads the sentence to miss out on a coherent meaning.  
   *For example: `Madhur study in a teacher`*

4. **Clean:** This category represents a set of words that form a complete and meaningful sentence on its own.  
   *For example: `I love this website`*

> **Tip:** To facilitate gibberish detection, you can combine the labels based on the desired level of detection. For instance, if you need to detect gibberish at level 1, you can group Noise and Word Salad together as ""Gibberish,"" while considering Mild gibberish and Clean separately as ""NotGibberish."" This approach allows for flexibility in detecting and categorizing different levels of gibberish based on specific requirements.


# Model Trained Using AutoNLP

- Problem type: Multi-class Classification
- Model ID: 492513457
- CO2 Emissions (in grams): 5.527544460835904

## Validation Metrics

- Loss: 0.07609463483095169
- Accuracy: 0.9735624586913417
- Macro F1: 0.9736173135739408
- Micro F1: 0.9735624586913417
- Weighted F1: 0.9736173135739408
- Macro Precision: 0.9737771415197378
- Micro Precision: 0.9735624586913417
- Weighted Precision: 0.9737771415197378
- Macro Recall: 0.9735624586913417
- Micro Recall: 0.9735624586913417
- Weighted Recall: 0.9735624586913417


## Usage

You can use cURL to access this model:

```
$ curl -X POST -H ""Authorization: Bearer YOUR_API_KEY"" -H ""Content-Type: application/json"" -d '{""inputs"": ""I love Machine Learning!""}' https://api-inference.huggingface.co/models/madhurjindal/autonlp-Gibberish-Detector-492513457
```

Or Python API:

```
import torch
import torch.nn.functional as F
from transformers import AutoModelForSequenceClassification, AutoTokenizer

model = AutoModelForSequenceClassification.from_pretrained(""madhurjindal/autonlp-Gibberish-Detector-492513457"", use_auth_token=True)

tokenizer = AutoTokenizer.from_pretrained(""madhurjindal/autonlp-Gibberish-Detector-492513457"", use_auth_token=True)

inputs = tokenizer(""I love Machine Learning!"", return_tensors=""pt"")

outputs = model(**inputs)

probs = F.softmax(outputs.logits, dim=-1)

predicted_index = torch.argmax(probs, dim=1).item()

predicted_prob = probs[0][predicted_index].item()

labels = model.config.id2label

predicted_label = labels[predicted_index]

for i, prob in enumerate(probs[0]):
    print(f""Class: {labels[i]}, Probability: {prob:.4f}"")
```

Another simplifed solution with transformers pipline:

```
from transformers import pipeline
selected_model = ""madhurjindal/autonlp-Gibberish-Detector-492513457""
classifier = pipeline(""text-classification"", model=selected_model)
classifier(""I love Machine Learning!"")
```","{""id"": ""trancoso-cc/gibberish-detector"", ""author"": ""trancoso-cc"", ""sha"": ""75c5d15fa3ed70b5b7e124cccd6b95b7bcfd3ef9"", ""last_modified"": ""2025-02-27 19:38:16+00:00"", ""created_at"": ""2025-02-27 19:35:55+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 15, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""pytorch"", ""safetensors"", ""distilbert"", ""text-classification"", ""autonlp"", ""en"", ""dataset:madhurjindal/autonlp-data-Gibberish-Detector"", ""base_model:deepseek-ai/Janus-Pro-7B"", ""base_model:finetune:deepseek-ai/Janus-Pro-7B"", ""license:mit"", ""co2_eq_emissions"", ""autotrain_compatible"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-classification"", ""mask_token"": ""[MASK]"", ""trending_score"": null, ""card_data"": ""base_model:\n- deepseek-ai/Janus-Pro-7B\ndatasets:\n- madhurjindal/autonlp-data-Gibberish-Detector\nlanguage: en\nlibrary_name: transformers\nlicense: mit\nmetrics:\n- bertscore\ntags:\n- autonlp\nwidget:\n- text: I love Machine Learning!\nco2_eq_emissions: 5.527544460835904\nnew_version: deepseek-ai/DeepSeek-V3"", ""widget_data"": [{""text"": ""I love Machine Learning!""}], ""model_index"": null, ""config"": {""architectures"": [""DistilBertForSequenceClassification""], ""model_type"": ""distilbert"", ""tokenizer_config"": {""unk_token"": ""[UNK]"", ""sep_token"": ""[SEP]"", ""pad_token"": ""[PAD]"", ""cls_token"": ""[CLS]"", ""mask_token"": ""[MASK]""}}, ""transformers_info"": {""auto_model"": ""AutoModelForSequenceClassification"", ""custom_class"": null, ""pipeline_tag"": ""text-classification"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='pytorch_model.bin', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='sample_input.pkl', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='vocab.txt', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": {""parameters"": {""F32"": 66956548}, ""total"": 66956548}, ""security_repo_status"": null, ""lastModified"": ""2025-02-27 19:38:16+00:00"", ""cardData"": ""base_model:\n- deepseek-ai/Janus-Pro-7B\ndatasets:\n- madhurjindal/autonlp-data-Gibberish-Detector\nlanguage: en\nlibrary_name: transformers\nlicense: mit\nmetrics:\n- bertscore\ntags:\n- autonlp\nwidget:\n- text: I love Machine Learning!\nco2_eq_emissions: 5.527544460835904\nnew_version: deepseek-ai/DeepSeek-V3"", ""transformersInfo"": {""auto_model"": ""AutoModelForSequenceClassification"", ""custom_class"": null, ""pipeline_tag"": ""text-classification"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67c0be9b4487c82f8b1a51a5"", ""modelId"": ""trancoso-cc/gibberish-detector"", ""usedStorage"": 535704945}",1,,0,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=trancoso-cc/gibberish-detector&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Btrancoso-cc%2Fgibberish-detector%5D(%2Ftrancoso-cc%2Fgibberish-detector)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1
Ammihammi/camile_vero,"---
license: ms-pl
language:
- en
base_model:
- deepseek-ai/Janus-Pro-7B
---","{""id"": ""Ammihammi/camile_vero"", ""author"": ""Ammihammi"", ""sha"": ""b257b7af6b4ea4f53d8b168a163afc13a88ac600"", ""last_modified"": ""2025-03-01 08:43:27+00:00"", ""created_at"": ""2025-03-01 00:50:17+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": null, ""gguf"": null, ""inference"": null, ""tags"": [""en"", ""base_model:deepseek-ai/Janus-Pro-7B"", ""base_model:finetune:deepseek-ai/Janus-Pro-7B"", ""license:ms-pl"", ""region:us""], ""pipeline_tag"": null, ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model:\n- deepseek-ai/Janus-Pro-7B\nlanguage:\n- en\nlicense: ms-pl"", ""widget_data"": null, ""model_index"": null, ""config"": null, ""transformers_info"": null, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='IMG_0236.jpeg', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='IMG_0238.jpeg', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='IMG_1151.jpeg', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-03-01 08:43:27+00:00"", ""cardData"": ""base_model:\n- deepseek-ai/Janus-Pro-7B\nlanguage:\n- en\nlicense: ms-pl"", ""transformersInfo"": null, ""_id"": ""67c259c95c7b90213559bc11"", ""modelId"": ""Ammihammi/camile_vero"", ""usedStorage"": 909830}",1,,0,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=Ammihammi/camile_vero&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5BAmmihammi%2Fcamile_vero%5D(%2FAmmihammi%2Fcamile_vero)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1
Vinayak9000/DHAIRYA,"---
license: mit
datasets:
- open-thoughts/OpenThoughts-114k
- PJMixers-Dev/open-thoughts_OpenThoughts-114k-CustomShareGPT
metrics:
- accuracy
base_model:
- deepseek-ai/Janus-Pro-7B
- hexgrad/Kokoro-82M
---","{""id"": ""Vinayak9000/DHAIRYA"", ""author"": ""Vinayak9000"", ""sha"": ""67c264576fe91dc16314ffd91e6129ff409986c4"", ""last_modified"": ""2025-03-01 14:41:05+00:00"", ""created_at"": ""2025-03-01 14:39:51+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": null, ""gguf"": null, ""inference"": null, ""tags"": [""dataset:open-thoughts/OpenThoughts-114k"", ""dataset:PJMixers-Dev/open-thoughts_OpenThoughts-114k-CustomShareGPT"", ""base_model:deepseek-ai/Janus-Pro-7B"", ""base_model:finetune:deepseek-ai/Janus-Pro-7B"", ""license:mit"", ""region:us""], ""pipeline_tag"": null, ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model:\n- deepseek-ai/Janus-Pro-7B\n- hexgrad/Kokoro-82M\ndatasets:\n- open-thoughts/OpenThoughts-114k\n- PJMixers-Dev/open-thoughts_OpenThoughts-114k-CustomShareGPT\nlicense: mit\nmetrics:\n- accuracy"", ""widget_data"": null, ""model_index"": null, ""config"": null, ""transformers_info"": null, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-03-01 14:41:05+00:00"", ""cardData"": ""base_model:\n- deepseek-ai/Janus-Pro-7B\n- hexgrad/Kokoro-82M\ndatasets:\n- open-thoughts/OpenThoughts-114k\n- PJMixers-Dev/open-thoughts_OpenThoughts-114k-CustomShareGPT\nlicense: mit\nmetrics:\n- accuracy"", ""transformersInfo"": null, ""_id"": ""67c31c371760da078598c269"", ""modelId"": ""Vinayak9000/DHAIRYA"", ""usedStorage"": 0}",1,,0,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=Vinayak9000/DHAIRYA&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5BVinayak9000%2FDHAIRYA%5D(%2FVinayak9000%2FDHAIRYA)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1
mlmecham/watch-your-toes,"---
license: mit
base_model:
- deepseek-ai/Janus-Pro-7B
---","{""id"": ""mlmecham/watch-your-toes"", ""author"": ""mlmecham"", ""sha"": ""11ef61a0d947b6936aecff6426b79bf6e85a386c"", ""last_modified"": ""2025-03-06 00:07:11+00:00"", ""created_at"": ""2025-03-06 00:05:41+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": null, ""gguf"": null, ""inference"": null, ""tags"": [""base_model:deepseek-ai/Janus-Pro-7B"", ""base_model:finetune:deepseek-ai/Janus-Pro-7B"", ""license:mit"", ""region:us""], ""pipeline_tag"": null, ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model:\n- deepseek-ai/Janus-Pro-7B\nlicense: mit"", ""widget_data"": null, ""model_index"": null, ""config"": null, ""transformers_info"": null, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-03-06 00:07:11+00:00"", ""cardData"": ""base_model:\n- deepseek-ai/Janus-Pro-7B\nlicense: mit"", ""transformersInfo"": null, ""_id"": ""67c8e6d5130ba886873a4da4"", ""modelId"": ""mlmecham/watch-your-toes"", ""usedStorage"": 0}",1,,0,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=mlmecham/watch-your-toes&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bmlmecham%2Fwatch-your-toes%5D(%2Fmlmecham%2Fwatch-your-toes)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1

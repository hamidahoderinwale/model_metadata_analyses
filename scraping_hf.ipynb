{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hamidahoderinwale/model_metadata_analyses/blob/main/scraping_hf.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Script 1\n",
        "Takes in a (validated) model url and output its metadata"
      ],
      "metadata": {
        "id": "cxlHKer226vF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Fmp0ftEomk86",
        "outputId": "619a4760-8142-49c5-eb4a-299ceb958e99"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting validators\n",
            "  Downloading validators-0.34.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Downloading validators-0.34.0-py3-none-any.whl (43 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/43.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.5/43.5 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: validators\n",
            "Successfully installed validators-0.34.0\n",
            "Enter model URL: https://huggingface.co/deepseek-ai/DeepSeek-R1\n",
            "You entered: https://huggingface.co/deepseek-ai/DeepSeek-R1\n",
            "{\n",
            "    \"id\": \"deepseek-ai/DeepSeek-R1\",\n",
            "    \"author\": \"deepseek-ai\",\n",
            "    \"sha\": \"a157fa3d494497a54586a333a23df6c2143e7697\",\n",
            "    \"last_modified\": \"2025-02-24 03:30:31+00:00\",\n",
            "    \"created_at\": \"2025-01-20 03:46:07+00:00\",\n",
            "    \"private\": false,\n",
            "    \"gated\": false,\n",
            "    \"disabled\": false,\n",
            "    \"downloads\": 1733502,\n",
            "    \"downloads_all_time\": null,\n",
            "    \"likes\": 11522,\n",
            "    \"library_name\": \"transformers\",\n",
            "    \"gguf\": null,\n",
            "    \"inference\": \"warm\",\n",
            "    \"inference_provider_mapping\": null,\n",
            "    \"tags\": [\n",
            "        \"transformers\",\n",
            "        \"safetensors\",\n",
            "        \"deepseek_v3\",\n",
            "        \"text-generation\",\n",
            "        \"conversational\",\n",
            "        \"custom_code\",\n",
            "        \"arxiv:2501.12948\",\n",
            "        \"license:mit\",\n",
            "        \"autotrain_compatible\",\n",
            "        \"fp8\",\n",
            "        \"region:us\"\n",
            "    ],\n",
            "    \"pipeline_tag\": \"text-generation\",\n",
            "    \"mask_token\": null,\n",
            "    \"trending_score\": null,\n",
            "    \"card_data\": \"library_name: transformers\\nlicense: mit\",\n",
            "    \"widget_data\": [\n",
            "        {\n",
            "            \"text\": \"Hi, what can you help me with?\"\n",
            "        },\n",
            "        {\n",
            "            \"text\": \"What is 84 * 3 / 2?\"\n",
            "        },\n",
            "        {\n",
            "            \"text\": \"Tell me an interesting fact about the universe!\"\n",
            "        },\n",
            "        {\n",
            "            \"text\": \"Explain quantum computing in simple terms.\"\n",
            "        }\n",
            "    ],\n",
            "    \"model_index\": null,\n",
            "    \"config\": {\n",
            "        \"architectures\": [\n",
            "            \"DeepseekV3ForCausalLM\"\n",
            "        ],\n",
            "        \"auto_map\": {\n",
            "            \"AutoConfig\": \"configuration_deepseek.DeepseekV3Config\",\n",
            "            \"AutoModel\": \"modeling_deepseek.DeepseekV3Model\",\n",
            "            \"AutoModelForCausalLM\": \"modeling_deepseek.DeepseekV3ForCausalLM\"\n",
            "        },\n",
            "        \"model_type\": \"deepseek_v3\",\n",
            "        \"quantization_config\": {\n",
            "            \"quant_method\": \"fp8\"\n",
            "        },\n",
            "        \"tokenizer_config\": {\n",
            "            \"bos_token\": {\n",
            "                \"__type\": \"AddedToken\",\n",
            "                \"content\": \"<\\uff5cbegin\\u2581of\\u2581sentence\\uff5c>\",\n",
            "                \"lstrip\": false,\n",
            "                \"normalized\": true,\n",
            "                \"rstrip\": false,\n",
            "                \"single_word\": false\n",
            "            },\n",
            "            \"eos_token\": {\n",
            "                \"__type\": \"AddedToken\",\n",
            "                \"content\": \"<\\uff5cend\\u2581of\\u2581sentence\\uff5c>\",\n",
            "                \"lstrip\": false,\n",
            "                \"normalized\": true,\n",
            "                \"rstrip\": false,\n",
            "                \"single_word\": false\n",
            "            },\n",
            "            \"pad_token\": {\n",
            "                \"__type\": \"AddedToken\",\n",
            "                \"content\": \"<\\uff5cend\\u2581of\\u2581sentence\\uff5c>\",\n",
            "                \"lstrip\": false,\n",
            "                \"normalized\": true,\n",
            "                \"rstrip\": false,\n",
            "                \"single_word\": false\n",
            "            },\n",
            "            \"unk_token\": null,\n",
            "            \"chat_template\": \"{% if not add_generation_prompt is defined %}{% set add_generation_prompt = false %}{% endif %}{% set ns = namespace(is_first=false, is_tool=false, is_output_first=true, system_prompt='', is_first_sp=true) %}{%- for message in messages %}{%- if message['role'] == 'system' %}{%- if ns.is_first_sp %}{% set ns.system_prompt = ns.system_prompt + message['content'] %}{% set ns.is_first_sp = false %}{%- else %}{% set ns.system_prompt = ns.system_prompt + '\\\\n\\\\n' + message['content'] %}{%- endif %}{%- endif %}{%- endfor %}{{ bos_token }}{{ ns.system_prompt }}{%- for message in messages %}{%- if message['role'] == 'user' %}{%- set ns.is_tool = false -%}{{'<\\uff5cUser\\uff5c>' + message['content']}}{%- endif %}{%- if message['role'] == 'assistant' and 'tool_calls' in message %}{%- set ns.is_tool = false -%}{%- for tool in message['tool_calls'] %}{%- if not ns.is_first %}{%- if message['content'] is none %}{{'<\\uff5cAssistant\\uff5c><\\uff5ctool\\u2581calls\\u2581begin\\uff5c><\\uff5ctool\\u2581call\\u2581begin\\uff5c>' + tool['type'] + '<\\uff5ctool\\u2581sep\\uff5c>' + tool['function']['name'] + '\\\\n' + '```json' + '\\\\n' + tool['function']['arguments'] + '\\\\n' + '```' + '<\\uff5ctool\\u2581call\\u2581end\\uff5c>'}}{%- else %}{{'<\\uff5cAssistant\\uff5c>' + message['content'] + '<\\uff5ctool\\u2581calls\\u2581begin\\uff5c><\\uff5ctool\\u2581call\\u2581begin\\uff5c>' + tool['type'] + '<\\uff5ctool\\u2581sep\\uff5c>' + tool['function']['name'] + '\\\\n' + '```json' + '\\\\n' + tool['function']['arguments'] + '\\\\n' + '```' + '<\\uff5ctool\\u2581call\\u2581end\\uff5c>'}}{%- endif %}{%- set ns.is_first = true -%}{%- else %}{{'\\\\n' + '<\\uff5ctool\\u2581call\\u2581begin\\uff5c>' + tool['type'] + '<\\uff5ctool\\u2581sep\\uff5c>' + tool['function']['name'] + '\\\\n' + '```json' + '\\\\n' + tool['function']['arguments'] + '\\\\n' + '```' + '<\\uff5ctool\\u2581call\\u2581end\\uff5c>'}}{%- endif %}{%- endfor %}{{'<\\uff5ctool\\u2581calls\\u2581end\\uff5c><\\uff5cend\\u2581of\\u2581sentence\\uff5c>'}}{%- endif %}{%- if message['role'] == 'assistant' and 'tool_calls' not in message %}{%- if ns.is_tool %}{{'<\\uff5ctool\\u2581outputs\\u2581end\\uff5c>' + message['content'] + '<\\uff5cend\\u2581of\\u2581sentence\\uff5c>'}}{%- set ns.is_tool = false -%}{%- else %}{% set content = message['content'] %}{% if '</think>' in content %}{% set content = content.split('</think>')[-1] %}{% endif %}{{'<\\uff5cAssistant\\uff5c>' + content + '<\\uff5cend\\u2581of\\u2581sentence\\uff5c>'}}{%- endif %}{%- endif %}{%- if message['role'] == 'tool' %}{%- set ns.is_tool = true -%}{%- if ns.is_output_first %}{{'<\\uff5ctool\\u2581outputs\\u2581begin\\uff5c><\\uff5ctool\\u2581output\\u2581begin\\uff5c>' + message['content'] + '<\\uff5ctool\\u2581output\\u2581end\\uff5c>'}}{%- set ns.is_output_first = false %}{%- else %}{{'<\\uff5ctool\\u2581output\\u2581begin\\uff5c>' + message['content'] + '<\\uff5ctool\\u2581output\\u2581end\\uff5c>'}}{%- endif %}{%- endif %}{%- endfor -%}{% if ns.is_tool %}{{'<\\uff5ctool\\u2581outputs\\u2581end\\uff5c>'}}{% endif %}{% if add_generation_prompt and not ns.is_tool %}{{'<\\uff5cAssistant\\uff5c><think>\\\\n'}}{% endif %}\"\n",
            "        }\n",
            "    },\n",
            "    \"transformers_info\": {\n",
            "        \"auto_model\": \"AutoModelForCausalLM\",\n",
            "        \"custom_class\": \"modeling_deepseek.DeepseekV3ForCausalLM\",\n",
            "        \"pipeline_tag\": \"text-generation\",\n",
            "        \"processor\": null\n",
            "    },\n",
            "    \"siblings\": [\n",
            "        \"RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='LICENSE', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='configuration_deepseek.py', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='figures/benchmark.jpg', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='generation_config.json', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='model-00001-of-000163.safetensors', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='model-00002-of-000163.safetensors', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='model-00003-of-000163.safetensors', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='model-00004-of-000163.safetensors', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='model-00005-of-000163.safetensors', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='model-00006-of-000163.safetensors', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='model-00007-of-000163.safetensors', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='model-00008-of-000163.safetensors', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='model-00009-of-000163.safetensors', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='model-00010-of-000163.safetensors', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='model-00011-of-000163.safetensors', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='model-00012-of-000163.safetensors', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='model-00013-of-000163.safetensors', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='model-00014-of-000163.safetensors', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='model-00015-of-000163.safetensors', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='model-00016-of-000163.safetensors', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='model-00017-of-000163.safetensors', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='model-00018-of-000163.safetensors', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='model-00019-of-000163.safetensors', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='model-00020-of-000163.safetensors', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='model-00021-of-000163.safetensors', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='model-00022-of-000163.safetensors', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='model-00023-of-000163.safetensors', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='model-00024-of-000163.safetensors', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='model-00025-of-000163.safetensors', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='model-00026-of-000163.safetensors', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='model-00027-of-000163.safetensors', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='model-00028-of-000163.safetensors', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='model-00029-of-000163.safetensors', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='model-00030-of-000163.safetensors', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='model-00031-of-000163.safetensors', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='model-00032-of-000163.safetensors', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='model-00033-of-000163.safetensors', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='model-00034-of-000163.safetensors', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='model-00035-of-000163.safetensors', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='model-00036-of-000163.safetensors', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='model-00037-of-000163.safetensors', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='model-00038-of-000163.safetensors', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='model-00039-of-000163.safetensors', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='model-00040-of-000163.safetensors', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='model-00041-of-000163.safetensors', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='model-00042-of-000163.safetensors', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='model-00043-of-000163.safetensors', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='model-00044-of-000163.safetensors', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='model-00045-of-000163.safetensors', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='model-00046-of-000163.safetensors', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='model-00047-of-000163.safetensors', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='model-00048-of-000163.safetensors', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='model-00049-of-000163.safetensors', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='model-00050-of-000163.safetensors', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='model-00051-of-000163.safetensors', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='model-00052-of-000163.safetensors', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='model-00053-of-000163.safetensors', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='model-00054-of-000163.safetensors', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='model-00055-of-000163.safetensors', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='model-00056-of-000163.safetensors', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='model-00057-of-000163.safetensors', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='model-00058-of-000163.safetensors', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='model-00059-of-000163.safetensors', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='model-00060-of-000163.safetensors', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='model-00061-of-000163.safetensors', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='model-00062-of-000163.safetensors', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='model-00063-of-000163.safetensors', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='model-00064-of-000163.safetensors', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='model-00065-of-000163.safetensors', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='model-00066-of-000163.safetensors', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='model-00067-of-000163.safetensors', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='model-00068-of-000163.safetensors', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='model-00069-of-000163.safetensors', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='model-00070-of-000163.safetensors', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='model-00071-of-000163.safetensors', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='model-00072-of-000163.safetensors', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='model-00073-of-000163.safetensors', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='model-00074-of-000163.safetensors', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='model-00075-of-000163.safetensors', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='model-00076-of-000163.safetensors', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='model-00077-of-000163.safetensors', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='model-00078-of-000163.safetensors', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='model-00079-of-000163.safetensors', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='model-00080-of-000163.safetensors', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='model-00081-of-000163.safetensors', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='model-00082-of-000163.safetensors', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='model-00083-of-000163.safetensors', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='model-00084-of-000163.safetensors', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='model-00085-of-000163.safetensors', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='model-00086-of-000163.safetensors', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='model-00087-of-000163.safetensors', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='model-00088-of-000163.safetensors', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='model-00089-of-000163.safetensors', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='model-00090-of-000163.safetensors', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='model-00091-of-000163.safetensors', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='model-00092-of-000163.safetensors', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='model-00093-of-000163.safetensors', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='model-00094-of-000163.safetensors', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='model-00095-of-000163.safetensors', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='model-00096-of-000163.safetensors', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='model-00097-of-000163.safetensors', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='model-00098-of-000163.safetensors', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='model-00099-of-000163.safetensors', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='model-00100-of-000163.safetensors', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='model-00101-of-000163.safetensors', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='model-00102-of-000163.safetensors', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='model-00103-of-000163.safetensors', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='model-00104-of-000163.safetensors', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='model-00105-of-000163.safetensors', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='model-00106-of-000163.safetensors', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='model-00107-of-000163.safetensors', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='model-00108-of-000163.safetensors', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='model-00109-of-000163.safetensors', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='model-00110-of-000163.safetensors', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='model-00111-of-000163.safetensors', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='model-00112-of-000163.safetensors', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='model-00113-of-000163.safetensors', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='model-00114-of-000163.safetensors', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='model-00115-of-000163.safetensors', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='model-00116-of-000163.safetensors', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='model-00117-of-000163.safetensors', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='model-00118-of-000163.safetensors', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='model-00119-of-000163.safetensors', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='model-00120-of-000163.safetensors', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='model-00121-of-000163.safetensors', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='model-00122-of-000163.safetensors', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='model-00123-of-000163.safetensors', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='model-00124-of-000163.safetensors', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='model-00125-of-000163.safetensors', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='model-00126-of-000163.safetensors', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='model-00127-of-000163.safetensors', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='model-00128-of-000163.safetensors', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='model-00129-of-000163.safetensors', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='model-00130-of-000163.safetensors', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='model-00131-of-000163.safetensors', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='model-00132-of-000163.safetensors', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='model-00133-of-000163.safetensors', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='model-00134-of-000163.safetensors', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='model-00135-of-000163.safetensors', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='model-00136-of-000163.safetensors', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='model-00137-of-000163.safetensors', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='model-00138-of-000163.safetensors', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='model-00139-of-000163.safetensors', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='model-00140-of-000163.safetensors', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='model-00141-of-000163.safetensors', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='model-00142-of-000163.safetensors', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='model-00143-of-000163.safetensors', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='model-00144-of-000163.safetensors', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='model-00145-of-000163.safetensors', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='model-00146-of-000163.safetensors', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='model-00147-of-000163.safetensors', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='model-00148-of-000163.safetensors', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='model-00149-of-000163.safetensors', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='model-00150-of-000163.safetensors', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='model-00151-of-000163.safetensors', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='model-00152-of-000163.safetensors', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='model-00153-of-000163.safetensors', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='model-00154-of-000163.safetensors', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='model-00155-of-000163.safetensors', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='model-00156-of-000163.safetensors', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='model-00157-of-000163.safetensors', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='model-00158-of-000163.safetensors', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='model-00159-of-000163.safetensors', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='model-00160-of-000163.safetensors', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='model-00161-of-000163.safetensors', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='model-00162-of-000163.safetensors', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='model-00163-of-000163.safetensors', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='model.safetensors.index.json', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='modeling_deepseek.py', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)\",\n",
            "        \"RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)\"\n",
            "    ],\n",
            "    \"spaces\": [\n",
            "        \"akhaliq/anychat\",\n",
            "        \"llamameta/DeepSeek-R1-Chat-Assistant-Web-Search\",\n",
            "        \"openfree/deepseek_r1_API\",\n",
            "        \"seawolf2357/DeepSeek-R1-32b-search\",\n",
            "        \"Intelligent-Internet/CoT-Lab\",\n",
            "        \"ruslanmv/DeepSeek-R1-Chatbot\",\n",
            "        \"KBaba7/Quant\",\n",
            "        \"fdaudens/deepseek-download-stats\",\n",
            "        \"Dima123e/deepseek-ai-DeepSeek-R1\",\n",
            "        \"awacke1/Deepseek-HPC-GPU-KEDA\",\n",
            "        \"totolook/Quant\",\n",
            "        \"openfree/DeepSeek-R1-32b-api\",\n",
            "        \"bhaskartripathi/LLM_Quantization\",\n",
            "        \"McLoviniTtt/Reasoner4All\",\n",
            "        \"FallnAI/Quantize-HF-Models\",\n",
            "        \"AMKhakbaz/AMKAPP\",\n",
            "        \"DvorakInnovationAI/Brain-Stroming-Story-Gen\",\n",
            "        \"ehagey/LLM_Healthcare_Benchmarking\",\n",
            "        \"levalencia/deepseek_togetherai_streamlit\",\n",
            "        \"drdro1/First_agent_template\",\n",
            "        \"UltraRonin/LR2Bench_old\",\n",
            "        \"victor/deepseek-ai-DeepSeek-R1\",\n",
            "        \"victor/deepseek-ai-DeepSeek-R12\",\n",
            "        \"barttee/tokenizers\",\n",
            "        \"UltraRonin/LR2Bench\",\n",
            "        \"BarBar288/Chatbot\",\n",
            "        \"thanhkt/text2manim\",\n",
            "        \"ruslanmv/convert_to_gguf\",\n",
            "        \"manojdahal191gom/deepseek-ai-DeepSeek-R1\",\n",
            "        \"Payknayk/deepseekaiR1\",\n",
            "        \"rautakshay136/deepseek-ai-DeepSeek-R1\",\n",
            "        \"Uener/deepseek-ai-DeepSeek-R1\",\n",
            "        \"Nixic/DeepChat\",\n",
            "        \"migueldeguzmandev/deepseek-build\",\n",
            "        \"nikhil-kumar/Financial_Assistant\",\n",
            "        \"Hkb2001/Medical_Analyzer\",\n",
            "        \"faizaltkl/First_agent_template\",\n",
            "        \"openfree/DeepSeek-R1-Chatbot\",\n",
            "        \"Cenes44/Qwen-2.5-vl-api\",\n",
            "        \"kolaslab/DeepSeek-R1-Chatbot-70b\",\n",
            "        \"seawolf2357/DeepSeek-R1-32b-api\",\n",
            "        \"htilssu/deepseek-ai-DeepSeek-R1\",\n",
            "        \"Lyte/tokenizer-leaderboard\",\n",
            "        \"rayajahan/First_agent_template1\",\n",
            "        \"megatrump/DeepClaudeProxy\",\n",
            "        \"nathannarrik/TUTOR\",\n",
            "        \"akhaliq/deepseek-ai-DeepSeek-R1\",\n",
            "        \"ItayR31/puchifypro\",\n",
            "        \"burtenshaw/deepseek-ai-DeepSeek-R1\",\n",
            "        \"readomni/literate\",\n",
            "        \"Isidorophp/Executive-Assistant\",\n",
            "        \"Godking0181/deepseek-ai-DeepSeek-R1\",\n",
            "        \"Vedantonhf/deepseek-ai-DeepSeek-R1\",\n",
            "        \"leh146215/deepseek-ai-DeepSeek-R1\",\n",
            "        \"BarBar288/AI_Tools\",\n",
            "        \"mianumairsiddiquie/deepseek-ai-DeepSeek-R1\",\n",
            "        \"sbudni/sk\",\n",
            "        \"migueldeguzmandev/migueldeguzmandev-papercliptodd_v2\",\n",
            "        \"alx-d/philosophy_aristotle\",\n",
            "        \"Lakshan2003/llama-chat\",\n",
            "        \"dlflannery/GradioTest\",\n",
            "        \"hotdeem/mp3\",\n",
            "        \"ashok2216/SkyTrack\",\n",
            "        \"holytinz278/Microdot\",\n",
            "        \"carlosdimare/RSU\",\n",
            "        \"holytinz278/fishai\",\n",
            "        \"mazkobot66/candlestick\",\n",
            "        \"oriolcortes/llama3-text-generator\",\n",
            "        \"lunarflu/deepseek-ai-DeepSeek-R1\",\n",
            "        \"spireeewq/deepseek-ai-DeepSeek-R1\",\n",
            "        \"lukasholovsky/deepseek-ai-DeepSeek-R1\",\n",
            "        \"yeniu/deepseek-ai-DeepSeek-R1\",\n",
            "        \"d3m0n/deepseek-ai-DeepSeek-R1\",\n",
            "        \"theamrelhady/deepseek-ai-DeepSeek-R1\",\n",
            "        \"Ismael7777/deepseek-ai-DeepSeek-R1\",\n",
            "        \"kneeyee/deepseek-ai-DeepSeek-R1\",\n",
            "        \"Jodowo/deepseek-ai-DeepSeek-R1\",\n",
            "        \"alwaysrunning/deepseek-ai-DeepSeek-R1\",\n",
            "        \"madmn69/deepseek-ai-DeepSeek-R1\",\n",
            "        \"assasdf/deepseek-ai-DeepSeek-R1\",\n",
            "        \"Jevon925/deepseek-ai-DeepSeek-R1\",\n",
            "        \"Crow34/Deep\",\n",
            "        \"cdtermux1011/deepseek-ai-DeepSeek-R1\",\n",
            "        \"Evgenii-Bubolev/deepseek-ai-DeepSeek-R1\",\n",
            "        \"wheattoast11/deepseek-ai-DeepSeek-R1\",\n",
            "        \"augustocmarinho/my-first-ia\",\n",
            "        \"dogsanddogs914/deepseek-ai-DeepSeek-R1\",\n",
            "        \"zmos1/deepseek-ai-DeepSeek-R1\",\n",
            "        \"JasGRE/deepseek-ai-DeepSeek-R1\",\n",
            "        \"Rorolinux/deepseek-ai-DeepSeek-R1\",\n",
            "        \"kazukikun/deepseek-ai-DeepSeek-R1\",\n",
            "        \"juanaguirre96/deepseek-ai-DeepSeek-R1\",\n",
            "        \"unpourcent/deepseek-ai-DeepSeek-R1\",\n",
            "        \"j0nrages/deepseek-ai-DeepSeek-R1\",\n",
            "        \"Techguy3389/deepseek-ai-DeepSeek-R1\",\n",
            "        \"Linken123/deepseek-ai-DeepSeek-R1\",\n",
            "        \"wteverrrr/deepseek-ai-DeepSeek-R1\",\n",
            "        \"Arjuntamil/deepseek-ai-DeepSeek-R1\",\n",
            "        \"udenlee/deepseek-ai-DeepSeek-R1\",\n",
            "        \"barreybro/deepseek-ai-DeepSeek-R1\"\n",
            "    ],\n",
            "    \"safetensors\": {\n",
            "        \"parameters\": {\n",
            "            \"BF16\": 3918786560,\n",
            "            \"F8_E4M3\": 680571043840,\n",
            "            \"F32\": 41555600\n",
            "        },\n",
            "        \"total\": 684531386000\n",
            "    },\n",
            "    \"security_repo_status\": null,\n",
            "    \"lastModified\": \"2025-02-24 03:30:31+00:00\",\n",
            "    \"cardData\": \"library_name: transformers\\nlicense: mit\",\n",
            "    \"transformersInfo\": {\n",
            "        \"auto_model\": \"AutoModelForCausalLM\",\n",
            "        \"custom_class\": \"modeling_deepseek.DeepseekV3ForCausalLM\",\n",
            "        \"pipeline_tag\": \"text-generation\",\n",
            "        \"processor\": null\n",
            "    },\n",
            "    \"_id\": \"678dc6fff905d106be796d8a\",\n",
            "    \"modelId\": \"deepseek-ai/DeepSeek-R1\",\n",
            "    \"usedStorage\": 688624134307\n",
            "}\n",
            "id: deepseek-ai/DeepSeek-R1\n"
          ]
        }
      ],
      "source": [
        "# Script 1: takes input model url, validates url, and gives model metadata\n",
        "!pip install validators\n",
        "from huggingface_hub import HfApi\n",
        "import validators\n",
        "import json\n",
        "import csv\n",
        "\n",
        "hf_api = HfApi()\n",
        "\n",
        "def input_url():\n",
        "    while True:\n",
        "        input_model_url = input(\"Enter model URL: \")\n",
        "        print(f\"You entered: {input_model_url}\")\n",
        "\n",
        "        if validators.url(input_model_url) and \"huggingface.co\" in input_model_url:\n",
        "            try:\n",
        "                # Extract the model ID from the URL\n",
        "                model_id = input_model_url.split(\"huggingface.co/\")[-1]\n",
        "                model_info = hf_api.model_info(model_id) # Get model info: https://huggingface.co/docs/huggingface_hub/v0.29.2/en/package_reference/hf_api#huggingface_hub.ModelInfo\n",
        "                json_output = json.dumps(model_info.__dict__, indent=4, default=str)\n",
        "                print(json_output)\n",
        "                with open('model_info.json', 'w') as json_file:\n",
        "                    json_file.write(json_output)\n",
        "            except Exception as e:\n",
        "                    print(f\"Error fetching model info: {str(e)}\")\n",
        "            for key, value in model_info.__dict__.items():\n",
        "                    print(f\"{key}: {value}\")\n",
        "                    return model_info\n",
        "\n",
        "        else:\n",
        "            print(\"Invalid URL. Please enter a valid Hugging Face model URL.\") # error code\n",
        "\n",
        "# Call the function\n",
        "model_info = input_url()\n",
        "\n",
        "# DeepSeek link for testing: https://huggingface.co/deepseek-ai/DeepSeek-R1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Script 2\n",
        "Takes in a (validated) model and outputs the children models/fine-tunes"
      ],
      "metadata": {
        "id": "gOnHUAW23SNE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6petSSd-m2Qi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d30cb88-1bf4-4917-fc51-61b9597218c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the Hugging Face model URL: https://huggingface.co/deepseek-ai/DeepSeek-R1\n",
            "Fine-tuned models found:\n",
            "https://huggingface.co/nvidia/DeepSeek-R1-FP4\n",
            "https://huggingface.co/unsloth/DeepSeek-R1-GGUF\n",
            "https://huggingface.co/mlx-community/DeepSeek-R1-4bit\n",
            "https://huggingface.co/huihui-ai/DeepSeek-R1-Distill-Qwen-32B-abliterated\n",
            "https://huggingface.co/bartowski/DeepSeek-R1-Distill-Qwen-32B-GGUF\n",
            "https://huggingface.co/meituan/DeepSeek-R1-Block-INT8\n",
            "https://huggingface.co/unsloth/DeepSeek-R1-Distill-Llama-8B-GGUF\n",
            "https://huggingface.co/bartowski/DeepSeek-R1-Distill-Qwen-7B-GGUF\n",
            "https://huggingface.co/mradermacher/DeepSeek-R1-Distill-Qwen-14B-Uncensored-GGUF\n",
            "https://huggingface.co/lmsys/DeepSeek-R1-NextN\n",
            "https://huggingface.co/mlx-community/QwQ-DeepSeek-R1-SkyT1-Flash-Lightest-32B-mlx-4Bit\n",
            "https://huggingface.co/unsloth/DeepSeek-R1-Distill-Llama-8B\n",
            "https://huggingface.co/lmstudio-community/DeepSeek-R1-Distill-Qwen-7B-GGUF\n",
            "https://huggingface.co/unsloth/DeepSeek-R1-Distill-Llama-70B-GGUF\n",
            "https://huggingface.co/neuralmagic/DeepSeek-R1-Distill-Qwen-32B-quantized.w8a8\n",
            "https://huggingface.co/suayptalha/DeepSeek-R1-Distill-Qwen-0.5B-CoMa\n",
            "https://huggingface.co/unsloth/DeepSeek-R1-BF16\n",
            "https://huggingface.co/unsloth/DeepSeek-R1-Distill-Qwen-1.5B\n",
            "https://huggingface.co/unsloth/DeepSeek-R1-Distill-Qwen-1.5B-GGUF\n",
            "https://huggingface.co?p=0&sort=trending&search=DeepSeek-R1\n",
            "https://huggingface.co?p=1&sort=trending&search=DeepSeek-R1\n",
            "https://huggingface.co?p=2&sort=trending&search=DeepSeek-R1\n",
            "https://huggingface.co?p=99&sort=trending&search=DeepSeek-R1\n",
            "https://huggingface.co?p=1&sort=trending&search=DeepSeek-R1\n"
          ]
        }
      ],
      "source": [
        "# Script 2\n",
        "  # 1. Take link as input (format check). This is the \"main model\"\n",
        "  # 2. Give the link to the page with the fine-tunes for the inputted model\n",
        "\n",
        "from huggingface_hub import HfApi\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "\n",
        "# Initialize API\n",
        "api = HfApi()\n",
        "\n",
        "# Function to validate Hugging Face model URL\n",
        "def validate_hf_model_url(url):\n",
        "    pattern = r\"^https://huggingface.co/([\\w\\-]+)/([\\w\\-]+)$\"\n",
        "    match = re.match(pattern, url)\n",
        "    if match:\n",
        "        return match.groups()  # Returns (org/user, model_name)\n",
        "    return None\n",
        "\n",
        "# Function to find fine-tuned models\n",
        "def get_finetuned_models_page(model_org, model_name):\n",
        "    search_url = f\"https://huggingface.co/models?search={model_name}\"\n",
        "    response = requests.get(search_url)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "        model_links = [\n",
        "            a[\"href\"] for a in soup.find_all(\"a\", href=True)\n",
        "            if model_name.lower() in a[\"href\"].lower()\n",
        "        ]\n",
        "        return [f\"https://huggingface.co{link}\" for link in model_links if model_org not in link]\n",
        "\n",
        "    return []\n",
        "\n",
        "# Main execution\n",
        "model_url = input(\"Enter the Hugging Face model URL: \").strip()\n",
        "\n",
        "validated = validate_hf_model_url(model_url)\n",
        "if validated:\n",
        "    org, model_name = validated\n",
        "    finetune_links = get_finetuned_models_page(org, model_name)\n",
        "\n",
        "    if finetune_links:\n",
        "        print(\"Fine-tuned models found:\")\n",
        "        for link in finetune_links:\n",
        "            print(link)\n",
        "    else:\n",
        "        print(\"No fine-tuned models found for this model.\")\n",
        "else:\n",
        "    print(\"Invalid Hugging Face model URL format.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Script 3\n",
        "## Search steps overview\n",
        "- `dfs_finetunes` we take the `model_url` as input. Alternatively, we can add this var as an argument.\n",
        "- We go layer-by-layer and find the children of the current model (i.e. the fine-tunes of a model)\n",
        "- We call the `dfs_funetunes` function recursively and store the models that have been \"visited\" to avoid duplicates.\n",
        "- We have a dictionary of information that we store aboutthe \"current model\" and have the information stored in respective columns\n",
        "- We have a `results` list that has the information about all the models and their fine-tunes."
      ],
      "metadata": {
        "id": "ruI5-1FA1ipq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Da_92M_Cgv1N"
      },
      "outputs": [],
      "source": [
        "# Script 3\n",
        "import requests\n",
        "import datetime\n",
        "import json\n",
        "import csv\n",
        "from huggingface_hub import HfApi\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "\n",
        "# Initialize API\n",
        "api = HfApi()\n",
        "\n",
        "# Function to validate Hugging Face model URL\n",
        "def validate_hf_model_url(url):\n",
        "    pattern = r\"^https://huggingface.co/([\\w\\-]+)/([\\w\\-]+)$\"\n",
        "    match = re.match(pattern, url)\n",
        "    return match.groups() if match else None\n",
        "\n",
        "\n",
        "# Function to find fine-tuned models\n",
        "def get_finetuned_models_page(model_org, model_name):\n",
        "    search_url = f\"https://huggingface.co/models?search={model_name}\"\n",
        "    response = requests.get(search_url)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "        model_links = [\n",
        "            a[\"href\"] for a in soup.find_all(\"a\", href=True)\n",
        "            if model_name.lower() in a[\"href\"].lower()\n",
        "        ]\n",
        "        return [f\"https://huggingface.co{link}\" for link in model_links if model_org not in link]\n",
        "\n",
        "    return []\n",
        "\n",
        "# Function to get parent model\n",
        "def get_parent_model(model_url):\n",
        "    return model_url.split(f\"/{model_name}/\")[0]\n",
        "\n",
        "# Recursive DFS (depth-first search) for finding fine-tunes\n",
        "def dfs_finetunes(model_url, visited, depth=0, results=None):\n",
        "    if results is None:\n",
        "        results = []\n",
        "\n",
        "    if model_url in visited:\n",
        "        return results\n",
        "    visited.add(model_url)\n",
        "\n",
        "    validated = validate_hf_model_url(model_url)\n",
        "    if not validated:\n",
        "        print(f\"Invalid URL skipped: {model_url}\")\n",
        "        model_url = \"N/A\"\n",
        "        return results\n",
        "\n",
        "    model_org, model_name = validated\n",
        "    model_id = f\"{model_org}/{model_name}\"\n",
        "\n",
        "    print(f\"\\n{'  ' * depth}Fetching metadata for: {model_id}\")\n",
        "    try:\n",
        "        model_metadata = api.model_info(model_id).__dict__\n",
        "    except Exception as e:\n",
        "        print(f\"Error fetching metadata: {e}\")\n",
        "        return results\n",
        "\n",
        "    finetune_links = get_finetuned_models_page(model_org, model_name)\n",
        "    print(f\"{'  ' * depth}Found {len(finetune_links)} fine-tunes at depth {depth}.\")\n",
        "\n",
        "    results.append({\n",
        "        \"model_id\": model_id,\n",
        "        # \"metadata\": model_metadata,\n",
        "        \"depth\": depth, # Define depth as the length of this parent model ID list (layers of the tree away from the base model)\n",
        "        \"children\": finetune_links,\n",
        "    })\n",
        "    for link in finetune_links:\n",
        "          dfs_finetunes(link, visited, depth + 1, results)\n",
        "\n",
        "    return results\n",
        "\n",
        "# Timestamp for the run\n",
        "timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "\n",
        "# Function to save results as JSON\n",
        "def save_json(results, model_name):\n",
        "    filename = f\"{timestamp}_{model_name}_finetunes.json\"\n",
        "    data = {\n",
        "        \"models\": results\n",
        "    }\n",
        "    with open(filename, \"w\") as f:\n",
        "        json.dump(data, f, indent=4, default=str)\n",
        "    print(f\"Results saved to {filename}\")\n",
        "\n",
        "# Function to save results as CSV\n",
        "def save_csv(results, model_name):\n",
        "       filename = f\"{timestamp}_{model_name}finetunes.csv\"\n",
        "       with open(filename, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
        "           writer = csv.DictWriter(f, fieldnames=[\"model_id\", \"depth\", \"children\"])  # Removed 'parents' field\n",
        "           writer.writeheader()\n",
        "           for entry in results:\n",
        "               entry[\"children\"] = \", \".join(entry[\"children\"])\n",
        "               writer.writerow(entry)\n",
        "       print(f\"Results saved to {filename}\")\n",
        "\n",
        "# Main execution\n",
        "if __name__ == \"__main__\":\n",
        "    model_url = input(\"Enter the Hugging Face model URL: \").strip()\n",
        "    visited = set()\n",
        "    results = dfs_finetunes(model_url, visited)\n",
        "\n",
        "    if results:\n",
        "        model_name = results[0][\"model_id\"].split(\"/\")[-1]  # Extract model name for file naming\n",
        "        save_json(results, model_name)\n",
        "        save_csv(results, model_name)\n",
        "    else:\n",
        "        print(\"No fine-tuned models found.\")\n",
        "\n",
        "# Link for testing: https://huggingface.co/NousResearch/DeepHermes-3-Mistral-24B-Preview\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOqstpY1ihWOdZMjREg0S5D",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
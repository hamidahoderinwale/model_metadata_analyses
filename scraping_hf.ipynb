{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hamidahoderinwale/model_metadata_analyses/blob/main/scraping_hf.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KE9l4j37dn6r",
        "outputId": "759bd341-fccf-40f6-d0c3-3e838974ed34"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (0.28.1)\n",
            "Collecting huggingface_hub\n",
            "  Downloading huggingface_hub-0.29.2-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (3.17.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (2025.1.31)\n",
            "Downloading huggingface_hub-0.29.2-py3-none-any.whl (468 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m468.1/468.1 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: huggingface_hub\n",
            "  Attempting uninstall: huggingface_hub\n",
            "    Found existing installation: huggingface-hub 0.28.1\n",
            "    Uninstalling huggingface-hub-0.28.1:\n",
            "      Successfully uninstalled huggingface-hub-0.28.1\n",
            "Successfully installed huggingface_hub-0.29.2\n",
            "Collecting backoff\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Installing collected packages: backoff\n",
            "Successfully installed backoff-2.2.1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "!pip install huggingface_hub -U\n",
        "!pip install backoff\n",
        "\n",
        "import pandas as pd\n",
        "from huggingface_hub import HfApi\n",
        "import json\n",
        "import time\n",
        "import backoff # for rate limit managing\n",
        "\n",
        "# Initialize API\n",
        "api = HfApi()\n",
        "\n",
        "\n",
        "models = api.list_models()\n",
        "model_list = [model.__dict__ for model in models]\n",
        "df = pd.DataFrame(model_list)\n",
        "df.head()\n",
        "\n",
        "\n",
        "quantized_models = df[df['tags'].apply(lambda x: 'quantized' in x)] # looks for quantized models\n",
        "\n",
        "def find_child_models(base_model_id, all_models):\n",
        "    return [model for model in all_models if model['id'].startswith(base_model_id + '/')]\n",
        "\n",
        "def create_model_tree(base_model_id, all_models):\n",
        "    base_model = next((model for model in all_models if model['id'] == base_model_id), None)\n",
        "    if not base_model:\n",
        "        return None\n",
        "\n",
        "    child_models = find_child_models(base_model_id, all_models)\n",
        "    quantized_versions = [model for model in all_models if model['id'].startswith(base_model_id) and 'quantized' in model['tags']]\n",
        "\n",
        "    return {\n",
        "        \"model_id\": base_model_id,\n",
        "        \"parent_models\": [],\n",
        "        \"child_models\": [create_model_tree(child['id'], all_models) for child in child_models],\n",
        "        \"quantizations\": [model['id'] for model in quantized_versions],\n",
        "        \"model_merges\": []\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NTsmxQI_KuVL",
        "outputId": "a94f3c17-d92b-4cf1-fdf7-40e6e4099035"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“Œ Building model tree for: deepseek-ai/DeepSeek-R1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing deepseek-ai/DeepSeek-R1 models: 0it [00:00, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model collection saved: deepseek-ai_DeepSeek-R1_model_collection.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import json\n",
        "import time\n",
        "import backoff\n",
        "import networkx as nx\n",
        "from tqdm import tqdm  # Progress bar\n",
        "import uuid\n",
        "from datetime import datetime\n",
        "\n",
        "# Base URL for Hugging Face model categories\n",
        "CATEGORY_TEMPLATE = \"https://huggingface.co/models?other=base_model:{}:{}\"\n",
        "\n",
        "# Different types of derived models\n",
        "DERIVED_TYPES = [\"finetune\", \"adapter\", \"quantized\", \"merge\"]\n",
        "\n",
        "# Base Model URL\n",
        "BASE_MODEL_URL = \"https://huggingface.co/deepseek-ai/DeepSeek-R1\"\n",
        "\n",
        "# Metadata for the collection\n",
        "metadata = {\n",
        "    \"collection_id\": str(uuid.uuid4()),\n",
        "    \"name\": \"Model Collection for DeepSeek-R1\",\n",
        "    \"description\": \"Collection of all derived models and relationships from DeepSeek-R1\",\n",
        "    \"created_date\": datetime.now().isoformat(),\n",
        "    \"last_updated\": datetime.now().isoformat(),\n",
        "    \"tags\": [\"DeepSeek-R1\", \"HuggingFace\", \"AI Models\"],\n",
        "    \"organization\": \"DeepSeek AI\"\n",
        "}\n",
        "\n",
        "# Initialize Model Tree Structure\n",
        "model_trees = []\n",
        "\n",
        "@backoff.on_exception(backoff.expo, requests.exceptions.RequestException, max_tries=5)\n",
        "def fetch_page(url):\n",
        "    \"\"\"Fetch an HTML page and return a BeautifulSoup object.\"\"\"\n",
        "    response = requests.get(url)\n",
        "    response.raise_for_status()\n",
        "    return BeautifulSoup(response.text, \"html.parser\")\n",
        "\n",
        "def extract_derived_models(base_model):\n",
        "    \"\"\"Find all models derived from a given base model.\"\"\"\n",
        "    derived_models = []\n",
        "\n",
        "    for model_type in DERIVED_TYPES:\n",
        "        url = CATEGORY_TEMPLATE.format(model_type, base_model)\n",
        "        soup = fetch_page(url)\n",
        "\n",
        "        for link in soup.find_all(\"a\", class_=\"text-gray-700 underline\"):\n",
        "            model_url = \"https://huggingface.co\" + link[\"href\"]\n",
        "            derived_models.append({\"type\": model_type, \"url\": model_url})\n",
        "\n",
        "    return derived_models\n",
        "\n",
        "def extract_model_id(model_url):\n",
        "    \"\"\"Extract the model ID from a model page.\"\"\"\n",
        "    try:\n",
        "        soup = fetch_page(model_url)\n",
        "        header = soup.find(\"header\", class_=\"flex items-center mb-0.5\")\n",
        "        if header and \"title\" in header.attrs:\n",
        "            return header[\"title\"]\n",
        "    except Exception as e:\n",
        "        print(f\"Error fetching {model_url}: {e}\")\n",
        "    return None\n",
        "\n",
        "def extract_base_models(model_url):\n",
        "    \"\"\"Extract base model(s) from a model's page.\"\"\"\n",
        "    try:\n",
        "        soup = fetch_page(model_url)\n",
        "        base_model_section = soup.find(\"div\", class_=\"font-semibold\", text=\"Base model\")\n",
        "        if base_model_section:\n",
        "            base_model_links = base_model_section.find_next_sibling(\"div\").find_all(\"a\")\n",
        "            return [link.text for link in base_model_links]\n",
        "    except Exception as e:\n",
        "        print(f\"Error fetching base models for {model_url}: {e}\")\n",
        "    return []\n",
        "\n",
        "def build_model_tree(base_model):\n",
        "    \"\"\"Recursively build a model tree for a given base model.\"\"\"\n",
        "    print(f\"ðŸ“Œ Building model tree for: {base_model}\")\n",
        "\n",
        "    # Graph representation of the tree\n",
        "    G = nx.DiGraph()\n",
        "    G.add_node(base_model)\n",
        "\n",
        "    # Scrape derived models\n",
        "    derived_models = extract_derived_models(base_model)\n",
        "\n",
        "    for model in tqdm(derived_models, desc=\"Processing models\"):\n",
        "        model_id = extract_model_id(model[\"url\"])\n",
        "        if model_id:\n",
        "            G.add_edge(base_model, model_id, relation=model[\"type\"])\n",
        "\n",
        "            # Fetch base models of this model (to handle multi-parent relationships)\n",
        "            base_models = extract_base_models(model[\"url\"])\n",
        "            for parent_model in base_models:\n",
        "                G.add_edge(parent_model, model_id, relation=\"derived\")\n",
        "\n",
        "    return G\n",
        "\n",
        "def build_model_collection(base_model):\n",
        "    \"\"\"Build and save model tree collection.\"\"\"\n",
        "    model_graph = build_model_tree(base_model)\n",
        "\n",
        "    # Generate tree data\n",
        "    tree_data = []\n",
        "    for parent, child, attr in model_graph.edges(data=True):\n",
        "        tree_data.append({\n",
        "            \"parent\": parent,\n",
        "            \"child\": child,\n",
        "            \"relation\": attr[\"relation\"]\n",
        "        })\n",
        "\n",
        "    # Add model tree data\n",
        "    tree_id = str(uuid.uuid4())\n",
        "    model_tree = {\n",
        "        \"tree_id\": tree_id,\n",
        "        \"root_model_id\": base_model,\n",
        "        \"tree_name\": f\"Model Tree for {base_model}\",\n",
        "        \"tree_description\": f\"Model tree for {base_model} including all derived models\",\n",
        "        \"model_family\": \"DeepSeek\",\n",
        "        \"tree_data\": tree_data\n",
        "    }\n",
        "\n",
        "    # Append the model tree to the collection\n",
        "    model_trees.append(model_tree)\n",
        "\n",
        "    return model_graph, tree_id, model_tree\n",
        "\n",
        "def save_model_collection(model_graph, base_model):\n",
        "    \"\"\"Save the collection in the required JSON format.\"\"\"\n",
        "    collection = {\n",
        "        \"metadata\": metadata,\n",
        "        \"model_trees\": model_trees,\n",
        "        \"cross_tree_relationships\": []  # Can be populated later if needed\n",
        "    }\n",
        "\n",
        "    # Create a safe filename by replacing slashes with underscores or another safe character becuase the OS takes the slash as a dir. seperator\n",
        "    safe_filename = base_model.replace(\"/\", \"_\")\n",
        "\n",
        "    with open(f\"{safe_filename}_model_collection.json\", \"w\") as f:\n",
        "        json.dump(collection, f, indent=2)\n",
        "\n",
        "    print(f\"Model collection saved: {safe_filename}_model_collection.json\")\n",
        "\n",
        "# Example usage\n",
        "model_graph, tree_id, model_tree = build_model_collection(\"deepseek-ai/DeepSeek-R1\")\n",
        "save_model_collection(model_graph, \"deepseek-ai/DeepSeek-R1\")\n",
        "\n",
        "# check the div of the model tree\n",
        "# get the numbers as well\n",
        "# model level feature (parent & children)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Script 2\n",
        "# 1. Take link as input (format check). This is the \"main model\"\n",
        "# 2. Give the link to the page with the finetunes for the inputted model\n",
        "\n",
        "from huggingface_hub import HfApi\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import json\n",
        "\n",
        "# Initialize API\n",
        "api = HfApi()\n",
        "\n",
        "model_url="
      ],
      "metadata": {
        "id": "6petSSd-m2Qi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Script 1: takes input model url, validates url, and generates file metadata\n",
        "\n",
        "from huggingface_hub import HfApi\n",
        "import validators\n",
        "\n",
        "hf_api = HfApi()\n",
        "\n",
        "def input_url():\n",
        "    while True:\n",
        "        input_model_url = input(\"Enter model URL: \")\n",
        "        print(f\"You entered: {input_model_url}\")\n",
        "\n",
        "        if validators.url(input_model_url) and \"huggingface.co\" in input_model_url:\n",
        "            try:\n",
        "                # Extract the model ID from the URL\n",
        "                model_id = input_model_url.split(\"huggingface.co/\")[-1]\n",
        "                model_info = hf_api.model_info(model_id)\n",
        "                print(f\"Model info: {model_info}\")\n",
        "                return model_info\n",
        "            except Exception as e:\n",
        "                print(f\"Error fetching model info: {str(e)}\")\n",
        "        else:\n",
        "            print(\"Invalid URL. Please enter a valid Hugging Face model URL.\")\n",
        "\n",
        "# Call the function\n",
        "model_info = input_url()\n"
      ],
      "metadata": {
        "id": "Fmp0ftEomk86"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "lRPhbASHM-UI",
        "outputId": "c317437b-f6b8-45ca-e8f1-1256318136f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (0.29.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (3.17.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (2025.1.31)\n",
            "Requirement already satisfied: backoff in /usr/local/lib/python3.11/dist-packages (2.2.1)\n",
            "                                                        id author   sha  \\\n",
            "9461                                           espnet/xeus   None  None   \n",
            "5507                                       cis-lmu/glotlid   None  None   \n",
            "953771                          vonjack/opus-mt-mul-en-big   None  None   \n",
            "1027546  Helsinki-NLP/opus-mt-tc-bible-big-mul-deu_eng_...   None  None   \n",
            "1027617  Helsinki-NLP/opus-mt-tc-bible-big-deu_eng_fra_...   None  None   \n",
            "\n",
            "        last_modified                created_at  private gated disabled  \\\n",
            "9461             None 2024-06-25 04:25:33+00:00    False  None     None   \n",
            "5507             None 2023-10-19 23:46:58+00:00    False  None     None   \n",
            "953771           None 2024-09-18 13:27:10+00:00    False  None     None   \n",
            "1027546          None 2024-10-09 15:24:39+00:00    False  None     None   \n",
            "1027617          None 2024-10-09 15:54:32+00:00    False  None     None   \n",
            "\n",
            "         downloads downloads_all_time  ...  siblings spaces safetensors  \\\n",
            "9461            18               None  ...      None   None        None   \n",
            "5507         49462               None  ...      None   None        None   \n",
            "953771         116               None  ...      None   None        None   \n",
            "1027546         48               None  ...      None   None        None   \n",
            "1027617        246               None  ...      None   None        None   \n",
            "\n",
            "        security_repo_status lastModified cardData transformersInfo  \\\n",
            "9461                    None         None     None             None   \n",
            "5507                    None         None     None             None   \n",
            "953771                  None         None     None             None   \n",
            "1027546                 None         None     None             None   \n",
            "1027617                 None         None     None             None   \n",
            "\n",
            "                              _id  \\\n",
            "9461     667a46bdf922286634ae79cc   \n",
            "5507     6531bff2a1162a3f8795eaeb   \n",
            "953771   66ead52edf6c4ba806b35a51   \n",
            "1027546  6706a0378a5069b9fad040b6   \n",
            "1027617  6706a7380681f4d0a91c00ae   \n",
            "\n",
            "                                                   modelId tags_count  \n",
            "9461                                           espnet/xeus       4046  \n",
            "5507                                       cis-lmu/glotlid       2164  \n",
            "953771                          vonjack/opus-mt-mul-en-big       1090  \n",
            "1027546  Helsinki-NLP/opus-mt-tc-bible-big-mul-deu_eng_...       1071  \n",
            "1027617  Helsinki-NLP/opus-mt-tc-bible-big-deu_eng_fra_...       1071  \n",
            "\n",
            "[5 rows x 34 columns]\n",
            "Quantized models:\n",
            "                                                     id  \\\n",
            "624                            Tonic/GemmaX2-28-2B-gguf   \n",
            "909              MaziyarPanahi/Phi-4-mini-instruct-GGUF   \n",
            "1093                        argmaxinc/whisperkit-coreml   \n",
            "1372                   Gurubot/TopicalStorm-Llama3.2-3b   \n",
            "1464  MaziyarPanahi/Mistral-Small-24B-Instruct-2501-...   \n",
            "\n",
            "                                                   tags  \n",
            "624   [transformers, gguf, gemma, translation, multi...  \n",
            "909   [gguf, mistral, quantized, 2-bit, 3-bit, 4-bit...  \n",
            "1093  [whisperkit, coreml, whisper, asr, quantized, ...  \n",
            "1372  [gguf, llama, finetuned, quantized, base_model...  \n",
            "1464  [gguf, mistral, quantized, 2-bit, 3-bit, 4-bit...  \n",
            "Model Tree for deepseek-ai/DeepSeek-R1: {\n",
            "  \"model_id\": \"deepseek-ai/DeepSeek-R1\",\n",
            "  \"parent_models\": [],\n",
            "  \"child_models\": [],\n",
            "  \"quantizations\": [],\n",
            "  \"model_merges\": []\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "!pip install huggingface_hub -U\n",
        "!pip install backoff\n",
        "\n",
        "import pandas as pd\n",
        "from huggingface_hub import HfApi\n",
        "import json\n",
        "import time\n",
        "import backoff  # for rate limit management\n",
        "\n",
        "# Initialize API\n",
        "api = HfApi()\n",
        "\n",
        "# Backoff decorator to manage rate limiting\n",
        "@backoff.on_exception(backoff.expo, Exception, max_tries=5, jitter=None)\n",
        "def get_all_models():\n",
        "    return api.list_models()\n",
        "\n",
        "# Fetch all models with retries to handle rate limiting\n",
        "models = get_all_models()\n",
        "model_list = [model.__dict__ for model in models]\n",
        "\n",
        "# Create a dataframe\n",
        "df = pd.DataFrame(model_list)\n",
        "\n",
        "# Extract top 10 models, based on a criterion (e.g., number of tags, or sorted by model ID)\n",
        "df['tags_count'] = df['tags'].apply(lambda x: len(x) if isinstance(x, list) else 0)\n",
        "top_10_df = df.nlargest(10, 'tags_count')\n",
        "\n",
        "# Save the full model data to CSV\n",
        "df.to_csv('huggingface_models.csv', index=False)\n",
        "\n",
        "# Save top 10 models to a CSV\n",
        "top_10_df.to_csv('huggingface_top_10_models.csv', index=False)\n",
        "\n",
        "# Show top 10 models DataFrame\n",
        "print(top_10_df.head())\n",
        "\n",
        "# Find models that are quantized\n",
        "quantized_models = df[df['tags'].apply(lambda x: 'quantized' in x if isinstance(x, list) else False)]  # looks for quantized models\n",
        "print(f\"Quantized models:\\n{quantized_models[['id', 'tags']].head()}\")\n",
        "\n",
        "# Helper function to find child models (models derived from a base model)\n",
        "def find_child_models(base_model_id, all_models):\n",
        "    return [model for model in all_models if model['id'].startswith(base_model_id + '/')]\n",
        "\n",
        "# Function to create model tree for a given base model\n",
        "def create_model_tree(base_model_id, all_models):\n",
        "    base_model = next((model for model in all_models if model['id'] == base_model_id), None)\n",
        "    if not base_model:\n",
        "        return None\n",
        "\n",
        "    child_models = find_child_models(base_model_id, all_models)\n",
        "    quantized_versions = [model for model in all_models if model['id'].startswith(base_model_id) and 'quantized' in model['tags']]\n",
        "\n",
        "    return {\n",
        "        \"model_id\": base_model_id,\n",
        "        \"parent_models\": [],\n",
        "        \"child_models\": [create_model_tree(child['id'], all_models) for child in child_models],\n",
        "        \"quantizations\": [model['id'] for model in quantized_versions],\n",
        "        \"model_merges\": []  # Placeholder for model merges, can be extended later\n",
        "    }\n",
        "\n",
        "# Example: Create model tree for a specific base model\n",
        "base_model_id = 'deepseek-ai/DeepSeek-R1'  # Replace with any model ID\n",
        "model_tree = create_model_tree(base_model_id, model_list)\n",
        "print(f\"Model Tree for {base_model_id}: {json.dumps(model_tree, indent=2)}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOzQN2IN2Yj3ZAyg415Wa6q",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hamidahoderinwale/model_metadata_analyses/blob/main/scraping_hf.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fmp0ftEomk86",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# Script 1: takes input model url, validates url, and gives model metadata\n",
        "!pip install validators\n",
        "from huggingface_hub import HfApi\n",
        "import validators\n",
        "import json\n",
        "import csv\n",
        "\n",
        "hf_api = HfApi()\n",
        "\n",
        "def input_url():\n",
        "    while True:\n",
        "        input_model_url = input(\"Enter model URL: \")\n",
        "        print(f\"You entered: {input_model_url}\")\n",
        "\n",
        "        if validators.url(input_model_url) and \"huggingface.co\" in input_model_url:\n",
        "            try:\n",
        "                # Extract the model ID from the URL\n",
        "                model_id = input_model_url.split(\"huggingface.co/\")[-1]\n",
        "                model_info = hf_api.model_info(model_id) # Get model info: https://huggingface.co/docs/huggingface_hub/v0.29.2/en/package_reference/hf_api#huggingface_hub.ModelInfo\n",
        "                json_output = json.dumps(model_info.__dict__, indent=4, default=str)\n",
        "                print(json_output)\n",
        "                with open('model_info.json', 'w') as json_file:\n",
        "                    json_file.write(json_output)\n",
        "            except Exception as e:\n",
        "                    print(f\"Error fetching model info: {str(e)}\")\n",
        "            for key, value in model_info.__dict__.items():\n",
        "                    print(f\"{key}: {value}\")\n",
        "                    return model_info\n",
        "\n",
        "        else:\n",
        "            print(\"Invalid URL. Please enter a valid Hugging Face model URL.\") # error code\n",
        "\n",
        "# Call the function\n",
        "model_info = input_url()\n",
        "\n",
        "# DeepSeek link for testing: https://huggingface.co/deepseek-ai/DeepSeek-R1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "6petSSd-m2Qi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06018ded-b128-433a-8e2f-19e3c2dd7aa4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the Hugging Face model URL: https://huggingface.co/deepseek-ai/DeepSeek-R1\n",
            "Fine-tuned models found:\n",
            "https://huggingface.co/unsloth/DeepSeek-R1-GGUF\n",
            "https://huggingface.co/nvidia/DeepSeek-R1-FP4\n",
            "https://huggingface.co/meituan/DeepSeek-R1-Block-INT8\n",
            "https://huggingface.co/mradermacher/DeepSeek-R1-Distill-Qwen-14B-Uncensored-GGUF\n",
            "https://huggingface.co/bartowski/DeepSeek-R1-Distill-Qwen-32B-GGUF\n",
            "https://huggingface.co/cognitivecomputations/DeepSeek-R1-AWQ\n",
            "https://huggingface.co/unsloth/DeepSeek-R1-Distill-Llama-8B\n",
            "https://huggingface.co/suayptalha/DeepSeek-R1-Distill-Llama-3B\n",
            "https://huggingface.co/meituan/DeepSeek-R1-Channel-INT8\n",
            "https://huggingface.co/bartowski/DeepSeek-R1-Distill-Qwen-14B-GGUF\n",
            "https://huggingface.co/huihui-ai/DeepSeek-R1-Distill-Qwen-32B-abliterated\n",
            "https://huggingface.co/unsloth/DeepSeek-R1-Distill-Llama-8B-GGUF\n",
            "https://huggingface.co/bartowski/DeepSeek-R1-GGUF\n",
            "https://huggingface.co/unsloth/DeepSeek-R1-BF16\n",
            "https://huggingface.co/mlx-community/DeepSeek-R1-Distill-Qwen-32B-MLX-8Bit\n",
            "https://huggingface.co/unsloth/DeepSeek-R1-Distill-Llama-70B-GGUF\n",
            "https://huggingface.co/unsloth/DeepSeek-R1-Distill-Llama-8B-unsloth-bnb-4bit\n",
            "https://huggingface.co?p=0&sort=trending&search=DeepSeek-R1\n",
            "https://huggingface.co?p=1&sort=trending&search=DeepSeek-R1\n",
            "https://huggingface.co?p=2&sort=trending&search=DeepSeek-R1\n",
            "https://huggingface.co?p=99&sort=trending&search=DeepSeek-R1\n",
            "https://huggingface.co?p=1&sort=trending&search=DeepSeek-R1\n"
          ]
        }
      ],
      "source": [
        "# Script 2\n",
        "  # 1. Take link as input (format check). This is the \"main model\"\n",
        "  # 2. Give the link to the page with the fine-tunes for the inputted model\n",
        "\n",
        "from huggingface_hub import HfApi\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "\n",
        "# Initialize API\n",
        "api = HfApi()\n",
        "\n",
        "# Function to validate Hugging Face model URL\n",
        "def validate_hf_model_url(url):\n",
        "    pattern = r\"^https://huggingface.co/([\\w\\-]+)/([\\w\\-]+)$\"\n",
        "    match = re.match(pattern, url)\n",
        "    if match:\n",
        "        return match.groups()  # Returns (org/user, model_name)\n",
        "    return None\n",
        "\n",
        "# Function to find fine-tuned models\n",
        "def get_finetuned_models_page(model_org, model_name):\n",
        "    search_url = f\"https://huggingface.co/models?search={model_name}\"\n",
        "    response = requests.get(search_url)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "        model_links = [\n",
        "            a[\"href\"] for a in soup.find_all(\"a\", href=True)\n",
        "            if model_name.lower() in a[\"href\"].lower()\n",
        "        ]\n",
        "        return [f\"https://huggingface.co{link}\" for link in model_links if model_org not in link]\n",
        "\n",
        "    return []\n",
        "\n",
        "# Main execution\n",
        "model_url = input(\"Enter the Hugging Face model URL: \").strip()\n",
        "\n",
        "validated = validate_hf_model_url(model_url)\n",
        "if validated:\n",
        "    org, model_name = validated\n",
        "    finetune_links = get_finetuned_models_page(org, model_name)\n",
        "\n",
        "    if finetune_links:\n",
        "        print(\"Fine-tuned models found:\")\n",
        "        for link in finetune_links:\n",
        "            print(link)\n",
        "    else:\n",
        "        print(\"No fine-tuned models found for this model.\")\n",
        "else:\n",
        "    print(\"Invalid Hugging Face model URL format.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import json\n",
        "import csv\n",
        "from huggingface_hub import HfApi\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "\n",
        "# Initialize API\n",
        "api = HfApi()\n",
        "\n",
        "# Function to validate Hugging Face model URL\n",
        "def validate_hf_model_url(url):\n",
        "    pattern = r\"^https://huggingface.co/([\\w\\-]+)/([\\w\\-]+)$\"\n",
        "    match = re.match(pattern, url)\n",
        "    return match.groups() if match else None\n",
        "\n",
        "# Function to find fine-tuned models\n",
        "def get_finetuned_models_page(model_org, model_name):\n",
        "    search_url = f\"https://huggingface.co/models?search={model_name}\"\n",
        "    response = requests.get(search_url)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "        model_links = [\n",
        "            a[\"href\"] for a in soup.find_all(\"a\", href=True)\n",
        "            if model_name.lower() in a[\"href\"].lower()\n",
        "        ]\n",
        "        return [f\"https://huggingface.co{link}\" for link in model_links if model_org not in link]\n",
        "\n",
        "    return []\n",
        "\n",
        "# Recursive DFS for finding fine-tunes\n",
        "def dfs_finetunes(model_url, visited, depth=0, results=None):\n",
        "    if results is None:\n",
        "        results = []\n",
        "\n",
        "    if model_url in visited:\n",
        "        return results\n",
        "    visited.add(model_url)\n",
        "\n",
        "    validated = validate_hf_model_url(model_url)\n",
        "    if not validated:\n",
        "        print(f\"Invalid URL skipped: {model_url}\")\n",
        "        return results\n",
        "\n",
        "    model_org, model_name = validated\n",
        "    model_id = f\"{model_org}/{model_name}\"\n",
        "\n",
        "    print(f\"\\n{'  ' * depth}Fetching metadata for: {model_id}\")\n",
        "    try:\n",
        "        model_metadata = api.model_info(model_id).__dict__\n",
        "    except Exception as e:\n",
        "        print(f\"Error fetching metadata: {e}\")\n",
        "        return results\n",
        "\n",
        "    results.append({\n",
        "        \"model_id\": model_id,\n",
        "        \"url\": model_url,\n",
        "        \"metadata\": model_metadata,\n",
        "        \"depth\": depth\n",
        "    })\n",
        "\n",
        "    finetune_links = get_finetuned_models_page(model_org, model_name)\n",
        "    print(f\"{'  ' * depth}Found {len(finetune_links)} fine-tunes at depth {depth}.\")\n",
        "\n",
        "    for link in finetune_links:\n",
        "        dfs_finetunes(link, visited, depth + 1, results)\n",
        "\n",
        "    return results\n",
        "\n",
        "# Function to save results as JSON\n",
        "def save_json(results, model_name):\n",
        "    filename = f\"{model_name}_finetunes.json\"\n",
        "    data = {\n",
        "        \"models\": results\n",
        "    }\n",
        "    with open(filename, \"w\") as f:\n",
        "        json.dump(data, f, indent=4, default=str)\n",
        "    print(f\"Results saved to {filename}\")\n",
        "\n",
        "# Function to save results as CSV\n",
        "def save_csv(results, model_name):\n",
        "    filename = f\"{model_name}_finetunes.csv\"\n",
        "    with open(filename, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
        "        writer = csv.DictWriter(f, fieldnames=[\"model_id\", \"url\", \"depth\"])\n",
        "        writer.writeheader()\n",
        "        for entry in results:\n",
        "            writer.writerow({\n",
        "                \"model_id\": entry[\"model_id\"],\n",
        "                \"url\": entry[\"url\"],\n",
        "                \"depth\": entry[\"depth\"]\n",
        "            })\n",
        "    print(f\"Results saved to {filename}\")\n",
        "\n",
        "# Main execution\n",
        "if __name__ == \"__main__\":\n",
        "    model_url = input(\"Enter the Hugging Face model URL: \").strip()\n",
        "    visited = set()\n",
        "    results = dfs_finetunes(model_url, visited)\n",
        "\n",
        "    if results:\n",
        "        model_name = results[0][\"model_id\"].split(\"/\")[-1]  # Extract model name for file naming\n",
        "        save_json(results, model_name)\n",
        "        save_csv(results, model_name)\n",
        "    else:\n",
        "        print(\"No fine-tuned models found.\")\n"
      ],
      "metadata": {
        "id": "Da_92M_Cgv1N"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMkIHocWBXhjg4qs5wc0UAd",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hamidahoderinwale/model_metadata_analyses/blob/main/scraping_hf.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 983
        },
        "outputId": "6c30e5bf-3ac1-45c2-a58b-8c2725f2b1a1",
        "id": "zvydG0Vljv4O"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (0.30.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (2025.3.2)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (4.13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (2025.1.31)\n",
            "Requirement already satisfied: adapters in /usr/local/lib/python3.11/dist-packages (1.1.1)\n",
            "Requirement already satisfied: transformers~=4.48.3 in /usr/local/lib/python3.11/dist-packages (from adapters) (4.48.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from adapters) (24.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers~=4.48.3->adapters) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers~=4.48.3->adapters) (0.30.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers~=4.48.3->adapters) (2.0.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers~=4.48.3->adapters) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers~=4.48.3->adapters) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers~=4.48.3->adapters) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers~=4.48.3->adapters) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers~=4.48.3->adapters) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers~=4.48.3->adapters) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers~=4.48.3->adapters) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers~=4.48.3->adapters) (4.13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers~=4.48.3->adapters) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers~=4.48.3->adapters) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers~=4.48.3->adapters) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers~=4.48.3->adapters) (2025.1.31)\n",
            "Enter the Hugging Face model URL: https://huggingface.co/deepseek-ai/DeepSeek-R1\n",
            "\n",
            "Fetching metadata for: deepseek-ai/DeepSeek-R1\n",
            "Found 297 fine-tunes at depth 0.\n",
            "Found 121 adapter models for deepseek-ai/DeepSeek-R1.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'model_name' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-c00c90202382>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[0mmodel_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Enter the Hugging Face model URL: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0mvisited\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdfs_finetunes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvisited\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-39-c00c90202382>\u001b[0m in \u001b[0;36mdfs_finetunes\u001b[0;34m(model_url, visited, depth, results)\u001b[0m\n\u001b[1;32m    145\u001b[0m            \u001b[0;34m\"adapters\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0madapter_links\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m            \u001b[0;34m\"adapters_count\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madapter_links\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m            \u001b[0;34m\"parent_model\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mget_parent_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m        })\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-39-c00c90202382>\u001b[0m in \u001b[0;36mget_parent_model\u001b[0;34m(model_url)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;31m# Function to get parent model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_parent_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel_url\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"/{model_name}/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;31m# Truncate metadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model_name' is not defined"
          ]
        }
      ],
      "source": [
        "# Script 3\n",
        "!pip install huggingface_hub\n",
        "!pip install adapters\n",
        "import requests\n",
        "import pandas as pd\n",
        "import datetime\n",
        "import json\n",
        "import csv\n",
        "from huggingface_hub import HfApi\n",
        "from bs4 import BeautifulSoup\n",
        "from adapters import list_adapters\n",
        "from huggingface_hub import hf_hub_download\n",
        "from adapters import AutoAdapterModel\n",
        "import re\n",
        "\n",
        "\n",
        "\n",
        "# Initialize API\n",
        "api = HfApi()\n",
        "\n",
        "# Function to validate Hugging Face model URL\n",
        "def validate_hf_model_url(url):\n",
        "    pattern = r\"^https://huggingface.co/([\\w\\-]+)/([\\w\\-]+)$\"\n",
        "    match = re.match(pattern, url)\n",
        "    return match.groups() if match else None\n",
        "\n",
        "# page with model finetunes\n",
        "def get_finetuned_models_page(model_org, model_name):\n",
        "    all_model_links = []  # Store all links across pages\n",
        "    page_num = 0\n",
        "    while True:\n",
        "        search_url = f\"https://huggingface.co/models?other=base_model:finetune:{model_org}/{model_name}&p={page_num}\"\n",
        "        response = requests.get(search_url)\n",
        "        if response.status_code != 200:\n",
        "            break  # Exit if page not found\n",
        "\n",
        "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "        model_divs = soup.find_all(\"div\", class_=\"w-full truncate\")\n",
        "        if not model_divs:\n",
        "            break  # Exit if no more models on the page\n",
        "\n",
        "        for div in model_divs:\n",
        "            header = div.find(\"header\")\n",
        "            if header:\n",
        "                model_link = header.get(\"title\")\n",
        "                if model_link:\n",
        "                    all_model_links.append(f\"https://huggingface.co/{model_link}\")\n",
        "\n",
        "        page_num += 1  # Move to the next page\n",
        "\n",
        "    return all_model_links\n",
        "\n",
        "# model card data\n",
        "def get_model_card(model_id):\n",
        "    try:\n",
        "        # Try to download model card if available\n",
        "        readme_path = hf_hub_download(repo_id=model_id, filename='README.md')\n",
        "        with open(readme_path, 'r', encoding='utf-8') as f:\n",
        "            card_content = f.read()\n",
        "        return card_content\n",
        "    except Exception as e:\n",
        "        print(f\"  Could not download model card: {str(e)[:100]}...\")\n",
        "        return \"\"\n",
        "\n",
        "\n",
        "# Function to get parent model\n",
        "def get_parent_model(model_url):\n",
        "    return model_url.split(f\"/{model_name}/\")[0]\n",
        "\n",
        "# Truncate metadata\n",
        "def filter_metadata(json_metadata):\n",
        "            keys_to_keep = [\"modelId\", \"sha\", \"tags\", \"downloads\", \"pipeline_tag\"]\n",
        "            return {k: json_metadata.get(k) for k in keys_to_keep if k in json_metadata}\n",
        "            filtered_metadata = filter_metadata(api.model_info(model_id).__dict__)\n",
        "\n",
        "# Get adapter models\n",
        "def get_adapter_models_page(model_org, model_name):\n",
        "    all_adapter_links = []  # Store all adapter links across pages\n",
        "    page_num = 0\n",
        "    while True:\n",
        "        search_url = f\"https://huggingface.co/models?other=base_model:adapter:{model_org}/{model_name}&p={page_num}\"\n",
        "        response = requests.get(search_url)\n",
        "        if response.status_code != 200:\n",
        "            break  # Exit if page not found\n",
        "\n",
        "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "        model_divs = soup.find_all(\"div\", class_=\"w-full truncate\")\n",
        "        if not model_divs:\n",
        "            break  # Exit if no more models on the page\n",
        "\n",
        "        for div in model_divs:\n",
        "            header = div.find(\"header\")\n",
        "            if header:\n",
        "                model_link = header.get(\"title\")\n",
        "                if model_link:\n",
        "                    all_adapter_links.append(f\"https://huggingface.co/{model_link}\")\n",
        "\n",
        "        page_num += 1  # Move to the next page\n",
        "\n",
        "    return all_adapter_links\n",
        "\n",
        "# Recursive DFS (depth-first search) for finding fine-tunes\n",
        "def dfs_finetunes(model_url, visited, depth=0, results=None):\n",
        "       if results is None:\n",
        "           results = []\n",
        "\n",
        "       if model_url in visited:\n",
        "           return results\n",
        "       visited.add(model_url)\n",
        "\n",
        "       validated = validate_hf_model_url(model_url)\n",
        "       if not validated:\n",
        "           print(f\"Invalid URL skipped: {model_url}\")\n",
        "           model_url = \"N/A\"\n",
        "           return results\n",
        "\n",
        "       model_org, model_name = validated\n",
        "       model_id = f\"{model_org}/{model_name}\"\n",
        "\n",
        "\n",
        "       print(f\"\\n{'  ' * depth}Fetching metadata for: {model_id}\")\n",
        "       try:\n",
        "           model_metadata = api.model_info(model_id).__dict__\n",
        "           json_metadata = json.dumps(model_metadata, default=str)\n",
        "           model_card = get_model_card(model_id)\n",
        "\n",
        "       except Exception as e:\n",
        "           print(f\"Error fetching metadata: {e}\")\n",
        "           return results\n",
        "\n",
        "       finetune_links = get_finetuned_models_page(model_org, model_name)\n",
        "       # Removing Duplicate Children\n",
        "       finetune_links = list(set(finetune_links))\n",
        "       print(f\"{'  ' * depth}Found {len(finetune_links)} fine-tunes at depth {depth}.\")\n",
        "       adapter_links = get_adapter_models_page(model_org, model_name)\n",
        "       print(f\"{'  ' * depth}Found {len(adapter_links)} adapter models for {model_id}.\")\n",
        "\n",
        "       results.append({\n",
        "           \"model_id\": model_id,\n",
        "           \"card\": model_card,\n",
        "           \"metadata\": json_metadata,\n",
        "           \"depth\": depth,\n",
        "           \"children\": finetune_links,\n",
        "           \"children_count\": len(finetune_links),\n",
        "           \"adapters\": adapter_links,\n",
        "           \"adapters_count\": len(adapter_links),\n",
        "           \"parent_model\": get_parent_model(model_url)\n",
        "       })\n",
        "\n",
        "       for link in finetune_links:\n",
        "             dfs_finetunes(link, visited, depth + 1, results)\n",
        "       return results\n",
        "\n",
        "# Timestamp for the run\n",
        "timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "\n",
        "# Function to save results as JSON\n",
        "def save_json(results, model_name):\n",
        "    filename = f\"{model_name}_finetunes_{timestamp}.json\"\n",
        "    data = {\n",
        "        \"models\": results\n",
        "    }\n",
        "    with open(filename, \"w\") as f:\n",
        "        json.dump(data, f, indent=4, default=str)\n",
        "    print(f\"Results saved to {filename}\")\n",
        "\n",
        "# Function to save results as CSV\n",
        "''' def save_csv(results, model_name):\n",
        "    filename = f\"{model_name}_{timestamp}_finetunes.csv\"\n",
        "    with open(filename, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
        "        writer = csv.DictWriter(f, fieldnames=[\"model_id\", \"depth\", \"children_count\", \"children\", \"metadata\"])\n",
        "        writer.writeheader()\n",
        "        for entry in results:\n",
        "            # Ensure metadata is a JSON string\n",
        "            if isinstance(entry[\"metadata\"], dict):\n",
        "                entry[\"metadata\"] = json.dumps(entry[\"metadata\"], indent=2, default=str)\n",
        "            # Join children list as a string\n",
        "            entry[\"children\"] = \", \".join(entry[\"children\"])\n",
        "            writer.writerow(entry)\n",
        "    print(f\"Results saved to {filename}\") '''\n",
        "\n",
        "# Function to save results as CSV (pandas)\n",
        "def save_csv(results, model_name):\n",
        "    filename = f\"{model_name}_finetunes_{timestamp}.csv\"\n",
        "    df = pd.DataFrame(results)\n",
        "    df.to_csv(filename, index=True)\n",
        "    print(f\"Results saved to {filename}\")\n",
        "\n",
        "# Main execution\n",
        "if __name__ == \"__main__\":\n",
        "    model_url = input(\"Enter the Hugging Face model URL: \").strip()\n",
        "    visited = set()\n",
        "    results = dfs_finetunes(model_url, visited)\n",
        "\n",
        "    if results:\n",
        "        model_name = results[0][\"model_id\"].split(\"/\")[-1]  # Extract model name for file naming\n",
        "        save_json(results, model_name)\n",
        "        save_csv(results, model_name)\n",
        "    else:\n",
        "        print(\"No fine-tuned models found.\")\n",
        "\n",
        "'''Links for testing: https://huggingface.co/NousResearch/DeepHermes-3-Mistral-24B-Preview (3 fine-tunes at depth 0, 1 fine-tune at depth 1 for 'AlSamCur123/DeepHermes-3-Mistral-24BContinuedFine')\n",
        "https://huggingface.co/perplexity-ai/r1-1776 (11 fine-tunes at depth 0)'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 983
        },
        "outputId": "6c30e5bf-3ac1-45c2-a58b-8c2725f2b1a1",
        "id": "ExG6gRZZjxAQ"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (0.30.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (2025.3.2)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (4.13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (2025.1.31)\n",
            "Requirement already satisfied: adapters in /usr/local/lib/python3.11/dist-packages (1.1.1)\n",
            "Requirement already satisfied: transformers~=4.48.3 in /usr/local/lib/python3.11/dist-packages (from adapters) (4.48.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from adapters) (24.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers~=4.48.3->adapters) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers~=4.48.3->adapters) (0.30.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers~=4.48.3->adapters) (2.0.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers~=4.48.3->adapters) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers~=4.48.3->adapters) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers~=4.48.3->adapters) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers~=4.48.3->adapters) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers~=4.48.3->adapters) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers~=4.48.3->adapters) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers~=4.48.3->adapters) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers~=4.48.3->adapters) (4.13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers~=4.48.3->adapters) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers~=4.48.3->adapters) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers~=4.48.3->adapters) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers~=4.48.3->adapters) (2025.1.31)\n",
            "Enter the Hugging Face model URL: https://huggingface.co/deepseek-ai/DeepSeek-R1\n",
            "\n",
            "Fetching metadata for: deepseek-ai/DeepSeek-R1\n",
            "Found 297 fine-tunes at depth 0.\n",
            "Found 121 adapter models for deepseek-ai/DeepSeek-R1.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'model_name' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-c00c90202382>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[0mmodel_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Enter the Hugging Face model URL: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0mvisited\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdfs_finetunes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvisited\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-39-c00c90202382>\u001b[0m in \u001b[0;36mdfs_finetunes\u001b[0;34m(model_url, visited, depth, results)\u001b[0m\n\u001b[1;32m    145\u001b[0m            \u001b[0;34m\"adapters\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0madapter_links\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m            \u001b[0;34m\"adapters_count\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madapter_links\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m            \u001b[0;34m\"parent_model\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mget_parent_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m        })\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-39-c00c90202382>\u001b[0m in \u001b[0;36mget_parent_model\u001b[0;34m(model_url)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;31m# Function to get parent model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_parent_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel_url\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"/{model_name}/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;31m# Truncate metadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model_name' is not defined"
          ]
        }
      ],
      "source": [
        "# Script 3\n",
        "!pip install huggingface_hub\n",
        "!pip install adapters\n",
        "import requests\n",
        "import pandas as pd\n",
        "import datetime\n",
        "import json\n",
        "import csv\n",
        "from huggingface_hub import HfApi\n",
        "from bs4 import BeautifulSoup\n",
        "from adapters import list_adapters\n",
        "from huggingface_hub import hf_hub_download\n",
        "from adapters import AutoAdapterModel\n",
        "import re\n",
        "\n",
        "\n",
        "\n",
        "# Initialize API\n",
        "api = HfApi()\n",
        "\n",
        "# Function to validate Hugging Face model URL\n",
        "def validate_hf_model_url(url):\n",
        "    pattern = r\"^https://huggingface.co/([\\w\\-]+)/([\\w\\-]+)$\"\n",
        "    match = re.match(pattern, url)\n",
        "    return match.groups() if match else None\n",
        "\n",
        "# page with model finetunes\n",
        "def get_finetuned_models_page(model_org, model_name):\n",
        "    all_model_links = []  # Store all links across pages\n",
        "    page_num = 0\n",
        "    while True:\n",
        "        search_url = f\"https://huggingface.co/models?other=base_model:finetune:{model_org}/{model_name}&p={page_num}\"\n",
        "        response = requests.get(search_url)\n",
        "        if response.status_code != 200:\n",
        "            break  # Exit if page not found\n",
        "\n",
        "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "        model_divs = soup.find_all(\"div\", class_=\"w-full truncate\")\n",
        "        if not model_divs:\n",
        "            break  # Exit if no more models on the page\n",
        "\n",
        "        for div in model_divs:\n",
        "            header = div.find(\"header\")\n",
        "            if header:\n",
        "                model_link = header.get(\"title\")\n",
        "                if model_link:\n",
        "                    all_model_links.append(f\"https://huggingface.co/{model_link}\")\n",
        "\n",
        "        page_num += 1  # Move to the next page\n",
        "\n",
        "    return all_model_links\n",
        "\n",
        "# model card data\n",
        "def get_model_card(model_id):\n",
        "    try:\n",
        "        # Try to download model card if available\n",
        "        readme_path = hf_hub_download(repo_id=model_id, filename='README.md')\n",
        "        with open(readme_path, 'r', encoding='utf-8') as f:\n",
        "            card_content = f.read()\n",
        "        return card_content\n",
        "    except Exception as e:\n",
        "        print(f\"  Could not download model card: {str(e)[:100]}...\")\n",
        "        return \"\"\n",
        "\n",
        "\n",
        "# Function to get parent model\n",
        "def get_parent_model(model_url):\n",
        "    return model_url.split(f\"/{model_name}/\")[0]\n",
        "\n",
        "# Truncate metadata\n",
        "def filter_metadata(json_metadata):\n",
        "            keys_to_keep = [\"modelId\", \"sha\", \"tags\", \"downloads\", \"pipeline_tag\"]\n",
        "            return {k: json_metadata.get(k) for k in keys_to_keep if k in json_metadata}\n",
        "            filtered_metadata = filter_metadata(api.model_info(model_id).__dict__)\n",
        "\n",
        "# Get adapter models\n",
        "def get_adapter_models_page(model_org, model_name):\n",
        "    all_adapter_links = []  # Store all adapter links across pages\n",
        "    page_num = 0\n",
        "    while True:\n",
        "        search_url = f\"https://huggingface.co/models?other=base_model:adapter:{model_org}/{model_name}&p={page_num}\"\n",
        "        response = requests.get(search_url)\n",
        "        if response.status_code != 200:\n",
        "            break  # Exit if page not found\n",
        "\n",
        "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "        model_divs = soup.find_all(\"div\", class_=\"w-full truncate\")\n",
        "        if not model_divs:\n",
        "            break  # Exit if no more models on the page\n",
        "\n",
        "        for div in model_divs:\n",
        "            header = div.find(\"header\")\n",
        "            if header:\n",
        "                model_link = header.get(\"title\")\n",
        "                if model_link:\n",
        "                    all_adapter_links.append(f\"https://huggingface.co/{model_link}\")\n",
        "\n",
        "        page_num += 1  # Move to the next page\n",
        "\n",
        "    return all_adapter_links\n",
        "\n",
        "# Recursive DFS (depth-first search) for finding fine-tunes\n",
        "def dfs_finetunes(model_url, visited, depth=0, results=None):\n",
        "       if results is None:\n",
        "           results = []\n",
        "\n",
        "       if model_url in visited:\n",
        "           return results\n",
        "       visited.add(model_url)\n",
        "\n",
        "       validated = validate_hf_model_url(model_url)\n",
        "       if not validated:\n",
        "           print(f\"Invalid URL skipped: {model_url}\")\n",
        "           model_url = \"N/A\"\n",
        "           return results\n",
        "\n",
        "       model_org, model_name = validated\n",
        "       model_id = f\"{model_org}/{model_name}\"\n",
        "\n",
        "\n",
        "       print(f\"\\n{'  ' * depth}Fetching metadata for: {model_id}\")\n",
        "       try:\n",
        "           model_metadata = api.model_info(model_id).__dict__\n",
        "           json_metadata = json.dumps(model_metadata, default=str)\n",
        "           model_card = get_model_card(model_id)\n",
        "\n",
        "       except Exception as e:\n",
        "           print(f\"Error fetching metadata: {e}\")\n",
        "           return results\n",
        "\n",
        "       finetune_links = get_finetuned_models_page(model_org, model_name)\n",
        "       # Removing Duplicate Children\n",
        "       finetune_links = list(set(finetune_links))\n",
        "       print(f\"{'  ' * depth}Found {len(finetune_links)} fine-tunes at depth {depth}.\")\n",
        "       adapter_links = get_adapter_models_page(model_org, model_name)\n",
        "       print(f\"{'  ' * depth}Found {len(adapter_links)} adapter models for {model_id}.\")\n",
        "\n",
        "       results.append({\n",
        "           \"model_id\": model_id,\n",
        "           \"card\": model_card,\n",
        "           \"metadata\": json_metadata,\n",
        "           \"depth\": depth,\n",
        "           \"children\": finetune_links,\n",
        "           \"children_count\": len(finetune_links),\n",
        "           \"adapters\": adapter_links,\n",
        "           \"adapters_count\": len(adapter_links),\n",
        "           \"parent_model\": get_parent_model(model_url)\n",
        "       })\n",
        "\n",
        "       for link in finetune_links:\n",
        "             dfs_finetunes(link, visited, depth + 1, results)\n",
        "       return results\n",
        "\n",
        "# Timestamp for the run\n",
        "timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "\n",
        "# Function to save results as JSON\n",
        "def save_json(results, model_name):\n",
        "    filename = f\"{model_name}_finetunes_{timestamp}.json\"\n",
        "    data = {\n",
        "        \"models\": results\n",
        "    }\n",
        "    with open(filename, \"w\") as f:\n",
        "        json.dump(data, f, indent=4, default=str)\n",
        "    print(f\"Results saved to {filename}\")\n",
        "\n",
        "# Function to save results as CSV\n",
        "''' def save_csv(results, model_name):\n",
        "    filename = f\"{model_name}_{timestamp}_finetunes.csv\"\n",
        "    with open(filename, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
        "        writer = csv.DictWriter(f, fieldnames=[\"model_id\", \"depth\", \"children_count\", \"children\", \"metadata\"])\n",
        "        writer.writeheader()\n",
        "        for entry in results:\n",
        "            # Ensure metadata is a JSON string\n",
        "            if isinstance(entry[\"metadata\"], dict):\n",
        "                entry[\"metadata\"] = json.dumps(entry[\"metadata\"], indent=2, default=str)\n",
        "            # Join children list as a string\n",
        "            entry[\"children\"] = \", \".join(entry[\"children\"])\n",
        "            writer.writerow(entry)\n",
        "    print(f\"Results saved to {filename}\") '''\n",
        "\n",
        "# Function to save results as CSV (pandas)\n",
        "def save_csv(results, model_name):\n",
        "    filename = f\"{model_name}_finetunes_{timestamp}.csv\"\n",
        "    df = pd.DataFrame(results)\n",
        "    df.to_csv(filename, index=True)\n",
        "    print(f\"Results saved to {filename}\")\n",
        "\n",
        "# Main execution\n",
        "if __name__ == \"__main__\":\n",
        "    model_url = input(\"Enter the Hugging Face model URL: \").strip()\n",
        "    visited = set()\n",
        "    results = dfs_finetunes(model_url, visited)\n",
        "\n",
        "    if results:\n",
        "        model_name = results[0][\"model_id\"].split(\"/\")[-1]  # Extract model name for file naming\n",
        "        save_json(results, model_name)\n",
        "        save_csv(results, model_name)\n",
        "    else:\n",
        "        print(\"No fine-tuned models found.\")\n",
        "\n",
        "'''Links for testing: https://huggingface.co/NousResearch/DeepHermes-3-Mistral-24B-Preview (3 fine-tunes at depth 0, 1 fine-tune at depth 1 for 'AlSamCur123/DeepHermes-3-Mistral-24BContinuedFine')\n",
        "https://huggingface.co/perplexity-ai/r1-1776 (11 fine-tunes at depth 0)'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 983
        },
        "outputId": "6c30e5bf-3ac1-45c2-a58b-8c2725f2b1a1",
        "id": "kUiZZoDqjyOO"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (0.30.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (2025.3.2)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (4.13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (2025.1.31)\n",
            "Requirement already satisfied: adapters in /usr/local/lib/python3.11/dist-packages (1.1.1)\n",
            "Requirement already satisfied: transformers~=4.48.3 in /usr/local/lib/python3.11/dist-packages (from adapters) (4.48.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from adapters) (24.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers~=4.48.3->adapters) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers~=4.48.3->adapters) (0.30.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers~=4.48.3->adapters) (2.0.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers~=4.48.3->adapters) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers~=4.48.3->adapters) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers~=4.48.3->adapters) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers~=4.48.3->adapters) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers~=4.48.3->adapters) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers~=4.48.3->adapters) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers~=4.48.3->adapters) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers~=4.48.3->adapters) (4.13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers~=4.48.3->adapters) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers~=4.48.3->adapters) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers~=4.48.3->adapters) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers~=4.48.3->adapters) (2025.1.31)\n",
            "Enter the Hugging Face model URL: https://huggingface.co/deepseek-ai/DeepSeek-R1\n",
            "\n",
            "Fetching metadata for: deepseek-ai/DeepSeek-R1\n",
            "Found 297 fine-tunes at depth 0.\n",
            "Found 121 adapter models for deepseek-ai/DeepSeek-R1.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'model_name' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-c00c90202382>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[0mmodel_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Enter the Hugging Face model URL: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0mvisited\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdfs_finetunes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvisited\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-39-c00c90202382>\u001b[0m in \u001b[0;36mdfs_finetunes\u001b[0;34m(model_url, visited, depth, results)\u001b[0m\n\u001b[1;32m    145\u001b[0m            \u001b[0;34m\"adapters\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0madapter_links\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m            \u001b[0;34m\"adapters_count\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madapter_links\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m            \u001b[0;34m\"parent_model\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mget_parent_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m        })\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-39-c00c90202382>\u001b[0m in \u001b[0;36mget_parent_model\u001b[0;34m(model_url)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;31m# Function to get parent model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_parent_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel_url\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"/{model_name}/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;31m# Truncate metadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model_name' is not defined"
          ]
        }
      ],
      "source": [
        "# Script 3\n",
        "!pip install huggingface_hub\n",
        "!pip install adapters\n",
        "import requests\n",
        "import pandas as pd\n",
        "import datetime\n",
        "import json\n",
        "import csv\n",
        "from huggingface_hub import HfApi\n",
        "from bs4 import BeautifulSoup\n",
        "from adapters import list_adapters\n",
        "from huggingface_hub import hf_hub_download\n",
        "from adapters import AutoAdapterModel\n",
        "import re\n",
        "\n",
        "\n",
        "\n",
        "# Initialize API\n",
        "api = HfApi()\n",
        "\n",
        "# Function to validate Hugging Face model URL\n",
        "def validate_hf_model_url(url):\n",
        "    pattern = r\"^https://huggingface.co/([\\w\\-]+)/([\\w\\-]+)$\"\n",
        "    match = re.match(pattern, url)\n",
        "    return match.groups() if match else None\n",
        "\n",
        "# page with model finetunes\n",
        "def get_finetuned_models_page(model_org, model_name):\n",
        "    all_model_links = []  # Store all links across pages\n",
        "    page_num = 0\n",
        "    while True:\n",
        "        search_url = f\"https://huggingface.co/models?other=base_model:finetune:{model_org}/{model_name}&p={page_num}\"\n",
        "        response = requests.get(search_url)\n",
        "        if response.status_code != 200:\n",
        "            break  # Exit if page not found\n",
        "\n",
        "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "        model_divs = soup.find_all(\"div\", class_=\"w-full truncate\")\n",
        "        if not model_divs:\n",
        "            break  # Exit if no more models on the page\n",
        "\n",
        "        for div in model_divs:\n",
        "            header = div.find(\"header\")\n",
        "            if header:\n",
        "                model_link = header.get(\"title\")\n",
        "                if model_link:\n",
        "                    all_model_links.append(f\"https://huggingface.co/{model_link}\")\n",
        "\n",
        "        page_num += 1  # Move to the next page\n",
        "\n",
        "    return all_model_links\n",
        "\n",
        "# model card data\n",
        "def get_model_card(model_id):\n",
        "    try:\n",
        "        # Try to download model card if available\n",
        "        readme_path = hf_hub_download(repo_id=model_id, filename='README.md')\n",
        "        with open(readme_path, 'r', encoding='utf-8') as f:\n",
        "            card_content = f.read()\n",
        "        return card_content\n",
        "    except Exception as e:\n",
        "        print(f\"  Could not download model card: {str(e)[:100]}...\")\n",
        "        return \"\"\n",
        "\n",
        "\n",
        "# Function to get parent model\n",
        "def get_parent_model(model_url):\n",
        "    return model_url.split(f\"/{model_name}/\")[0]\n",
        "\n",
        "# Truncate metadata\n",
        "def filter_metadata(json_metadata):\n",
        "            keys_to_keep = [\"modelId\", \"sha\", \"tags\", \"downloads\", \"pipeline_tag\"]\n",
        "            return {k: json_metadata.get(k) for k in keys_to_keep if k in json_metadata}\n",
        "            filtered_metadata = filter_metadata(api.model_info(model_id).__dict__)\n",
        "\n",
        "# Get adapter models\n",
        "def get_adapter_models_page(model_org, model_name):\n",
        "    all_adapter_links = []  # Store all adapter links across pages\n",
        "    page_num = 0\n",
        "    while True:\n",
        "        search_url = f\"https://huggingface.co/models?other=base_model:adapter:{model_org}/{model_name}&p={page_num}\"\n",
        "        response = requests.get(search_url)\n",
        "        if response.status_code != 200:\n",
        "            break  # Exit if page not found\n",
        "\n",
        "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "        model_divs = soup.find_all(\"div\", class_=\"w-full truncate\")\n",
        "        if not model_divs:\n",
        "            break  # Exit if no more models on the page\n",
        "\n",
        "        for div in model_divs:\n",
        "            header = div.find(\"header\")\n",
        "            if header:\n",
        "                model_link = header.get(\"title\")\n",
        "                if model_link:\n",
        "                    all_adapter_links.append(f\"https://huggingface.co/{model_link}\")\n",
        "\n",
        "        page_num += 1  # Move to the next page\n",
        "\n",
        "    return all_adapter_links\n",
        "\n",
        "# Recursive DFS (depth-first search) for finding fine-tunes\n",
        "def dfs_finetunes(model_url, visited, depth=0, results=None):\n",
        "       if results is None:\n",
        "           results = []\n",
        "\n",
        "       if model_url in visited:\n",
        "           return results\n",
        "       visited.add(model_url)\n",
        "\n",
        "       validated = validate_hf_model_url(model_url)\n",
        "       if not validated:\n",
        "           print(f\"Invalid URL skipped: {model_url}\")\n",
        "           model_url = \"N/A\"\n",
        "           return results\n",
        "\n",
        "       model_org, model_name = validated\n",
        "       model_id = f\"{model_org}/{model_name}\"\n",
        "\n",
        "\n",
        "       print(f\"\\n{'  ' * depth}Fetching metadata for: {model_id}\")\n",
        "       try:\n",
        "           model_metadata = api.model_info(model_id).__dict__\n",
        "           json_metadata = json.dumps(model_metadata, default=str)\n",
        "           model_card = get_model_card(model_id)\n",
        "\n",
        "       except Exception as e:\n",
        "           print(f\"Error fetching metadata: {e}\")\n",
        "           return results\n",
        "\n",
        "       finetune_links = get_finetuned_models_page(model_org, model_name)\n",
        "       # Removing Duplicate Children\n",
        "       finetune_links = list(set(finetune_links))\n",
        "       print(f\"{'  ' * depth}Found {len(finetune_links)} fine-tunes at depth {depth}.\")\n",
        "       adapter_links = get_adapter_models_page(model_org, model_name)\n",
        "       print(f\"{'  ' * depth}Found {len(adapter_links)} adapter models for {model_id}.\")\n",
        "\n",
        "       results.append({\n",
        "           \"model_id\": model_id,\n",
        "           \"card\": model_card,\n",
        "           \"metadata\": json_metadata,\n",
        "           \"depth\": depth,\n",
        "           \"children\": finetune_links,\n",
        "           \"children_count\": len(finetune_links),\n",
        "           \"adapters\": adapter_links,\n",
        "           \"adapters_count\": len(adapter_links),\n",
        "           \"parent_model\": get_parent_model(model_url)\n",
        "       })\n",
        "\n",
        "       for link in finetune_links:\n",
        "             dfs_finetunes(link, visited, depth + 1, results)\n",
        "       return results\n",
        "\n",
        "# Timestamp for the run\n",
        "timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "\n",
        "# Function to save results as JSON\n",
        "def save_json(results, model_name):\n",
        "    filename = f\"{model_name}_finetunes_{timestamp}.json\"\n",
        "    data = {\n",
        "        \"models\": results\n",
        "    }\n",
        "    with open(filename, \"w\") as f:\n",
        "        json.dump(data, f, indent=4, default=str)\n",
        "    print(f\"Results saved to {filename}\")\n",
        "\n",
        "# Function to save results as CSV\n",
        "''' def save_csv(results, model_name):\n",
        "    filename = f\"{model_name}_{timestamp}_finetunes.csv\"\n",
        "    with open(filename, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
        "        writer = csv.DictWriter(f, fieldnames=[\"model_id\", \"depth\", \"children_count\", \"children\", \"metadata\"])\n",
        "        writer.writeheader()\n",
        "        for entry in results:\n",
        "            # Ensure metadata is a JSON string\n",
        "            if isinstance(entry[\"metadata\"], dict):\n",
        "                entry[\"metadata\"] = json.dumps(entry[\"metadata\"], indent=2, default=str)\n",
        "            # Join children list as a string\n",
        "            entry[\"children\"] = \", \".join(entry[\"children\"])\n",
        "            writer.writerow(entry)\n",
        "    print(f\"Results saved to {filename}\") '''\n",
        "\n",
        "# Function to save results as CSV (pandas)\n",
        "def save_csv(results, model_name):\n",
        "    filename = f\"{model_name}_finetunes_{timestamp}.csv\"\n",
        "    df = pd.DataFrame(results)\n",
        "    df.to_csv(filename, index=True)\n",
        "    print(f\"Results saved to {filename}\")\n",
        "\n",
        "# Main execution\n",
        "if __name__ == \"__main__\":\n",
        "    model_url = input(\"Enter the Hugging Face model URL: \").strip()\n",
        "    visited = set()\n",
        "    results = dfs_finetunes(model_url, visited)\n",
        "\n",
        "    if results:\n",
        "        model_name = results[0][\"model_id\"].split(\"/\")[-1]  # Extract model name for file naming\n",
        "        save_json(results, model_name)\n",
        "        save_csv(results, model_name)\n",
        "    else:\n",
        "        print(\"No fine-tuned models found.\")\n",
        "\n",
        "'''Links for testing: https://huggingface.co/NousResearch/DeepHermes-3-Mistral-24B-Preview (3 fine-tunes at depth 0, 1 fine-tune at depth 1 for 'AlSamCur123/DeepHermes-3-Mistral-24BContinuedFine')\n",
        "https://huggingface.co/perplexity-ai/r1-1776 (11 fine-tunes at depth 0)'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cxlHKer226vF"
      },
      "source": [
        "# Script 1\n",
        "Takes in a (validated) model url and output its metadata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 474
        },
        "id": "Fmp0ftEomk86",
        "outputId": "3b3d0b58-f682-4d40-d0cb-9d2f0f493bbf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting validators\n",
            "  Downloading validators-0.34.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Downloading validators-0.34.0-py3-none-any.whl (43 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m43.5/43.5 kB\u001b[0m \u001b[31m781.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: validators\n",
            "Successfully installed validators-0.34.0\n",
            "Enter model URL: https://huggingface.co/deepseek-ai/DeepSeek-R1\n",
            "You entered: https://huggingface.co/deepseek-ai/DeepSeek-R1\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "'generator' object is not subscriptable",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-b08047d983af>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;31m# To test: https://huggingface.co/deepseek-ai/DeepSeek-R1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0minput_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-37-b08047d983af>\u001b[0m in \u001b[0;36minput_url\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m                 \u001b[0mmodel_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_model_url\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"huggingface.co/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                 \u001b[0mmodel_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhf_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_id\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Get model info: https://huggingface.co/docs/huggingface_hub/v0.29.2/en/package_reference/hf_api#huggingface_hub.ModelInfo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m                 \u001b[0mmodel_card\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhf_hub_download\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodelId\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'README.md'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m                 metadata = { # Moved metadata assignment inside the if block\n",
            "\u001b[0;31mTypeError\u001b[0m: 'generator' object is not subscriptable"
          ]
        }
      ],
      "source": [
        "# Script 1: takes input model url, validates url, and gives model metadata\n",
        "!pip install validators\n",
        "from huggingface_hub import HfApi\n",
        "import huggingface_hub as hf\n",
        "import validators\n",
        "import json\n",
        "import csv\n",
        "\n",
        "hf_api = HfApi()\n",
        "\n",
        "def input_url():\n",
        "    while True:\n",
        "        input_model_url = input(\"Enter model URL: \")\n",
        "        print(f\"You entered: {input_model_url}\")\n",
        "\n",
        "        if validators.url(input_model_url) and \"huggingface.co\" in input_model_url:\n",
        "                # Extract the model ID from the URL\n",
        "                model_id = input_model_url.split(\"huggingface.co/\")[-1]\n",
        "                model_info = hf_api.model_info(model_id) # Get model info: https://huggingface.co/docs/huggingface_hub/v0.29.2/en/package_reference/hf_api#huggingface_hub.ModelInfo\n",
        "                model_card = hf.hf_hub_download(models[0].modelId, 'README.md')\n",
        "\n",
        "                metadata = { # Moved metadata assignment inside the if block\n",
        "                    \"model_id\": model_id,\n",
        "                    \"model_info\": model_info.__dict__\n",
        "                }\n",
        "                return metadata # Return is now inside if block\n",
        "                json_output = json.dumps(metadata, indent=4, default=str)\n",
        "                with open('model_info.json', 'w') as json_file:\n",
        "                 json_file.write(json_output)\n",
        "                print(json_output)\n",
        "        else:\n",
        "            print(\"Invalid URL. Please enter a valid Hugging Face model URL.\")\n",
        "            # Optionally: You could return None or an empty dictionary here\n",
        "            # to indicate an invalid URL\n",
        "# To test: https://huggingface.co/deepseek-ai/DeepSeek-R1\n",
        "\n",
        "input_url()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gOnHUAW23SNE"
      },
      "source": [
        "# Script 2\n",
        "Takes in a (validated) model and outputs the children models/fine-tunes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6petSSd-m2Qi"
      },
      "outputs": [],
      "source": [
        "# Script 2\n",
        "  # 1. Take link as input (format check). This is the \"main model\"\n",
        "  # 2. Give the link to the page with the fine-tunes for the inputted model\n",
        "\n",
        "from huggingface_hub import HfApi\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "\n",
        "# Initialize API\n",
        "api = HfApi()\n",
        "\n",
        "# Function to validate Hugging Face model URL\n",
        "def validate_hf_model_url(url):\n",
        "    pattern = r\"^https://huggingface.co/([\\w\\-]+)/([\\w\\-]+)$\"\n",
        "    match = re.match(pattern, url)\n",
        "    if match:\n",
        "        return match.groups()  # Returns (org/user, model_name)\n",
        "    return None\n",
        "\n",
        "# Function to find fine-tuned models\n",
        "def get_finetuned_models_page(model_org, model_name):\n",
        "    search_url = f\"https://huggingface.co/models?search={model_name}\"\n",
        "    response = requests.get(search_url)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "        model_links = [\n",
        "            a[\"href\"] for a in soup.find_all(\"a\", href=True)\n",
        "            if model_name.lower() in a[\"href\"].lower()\n",
        "        ]\n",
        "        return [f\"https://huggingface.co{link}\" for link in model_links if model_org not in link]\n",
        "\n",
        "    return []\n",
        "\n",
        "# Main execution\n",
        "model_url = input(\"Enter the Hugging Face model URL: \").strip()\n",
        "\n",
        "validated = validate_hf_model_url(model_url)\n",
        "if validated:\n",
        "    org, model_name = validated\n",
        "    finetune_links = get_finetuned_models_page(org, model_name)\n",
        "\n",
        "    if finetune_links:\n",
        "        print(\"Fine-tuned models found:\")\n",
        "        for link in finetune_links:\n",
        "            print(link)\n",
        "    else:\n",
        "        print(\"No fine-tuned models found for this model.\")\n",
        "else:\n",
        "    print(\"Invalid Hugging Face model URL format.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ruI5-1FA1ipq"
      },
      "source": [
        "# Script 3\n",
        "## Search steps overview\n",
        "- `dfs_finetunes` we take the `model_url` as input. Alternatively, we can add this var as an argument.\n",
        "- We go layer-by-layer and find the children of the current model (i.e. the fine-tunes of a model)\n",
        "- We call the `dfs_funetunes` function recursively and store the models that have been \"visited\" to avoid duplicates.\n",
        "- We have a dictionary of information that we store about the \"current model\" and have the information stored in respective columns (model_id, card, metadata, depth, children (list of model links), children count).\n",
        "- We have a `results` list that has the information about all the models and their fine-tunes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Da_92M_Cgv1N",
        "outputId": "11604753-b258-4489-e65f-6d90190719a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: adapters in /usr/local/lib/python3.11/dist-packages (1.1.1)\n",
            "Requirement already satisfied: transformers~=4.48.3 in /usr/local/lib/python3.11/dist-packages (from adapters) (4.48.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from adapters) (24.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers~=4.48.3->adapters) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers~=4.48.3->adapters) (0.30.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers~=4.48.3->adapters) (2.0.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers~=4.48.3->adapters) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers~=4.48.3->adapters) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers~=4.48.3->adapters) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers~=4.48.3->adapters) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers~=4.48.3->adapters) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers~=4.48.3->adapters) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers~=4.48.3->adapters) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers~=4.48.3->adapters) (4.13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers~=4.48.3->adapters) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers~=4.48.3->adapters) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers~=4.48.3->adapters) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers~=4.48.3->adapters) (2025.1.31)\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0mTraceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/base_command.py\", line 179, in exc_logging_wrapper\n",
            "    status = run_func(*args)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/req_command.py\", line 67, in wrapper\n",
            "    return func(self, options, args)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/commands/install.py\", line 447, in run\n",
            "    conflicts = self._determine_conflicts(to_install)\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/commands/install.py\", line 578, in _determine_conflicts\n",
            "    return check_install_conflicts(to_install)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/operations/check.py\", line 101, in check_install_conflicts\n",
            "    package_set, _ = create_package_set_from_installed()\n",
            "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/operations/check.py\", line 42, in create_package_set_from_installed\n",
            "    dependencies = list(dist.iter_dependencies())\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/metadata/importlib/_dists.py\", line 222, in iter_dependencies\n",
            "    req = Requirement(req_string.strip())\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_vendor/packaging/requirements.py\", line 36, in __init__\n",
            "    parsed = _parse_requirement(requirement_string)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_vendor/packaging/_parser.py\", line 62, in parse_requirement\n",
            "    return _parse_requirement(Tokenizer(source, rules=DEFAULT_RULES))\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_vendor/packaging/_parser.py\", line 80, in _parse_requirement\n",
            "    url, specifier, marker = _parse_requirement_details(tokenizer)\n",
            "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_vendor/packaging/_parser.py\", line 124, in _parse_requirement_details\n",
            "    marker = _parse_requirement_marker(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_vendor/packaging/_parser.py\", line 151, in _parse_requirement_marker\n",
            "    marker = _parse_marker(tokenizer)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_vendor/packaging/_parser.py\", line 266, in _parse_marker\n",
            "    expression = [_parse_marker_atom(tokenizer)]\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_vendor/packaging/_parser.py\", line 291, in _parse_marker_atom\n",
            "    marker = _parse_marker_item(tokenizer)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_vendor/packaging/_parser.py\", line 305, in _parse_marker_item\n",
            "    marker_var_right = _parse_marker_var(tokenizer)\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_vendor/packaging/_parser.py\", line 316, in _parse_marker_var\n",
            "    elif tokenizer.check(\"QUOTED_STRING\"):\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_vendor/packaging/_tokenizer.py\", line 129, in check\n",
            "    match = expression.match(self.source, self.position)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/pip3\", line 10, in <module>\n",
            "    sys.exit(main())\n",
            "             ^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/main.py\", line 80, in main\n",
            "    return command.main(cmd_args)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/base_command.py\", line 100, in main\n",
            "    return self._main(args)\n",
            "           ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/base_command.py\", line 232, in _main\n",
            "    return run(options, args)\n",
            "           ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/base_command.py\", line 215, in exc_logging_wrapper\n",
            "    logger.critical(\"Operation cancelled by user\")\n",
            "  File \"/usr/lib/python3.11/logging/__init__.py\", line 1536, in critical\n",
            "    self._log(CRITICAL, msg, args, **kwargs)\n",
            "  File \"/usr/lib/python3.11/logging/__init__.py\", line 1634, in _log\n",
            "    self.handle(record)\n",
            "  File \"/usr/lib/python3.11/logging/__init__.py\", line 1644, in handle\n",
            "    self.callHandlers(record)\n",
            "  File \"/usr/lib/python3.11/logging/__init__.py\", line 1706, in callHandlers\n",
            "    hdlr.handle(record)\n",
            "  File \"/usr/lib/python3.11/logging/__init__.py\", line 978, in handle\n",
            "    self.emit(record)\n",
            "  File \"/usr/lib/python3.11/logging/handlers.py\", line 75, in emit\n",
            "    logging.FileHandler.emit(self, record)\n",
            "  File \"/usr/lib/python3.11/logging/__init__.py\", line 1230, in emit\n",
            "    StreamHandler.emit(self, record)\n",
            "  File \"/usr/lib/python3.11/logging/__init__.py\", line 1110, in emit\n",
            "    msg = self.format(record)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/logging/__init__.py\", line 953, in format\n",
            "    return fmt.format(record)\n",
            "           ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/utils/logging.py\", line 118, in format\n",
            "    prefix = f\"{self.formatTime(record)} \"\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/logging/__init__.py\", line 624, in formatTime\n",
            "    ct = self.converter(record.created)\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "KeyboardInterrupt\n",
            "^C\n",
            "Requirement already satisfied: backoff in /usr/local/lib/python3.11/dist-packages (2.2.1)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-c475e2578d5f>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[0;31m# Main execution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m     \u001b[0mmodel_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Enter the Hugging Face model URL: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m     \u001b[0mvisited\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdfs_finetunes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvisited\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1175\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m             )\n\u001b[0;32m-> 1177\u001b[0;31m         return self._input_request(\n\u001b[0m\u001b[1;32m   1178\u001b[0m             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"shell\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1219\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1220\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ],
      "source": [
        "!pip install adapters\n",
        "!pip install backoff # handle rate-limiting\n",
        "import requests\n",
        "import pandas as pd\n",
        "import datetime\n",
        "import json\n",
        "import csv\n",
        "from huggingface_hub import HfApi\n",
        "from bs4 import BeautifulSoup\n",
        "from adapters import list_adapters\n",
        "from huggingface_hub import hf_hub_download\n",
        "from adapters import AutoAdapterModel\n",
        "import re\n",
        "import backoff\n",
        "\n",
        "# Initialize API\n",
        "api = HfApi()\n",
        "\n",
        "# Function to validate Hugging Face model URL\n",
        "def validate_hf_model_url(url):\n",
        "    pattern = r\"^https://huggingface.co/([\\w\\-]+)/([\\w\\-]+)$\"\n",
        "    match = re.match(pattern, url)\n",
        "    return match.groups() if match else None\n",
        "\n",
        "# Apply backoff to requests\n",
        "@backoff.on_exception(\n",
        "    backoff.expo,\n",
        "    (requests.exceptions.RequestException, Exception),\n",
        "    max_tries=5,\n",
        "    factor=2,  # Base of exponential backoff\n",
        "    jitter=backoff.full_jitter  # Add randomness to prevent thundering herd\n",
        ")\n",
        "def make_http_request(url):\n",
        "    response = requests.get(url)\n",
        "    response.raise_for_status()  # Raise exception for non-200 status codes\n",
        "    return response\n",
        "\n",
        "# Page with model finetunes\n",
        "@backoff.on_exception(\n",
        "    backoff.expo,\n",
        "    (requests.exceptions.RequestException, Exception),\n",
        "    max_tries=5,\n",
        "    factor=2,\n",
        "    jitter=backoff.full_jitter\n",
        ")\n",
        "def get_finetuned_models_page(model_org, model_name):\n",
        "    all_model_links = []  # Store all links across pages\n",
        "    page_num = 0\n",
        "    while True:\n",
        "        try:\n",
        "            search_url = f\"https://huggingface.co/models?other=base_model:finetune:{model_org}/{model_name}&p={page_num}\"\n",
        "            response = make_http_request(search_url)\n",
        "\n",
        "            soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "            model_divs = soup.find_all(\"div\", class_=\"w-full truncate\")\n",
        "            if not model_divs:\n",
        "                break  # Exit if no more models on the page\n",
        "\n",
        "            for div in model_divs:\n",
        "                header = div.find(\"header\")\n",
        "                if header:\n",
        "                    model_link = header.get(\"title\")\n",
        "                    if model_link:\n",
        "                        all_model_links.append(f\"https://huggingface.co/{model_link}\")\n",
        "\n",
        "            page_num += 1  # Move to the next page\n",
        "        except requests.exceptions.HTTPError as e:\n",
        "            print(f\"HTTP error occurred: {e}\")\n",
        "            break\n",
        "\n",
        "    return all_model_links\n",
        "\n",
        "# Get model card data\n",
        "@backoff.on_exception(\n",
        "    backoff.expo,\n",
        "    (requests.exceptions.RequestException, Exception),\n",
        "    max_tries=5,\n",
        "    factor=2,\n",
        "    jitter=backoff.full_jitter\n",
        ")\n",
        "def get_model_card(model_id):\n",
        "    try:\n",
        "        # Try to download model card if available\n",
        "        readme_path = hf_hub_download(repo_id=model_id, filename='README.md')\n",
        "        with open(readme_path, 'r', encoding='utf-8') as f:\n",
        "            card_content = f.read()\n",
        "        return card_content\n",
        "    except Exception as e:\n",
        "        print(f\"  Could not download model card: {str(e)[:100]}...\")\n",
        "        return \"\"\n",
        "\n",
        "# Get model metadata with backoff\n",
        "@backoff.on_exception(\n",
        "    backoff.expo,\n",
        "    (requests.exceptions.RequestException, Exception),\n",
        "    max_tries=5,\n",
        "    factor=2,\n",
        "    jitter=backoff.full_jitter\n",
        ")\n",
        "def get_model_metadata(model_id):\n",
        "    return api.model_info(model_id).__dict__\n",
        "\n",
        "# Truncate metadata\n",
        "def filter_metadata(json_metadata):\n",
        "    keys_to_keep = [\"modelId\", \"sha\", \"tags\", \"downloads\", \"pipeline_tag\"]\n",
        "    return {k: json_metadata.get(k) for k in keys_to_keep if k in json_metadata}\n",
        "\n",
        "# Get adapter models\n",
        "@backoff.on_exception(\n",
        "    backoff.expo,\n",
        "    (requests.exceptions.RequestException, Exception),\n",
        "    max_tries=5,\n",
        "    factor=2,\n",
        "    jitter=backoff.full_jitter\n",
        ")\n",
        "def get_adapter_models_page(model_org, model_name):\n",
        "    all_adapter_links = []  # Store all adapter links across pages\n",
        "    page_num = 0\n",
        "    while True:\n",
        "        try:\n",
        "            search_url = f\"https://huggingface.co/models?other=base_model:adapter:{model_org}/{model_name}&p={page_num}\"\n",
        "            response = make_http_request(search_url)\n",
        "\n",
        "            soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "            model_divs = soup.find_all(\"div\", class_=\"w-full truncate\")\n",
        "            if not model_divs:\n",
        "                break  # Exit if no more models on the page\n",
        "\n",
        "            for div in model_divs:\n",
        "                header = div.find(\"header\")\n",
        "                if header:\n",
        "                    model_link = header.get(\"title\")\n",
        "                    if model_link:\n",
        "                        all_adapter_links.append(f\"https://huggingface.co/{model_link}\")\n",
        "\n",
        "            page_num += 1  # Move to the next page\n",
        "        except requests.exceptions.HTTPError as e:\n",
        "            print(f\"HTTP error occurred: {e}\")\n",
        "            break\n",
        "\n",
        "    return all_adapter_links\n",
        "\n",
        "# Recursive DFS (depth-first search) for finding fine-tunes\n",
        "def dfs_finetunes(model_url, visited, depth=0, results=None):\n",
        "    if results is None:\n",
        "        results = []\n",
        "\n",
        "    if model_url in visited:\n",
        "        return results\n",
        "    visited.add(model_url)\n",
        "\n",
        "    validated = validate_hf_model_url(model_url)\n",
        "    if not validated:\n",
        "        print(f\"Invalid URL skipped: {model_url}\")\n",
        "        return results\n",
        "\n",
        "    model_org, model_name = validated\n",
        "    model_id = f\"{model_org}/{model_name}\"\n",
        "\n",
        "    print(f\"\\n{'  ' * depth}Fetching metadata for: {model_id}\")\n",
        "    try:\n",
        "        model_metadata = get_model_metadata(model_id)\n",
        "        filtered_metadata = filter_metadata(model_metadata)\n",
        "        json_metadata = json.dumps(filtered_metadata, default=str)\n",
        "        model_card = get_model_card(model_id)\n",
        "\n",
        "        finetune_links = get_finetuned_models_page(model_org, model_name)\n",
        "        # Removing Duplicate Children\n",
        "        finetune_links = list(set(finetune_links))\n",
        "        print(f\"{'  ' * depth}Found {len(finetune_links)} fine-tunes at depth {depth}.\")\n",
        "\n",
        "        adapter_links = get_adapter_models_page(model_org, model_name)\n",
        "        print(f\"{'  ' * depth}Found {len(adapter_links)} adapter models for {model_id}.\")\n",
        "\n",
        "        results.append({\n",
        "            \"model_id\": model_id,\n",
        "            \"card\": model_card,\n",
        "            \"metadata\": json_metadata,\n",
        "            \"depth\": depth,\n",
        "            \"children\": finetune_links,\n",
        "            \"children_count\": len(finetune_links),\n",
        "            \"adapters\": adapter_links,\n",
        "            \"adapters_count\": len(adapter_links)\n",
        "        })\n",
        "\n",
        "        for link in finetune_links:\n",
        "            dfs_finetunes(link, visited, depth + 1, results)\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {model_id}: {e}\")\n",
        "\n",
        "    return results\n",
        "\n",
        "# Timestamp for the run\n",
        "timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "\n",
        "# Function to save results as JSON\n",
        "def save_json(results, model_name):\n",
        "    filename = f\"{model_name}_finetunes_{timestamp}.json\"\n",
        "    data = {\n",
        "        \"models\": results\n",
        "    }\n",
        "    with open(filename, \"w\") as f:\n",
        "        json.dump(data, f, indent=4, default=str)\n",
        "    print(f\"Results saved to {filename}\")\n",
        "\n",
        "# Function to save results as CSV (pandas)\n",
        "def save_csv(results, model_name):\n",
        "    filename = f\"{model_name}_finetunes_{timestamp}.csv\"\n",
        "    df = pd.DataFrame(results)\n",
        "    df.to_csv(filename, index=True)\n",
        "    print(f\"Results saved to {filename}\")\n",
        "\n",
        "# Main execution\n",
        "if __name__ == \"__main__\":\n",
        "    model_url = input(\"Enter the Hugging Face model URL: \").strip()\n",
        "    visited = set()\n",
        "    results = dfs_finetunes(model_url, visited)\n",
        "\n",
        "    if results:\n",
        "        model_name = results[0][\"model_id\"].split(\"/\")[-1]  # Extract model name for file naming\n",
        "        save_json(results, model_name)\n",
        "        save_csv(results, model_name)\n",
        "    else:\n",
        "        print(\"No fine-tuned models found.\")\n",
        "\n",
        "'''Links for testing: https://huggingface.co/NousResearch/DeepHermes-3-Mistral-24B-Preview (3 fine-tunes at depth 0, 1 fine-tune at depth 1 for 'AlSamCur123/DeepHermes-3-Mistral-24BContinuedFine')\n",
        "https://huggingface.co/perplexity-ai/r1-1776 (11 fine-tunes at depth 0)'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zWhCzNPsiXgX"
      },
      "source": [
        "# Scripts 4 (Tree Viz)\n",
        "\n",
        "Iteratively produces model tree datasets when given a list of models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kn8T_f0IivaD"
      },
      "outputs": [],
      "source": [
        "# 4.1 Phylogenetic tree\n",
        "\n",
        "!pip install Bio\n",
        "!pip install pandas\n",
        "import pandas as pd\n",
        "import ast\n",
        "import matplotlib.pyplot as plt\n",
        "from Bio import Phylo\n",
        "from Bio.Phylo.BaseTree import Clade, Tree\n",
        "\n",
        "# Load and prepare tree\n",
        "df = pd.read_csv(\"/content/DeepSeek-R1_finetunes_20250408_202441.csv\")\n",
        "df['children'] = df['children'].apply(ast.literal_eval)\n",
        "\n",
        "def build_phylo_tree_from_dfs(df):\n",
        "    clade_map = {row['model_id']: Clade(name=row['model_id']) for _, row in df.iterrows()}\n",
        "    parent_links = {}\n",
        "    for _, row in df.iterrows():\n",
        "        parent = row['model_id']\n",
        "        for child_url in row['children']:\n",
        "            child = '/'.join(child_url.split(\"/\")[-2:])\n",
        "            parent_links[child] = parent\n",
        "    all_models = set(df['model_id'])\n",
        "    child_models = set(parent_links.keys())\n",
        "    root_model_id = list(all_models - child_models)[0]\n",
        "    for child, parent in parent_links.items():\n",
        "        if child in clade_map and parent in clade_map:\n",
        "            clade_map[parent].clades.append(clade_map[child])\n",
        "    return Tree(root=clade_map[root_model_id])\n",
        "\n",
        "tree = build_phylo_tree_from_dfs(df)\n",
        "\n",
        "# Plotting with labels on branches\n",
        "fig = plt.figure(figsize=(24, 36))\n",
        "ax = fig.add_subplot(1, 1, 1)\n",
        "\n",
        "# Draw the tree without axes\n",
        "Phylo.draw(tree, axes=ax, do_show=False)\n",
        "\n",
        "# Remove all axes elements\n",
        "ax.set_axis_off()\n",
        "ax.set_xticks([])\n",
        "ax.set_yticks([])\n",
        "ax.set_xticklabels([])\n",
        "ax.set_yticklabels([])\n",
        "ax.spines['top'].set_visible(False)\n",
        "ax.spines['right'].set_visible(False)\n",
        "ax.spines['bottom'].set_visible(False)\n",
        "ax.spines['left'].set_visible(False)\n",
        "\n",
        "# Ensure labels are positioned away from branch lines\n",
        "for label in ax.texts:\n",
        "    pos = label.get_position()\n",
        "    label.set_position((pos[0], pos[1]))\n",
        "    label.set_bbox(dict(facecolor='white', alpha=0.8, edgecolor='none', pad=3))\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('clean_phylogenetic_tree.png', dpi=200, bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "uAQvfhCa0TJ6",
        "outputId": "44c7e645-1be5-45e5-9c37-96eb58b76418"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "graphviz is already the newest version (2.42.2-6ubuntu0.1).\n",
            "The following additional packages will be installed:\n",
            "  libgail-common libgail18 libgtk2.0-0 libgtk2.0-bin libgtk2.0-common\n",
            "  libgvc6-plugins-gtk librsvg2-common libxdot4\n",
            "Suggested packages:\n",
            "  gvfs\n",
            "The following NEW packages will be installed:\n",
            "  libgail-common libgail18 libgraphviz-dev libgtk2.0-0 libgtk2.0-bin\n",
            "  libgtk2.0-common libgvc6-plugins-gtk librsvg2-common libxdot4\n",
            "0 upgraded, 9 newly installed, 0 to remove and 30 not upgraded.\n",
            "Need to get 2,434 kB of archives.\n",
            "After this operation, 7,681 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgtk2.0-common all 2.24.33-2ubuntu2.1 [125 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgtk2.0-0 amd64 2.24.33-2ubuntu2.1 [2,038 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgail18 amd64 2.24.33-2ubuntu2.1 [15.9 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgail-common amd64 2.24.33-2ubuntu2.1 [132 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libxdot4 amd64 2.42.2-6ubuntu0.1 [16.4 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libgvc6-plugins-gtk amd64 2.42.2-6ubuntu0.1 [22.5 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libgraphviz-dev amd64 2.42.2-6ubuntu0.1 [58.5 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgtk2.0-bin amd64 2.24.33-2ubuntu2.1 [7,936 B]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 librsvg2-common amd64 2.52.5+dfsg-3ubuntu0.2 [17.7 kB]\n",
            "Fetched 2,434 kB in 1s (2,832 kB/s)\n",
            "Selecting previously unselected package libgtk2.0-common.\n",
            "(Reading database ... 126315 files and directories currently installed.)\n",
            "Preparing to unpack .../0-libgtk2.0-common_2.24.33-2ubuntu2.1_all.deb ...\n",
            "Unpacking libgtk2.0-common (2.24.33-2ubuntu2.1) ...\n",
            "Selecting previously unselected package libgtk2.0-0:amd64.\n",
            "Preparing to unpack .../1-libgtk2.0-0_2.24.33-2ubuntu2.1_amd64.deb ...\n",
            "Unpacking libgtk2.0-0:amd64 (2.24.33-2ubuntu2.1) ...\n",
            "Selecting previously unselected package libgail18:amd64.\n",
            "Preparing to unpack .../2-libgail18_2.24.33-2ubuntu2.1_amd64.deb ...\n",
            "Unpacking libgail18:amd64 (2.24.33-2ubuntu2.1) ...\n",
            "Selecting previously unselected package libgail-common:amd64.\n",
            "Preparing to unpack .../3-libgail-common_2.24.33-2ubuntu2.1_amd64.deb ...\n",
            "Unpacking libgail-common:amd64 (2.24.33-2ubuntu2.1) ...\n",
            "Selecting previously unselected package libxdot4:amd64.\n",
            "Preparing to unpack .../4-libxdot4_2.42.2-6ubuntu0.1_amd64.deb ...\n",
            "Unpacking libxdot4:amd64 (2.42.2-6ubuntu0.1) ...\n",
            "Selecting previously unselected package libgvc6-plugins-gtk.\n",
            "Preparing to unpack .../5-libgvc6-plugins-gtk_2.42.2-6ubuntu0.1_amd64.deb ...\n",
            "Unpacking libgvc6-plugins-gtk (2.42.2-6ubuntu0.1) ...\n",
            "Selecting previously unselected package libgraphviz-dev:amd64.\n",
            "Preparing to unpack .../6-libgraphviz-dev_2.42.2-6ubuntu0.1_amd64.deb ...\n",
            "Unpacking libgraphviz-dev:amd64 (2.42.2-6ubuntu0.1) ...\n",
            "Selecting previously unselected package libgtk2.0-bin.\n",
            "Preparing to unpack .../7-libgtk2.0-bin_2.24.33-2ubuntu2.1_amd64.deb ...\n",
            "Unpacking libgtk2.0-bin (2.24.33-2ubuntu2.1) ...\n",
            "Selecting previously unselected package librsvg2-common:amd64.\n",
            "Preparing to unpack .../8-librsvg2-common_2.52.5+dfsg-3ubuntu0.2_amd64.deb ...\n",
            "Unpacking librsvg2-common:amd64 (2.52.5+dfsg-3ubuntu0.2) ...\n",
            "Setting up libxdot4:amd64 (2.42.2-6ubuntu0.1) ...\n",
            "Setting up librsvg2-common:amd64 (2.52.5+dfsg-3ubuntu0.2) ...\n",
            "Setting up libgtk2.0-common (2.24.33-2ubuntu2.1) ...\n",
            "Setting up libgtk2.0-0:amd64 (2.24.33-2ubuntu2.1) ...\n",
            "Setting up libgvc6-plugins-gtk (2.42.2-6ubuntu0.1) ...\n",
            "Setting up libgail18:amd64 (2.24.33-2ubuntu2.1) ...\n",
            "Setting up libgtk2.0-bin (2.24.33-2ubuntu2.1) ...\n",
            "Setting up libgail-common:amd64 (2.24.33-2ubuntu2.1) ...\n",
            "Setting up libgraphviz-dev:amd64 (2.42.2-6ubuntu0.1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for libgdk-pixbuf-2.0-0:amd64 (2.42.8+dfsg-1ubuntu0.3) ...\n",
            "Collecting pygraphviz\n",
            "  Downloading pygraphviz-1.14.tar.gz (106 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m106.0/106.0 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: pygraphviz\n",
            "  Building wheel for pygraphviz (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pygraphviz: filename=pygraphviz-1.14-cp311-cp311-linux_x86_64.whl size=169713 sha256=14200728290892ddc10302fb4aa5e24b52366827561e0a25b6ba05b21b137890\n",
            "  Stored in directory: /root/.cache/pip/wheels/9c/5f/df/6fffd2a4353f26dbb0e3672a1baf070c124a1d74a5f9318279\n",
            "Successfully built pygraphviz\n",
            "Installing collected packages: pygraphviz\n",
            "Successfully installed pygraphviz-1.14\n"
          ]
        },
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/DeepSeek-R1_finetunes_20250408_202441.csv'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-88285ae38124>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Load and prepare the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/DeepSeek-R1_finetunes_20250408_202441.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'children'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'children'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mast\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mliteral_eval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/DeepSeek-R1_finetunes_20250408_202441.csv'"
          ]
        }
      ],
      "source": [
        "# 4.1 Networkx (in progress)\n",
        "!apt install graphviz libgraphviz-dev\n",
        "!pip install pygraphviz\n",
        "import pandas as pd\n",
        "import ast\n",
        "import matplotlib.pyplot as plt\n",
        "import networkx as nx\n",
        "\n",
        "# Load and prepare the dataset\n",
        "df = pd.read_csv(\"/content/DeepSeek-R1_finetunes_20250408_202441.csv\")\n",
        "df['children'] = df['children'].apply(ast.literal_eval)\n",
        "\n",
        "# Create a directed graph\n",
        "G = nx.DiGraph()\n",
        "\n",
        "# Add nodes and edges\n",
        "for _, row in df.iterrows():\n",
        "    parent = row['model_id']\n",
        "    G.add_node(parent)\n",
        "    for child_url in row['children']:\n",
        "        child = '/'.join(child_url.split(\"/\")[-2:])\n",
        "        G.add_node(child)\n",
        "        G.add_edge(parent, child)\n",
        "\n",
        "# Find root node\n",
        "root = [n for n, d in G.in_degree() if d == 0][0]\n",
        "\n",
        "# Create a hierarchical layout\n",
        "pos = nx.nx_agraph.graphviz_layout(G, prog='dot', root=root)\n",
        "\n",
        "# Create figure\n",
        "plt.figure(figsize=(16, 24))\n",
        "\n",
        "# Draw nodes\n",
        "nx.draw_networkx_nodes(G, pos, node_size=10, node_color='white', edgecolors='black')\n",
        "\n",
        "# Draw edges\n",
        "nx.draw_networkx_edges(G, pos, arrows=False)\n",
        "\n",
        "# Draw labels, rotating only non-root nodes\n",
        "label_pos = {k: (v[0], v[1]) for k, v in pos.items()}\n",
        "for node, (x, y) in label_pos.items():\n",
        "    if node != root:  # Rotate labels for non-root nodes\n",
        "        plt.text(x, y, s=node, rotation=90, ha='center', va='center', fontsize=9)\n",
        "    else:  # Keep root label horizontal\n",
        "        plt.text(x, y, s=node, ha='center', va='center', fontsize=9)\n",
        "\n",
        "# Remove axes\n",
        "plt.axis('off')\n",
        "plt.tight_layout()\n",
        "\n",
        "# Save the figure\n",
        "plt.savefig(\"mistral_finetune_tree_networkx.png\", dpi=150, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"Tree visualization saved to mistral_finetune_tree_networkx.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "JM61pKgp77Vl",
        "outputId": "960c6c93-9271-4ea4-a696-29953415e7fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ete3 in /usr/local/lib/python3.11/dist-packages (3.1.3)\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/base_command.py\", line 179, in exc_logging_wrapper\n",
            "    status = run_func(*args)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/req_command.py\", line 67, in wrapper\n",
            "    return func(self, options, args)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/commands/install.py\", line 447, in run\n",
            "    conflicts = self._determine_conflicts(to_install)\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/commands/install.py\", line 578, in _determine_conflicts\n",
            "    return check_install_conflicts(to_install)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/operations/check.py\", line 101, in check_install_conflicts\n",
            "    package_set, _ = create_package_set_from_installed()\n",
            "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/operations/check.py\", line 42, in create_package_set_from_installed\n",
            "    dependencies = list(dist.iter_dependencies())\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/metadata/importlib/_dists.py\", line 225, in iter_dependencies\n",
            "    elif not extras and req.marker.evaluate({\"extra\": \"\"}):\n",
            "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_vendor/packaging/markers.py\", line 301, in evaluate\n",
            "    def evaluate(self, environment: dict[str, str] | None = None) -> bool:\n",
            "\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/pip3\", line 10, in <module>\n",
            "    sys.exit(main())\n",
            "             ^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/main.py\", line 80, in main\n",
            "    return command.main(cmd_args)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/base_command.py\", line 100, in main\n",
            "    return self._main(args)\n",
            "           ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/base_command.py\", line 232, in _main\n",
            "    return run(options, args)\n",
            "           ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/base_command.py\", line 215, in exc_logging_wrapper\n",
            "    logger.critical(\"Operation cancelled by user\")\n",
            "  File \"/usr/lib/python3.11/logging/__init__.py\", line 1536, in critical\n",
            "    self._log(CRITICAL, msg, args, **kwargs)\n",
            "  File \"/usr/lib/python3.11/logging/__init__.py\", line 1632, in _log\n",
            "    record = self.makeRecord(self.name, level, fn, lno, msg, args,\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/logging/__init__.py\", line 1601, in makeRecord\n",
            "    rv = _logRecordFactory(name, level, fn, lno, msg, args, exc_info, func,\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/logging/__init__.py\", line 326, in __init__\n",
            "    self.filename = os.path.basename(pathname)\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"<frozen posixpath>\", line 140, in basename\n",
            "KeyboardInterrupt\n",
            "^C\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/pip3\", line 10, in <module>\n",
            "    sys.exit(main())\n",
            "             ^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/main.py\", line 78, in main\n",
            "    command = create_command(cmd_name, isolated=(\"--isolated\" in cmd_args))\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/commands/__init__.py\", line 114, in create_command\n",
            "    module = importlib.import_module(module_path)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/importlib/__init__.py\", line 126, in import_module\n",
            "    return _bootstrap._gcd_import(name[level:], package, level)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"<frozen importlib._bootstrap>\", line 1204, in _gcd_import\n",
            "  File \"<frozen importlib._bootstrap>\", line 1176, in _find_and_load\n",
            "  File \"<frozen importlib._bootstrap>\", line 1147, in _find_and_load_unlocked\n",
            "  File \"<frozen importlib._bootstrap>\", line 690, in _load_unlocked\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 940, in exec_module\n",
            "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/commands/install.py\", line 15, in <module>\n",
            "    from pip._internal.cli.req_command import (\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/req_command.py\", line 18, in <module>\n",
            "    from pip._internal.index.collector import LinkCollector\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/index/collector.py\", line 31, in <module>\n",
            "    from pip._vendor import requests\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_vendor/requests/__init__.py\", line 159, in <module>\n",
            "    from .api import delete, get, head, options, patch, post, put, request\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_vendor/requests/api.py\", line 11, in <module>\n",
            "    from . import sessions\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_vendor/requests/sessions.py\", line 15, in <module>\n",
            "    from .adapters import HTTPAdapter\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_vendor/requests/adapters.py\", line 81, in <module>\n",
            "    _preloaded_ssl_context.load_verify_locations(\n",
            "KeyboardInterrupt\n",
            "^C\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/pip3\", line 10, in <module>\n",
            "    sys.exit(main())\n",
            "             ^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/main.py\", line 78, in main\n",
            "    command = create_command(cmd_name, isolated=(\"--isolated\" in cmd_args))\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/commands/__init__.py\", line 114, in create_command\n",
            "    module = importlib.import_module(module_path)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/importlib/__init__.py\", line 126, in import_module\n",
            "    return _bootstrap._gcd_import(name[level:], package, level)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"<frozen importlib._bootstrap>\", line 1204, in _gcd_import\n",
            "  File \"<frozen importlib._bootstrap>\", line 1176, in _find_and_load\n",
            "  File \"<frozen importlib._bootstrap>\", line 1147, in _find_and_load_unlocked\n",
            "  File \"<frozen importlib._bootstrap>\", line 690, in _load_unlocked\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 940, in exec_module\n",
            "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/commands/install.py\", line 15, in <module>\n",
            "    from pip._internal.cli.req_command import (\n",
            "object address  : 0x7d93ed736c80\n",
            "object refcount : 2\n",
            "object type     : 0x9d5ea0\n",
            "object type name: KeyboardInterrupt\n",
            "object repr     : KeyboardInterrupt()\n",
            "lost sys.stderr\n",
            "^C\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/DeepSeek-R1_finetunes_20250408_202441.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-205e6eecddea>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Load and prepare the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/DeepSeek-R1_finetunes_20250408_202441.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'children'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'children'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mast\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mliteral_eval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/DeepSeek-R1_finetunes_20250408_202441.csv'"
          ]
        }
      ],
      "source": [
        "# 4.3 library (in progress)\n",
        "!pip install ete3\n",
        "!pip install tree\n",
        "!pip install PyQt5\n",
        "import pandas as pd\n",
        "import ast\n",
        "from ete3 import Tree, faces, AttrFace, TreeStyle\n",
        "\n",
        "\n",
        "# Load and prepare the dataset\n",
        "df = pd.read_csv(\"/content/DeepSeek-R1_finetunes_20250408_202441.csv\")\n",
        "df['children'] = df['children'].apply(ast.literal_eval)\n",
        "\n",
        "# Function to build the ete3 tree recursively\n",
        "def build_ete3_tree(df, parent_node=None, parent_name=None):\n",
        "    if parent_node is None:\n",
        "        # Create the root node if it's the first call\n",
        "        root_name = df.loc[df['depth'] == 0, 'model_id'].iloc[0]\n",
        "        tree = Tree(name=root_name)\n",
        "        parent_node = tree\n",
        "    else:\n",
        "        tree = parent_node  # Continue building the existing tree\n",
        "\n",
        "    # Find children of the current parent\n",
        "    children_rows = df.loc[df['model_id'] == parent_name]\n",
        "    if not children_rows.empty:\n",
        "        children_urls = children_rows['children'].iloc[0]\n",
        "        for child_url in children_urls:\n",
        "            child_name = '/'.join(child_url.split(\"/\")[-2:])\n",
        "            child_node = tree.add_child(name=child_name)\n",
        "            build_ete3_tree(df, child_node, child_name)  # Recursive call\n",
        "    return tree\n",
        "\n",
        "# Build the tree\n",
        "tree = build_ete3_tree(df)\n",
        "\n",
        "# Style the tree\n",
        "ts.show_leaf_name = False  # Hide leaf names\n",
        "ts.mode = \"c\"  # Circular tree layout\n",
        "ts.root_opening_factor = 1  # Adjust root opening for circular layout\n",
        "\n",
        "# Style the nodes\n",
        "nst = NodeStyle()\n",
        "nst[\"size\"] = 0  # Hide node circles\n",
        "nst[\"hz_line_width\"] = 2\n",
        "nst[\"vt_line_width\"] = 2\n",
        "\n",
        "for n in tree.traverse():\n",
        "    n.set_style(nst)\n",
        "    # Add model name as a branch label\n",
        "    name_face = TextFace(n.name, fsize=10, fgcolor=\"black\")\n",
        "    n.add_face(name_face, column=0, position=\"branch-right\")\n",
        "\n",
        "# Render and save the tree\n",
        "tree.render(\"mistral_finetune_tree_ete3.png\", tree_style=ts, dpi=300)\n",
        "print(\"Tree visualization saved to mistral_finetune_tree_ete3.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Script 6\n",
        "\n",
        "Get top 1000 models from the model-hub ordered by the number of likes"
      ],
      "metadata": {
        "id": "4rt2ohl3wnxA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install huggingface_hub\n",
        "import pandas as pd\n",
        "import datetime\n",
        "import csv\n",
        "from huggingface_hub import HfApi\n",
        "\n",
        "api = HfApi()\n",
        "time = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "# documentation: https://huggingface.co/docs/hub/en/api, gets top 1000 models sorted by likes in descending order\n",
        "models = api.list_models(sort=\"likes\", direction=\"-1\", limit=1000)\n",
        "\n",
        "df = pd.DataFrame(models)\n",
        "models_file = df.to_csv(f\"{time}_model_list.csv\", index=\"false\")\n",
        "print(\"Models saved to CSV\")\n"
      ],
      "metadata": {
        "id": "cH5A_cZUwnJd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tgXrshhgesGd"
      },
      "source": [
        "# Script 7\n",
        "\n",
        "This script allows you to iteratively run the dfs function for multiple models given as a CSV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rS_K1AScbBdE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "73a70967cf2d4d64888b0f2530bcb369",
            "d961f0316b8e41b1961444ace22ee952",
            "ffb0fdf069c74f9a8e2532802eac5175",
            "b713fc94b9ef4b839f0183d6f190ae18",
            "c001daca18944736856c68e477ecf2a4",
            "56d9ad4c0fff4fbf953d53d14ec35ead",
            "663be1013f2c4d50a422019f8ad1c344",
            "27467f2dee6e40ce8a95ada12c09e7eb",
            "229efeb6c08b4d3589e10d0429377581",
            "48a1ecc66ab6463db0e4ccdd075a8435",
            "c2ecc10f754b4cd0bb868793140ec24e",
            "8ebe71bc81d04847bb9714d60b7f0dc1",
            "041b7b6cd8bb42c8935a9793bc1b5d05",
            "7ed0c27a87d841129340a008c215008c",
            "8b122d5f52be4b0787fff88d54789a09",
            "703cbdd022a34cf9974e7c4ad777de19",
            "3c7d541567b7403fa54a026182d35da8",
            "6a2ea8e1efb549ebbf83fa3ca97d7932",
            "7a90dececc29455687869c34d01978d9",
            "a4816eda8d794b00bb6e941eedc6d350",
            "8b0934701b854ed3a4fe6adfb9223dbd",
            "3f10a427121c4553844b8535ea359128",
            "09cd632e37aa4f87b1af4a3a06b7aef8",
            "5e7a196d2d0047ca9a7eb46a2274d698",
            "0391699c31844e598b7ac325872fa0ec",
            "3e1014676c154ec68defb386b60742de",
            "735558928c6c4851a130b143fd16f7ee",
            "c358566eb34d42d092fa38208009f4f2",
            "298aca81e3594a72b0f97aadca801625",
            "ec277bb4ee0a45109643b23ad34b5982",
            "3d06011fc08a4e9eb1323c57f654a5ca",
            "2138f5da54a74478b232474e33d12093",
            "88671425bec84643a3543c17d2292ef5"
          ]
        },
        "outputId": "ea5cb903-26b6-49cc-b94f-4cd25f68a400"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully imported functions from script3\n",
            "HuggingFace Multi-Model Analysis Tool\n",
            "====================================\n",
            "Path to CSV with model IDs: /content/20250416_204633_model_list.csv\n",
            "Number of models to process (default: 10): 1000\n",
            "Delay between models in seconds (default: 2): 3\n",
            "Output directory (default: 'results'): \n",
            "Warning: 218 invalid model IDs detected:\n",
            "['black-forest-labs/FLUX.1-dev', 'stabilityai/stable-diffusion-xl-base-1.0', 'mistralai/Mixtral-8x7B-Instruct-v0.1', 'meta-llama/Llama-3.1-8B-Instruct', 'mistralai/Mistral-7B-v0.1', 'black-forest-labs/FLUX.1-schnell', 'mistralai/Mistral-7B-Instruct-v0.2', 'stabilityai/stable-diffusion-3.5-large', 'meta-llama/Llama-3.3-70B-Instruct', 'nvidia/Llama-3.1-Nemotron-70B-Instruct-HF', 'stabilityai/stable-diffusion-xl-refiner-1.0', 'meta-llama/Llama-3.2-1B', 'Qwen/Qwen2.5-Coder-32B-Instruct', 'briaai/RMBG-1.4', 'mattshumer/Reflection-Llama-3.1-70B', 'dreamlike-art/dreamlike-photoreal-2.0', 'mistralai/Mixtral-8x7B-v0.1', 'mistralai/Mistral-7B-Instruct-v0.1', 'mistralai/Mistral-7B-Instruct-v0.3', 'gsdf/Counterfeit-V2.5', 'meta-llama/Llama-3.1-8B', 'meta-llama/Llama-3.2-11B-Vision-Instruct', 'stabilityai/stable-diffusion-xl-base-0.9', 'Qwen/Qwen2.5-Omni-7B', 'xinsir/controlnet-union-sdxl-1.0', 'meta-llama/Llama-3.2-3B-Instruct', 'mistralai/Codestral-22B-v0.1', 'cognitivecomputations/dolphin-2.5-mixtral-8x7b', 'TinyLlama/TinyLlama-1.1B-Chat-v1.0', 'microsoft/OmniParser-v2.0', 'Wan-AI/Wan2.1-T2V-14B', 'ai21labs/Jamba-v0.1', 'deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B', 'stabilityai/stable-audio-open-1.0', 'openchat/openchat_3.5', 'mistralai/Mistral-Small-3.1-24B-Instruct-2503', 'Zyphra/Zonos-v0.1-hybrid', 'dreamlike-art/dreamlike-diffusion-1.0', 'city96/FLUX.1-dev-gguf', 'ggerganov/whisper.cpp', 'meta-llama/Llama-3.1-405B', 'meta-llama/Llama-3.2-1B-Instruct', 'microsoft/Phi-3.5-mini-instruct', 'teknium/OpenHermes-2.5-Mistral-7B', 'Qwen/Qwen2.5-VL-7B-Instruct', 'meta-llama/Llama-3.1-70B-Instruct', 'pyannote/speaker-diarization-3.1', 'Qwen/Qwen2.5-72B-Instruct', 'metavoiceio/metavoice-1B-v0.1', 'cagliostrolab/animagine-xl-3.0', 'WizardLMTeam/WizardCoder-Python-34B-V1.0', 'WizardLMTeam/WizardCoder-15B-V1.0', 'google/timesfm-1.0-200m', 'briaai/RMBG-2.0', 'mistralai/Mixtral-8x22B-Instruct-v0.1', 'Linaqruf/anything-v3.0', 'playgroundai/playground-v2.5-1024px-aesthetic', 'deepseek-ai/DeepSeek-V2.5', 'jasperai/Flux.1-dev-Controlnet-Upscaler', 'cagliostrolab/animagine-xl-3.1', 'microsoft/Phi-3.5-vision-instruct', 'stabilityai/stable-diffusion-3.5-medium', 'mistral-community/Mixtral-8x22B-v0.1', 'ostris/OpenFLUX.1', 'DeepFloyd/IF-I-XL-v1.0', 'Qwen/Qwen2.5-7B-Instruct', 'black-forest-labs/FLUX.1-Fill-dev', 'upstage/SOLAR-10.7B-Instruct-v1.0', 'ali-vilab/text-to-video-ms-1.7b', 'TheBloke/Mixtral-8x7B-Instruct-v0.1-GGUF', 'nomic-ai/nomic-embed-text-v1.5', 'SparkAudio/Spark-TTS-0.5B', 'jinaai/reader-lm-1.5b', 'HuggingFaceTB/SmolLM2-1.7B-Instruct', 'deepseek-ai/Janus-1.3B', 'mistralai/Mamba-Codestral-7B-v0.1', 'stabilityai/stable-diffusion-3.5-large-turbo', 'meta-llama/Llama-3.1-405B-Instruct', 'nvidia/Llama-3.1-Nemotron-70B-Instruct', 'microsoft/Phi-3.5-MoE-instruct', 'nvidia/Llama3-ChatQA-1.5-8B', 'TheBloke/Mistral-7B-Instruct-v0.1-GGUF', 'agentica-org/DeepScaleR-1.5B-Preview', 'meta-llama/Llama-3.2-3B', 'fishaudio/fish-speech-1.5', 'gsdf/Counterfeit-V3.0', 'Shakker-Labs/FLUX.1-dev-ControlNet-Union-Pro', 'BAAI/bge-large-zh-v1.5', 'meta-llama/Llama-3.2-11B-Vision', 'BAAI/bge-large-en-v1.5', 'dataautogpt3/OpenDalleV1.1', 'alimama-creative/FLUX.1-Turbo-Alpha', 'diffusers/controlnet-canny-sdxl-1.0', 'liuhaotian/llava-v1.5-13b', 'canopylabs/orpheus-3b-0.1-ft', 'black-forest-labs/FLUX.1-Redux-dev', 'EleutherAI/gpt-neo-2.7B', 'abacusai/Smaug-72B-v0.1', 'mistralai/Mistral-7B-v0.3', 'gsdf/Counterfeit-V2.0', 'Qwen/Qwen2.5-Coder-7B-Instruct', 'fishaudio/fish-speech-1.4', 'liuhaotian/llava-v1.5-7b', 'cognitivecomputations/dolphin-2.9-llama3-8b', 'Comfy-Org/Wan_2.1_ComfyUI_repackaged', 'hassanblend/hassanblend1.4', 'IDEA-CCNL/Taiyi-Stable-Diffusion-1B-Chinese-v0.1', 'Qwen/Qwen2.5-VL-72B-Instruct', 'TheBloke/Mistral-7B-Instruct-v0.2-GGUF', 'pyannote/segmentation-3.0', 'TheBloke/Mixtral-8x7B-v0.1-GGUF', 'InstantX/FLUX.1-dev-Controlnet-Union', 'ostris/Flex.1-alpha', 'Wan-AI/Wan2.1-I2V-14B-720P', 'Freepik/flux.1-lite-8B-alpha', 'lmsys/vicuna-13b-delta-v1.1', 'LGAI-EXAONE/EXAONE-3.0-7.8B-Instruct', 'Qwen/Qwen2.5-1.5B-Instruct', 'eimiss/EimisAnimeDiffusion_1.0v', 'ICTNLP/Llama-3.1-8B-Omni', 'deepseek-ai/deepseek-coder-6.7b-instruct', 'Zyphra/Zonos-v0.1-transformer', 'OpenAssistant/oasst-sft-4-pythia-12b-epoch-3.5', 'lmsys/fastchat-t5-3b-v1.0', 'Salesforce/blip2-opt-2.7b', 'openchat/openchat-3.5-0106', 'meta-llama/Llama-3.1-70B', 'eachadea/ggml-vicuna-13b-1.1', 'parler-tts/parler_tts_mini_v0.1', 'liuhaotian/llava-v1.6-34b', 'darkstorm2150/Protogen_x3.4_Official_Release', 'thibaud/controlnet-openpose-sdxl-1.0', 'all-hands/openhands-lm-32b-v0.1', 'SG161222/Realistic_Vision_V1.4', 'alimama-creative/FLUX.1-dev-Controlnet-Inpainting-Beta', 'meta-llama/Llama-3.2-90B-Vision-Instruct', 'lmsys/vicuna-7b-v1.5', 'nvidia/Llama3-ChatQA-1.5-70B', 'SG161222/Realistic_Vision_V2.0', 'Qwen/Qwen2.5-VL-32B-Instruct', 'stabilityai/stable-diffusion-xl-refiner-0.9', 'Qwen/CodeQwen1.5-7B-Chat', 'Shakker-Labs/FLUX.1-dev-LoRA-Logo-Design', 'Qwen/Qwen2.5-VL-3B-Instruct', 'diffusers/stable-diffusion-xl-1.0-inpainting-0.1', 'facebook/nllb-200-3.3B', 'MIT/ast-finetuned-audioset-10-10-0.4593', 'NousResearch/Hermes-3-Llama-3.1-8B', 'Qwen/Qwen2.5-7B-Instruct-1M', 'Wan-AI/Wan2.1-T2V-1.3B', 'BAAI/bge-small-en-v1.5', 'upstage/SOLAR-10.7B-v1.0', 'Qwen/Qwen2.5-0.5B-Instruct', 'Alpha-VLLM/Lumina-Image-2.0', 'TheBloke/dolphin-2.5-mixtral-8x7b-GGUF', 'OuteAI/OuteTTS-0.1-350M', 'Qwen/Qwen2.5-14B-Instruct-1M', 'EleutherAI/gpt-neo-1.3B', 'lmsys/vicuna-33b-v1.3', 'OuteAI/OuteTTS-0.2-500M', 'BAAI/bge-base-en-v1.5', 'Sao10K/L3-8B-Stheno-v3.2', 'ai-forever/ruGPT-3.5-13B', 'openchat/openchat-3.5-1210', 'google/gemma-1.1-7b-it', 'InstantX/FLUX.1-dev-IP-Adapter', '01-ai/Yi-1.5-34B-Chat', 'AIDC-AI/Ovis1.6-Gemma2-9B', 'HuggingFaceH4/zephyr-orpo-141b-A35b-v0.1', 'ai21labs/AI21-Jamba-Mini-1.5', 'ibm-nasa-geospatial/Prithvi-EO-1.0-100M', 'NexaAIDev/OmniAudio-2.6B', 'TheBloke/Mistral-7B-v0.1-GGUF', 'llava-hf/llava-v1.6-mistral-7b-hf', 'shenzhi-wang/Llama3.1-8B-Chinese-Chat', 'Qwen/Qwen2.5-32B-Instruct', 'fishaudio/fish-agent-v0.1-3b', 'cognitivecomputations/dolphin-2.1-mistral-7b', 'SG161222/RealVisXL_V4.0', 'rasbt/llama-3.2-from-scratch', 'Qwen/Qwen2.5-0.5B', 'deepseek-ai/DeepSeek-V2.5-1210', 'cagliostrolab/animagine-xl-4.0', 'dreamlike-art/dreamlike-anime-1.0', 'llava-hf/llava-1.5-7b-hf', 'colbert-ir/colbertv2.0', 'city96/FLUX.1-schnell-gguf', 'xinsir/controlnet-scribble-sdxl-1.0', 'lmstudio-community/Meta-Llama-3.1-8B-Instruct-GGUF', 'alimama-creative/FLUX.1-dev-Controlnet-Inpainting-Alpha', 'TheBloke/OpenHermes-2.5-Mistral-7B-GGUF', 'Qwen/Qwen2.5-3B-Instruct', 'liuhaotian/llava-v1.6-mistral-7b', 'NovaSearch/stella_en_1.5B_v5', 'WizardLMTeam/WizardLM-70B-V1.0', 'xinsir/controlnet-openpose-sdxl-1.0', 'xinsir/controlnet-tile-sdxl-1.0', 'nisten/Biggie-SmoLlm-0.15B-Base', 'mistral-community/Mistral-7B-v0.2', 'nvidia/Hymba-1.5B-Instruct', 'WizardLMTeam/WizardLM-13B-V1.2', 'lmsys/vicuna-13b-v1.5', 'cognitivecomputations/dolphin-2.8-mistral-7b-v02', 'SG161222/Realistic_Vision_V6.0_B1_noVAE', 'mistralai/Mathstral-7B-v0.1', 'Qwen/Qwen2.5-14B-Instruct', 'numind/NuExtract-1.5', 'lmsys/vicuna-13b-v1.5-16k', 'NousResearch/Hermes-3-Llama-3.1-405B', 'Qwen/Qwen1.5-72B-Chat', 'mistralai/Mixtral-8x22B-v0.1', 'Shakker-Labs/FLUX.1-dev-LoRA-AntiBlur', 'ai21labs/AI21-Jamba-Large-1.5', 'nvidia/Cosmos-1.0-Diffusion-7B-Text2World', 'hassanblend/HassanBlend1.5.1.2', 'Xwin-LM/Xwin-LM-70B-V0.1', 'Alibaba-NLP/gte-large-en-v1.5', 'cognitivecomputations/dolphin-2.6-mixtral-8x7b']\n",
            "Skipping invalid models...\n",
            "Starting analysis of 782 valid models\n",
            "\n",
            "[1/782] Processing: deepseek-ai/DeepSeek-R1\n",
            "Starting analysis for deepseek-ai/DeepSeek-R1\n",
            "\n",
            "Fetching metadata for: deepseek-ai/DeepSeek-R1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 297 fine-tunes at depth 0.\n",
            "Found 121 adapter models for deepseek-ai/DeepSeek-R1.\n",
            "\n",
            "  Fetching metadata for: samira456/english-hindi\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for samira456/english-hindi.\n",
            "\n",
            "  Fetching metadata for: Virtual-Herbalist/Herbalist-AI\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for Virtual-Herbalist/Herbalist-AI.\n",
            "\n",
            "  Fetching metadata for: deca-ai/2-mini-beta\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for deca-ai/2-mini-beta.\n",
            "\n",
            "  Fetching metadata for: wrestling-is-real-bro/airules\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for wrestling-is-real-bro/airules.\n",
            "\n",
            "  Fetching metadata for: mradermacher/DeepSeek-R1-GGUF\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for mradermacher/DeepSeek-R1-GGUF.\n",
            "\n",
            "  Fetching metadata for: Haryni/model\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for Haryni/model.\n",
            "\n",
            "  Fetching metadata for: DragosBDI/GPT_test\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for DragosBDI/GPT_test.\n",
            "\n",
            "  Fetching metadata for: Michael419/Ii\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for Michael419/Ii.\n",
            "\n",
            "  Fetching metadata for: kkangnom/test\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for kkangnom/test.\n",
            "\n",
            "  Fetching metadata for: c8tc/nnew_new\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for c8tc/nnew_new.\n",
            "\n",
            "  Fetching metadata for: chunien/gp44785\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for chunien/gp44785.\n",
            "\n",
            "  Fetching metadata for: Mexa57/Vi\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for Mexa57/Vi.\n",
            "\n",
            "  Fetching metadata for: zonnell/discord\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for zonnell/discord.\n",
            "\n",
            "  Fetching metadata for: kghuggingface/kg1repo\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for kghuggingface/kg1repo.\n",
            "\n",
            "  Fetching metadata for: Efeeg/beyza\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for Efeeg/beyza.\n",
            "\n",
            "  Fetching metadata for: Dombrenk30/0xDom\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for Dombrenk30/0xDom.\n",
            "\n",
            "  Fetching metadata for: Futuresony/Future_pics_26-01-2025\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for Futuresony/Future_pics_26-01-2025.\n",
            "\n",
            "  Fetching metadata for: theone2b/99\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for theone2b/99.\n",
            "\n",
            "  Fetching metadata for: DangChuVM/Model\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for DangChuVM/Model.\n",
            "\n",
            "  Fetching metadata for: 0xchum/Fugen\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for 0xchum/Fugen.\n",
            "\n",
            "  Fetching metadata for: InlineHydraulik/Autoencoder\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for InlineHydraulik/Autoencoder.\n",
            "\n",
            "  Fetching metadata for: FarhanisGoingTomakeaAi/NiteTalkbot\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for FarhanisGoingTomakeaAi/NiteTalkbot.\n",
            "\n",
            "  Fetching metadata for: mikaelcostake/brain0\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for mikaelcostake/brain0.\n",
            "\n",
            "  Fetching metadata for: AntVess/new74\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for AntVess/new74.\n",
            "\n",
            "  Fetching metadata for: sarthak156/anichat\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for sarthak156/anichat.\n",
            "\n",
            "  Fetching metadata for: William-zhao/Cozysmart\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for William-zhao/Cozysmart.\n",
            "\n",
            "  Fetching metadata for: rkeval/LearnAI\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for rkeval/LearnAI.\n",
            "\n",
            "  Fetching metadata for: pretonetworking/Roteirobom\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for pretonetworking/Roteirobom.\n",
            "\n",
            "  Fetching metadata for: ZZVCV/FHZBox\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for ZZVCV/FHZBox.\n",
            "\n",
            "  Fetching metadata for: Jianshu001/Efficient_CoT_DeepSeek-R1-Distill-Qwen-7B\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for Jianshu001/Efficient_CoT_DeepSeek-R1-Distill-Qwen-7B.\n",
            "\n",
            "  Fetching metadata for: harshw030/sameeraAI\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for harshw030/sameeraAI.\n",
            "\n",
            "  Fetching metadata for: gresres/test\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for gresres/test.\n",
            "\n",
            "  Fetching metadata for: Awaiz031/Awaizahmad\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for Awaiz031/Awaizahmad.\n",
            "\n",
            "  Fetching metadata for: sprunkiphase3/unblocked\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for sprunkiphase3/unblocked.\n",
            "\n",
            "  Fetching metadata for: cmoraes199322/autonomo\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for cmoraes199322/autonomo.\n",
            "\n",
            "  Fetching metadata for: xugui/test\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for xugui/test.\n",
            "\n",
            "  Fetching metadata for: Murphy112233/Murphy_Rose\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for Murphy112233/Murphy_Rose.\n",
            "\n",
            "  Fetching metadata for: gimmy256/deepseek_r1_finetuned\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for gimmy256/deepseek_r1_finetuned.\n",
            "\n",
            "  Fetching metadata for: GalaxyPoo/Mine\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for GalaxyPoo/Mine.\n",
            "\n",
            "  Fetching metadata for: YaserSabriFMD/Jj\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for YaserSabriFMD/Jj.\n",
            "\n",
            "  Fetching metadata for: Avener/RealTime\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for Avener/RealTime.\n",
            "\n",
            "  Fetching metadata for: clgingeniero/sammarty\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for clgingeniero/sammarty.\n",
            "\n",
            "  Fetching metadata for: tariqaziz80/dentists\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for tariqaziz80/dentists.\n",
            "\n",
            "  Fetching metadata for: JustVenus/Venus\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for JustVenus/Venus.\n",
            "\n",
            "  Fetching metadata for: idriscanbay/1\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for idriscanbay/1.\n",
            "\n",
            "  Fetching metadata for: Warnsey/Teaching_Model\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for Warnsey/Teaching_Model.\n",
            "\n",
            "  Fetching metadata for: nishantmourya/bio\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for nishantmourya/bio.\n",
            "Invalid URL skipped: https://huggingface.co/MISHANM/deepseek-ai-DeepSeek-R1-BF16.gguf\n",
            "Invalid URL skipped: https://huggingface.co/RajibGartia/Apache.2.0\n",
            "\n",
            "  Fetching metadata for: feitap/exp\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for feitap/exp.\n",
            "\n",
            "  Fetching metadata for: pinnacle001/steph\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for pinnacle001/steph.\n",
            "\n",
            "  Fetching metadata for: RecurvAI/Recurv-Clinical-Deepseek-R1\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for RecurvAI/Recurv-Clinical-Deepseek-R1.\n",
            "\n",
            "  Fetching metadata for: genaitiwari/deepseek\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for genaitiwari/deepseek.\n",
            "\n",
            "  Fetching metadata for: FANzinho/FanSilver\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for FANzinho/FanSilver.\n",
            "\n",
            "  Fetching metadata for: ExplodeMediaG/011_search-model\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for ExplodeMediaG/011_search-model.\n",
            "\n",
            "  Fetching metadata for: nvidia/DeepSeek-R1-FP4\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for nvidia/DeepSeek-R1-FP4.\n",
            "\n",
            "  Fetching metadata for: djibhefihnserfnh/vxfvf\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for djibhefihnserfnh/vxfvf.\n",
            "\n",
            "  Fetching metadata for: Szilard12/UNITY\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for Szilard12/UNITY.\n",
            "\n",
            "  Fetching metadata for: devl-8980-sn/india_legal_QA_deepseek\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for devl-8980-sn/india_legal_QA_deepseek.\n",
            "\n",
            "  Fetching metadata for: PrakashCider/Your-Solmate\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for PrakashCider/Your-Solmate.\n",
            "\n",
            "  Fetching metadata for: mattivityroom/huggingface_nlp\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for mattivityroom/huggingface_nlp.\n",
            "\n",
            "  Fetching metadata for: vataAiTech/songSystem\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for vataAiTech/songSystem.\n",
            "\n",
            "  Fetching metadata for: jatin183/Celci\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for jatin183/Celci.\n",
            "\n",
            "  Fetching metadata for: 0x6e676e/generate-context\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for 0x6e676e/generate-context.\n",
            "\n",
            "  Fetching metadata for: unsloth/DeepSeek-R1-BF16\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for unsloth/DeepSeek-R1-BF16.\n",
            "\n",
            "  Fetching metadata for: mradermacher/DeepSeek-R1-i1-GGUF\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for mradermacher/DeepSeek-R1-i1-GGUF.\n",
            "\n",
            "  Fetching metadata for: mertkb/palmtree\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for mertkb/palmtree.\n",
            "\n",
            "  Fetching metadata for: Yaroslavgtytry/gngn\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for Yaroslavgtytry/gngn.\n",
            "\n",
            "  Fetching metadata for: Pweenut/QazNLTK_Model\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for Pweenut/QazNLTK_Model.\n",
            "\n",
            "  Fetching metadata for: orgullomoore/TexLawLLM\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for orgullomoore/TexLawLLM.\n",
            "\n",
            "  Fetching metadata for: niloyda/AnythingChatBot\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for niloyda/AnythingChatBot.\n",
            "\n",
            "  Fetching metadata for: CyrusXtovia/MetLawBot\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for CyrusXtovia/MetLawBot.\n",
            "\n",
            "  Fetching metadata for: Al-rahman/Deepseek\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for Al-rahman/Deepseek.\n",
            "\n",
            "  Fetching metadata for: samaraamfetamina/frai\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for samaraamfetamina/frai.\n",
            "\n",
            "  Fetching metadata for: michaelngangom/dummy-bank\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for michaelngangom/dummy-bank.\n",
            "\n",
            "  Fetching metadata for: AlexandreCezar/SaudeMental\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for AlexandreCezar/SaudeMental.\n",
            "\n",
            "  Fetching metadata for: ayeshawtahir/pharmacopeia\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for ayeshawtahir/pharmacopeia.\n",
            "\n",
            "  Fetching metadata for: TanAIspaceX/test1\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for TanAIspaceX/test1.\n",
            "\n",
            "  Fetching metadata for: yangyu1111/2\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for yangyu1111/2.\n",
            "\n",
            "  Fetching metadata for: tonybb815/Tiny\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for tonybb815/Tiny.\n",
            "\n",
            "  Fetching metadata for: VybezR/Helop\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for VybezR/Helop.\n",
            "\n",
            "  Fetching metadata for: usamaaleem99tech/DeepSeek-R1-Medical\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for usamaaleem99tech/DeepSeek-R1-Medical.\n",
            "\n",
            "  Fetching metadata for: gokhandemirau/Elizabet\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for gokhandemirau/Elizabet.\n",
            "\n",
            "  Fetching metadata for: FernDelga/CorpoBotdelFer\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for FernDelga/CorpoBotdelFer.\n",
            "\n",
            "  Fetching metadata for: sanun4730/chat\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for sanun4730/chat.\n",
            "\n",
            "  Fetching metadata for: NazarMuts/FridayAPI\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for NazarMuts/FridayAPI.\n",
            "\n",
            "  Fetching metadata for: devayanihodgir/Resume_Analyzer\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for devayanihodgir/Resume_Analyzer.\n",
            "\n",
            "  Fetching metadata for: Jobzi/AhSimon\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for Jobzi/AhSimon.\n",
            "\n",
            "  Fetching metadata for: Kelly70/Kelly\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for Kelly70/Kelly.\n",
            "\n",
            "  Fetching metadata for: aodev/EmBotV2\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for aodev/EmBotV2.\n",
            "\n",
            "  Fetching metadata for: Lotusaihk/lotusaihk\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for Lotusaihk/lotusaihk.\n",
            "Invalid URL skipped: https://huggingface.co/XZHY/customer_service_chatbot_DeepSeek-R1-Distill-Qwen-1.5B_DPO\n",
            "\n",
            "  Fetching metadata for: 1986random/l\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for 1986random/l.\n",
            "\n",
            "  Fetching metadata for: Adamastor/bully\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for Adamastor/bully.\n",
            "\n",
            "  Fetching metadata for: Ebaturan/GokTurk\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for Ebaturan/GokTurk.\n",
            "\n",
            "  Fetching metadata for: athitiya/personal\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for athitiya/personal.\n",
            "\n",
            "  Fetching metadata for: Kumargogia/Kavya\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for Kumargogia/Kavya.\n",
            "\n",
            "  Fetching metadata for: yerifantess/weeklyupdate\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for yerifantess/weeklyupdate.\n",
            "\n",
            "  Fetching metadata for: Bilkees/Ikhlaq\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for Bilkees/Ikhlaq.\n",
            "\n",
            "  Fetching metadata for: tempbggff/test\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for tempbggff/test.\n",
            "\n",
            "  Fetching metadata for: UkYYY/eva\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for UkYYY/eva.\n",
            "\n",
            "  Fetching metadata for: shubhamnagane/news\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for shubhamnagane/news.\n",
            "\n",
            "  Fetching metadata for: Pim-mobile/Our-Pim\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for Pim-mobile/Our-Pim.\n",
            "\n",
            "  Fetching metadata for: curryNI/huaiqing_ml_model\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for curryNI/huaiqing_ml_model.\n",
            "\n",
            "  Fetching metadata for: sandeep-aipm/AI-Code\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for sandeep-aipm/AI-Code.\n",
            "\n",
            "  Fetching metadata for: Lukiii498/test\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for Lukiii498/test.\n",
            "\n",
            "  Fetching metadata for: MimiTechAI/DeepSeek-R1-Distill-Llama-70B\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for MimiTechAI/DeepSeek-R1-Distill-Llama-70B.\n",
            "\n",
            "  Fetching metadata for: dailong/mymode\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for dailong/mymode.\n",
            "\n",
            "  Fetching metadata for: huihui-ai/DeepSeek-R1-Pruned-Coder-411B\n",
            "  Found 2 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for huihui-ai/DeepSeek-R1-Pruned-Coder-411B.\n",
            "\n",
            "    Fetching metadata for: mradermacher/DeepSeek-R1-Pruned-Coder-411B-GGUF\n",
            "    Found 0 fine-tunes at depth 2.\n",
            "    Found 0 adapter models for mradermacher/DeepSeek-R1-Pruned-Coder-411B-GGUF.\n",
            "\n",
            "    Fetching metadata for: mradermacher/DeepSeek-R1-Pruned-Coder-411B-i1-GGUF\n",
            "    Found 0 fine-tunes at depth 2.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:backoff:Backing off get_model_metadata(...) for 1.3s (huggingface_hub.errors.HfHubHTTPError: 429 Client Error: Too Many Requests for url: https://huggingface.co/api/models/Nerker/Rdrffg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Found 0 adapter models for mradermacher/DeepSeek-R1-Pruned-Coder-411B-i1-GGUF.\n",
            "\n",
            "  Fetching metadata for: Nerker/Rdrffg\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:backoff:Backing off get_model_metadata(...) for 0.2s (huggingface_hub.errors.HfHubHTTPError: 429 Client Error: Too Many Requests for url: https://huggingface.co/api/models/Nerker/Rdrffg)\n",
            "INFO:backoff:Backing off get_model_metadata(...) for 3.5s (huggingface_hub.errors.HfHubHTTPError: 429 Client Error: Too Many Requests for url: https://huggingface.co/api/models/Nerker/Rdrffg)\n",
            "INFO:backoff:Backing off get_model_metadata(...) for 4.3s (huggingface_hub.errors.HfHubHTTPError: 429 Client Error: Too Many Requests for url: https://huggingface.co/api/models/Nerker/Rdrffg)\n",
            "ERROR:backoff:Giving up get_model_metadata(...) after 5 tries (huggingface_hub.errors.HfHubHTTPError: 429 Client Error: Too Many Requests for url: https://huggingface.co/api/models/Nerker/Rdrffg)\n",
            "INFO:backoff:Backing off get_model_metadata(...) for 0.8s (huggingface_hub.errors.HfHubHTTPError: 429 Client Error: Too Many Requests for url: https://huggingface.co/api/models/Albert9527/model-demo)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing Nerker/Rdrffg: 429 Client Error: Too Many Requests for url: https://huggingface.co/api/models/Nerker/Rdrffg\n",
            "\n",
            "  Fetching metadata for: Albert9527/model-demo\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:backoff:Backing off get_model_metadata(...) for 2.8s (huggingface_hub.errors.HfHubHTTPError: 429 Client Error: Too Many Requests for url: https://huggingface.co/api/models/Albert9527/model-demo)\n",
            "INFO:backoff:Backing off get_model_metadata(...) for 5.5s (huggingface_hub.errors.HfHubHTTPError: 429 Client Error: Too Many Requests for url: https://huggingface.co/api/models/Albert9527/model-demo)\n",
            "INFO:backoff:Backing off get_model_metadata(...) for 15.4s (huggingface_hub.errors.HfHubHTTPError: 429 Client Error: Too Many Requests for url: https://huggingface.co/api/models/Albert9527/model-demo)\n",
            "ERROR:backoff:Giving up get_model_metadata(...) after 5 tries (huggingface_hub.errors.HfHubHTTPError: 429 Client Error: Too Many Requests for url: https://huggingface.co/api/models/Albert9527/model-demo)\n",
            "INFO:backoff:Backing off get_model_metadata(...) for 1.7s (huggingface_hub.errors.HfHubHTTPError: 429 Client Error: Too Many Requests for url: https://huggingface.co/api/models/lilmos/twins-ai)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing Albert9527/model-demo: 429 Client Error: Too Many Requests for url: https://huggingface.co/api/models/Albert9527/model-demo\n",
            "\n",
            "  Fetching metadata for: lilmos/twins-ai\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:backoff:Backing off get_model_metadata(...) for 2.9s (huggingface_hub.errors.HfHubHTTPError: 429 Client Error: Too Many Requests for url: https://huggingface.co/api/models/lilmos/twins-ai)\n",
            "INFO:backoff:Backing off get_model_metadata(...) for 4.5s (huggingface_hub.errors.HfHubHTTPError: 429 Client Error: Too Many Requests for url: https://huggingface.co/api/models/lilmos/twins-ai)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for lilmos/twins-ai.\n",
            "\n",
            "  Fetching metadata for: andr1sv/hpp\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for andr1sv/hpp.\n",
            "\n",
            "  Fetching metadata for: sunooooone/KIMSUNOOMODEL\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for sunooooone/KIMSUNOOMODEL.\n",
            "\n",
            "  Fetching metadata for: sensey42/Talep\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for sensey42/Talep.\n",
            "Invalid URL skipped: https://huggingface.co/kauiu/janker0.0\n",
            "\n",
            "  Fetching metadata for: seenutheleo/imdb-model\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for seenutheleo/imdb-model.\n",
            "\n",
            "  Fetching metadata for: dla9944/test\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for dla9944/test.\n",
            "\n",
            "  Fetching metadata for: emirke159753159753/abii\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for emirke159753159753/abii.\n",
            "\n",
            "  Fetching metadata for: Jiajiawei/mySelfTalk\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for Jiajiawei/mySelfTalk.\n",
            "\n",
            "  Fetching metadata for: Random7878/Life\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for Random7878/Life.\n",
            "\n",
            "  Fetching metadata for: persadian/CropSeek-LLM\n",
            "  Found 2 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for persadian/CropSeek-LLM.\n",
            "\n",
            "    Fetching metadata for: DARJYO/Croptimize\n",
            "    Found 0 fine-tunes at depth 2.\n",
            "    Found 0 adapter models for DARJYO/Croptimize.\n",
            "\n",
            "    Fetching metadata for: persadian/Croptimize\n",
            "    Found 0 fine-tunes at depth 2.\n",
            "    Found 0 adapter models for persadian/Croptimize.\n",
            "\n",
            "  Fetching metadata for: Oluwadamo/Damo\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for Oluwadamo/Damo.\n",
            "\n",
            "  Fetching metadata for: YuRiVeRTi/VQ1\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for YuRiVeRTi/VQ1.\n",
            "\n",
            "  Fetching metadata for: d92refea/Asistente\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for d92refea/Asistente.\n",
            "\n",
            "  Fetching metadata for: tornado4651/test\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for tornado4651/test.\n",
            "\n",
            "  Fetching metadata for: an4l0g/test\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for an4l0g/test.\n",
            "\n",
            "  Fetching metadata for: JulienSunLib/Sunlib\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for JulienSunLib/Sunlib.\n",
            "\n",
            "  Fetching metadata for: Leto-cmd/Oddessey\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for Leto-cmd/Oddessey.\n",
            "\n",
            "  Fetching metadata for: fematt/telebot\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for fematt/telebot.\n",
            "\n",
            "  Fetching metadata for: yt-X/deepseek-r1-dpo\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for yt-X/deepseek-r1-dpo.\n",
            "\n",
            "  Fetching metadata for: Raymondjoe007/thor\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for Raymondjoe007/thor.\n",
            "\n",
            "  Fetching metadata for: Athipan01/GoDathipan\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for Athipan01/GoDathipan.\n",
            "Invalid URL skipped: https://huggingface.co/nicogptai/omega.1-2\n",
            "\n",
            "  Fetching metadata for: rehamhisham/saas\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for rehamhisham/saas.\n",
            "\n",
            "  Fetching metadata for: samfati/humanvoice\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for samfati/humanvoice.\n",
            "\n",
            "  Fetching metadata for: zain10000/ChatBot\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for zain10000/ChatBot.\n",
            "\n",
            "  Fetching metadata for: Owen14gjqwertkeyboard/LibrarianAI\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for Owen14gjqwertkeyboard/LibrarianAI.\n",
            "\n",
            "  Fetching metadata for: FEYSALjhn/Lisov\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for FEYSALjhn/Lisov.\n",
            "\n",
            "  Fetching metadata for: IcYhAwK88/BeeAndMe\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for IcYhAwK88/BeeAndMe.\n",
            "\n",
            "  Fetching metadata for: Kelinsia/Traininghuggy\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for Kelinsia/Traininghuggy.\n",
            "\n",
            "  Fetching metadata for: Monternot888/Test_de_Bert\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for Monternot888/Test_de_Bert.\n",
            "\n",
            "  Fetching metadata for: Mehrankarajii/Mehran\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for Mehrankarajii/Mehran.\n",
            "\n",
            "  Fetching metadata for: AIbyAnmol/publicity\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for AIbyAnmol/publicity.\n",
            "\n",
            "  Fetching metadata for: adarshgiri55/Adi\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for adarshgiri55/Adi.\n",
            "\n",
            "  Fetching metadata for: Yaavuzzz/Yavuz\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for Yaavuzzz/Yavuz.\n",
            "\n",
            "  Fetching metadata for: margerz156/margthink\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for margerz156/margthink.\n",
            "\n",
            "  Fetching metadata for: jasonlinn/yilanpass\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for jasonlinn/yilanpass.\n",
            "\n",
            "  Fetching metadata for: bkaplan/MRL2\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for bkaplan/MRL2.\n",
            "\n",
            "  Fetching metadata for: yookidz/my-code-Llama\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for yookidz/my-code-Llama.\n",
            "\n",
            "  Fetching metadata for: Average8/ast\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for Average8/ast.\n",
            "\n",
            "  Fetching metadata for: Minnus/rtrancit\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for Minnus/rtrancit.\n",
            "\n",
            "  Fetching metadata for: BadiciCyra/rag\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for BadiciCyra/rag.\n",
            "\n",
            "  Fetching metadata for: andong90/DeepSeek-R1-Distill-Qwen-7B-student-mental-health-json\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/4.19k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "73a70967cf2d4d64888b0f2530bcb369"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for andong90/DeepSeek-R1-Distill-Qwen-7B-student-mental-health-json.\n",
            "\n",
            "  Fetching metadata for: aishu1505/english-tamil-translation\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for aishu1505/english-tamil-translation.\n",
            "\n",
            "  Fetching metadata for: ashad846004/DeepSeek-R1-Medical-COT\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for ashad846004/DeepSeek-R1-Medical-COT.\n",
            "\n",
            "  Fetching metadata for: DivineNinja13/bubaModel\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for DivineNinja13/bubaModel.\n",
            "\n",
            "  Fetching metadata for: Yeeheng/repo\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for Yeeheng/repo.\n",
            "\n",
            "  Fetching metadata for: beita6969/deepseek-r1-medical-response\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for beita6969/deepseek-r1-medical-response.\n",
            "\n",
            "  Fetching metadata for: TrevSh/Demo_Edu_Model\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for TrevSh/Demo_Edu_Model.\n",
            "Invalid URL skipped: https://huggingface.co/Acardozo/llama3.2\n",
            "\n",
            "  Fetching metadata for: beita6969/DeepSeek-R1-Distill-Qwen-32B-Medical\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for beita6969/DeepSeek-R1-Distill-Qwen-32B-Medical.\n",
            "\n",
            "  Fetching metadata for: qp521/ibm-chatbot-model\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for qp521/ibm-chatbot-model.\n",
            "\n",
            "  Fetching metadata for: raajveers/youtube-title-gen\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for raajveers/youtube-title-gen.\n",
            "\n",
            "  Fetching metadata for: javier001/Javier\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for javier001/Javier.\n",
            "\n",
            "  Fetching metadata for: Prarabdha/law_gpt\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for Prarabdha/law_gpt.\n",
            "\n",
            "  Fetching metadata for: ImmersioNAI/Poppy\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for ImmersioNAI/Poppy.\n",
            "\n",
            "  Fetching metadata for: disconzi/oze\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for disconzi/oze.\n",
            "\n",
            "  Fetching metadata for: gabrial1927/gabrial\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for gabrial1927/gabrial.\n",
            "\n",
            "  Fetching metadata for: kalleopinheiro/deepseek\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for kalleopinheiro/deepseek.\n",
            "\n",
            "  Fetching metadata for: Harshitv/test\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for Harshitv/test.\n",
            "\n",
            "  Fetching metadata for: Sumitnawale68/Sumit\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for Sumitnawale68/Sumit.\n",
            "\n",
            "  Fetching metadata for: RZEE17/New1\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for RZEE17/New1.\n",
            "\n",
            "  Fetching metadata for: cr6276/mymodel\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for cr6276/mymodel.\n",
            "\n",
            "  Fetching metadata for: lorenzzzo/lorezAI\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for lorenzzzo/lorezAI.\n",
            "\n",
            "  Fetching metadata for: sarvar3697/sarvar_2\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for sarvar3697/sarvar_2.\n",
            "\n",
            "  Fetching metadata for: Vepa1979/turkmence\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for Vepa1979/turkmence.\n",
            "\n",
            "  Fetching metadata for: DaKaufeeBoii/Cleo\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for DaKaufeeBoii/Cleo.\n",
            "\n",
            "  Fetching metadata for: perplexity-ai/r1-1776\n",
            "  Found 11 fine-tunes at depth 1.\n",
            "  Found 1 adapter models for perplexity-ai/r1-1776.\n",
            "\n",
            "    Fetching metadata for: dahiya11/Ai-Assistant\n",
            "    Found 0 fine-tunes at depth 2.\n",
            "    Found 0 adapter models for dahiya11/Ai-Assistant.\n",
            "\n",
            "    Fetching metadata for: rash1dovt/tyncha_ai\n",
            "    Found 0 fine-tunes at depth 2.\n",
            "    Found 0 adapter models for rash1dovt/tyncha_ai.\n",
            "\n",
            "    Fetching metadata for: malypali18/WebWealthWizards\n",
            "    Found 0 fine-tunes at depth 2.\n",
            "    Found 0 adapter models for malypali18/WebWealthWizards.\n",
            "\n",
            "    Fetching metadata for: Hxh0211/11111\n",
            "    Found 0 fine-tunes at depth 2.\n",
            "    Found 0 adapter models for Hxh0211/11111.\n",
            "\n",
            "    Fetching metadata for: unsloth/r1-1776\n",
            "    Found 0 fine-tunes at depth 2.\n",
            "    Found 0 adapter models for unsloth/r1-1776.\n",
            "\n",
            "    Fetching metadata for: Khewa153/GleemanAI\n",
            "    Found 0 fine-tunes at depth 2.\n",
            "    Found 0 adapter models for Khewa153/GleemanAI.\n",
            "\n",
            "    Fetching metadata for: Renato186/ren\n",
            "    Found 0 fine-tunes at depth 2.\n",
            "    Found 0 adapter models for Renato186/ren.\n",
            "\n",
            "    Fetching metadata for: Delfileking/Histoirde2005\n",
            "    Found 0 fine-tunes at depth 2.\n",
            "    Found 0 adapter models for Delfileking/Histoirde2005.\n",
            "\n",
            "    Fetching metadata for: ALESSIO66/Law_CCII_IT_ProceduresCloud\n",
            "    Found 0 fine-tunes at depth 2.\n",
            "    Found 0 adapter models for ALESSIO66/Law_CCII_IT_ProceduresCloud.\n",
            "\n",
            "    Fetching metadata for: Suziwan/Model1\n",
            "    Found 0 fine-tunes at depth 2.\n",
            "    Found 0 adapter models for Suziwan/Model1.\n",
            "\n",
            "    Fetching metadata for: mlx-community/perplexity-ai-r1-1776-bf16\n",
            "    Found 0 fine-tunes at depth 2.\n",
            "    Found 0 adapter models for mlx-community/perplexity-ai-r1-1776-bf16.\n",
            "\n",
            "  Fetching metadata for: PNZAGI/TRAIN\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for PNZAGI/TRAIN.\n",
            "\n",
            "  Fetching metadata for: Smdhussain06/Joyboy\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for Smdhussain06/Joyboy.\n",
            "Invalid URL skipped: https://huggingface.co/OmarGX/Omar.Gx\n",
            "\n",
            "  Fetching metadata for: Gary88/mymodel\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for Gary88/mymodel.\n",
            "\n",
            "  Fetching metadata for: Northflux3/test\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for Northflux3/test.\n",
            "\n",
            "  Fetching metadata for: Hamzillo/Lolo\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for Hamzillo/Lolo.\n",
            "\n",
            "  Fetching metadata for: TheWolfOfWallStreet/The_Wolf_Of_Wall_Street\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for TheWolfOfWallStreet/The_Wolf_Of_Wall_Street.\n",
            "\n",
            "  Fetching metadata for: mahgam88/Jafr\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for mahgam88/Jafr.\n",
            "\n",
            "  Fetching metadata for: silkstringfiddlesink/Astra-49\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for silkstringfiddlesink/Astra-49.\n",
            "\n",
            "  Fetching metadata for: xiaoyuboi/test-model\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for xiaoyuboi/test-model.\n",
            "\n",
            "  Fetching metadata for: silence09/DeepSeek-R1-Small-2layers\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for silence09/DeepSeek-R1-Small-2layers.\n",
            "\n",
            "  Fetching metadata for: Hi14th/test\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for Hi14th/test.\n",
            "\n",
            "  Fetching metadata for: Alejandro1266/Studying\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for Alejandro1266/Studying.\n",
            "\n",
            "  Fetching metadata for: KaPe22/KaPe22\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for KaPe22/KaPe22.\n",
            "\n",
            "  Fetching metadata for: ritense/test-model\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for ritense/test-model.\n",
            "\n",
            "  Fetching metadata for: RecurvAI/Recurv-Medical-Deepseek-R1\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for RecurvAI/Recurv-Medical-Deepseek-R1.\n",
            "\n",
            "  Fetching metadata for: sezer2737/sorucoz\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for sezer2737/sorucoz.\n",
            "\n",
            "  Fetching metadata for: deca-ai/2-mini\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for deca-ai/2-mini.\n",
            "\n",
            "  Fetching metadata for: Reda2566/Reda_68\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for Reda2566/Reda_68.\n",
            "\n",
            "  Fetching metadata for: yifan-playground/deepseek-r1\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for yifan-playground/deepseek-r1.\n",
            "\n",
            "  Fetching metadata for: Alhdrawi/R-RAY-AI\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for Alhdrawi/R-RAY-AI.\n",
            "\n",
            "  Fetching metadata for: r4isy/kenu\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for r4isy/kenu.\n",
            "\n",
            "  Fetching metadata for: PARSIS/Moshaver\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for PARSIS/Moshaver.\n",
            "\n",
            "  Fetching metadata for: Tackit/Flensburg\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for Tackit/Flensburg.\n",
            "\n",
            "  Fetching metadata for: SirFestus/Text-To-Text\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for SirFestus/Text-To-Text.\n",
            "\n",
            "  Fetching metadata for: guanglian/test\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for guanglian/test.\n",
            "\n",
            "  Fetching metadata for: Joncarel/Vernertranslate\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for Joncarel/Vernertranslate.\n",
            "\n",
            "  Fetching metadata for: julelti/Ci\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for julelti/Ci.\n",
            "\n",
            "  Fetching metadata for: Klanik58/Devrim_DSE\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:backoff:Backing off make_http_request(...) for 1.6s (requests.exceptions.HTTPError: 429 Client Error: Too Many Requests for url: https://huggingface.co/models?other=base_model:adapter:Klanik58/Devrim_DSE&p=0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Found 0 fine-tunes at depth 1.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:backoff:Backing off make_http_request(...) for 0.3s (requests.exceptions.HTTPError: 429 Client Error: Too Many Requests for url: https://huggingface.co/models?other=base_model:adapter:Klanik58/Devrim_DSE&p=0)\n",
            "INFO:backoff:Backing off make_http_request(...) for 2.0s (requests.exceptions.HTTPError: 429 Client Error: Too Many Requests for url: https://huggingface.co/models?other=base_model:adapter:Klanik58/Devrim_DSE&p=0)\n",
            "INFO:backoff:Backing off make_http_request(...) for 14.2s (requests.exceptions.HTTPError: 429 Client Error: Too Many Requests for url: https://huggingface.co/models?other=base_model:adapter:Klanik58/Devrim_DSE&p=0)\n",
            "ERROR:backoff:Giving up make_http_request(...) after 5 tries (requests.exceptions.HTTPError: 429 Client Error: Too Many Requests for url: https://huggingface.co/models?other=base_model:adapter:Klanik58/Devrim_DSE&p=0)\n",
            "INFO:backoff:Backing off get_model_metadata(...) for 0.1s (huggingface_hub.errors.HfHubHTTPError: 429 Client Error: Too Many Requests for url: https://huggingface.co/api/models/ykarout/phi-4-deepseek-reasoning-fp16)\n",
            "INFO:backoff:Backing off get_model_metadata(...) for 2.2s (huggingface_hub.errors.HfHubHTTPError: 429 Client Error: Too Many Requests for url: https://huggingface.co/api/models/ykarout/phi-4-deepseek-reasoning-fp16)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HTTP error occurred: 429 Client Error: Too Many Requests for url: https://huggingface.co/models?other=base_model:adapter:Klanik58/Devrim_DSE&p=0\n",
            "  Found 0 adapter models for Klanik58/Devrim_DSE.\n",
            "\n",
            "  Fetching metadata for: ykarout/phi-4-deepseek-reasoning-fp16\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for ykarout/phi-4-deepseek-reasoning-fp16.\n",
            "\n",
            "  Fetching metadata for: Dashutosh884/Hugging_Face\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for Dashutosh884/Hugging_Face.\n",
            "\n",
            "  Fetching metadata for: ibtp1256/tpmodel\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for ibtp1256/tpmodel.\n",
            "\n",
            "  Fetching metadata for: YTPG524/The_Fight_for_Top\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for YTPG524/The_Fight_for_Top.\n",
            "\n",
            "  Fetching metadata for: Aspenini/Backwards-AI\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for Aspenini/Backwards-AI.\n",
            "\n",
            "  Fetching metadata for: Hataco/RR-SwordFigthing\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for Hataco/RR-SwordFigthing.\n",
            "\n",
            "  Fetching metadata for: marlono/test\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for marlono/test.\n",
            "\n",
            "  Fetching metadata for: opensourcerelease/DeepSeek-R1-bf16\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for opensourcerelease/DeepSeek-R1-bf16.\n",
            "\n",
            "  Fetching metadata for: Arrowxyz/hux-ai\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for Arrowxyz/hux-ai.\n",
            "\n",
            "  Fetching metadata for: sherooz/ahmed\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for sherooz/ahmed.\n",
            "\n",
            "  Fetching metadata for: death-walker/harmoni\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for death-walker/harmoni.\n",
            "\n",
            "  Fetching metadata for: SAMdahal/aiitenarary\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for SAMdahal/aiitenarary.\n",
            "\n",
            "  Fetching metadata for: Duckets/Duckbot1\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for Duckets/Duckbot1.\n",
            "\n",
            "  Fetching metadata for: Yeamkuan/enanalysis\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for Yeamkuan/enanalysis.\n",
            "\n",
            "  Fetching metadata for: chitdev/deepseek-r1-distill-7b\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for chitdev/deepseek-r1-distill-7b.\n",
            "\n",
            "  Fetching metadata for: desmond-initiative/news_api_context\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for desmond-initiative/news_api_context.\n",
            "\n",
            "  Fetching metadata for: lekadesire/Football_Predict\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for lekadesire/Football_Predict.\n",
            "\n",
            "  Fetching metadata for: aliMohammad16/sabrina-ai\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for aliMohammad16/sabrina-ai.\n",
            "\n",
            "  Fetching metadata for: himanshuvas/test\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for himanshuvas/test.\n",
            "\n",
            "  Fetching metadata for: GeorgeWeasley84/convert-case\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for GeorgeWeasley84/convert-case.\n",
            "\n",
            "  Fetching metadata for: CynthiaAAAA/deepseek-chat\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for CynthiaAAAA/deepseek-chat.\n",
            "\n",
            "  Fetching metadata for: 4TO/MC_Farmer\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for 4TO/MC_Farmer.\n",
            "\n",
            "  Fetching metadata for: bokomoko/boletoreader\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for bokomoko/boletoreader.\n",
            "\n",
            "  Fetching metadata for: alexpineda97/traductor_otoesp\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for alexpineda97/traductor_otoesp.\n",
            "\n",
            "  Fetching metadata for: VANNVISAL/LLM_Model\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for VANNVISAL/LLM_Model.\n",
            "\n",
            "  Fetching metadata for: Withersen/AIArtCreator\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for Withersen/AIArtCreator.\n",
            "\n",
            "  Fetching metadata for: Dach13/Darryc\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for Dach13/Darryc.\n",
            "\n",
            "  Fetching metadata for: mikmik2003/jaz2\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for mikmik2003/jaz2.\n",
            "\n",
            "  Fetching metadata for: bijorn/winger\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for bijorn/winger.\n",
            "\n",
            "  Fetching metadata for: buyun/test-model\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for buyun/test-model.\n",
            "\n",
            "  Fetching metadata for: Mylamoore040/Myla\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for Mylamoore040/Myla.\n",
            "\n",
            "  Fetching metadata for: Ai1God/Godboy\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for Ai1God/Godboy.\n",
            "\n",
            "  Fetching metadata for: myself-model/11\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for myself-model/11.\n",
            "Invalid URL skipped: https://huggingface.co/Drachenkrieger/Novela_Era_4.0\n",
            "\n",
            "  Fetching metadata for: Sugamk/vai\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for Sugamk/vai.\n",
            "\n",
            "  Fetching metadata for: Yadav009/Aiclothchange\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for Yadav009/Aiclothchange.\n",
            "\n",
            "  Fetching metadata for: maersee3423423/statuetka\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for maersee3423423/statuetka.\n",
            "\n",
            "  Fetching metadata for: weapon-x/chatbot\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for weapon-x/chatbot.\n",
            "\n",
            "  Fetching metadata for: Priyansu17/miningAact\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for Priyansu17/miningAact.\n",
            "\n",
            "  Fetching metadata for: zonnell/discord_bot\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for zonnell/discord_bot.\n",
            "\n",
            "  Fetching metadata for: exco369/infinity\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for exco369/infinity.\n",
            "\n",
            "  Fetching metadata for: deevnnv/nomadchroniclesapi\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for deevnnv/nomadchroniclesapi.\n",
            "\n",
            "  Fetching metadata for: lukeshaye/testelukeshaye\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for lukeshaye/testelukeshaye.\n",
            "\n",
            "  Fetching metadata for: ManishDipole/Demo\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for ManishDipole/Demo.\n",
            "\n",
            "  Fetching metadata for: emartinezra/Arsonai\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for emartinezra/Arsonai.\n",
            "\n",
            "  Fetching metadata for: mdjobayarehosen/Bing3\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for mdjobayarehosen/Bing3.\n",
            "\n",
            "  Fetching metadata for: kazzaou/app\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for kazzaou/app.\n",
            "\n",
            "  Fetching metadata for: rshaikh22/coachcarellm\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for rshaikh22/coachcarellm.\n",
            "\n",
            "  Fetching metadata for: mih12345/deepseek_R1_jaman_josna\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for mih12345/deepseek_R1_jaman_josna.\n",
            "\n",
            "  Fetching metadata for: thalesleal/carteiraia\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for thalesleal/carteiraia.\n",
            "\n",
            "  Fetching metadata for: praveenrmd/TamilGPT\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for praveenrmd/TamilGPT.\n",
            "\n",
            "  Fetching metadata for: Vaimee/fggggr\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for Vaimee/fggggr.\n",
            "\n",
            "  Fetching metadata for: Hqrunkeke/Deepseekk\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for Hqrunkeke/Deepseekk.\n",
            "\n",
            "  Fetching metadata for: Angiie/Angie-light\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for Angiie/Angie-light.\n",
            "\n",
            "  Fetching metadata for: meghrajs/demo\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for meghrajs/demo.\n",
            "\n",
            "  Fetching metadata for: zedx1/BlueAI\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for zedx1/BlueAI.\n",
            "\n",
            "  Fetching metadata for: Fr0sT-FLAB/SolidityGPT\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for Fr0sT-FLAB/SolidityGPT.\n",
            "Invalid URL skipped: https://huggingface.co/Kaanjoa/Joa0.6\n",
            "\n",
            "  Fetching metadata for: Dimaswa/openrail\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for Dimaswa/openrail.\n",
            "\n",
            "  Fetching metadata for: cwestbrook/lotrdata\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for cwestbrook/lotrdata.\n",
            "\n",
            "  Fetching metadata for: LiuTengYing/CarRadio\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for LiuTengYing/CarRadio.\n",
            "\n",
            "  Fetching metadata for: AbdullahAli06/abdullahali_ai\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for AbdullahAli06/abdullahali_ai.\n",
            "\n",
            "  Fetching metadata for: urjinchimed/khalkhmongol\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for urjinchimed/khalkhmongol.\n",
            "\n",
            "  Fetching metadata for: farypor/seoaigen\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for farypor/seoaigen.\n",
            "Invalid URL skipped: https://huggingface.co/raulmoraless/Raul.IA\n",
            "Invalid URL skipped: https://huggingface.co/SIMAMING/REVO-ART2.0\n",
            "\n",
            "  Fetching metadata for: Favour99/ALPHA\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for Favour99/ALPHA.\n",
            "\n",
            "  Fetching metadata for: ComputerAi/Bob\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for ComputerAi/Bob.\n",
            "\n",
            "  Fetching metadata for: antondanilevskiy/GTCauto\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for antondanilevskiy/GTCauto.\n",
            "\n",
            "  Fetching metadata for: usersomethingelze/birdinyourear\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for usersomethingelze/birdinyourear.\n",
            "\n",
            "  Fetching metadata for: Nitipoom/matcha888\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/128 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8ebe71bc81d04847bb9714d60b7f0dc1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for Nitipoom/matcha888.\n",
            "\n",
            "  Fetching metadata for: wsxdyzx2025/weigb\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for wsxdyzx2025/weigb.\n",
            "\n",
            "  Fetching metadata for: coralgables/crypto\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for coralgables/crypto.\n",
            "\n",
            "  Fetching metadata for: William-zhao/KuCozy\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for William-zhao/KuCozy.\n",
            "\n",
            "  Fetching metadata for: boilerbambam/NEW_APP\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for boilerbambam/NEW_APP.\n",
            "\n",
            "  Fetching metadata for: kuazi/deepseek-r1-medical-test\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for kuazi/deepseek-r1-medical-test.\n",
            "\n",
            "  Fetching metadata for: YooJeahkhn/YooJeahkhn\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for YooJeahkhn/YooJeahkhn.\n",
            "\n",
            "  Fetching metadata for: wangju123/xiaoju\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/72.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "09cd632e37aa4f87b1af4a3a06b7aef8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for wangju123/xiaoju.\n",
            "\n",
            "  Fetching metadata for: raghu1155/DeepSeek-R1-Codegeneration-COT\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for raghu1155/DeepSeek-R1-Codegeneration-COT.\n",
            "\n",
            "  Fetching metadata for: saleh1977/nexta-9101\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for saleh1977/nexta-9101.\n",
            "\n",
            "  Fetching metadata for: visnu90/pycooking\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for visnu90/pycooking.\n",
            "\n",
            "  Fetching metadata for: primaryPond/product_comparison\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for primaryPond/product_comparison.\n",
            "\n",
            "  Fetching metadata for: silence09/DeepSeek-R1-3layers\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for silence09/DeepSeek-R1-3layers.\n",
            "\n",
            "  Fetching metadata for: karrrr123456/ace\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for karrrr123456/ace.\n",
            "\n",
            "  Fetching metadata for: drperkybottom/DeepLerting-LLM\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for drperkybottom/DeepLerting-LLM.\n",
            "\n",
            "  Fetching metadata for: samwilenborg30/chatbot\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for samwilenborg30/chatbot.\n",
            "\n",
            "  Fetching metadata for: alex322r/deepseek-responder\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for alex322r/deepseek-responder.\n",
            "\n",
            "  Fetching metadata for: karim8955/mate\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for karim8955/mate.\n",
            "\n",
            "  Fetching metadata for: soupbutt/writefanfic\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "  Found 0 adapter models for soupbutt/writefanfic.\n",
            "Results saved to results/DeepSeek-R1_finetunes_20250416_234237.json_finetunes_20250416_234223.json\n",
            "Results saved to results/DeepSeek-R1_finetunes_20250416_234237.csv_finetunes_20250416_234223.csv\n",
            "Completed DeepSeek-R1 in 252.20s\n",
            "Waiting 3 seconds...\n",
            "\n",
            "[3/782] Processing: CompVis/stable-diffusion-v1-4\n",
            "Starting analysis for CompVis/stable-diffusion-v1-4\n",
            "\n",
            "Fetching metadata for: CompVis/stable-diffusion-v1-4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:backoff:Backing off make_http_request(...) for 1.0s (requests.exceptions.HTTPError: 429 Client Error: Too Many Requests for url: https://huggingface.co/models?other=base_model:finetune:CompVis/stable-diffusion-v1-4&p=29)\n",
            "INFO:backoff:Backing off make_http_request(...) for 3.6s (requests.exceptions.HTTPError: 429 Client Error: Too Many Requests for url: https://huggingface.co/models?other=base_model:finetune:CompVis/stable-diffusion-v1-4&p=29)\n",
            "INFO:backoff:Backing off make_http_request(...) for 4.7s (requests.exceptions.HTTPError: 429 Client Error: Too Many Requests for url: https://huggingface.co/models?other=base_model:finetune:CompVis/stable-diffusion-v1-4&p=29)\n",
            "INFO:backoff:Backing off make_http_request(...) for 9.9s (requests.exceptions.HTTPError: 429 Client Error: Too Many Requests for url: https://huggingface.co/models?other=base_model:finetune:CompVis/stable-diffusion-v1-4&p=29)\n",
            "ERROR:backoff:Giving up make_http_request(...) after 5 tries (requests.exceptions.HTTPError: 429 Client Error: Too Many Requests for url: https://huggingface.co/models?other=base_model:finetune:CompVis/stable-diffusion-v1-4&p=29)\n",
            "INFO:backoff:Backing off make_http_request(...) for 1.7s (requests.exceptions.HTTPError: 429 Client Error: Too Many Requests for url: https://huggingface.co/models?other=base_model:adapter:CompVis/stable-diffusion-v1-4&p=0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HTTP error occurred: 429 Client Error: Too Many Requests for url: https://huggingface.co/models?other=base_model:finetune:CompVis/stable-diffusion-v1-4&p=29\n",
            "Found 870 fine-tunes at depth 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:backoff:Backing off make_http_request(...) for 4.0s (requests.exceptions.HTTPError: 429 Client Error: Too Many Requests for url: https://huggingface.co/models?other=base_model:adapter:CompVis/stable-diffusion-v1-4&p=0)\n"
          ]
        }
      ],
      "source": [
        "# Multi-model runner for HuggingFace model analysis\n",
        "import requests\n",
        "import pandas as pd\n",
        "import datetime\n",
        "import json\n",
        "import csv\n",
        "import os\n",
        "import time\n",
        "import backoff\n",
        "from huggingface_hub import HfApi\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "\n",
        "# Import from script3\n",
        "try:\n",
        "    from script3 import dfs_finetunes, save_json, save_csv\n",
        "    print(\"Successfully imported functions from script3\")\n",
        "except ImportError as e:\n",
        "    raise ImportError(f\"Failed to import functions from script3: {e}. Make sure script3.py exists and contains the required functions.\")\n",
        "\n",
        "# Timestamp for output files\n",
        "timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "\n",
        "# Enhanced processing with backoff\n",
        "@backoff.on_exception(\n",
        "    backoff.expo,\n",
        "    (requests.exceptions.RequestException, Exception),\n",
        "    max_tries=5,\n",
        "    max_time=60,\n",
        "    factor=2,\n",
        "    jitter=backoff.full_jitter\n",
        ")\n",
        "def process_single_model(model_id, output_dir):\n",
        "    \"\"\"Process individual model with error handling\"\"\"\n",
        "    model_url = f\"https://huggingface.co/{model_id}\"\n",
        "    visited = set()\n",
        "\n",
        "    print(f\"Starting analysis for {model_id}\")\n",
        "    start_time = time.time()\n",
        "\n",
        "    results = dfs_finetunes(model_url, visited)\n",
        "\n",
        "    if results:\n",
        "        model_name = model_id.split(\"/\")[-1]\n",
        "        json_path = os.path.join(output_dir, f\"{model_name}_finetunes_{timestamp}.json\")\n",
        "        csv_path = os.path.join(output_dir, f\"{model_name}_finetunes_{timestamp}.csv\")\n",
        "\n",
        "        save_json(results, json_path)\n",
        "        save_csv(results, csv_path)\n",
        "\n",
        "        elapsed = time.time() - start_time\n",
        "        print(f\"Completed {model_name} in {elapsed:.2f}s\")\n",
        "        return True, model_name\n",
        "    else:\n",
        "        elapsed = time.time() - start_time\n",
        "        print(f\"No results for {model_id} after {elapsed:.2f}s\")\n",
        "        return False, model_id\n",
        "\n",
        "def process_models_from_csv(csv_path, output_dir=\"results\", limit=10, delay=2):\n",
        "    \"\"\"Process models from CSV with validation\"\"\"\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    try:\n",
        "        df = pd.read_csv(csv_path)\n",
        "    except Exception as e:\n",
        "        print(f\"Error reading CSV file: {e}\")\n",
        "        return\n",
        "\n",
        "    if 'id' not in df.columns:\n",
        "        raise ValueError(\"CSV must contain a column named 'id'.\")\n",
        "\n",
        "    # Validate model IDs\n",
        "    df = df.head(limit).copy()\n",
        "    df['is_valid'] = df['id'].apply(lambda x: bool(re.match(r'^[\\w-]+\\/[\\w-]+$', str(x))))\n",
        "    invalid_models = df[~df['is_valid']]\n",
        "\n",
        "    if not invalid_models.empty:\n",
        "        print(f\"Warning: {len(invalid_models)} invalid model IDs detected:\")\n",
        "        print(invalid_models['id'].tolist())\n",
        "        print(\"Skipping invalid models...\")\n",
        "\n",
        "    df = df[df['is_valid']]\n",
        "    total_models = len(df)\n",
        "\n",
        "    successful = 0\n",
        "    failed = 0\n",
        "\n",
        "    print(f\"Starting analysis of {total_models} valid models\")\n",
        "\n",
        "    for idx, row in df.iterrows():\n",
        "        model_id = row['id'].strip()\n",
        "        print(f\"\\n[{idx + 1}/{total_models}] Processing: {model_id}\")\n",
        "\n",
        "        try:\n",
        "            success, name = process_single_model(model_id, output_dir)\n",
        "\n",
        "            if success:\n",
        "                successful += 1\n",
        "            else:\n",
        "                failed += 1\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Critical error with {model_id}: {str(e)[:200]}\")\n",
        "            failed += 1\n",
        "\n",
        "        if idx < total_models - 1:\n",
        "            print(f\"Waiting {delay} seconds...\")\n",
        "            time.sleep(delay)\n",
        "\n",
        "    print(f\"\\nAnalysis Summary:\")\n",
        "    print(f\"Successful: {successful}\")\n",
        "    print(f\"Failed: {failed}\")\n",
        "    print(f\"Results saved to: {os.path.abspath(output_dir)}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"HuggingFace Multi-Model Analysis Tool\")\n",
        "    print(\"====================================\")\n",
        "\n",
        "    csv_input = input(\"Path to CSV with model IDs: \").strip()\n",
        "\n",
        "    try:\n",
        "        limit = int(input(\"Number of models to process (default: 10): \").strip() or 10)\n",
        "        delay = int(input(\"Delay between models in seconds (default: 2): \").strip() or 2)\n",
        "        output_dir = input(\"Output directory (default: 'results'): \").strip() or \"results\"\n",
        "\n",
        "        process_models_from_csv(csv_input, output_dir, limit, delay)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Initialization error: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OH9jmoQ64X4p"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOmVnwcHs9+Sdi3X99Wmx7B",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "73a70967cf2d4d64888b0f2530bcb369": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d961f0316b8e41b1961444ace22ee952",
              "IPY_MODEL_ffb0fdf069c74f9a8e2532802eac5175",
              "IPY_MODEL_b713fc94b9ef4b839f0183d6f190ae18"
            ],
            "layout": "IPY_MODEL_c001daca18944736856c68e477ecf2a4"
          }
        },
        "d961f0316b8e41b1961444ace22ee952": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_56d9ad4c0fff4fbf953d53d14ec35ead",
            "placeholder": "",
            "style": "IPY_MODEL_663be1013f2c4d50a422019f8ad1c344",
            "value": "README.md:100%"
          }
        },
        "ffb0fdf069c74f9a8e2532802eac5175": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_27467f2dee6e40ce8a95ada12c09e7eb",
            "max": 4186,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_229efeb6c08b4d3589e10d0429377581",
            "value": 4186
          }
        },
        "b713fc94b9ef4b839f0183d6f190ae18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_48a1ecc66ab6463db0e4ccdd075a8435",
            "placeholder": "",
            "style": "IPY_MODEL_c2ecc10f754b4cd0bb868793140ec24e",
            "value": "4.19k/4.19k[00:00&lt;00:00,276kB/s]"
          }
        },
        "c001daca18944736856c68e477ecf2a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "56d9ad4c0fff4fbf953d53d14ec35ead": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "663be1013f2c4d50a422019f8ad1c344": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "27467f2dee6e40ce8a95ada12c09e7eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "229efeb6c08b4d3589e10d0429377581": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "48a1ecc66ab6463db0e4ccdd075a8435": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c2ecc10f754b4cd0bb868793140ec24e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8ebe71bc81d04847bb9714d60b7f0dc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_041b7b6cd8bb42c8935a9793bc1b5d05",
              "IPY_MODEL_7ed0c27a87d841129340a008c215008c",
              "IPY_MODEL_8b122d5f52be4b0787fff88d54789a09"
            ],
            "layout": "IPY_MODEL_703cbdd022a34cf9974e7c4ad777de19"
          }
        },
        "041b7b6cd8bb42c8935a9793bc1b5d05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3c7d541567b7403fa54a026182d35da8",
            "placeholder": "",
            "style": "IPY_MODEL_6a2ea8e1efb549ebbf83fa3ca97d7932",
            "value": "README.md:100%"
          }
        },
        "7ed0c27a87d841129340a008c215008c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7a90dececc29455687869c34d01978d9",
            "max": 128,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a4816eda8d794b00bb6e941eedc6d350",
            "value": 128
          }
        },
        "8b122d5f52be4b0787fff88d54789a09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8b0934701b854ed3a4fe6adfb9223dbd",
            "placeholder": "",
            "style": "IPY_MODEL_3f10a427121c4553844b8535ea359128",
            "value": "128/128[00:00&lt;00:00,7.27kB/s]"
          }
        },
        "703cbdd022a34cf9974e7c4ad777de19": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c7d541567b7403fa54a026182d35da8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6a2ea8e1efb549ebbf83fa3ca97d7932": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7a90dececc29455687869c34d01978d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a4816eda8d794b00bb6e941eedc6d350": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8b0934701b854ed3a4fe6adfb9223dbd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3f10a427121c4553844b8535ea359128": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "09cd632e37aa4f87b1af4a3a06b7aef8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5e7a196d2d0047ca9a7eb46a2274d698",
              "IPY_MODEL_0391699c31844e598b7ac325872fa0ec",
              "IPY_MODEL_3e1014676c154ec68defb386b60742de"
            ],
            "layout": "IPY_MODEL_735558928c6c4851a130b143fd16f7ee"
          }
        },
        "5e7a196d2d0047ca9a7eb46a2274d698": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c358566eb34d42d092fa38208009f4f2",
            "placeholder": "",
            "style": "IPY_MODEL_298aca81e3594a72b0f97aadca801625",
            "value": "README.md:100%"
          }
        },
        "0391699c31844e598b7ac325872fa0ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ec277bb4ee0a45109643b23ad34b5982",
            "max": 72,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3d06011fc08a4e9eb1323c57f654a5ca",
            "value": 72
          }
        },
        "3e1014676c154ec68defb386b60742de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2138f5da54a74478b232474e33d12093",
            "placeholder": "",
            "style": "IPY_MODEL_88671425bec84643a3543c17d2292ef5",
            "value": "72.0/72.0[00:00&lt;00:00,4.22kB/s]"
          }
        },
        "735558928c6c4851a130b143fd16f7ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c358566eb34d42d092fa38208009f4f2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "298aca81e3594a72b0f97aadca801625": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ec277bb4ee0a45109643b23ad34b5982": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d06011fc08a4e9eb1323c57f654a5ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2138f5da54a74478b232474e33d12093": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "88671425bec84643a3543c17d2292ef5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hamidahoderinwale/model_metadata_analyses/blob/main/scraping_hf.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Script 1\n",
        "Takes in a (validated) model url and output its metadata"
      ],
      "metadata": {
        "id": "cxlHKer226vF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fmp0ftEomk86"
      },
      "outputs": [],
      "source": [
        "# Script 1: takes input model url, validates url, and gives model metadata\n",
        "!pip install validators\n",
        "from huggingface_hub import HfApi\n",
        "import validators\n",
        "import json\n",
        "import csv\n",
        "\n",
        "hf_api = HfApi()\n",
        "\n",
        "def input_url():\n",
        "    while True:\n",
        "        input_model_url = input(\"Enter model URL: \")\n",
        "        print(f\"You entered: {input_model_url}\")\n",
        "\n",
        "        if validators.url(input_model_url) and \"huggingface.co\" in input_model_url:\n",
        "            try:\n",
        "                # Extract the model ID from the URL\n",
        "                model_id = input_model_url.split(\"huggingface.co/\")[-1]\n",
        "                model_info = hf_api.model_info(model_id) # Get model info: https://huggingface.co/docs/huggingface_hub/v0.29.2/en/package_reference/hf_api#huggingface_hub.ModelInfo\n",
        "                json_output = json.dumps(model_info.__dict__, indent=4, default=str)\n",
        "                print(json_output)\n",
        "                with open('model_info.json', 'w') as json_file:\n",
        "                    json_file.write(json_output)\n",
        "            except Exception as e:\n",
        "                    print(f\"Error fetching model info: {str(e)}\")\n",
        "            for key, value in model_info.__dict__.items():\n",
        "                    print(f\"{key}: {value}\")\n",
        "                    return model_info\n",
        "\n",
        "        else:\n",
        "            print(\"Invalid URL. Please enter a valid Hugging Face model URL.\") # error code\n",
        "\n",
        "# Call the function\n",
        "model_info = input_url()\n",
        "\n",
        "# To test: https://huggingface.co/deepseek-ai/DeepSeek-R1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Script 2\n",
        "Takes in a (validated) model and outputs the children models/fine-tunes"
      ],
      "metadata": {
        "id": "gOnHUAW23SNE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6petSSd-m2Qi"
      },
      "outputs": [],
      "source": [
        "# Script 2\n",
        "  # 1. Take link as input (format check). This is the \"main model\"\n",
        "  # 2. Give the link to the page with the fine-tunes for the inputted model\n",
        "\n",
        "from huggingface_hub import HfApi\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "\n",
        "# Initialize API\n",
        "api = HfApi()\n",
        "\n",
        "# Function to validate Hugging Face model URL\n",
        "def validate_hf_model_url(url):\n",
        "    pattern = r\"^https://huggingface.co/([\\w\\-]+)/([\\w\\-]+)$\"\n",
        "    match = re.match(pattern, url)\n",
        "    if match:\n",
        "        return match.groups()  # Returns (org/user, model_name)\n",
        "    return None\n",
        "\n",
        "# Function to find fine-tuned models\n",
        "def get_finetuned_models_page(model_org, model_name):\n",
        "    search_url = f\"https://huggingface.co/models?search={model_name}\"\n",
        "    response = requests.get(search_url)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "        model_links = [\n",
        "            a[\"href\"] for a in soup.find_all(\"a\", href=True)\n",
        "            if model_name.lower() in a[\"href\"].lower()\n",
        "        ]\n",
        "        return [f\"https://huggingface.co{link}\" for link in model_links if model_org not in link]\n",
        "\n",
        "    return []\n",
        "\n",
        "# Main execution\n",
        "model_url = input(\"Enter the Hugging Face model URL: \").strip()\n",
        "\n",
        "validated = validate_hf_model_url(model_url)\n",
        "if validated:\n",
        "    org, model_name = validated\n",
        "    finetune_links = get_finetuned_models_page(org, model_name)\n",
        "\n",
        "    if finetune_links:\n",
        "        print(\"Fine-tuned models found:\")\n",
        "        for link in finetune_links:\n",
        "            print(link)\n",
        "    else:\n",
        "        print(\"No fine-tuned models found for this model.\")\n",
        "else:\n",
        "    print(\"Invalid Hugging Face model URL format.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Script 3\n",
        "## Search steps overview\n",
        "- `dfs_finetunes` we take the `model_url` as input. Alternatively, we can add this var as an argument.\n",
        "- We go layer-by-layer and find the children of the current model (i.e. the fine-tunes of a model)\n",
        "- We call the `dfs_funetunes` function recursively and store the models that have been \"visited\" to avoid duplicates.\n",
        "- We have a dictionary of information that we store aboutthe \"current model\" and have the information stored in respective columns\n",
        "- We have a `results` list that has the information about all the models and their fine-tunes."
      ],
      "metadata": {
        "id": "ruI5-1FA1ipq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "Da_92M_Cgv1N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1834fa76-2c8b-4de8-b0e3-d8841ec07cca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the Hugging Face model URL: https://huggingface.co/NousResearch/DeepHermes-3-Mistral-24B-Preview \n",
            "\n",
            "Fetching metadata for: NousResearch/DeepHermes-3-Mistral-24B-Preview\n",
            "Found 4 fine-tunes at depth 0.\n",
            "\n",
            "  Fetching metadata for: Eonara/Resonant-Red\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "\n",
            "  Fetching metadata for: mlx-community/DeepHermes-3-Mistral-24B-Preview-bf16\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "\n",
            "  Fetching metadata for: Jarrodbarnes/DeepHermes-3-Mistral-24B-Preview-mlx-fp16\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "\n",
            "  Fetching metadata for: AlSamCur123/DeepHermes-3-Mistral-24BContinuedFine\n",
            "  Found 0 fine-tunes at depth 1.\n",
            "Results saved to 20250325_005631_DeepHermes-3-Mistral-24B-Preview_finetunes.json\n",
            "Results saved to 20250325_005631_DeepHermes-3-Mistral-24B-Preview_finetunes.csv\n"
          ]
        }
      ],
      "source": [
        "# Script 3\n",
        "import requests\n",
        "import datetime\n",
        "import json\n",
        "import csv\n",
        "from huggingface_hub import HfApi\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "\n",
        "# Initialize API\n",
        "api = HfApi()\n",
        "\n",
        "# Function to validate Hugging Face model URL\n",
        "def validate_hf_model_url(url):\n",
        "    pattern = r\"^https://huggingface.co/([\\w\\-]+)/([\\w\\-]+)$\"\n",
        "    match = re.match(pattern, url)\n",
        "    return match.groups() if match else None\n",
        "\n",
        "\n",
        "# Function to find fine-tuned models\n",
        "def get_finetuned_models_page(model_org, model_name):\n",
        "    search_url = f\"https://huggingface.co/models?other=base_model:finetune:{model_org}/{model_name}\"\n",
        "    response = requests.get(search_url)\n",
        "    if response.status_code == 200:\n",
        "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "        model_divs = soup.find_all(\"div\", class_=\"w-full truncate\")\n",
        "        model_links = []\n",
        "        for div in model_divs:\n",
        "            header = div.find(\"header\")\n",
        "            if header:\n",
        "                model_link = header.get(\"title\")\n",
        "                if model_link:\n",
        "                    model_links.append(f\"https://huggingface.co/{model_link}\")\n",
        "        return model_links\n",
        "    return []\n",
        "\n",
        "# Function to get parent model\n",
        "def get_parent_model(model_url):\n",
        "    return model_url.split(f\"/{model_name}/\")[0]\n",
        "\n",
        "# Recursive DFS (depth-first search) for finding fine-tunes\n",
        "def dfs_finetunes(model_url, visited, depth=0, results=None):\n",
        "       if results is None:\n",
        "           results = []\n",
        "\n",
        "       if model_url in visited:\n",
        "           return results\n",
        "       visited.add(model_url)\n",
        "\n",
        "       validated = validate_hf_model_url(model_url)\n",
        "       if not validated:\n",
        "           print(f\"Invalid URL skipped: {model_url}\")\n",
        "           model_url = \"N/A\"\n",
        "           return results\n",
        "\n",
        "       model_org, model_name = validated\n",
        "       model_id = f\"{model_org}/{model_name}\"\n",
        "\n",
        "       print(f\"\\n{'  ' * depth}Fetching metadata for: {model_id}\")\n",
        "       try:\n",
        "           model_metadata = api.model_info(model_id).__dict__\n",
        "           json_metadata = json.dumps(model_metadata, default=str)\n",
        "       except Exception as e:\n",
        "           print(f\"Error fetching metadata: {e}\")\n",
        "           return results\n",
        "\n",
        "       finetune_links = get_finetuned_models_page(model_org, model_name)\n",
        "       # Removing Duplicate Children\n",
        "       finetune_links = list(set(finetune_links))\n",
        "       print(f\"{'  ' * depth}Found {len(finetune_links)} fine-tunes at depth {depth}.\")\n",
        "\n",
        "       results.append({\n",
        "           \"model_id\": model_id,\n",
        "           \"metadata\": json_metadata,\n",
        "           \"depth\": depth,\n",
        "           \"children\": finetune_links,\n",
        "           \"children_count\": len(finetune_links)\n",
        "       })\n",
        "       for link in finetune_links:\n",
        "             dfs_finetunes(link, visited, depth + 1, results)\n",
        "\n",
        "       return results\n",
        "\n",
        "# Timestamp for the run\n",
        "timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "\n",
        "# Function to save results as JSON\n",
        "def save_json(results, model_name):\n",
        "    filename = f\"{timestamp}_{model_name}_finetunes.json\"\n",
        "    data = {\n",
        "        \"models\": results\n",
        "    }\n",
        "    with open(filename, \"w\") as f:\n",
        "        json.dump(data, f, indent=4, default=str)\n",
        "    print(f\"Results saved to {filename}\")\n",
        "\n",
        "# Function to save results as CSV\n",
        "def save_csv(results, model_name):\n",
        "    filename = f\"{model_org}_{model_name}_{timestamp}_finetunes.csv\"\n",
        "    with open(filename, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
        "        writer = csv.DictWriter(f, fieldnames=[\"model_id\", \"metadata\", \"depth\", \"children_count\", \"children\"])\n",
        "        writer.writeheader()\n",
        "        for entry in results:\n",
        "            # Ensure metadata is a JSON string\n",
        "            if isinstance(entry[\"metadata\"], dict):\n",
        "                entry[\"metadata\"] = json.dumps(entry[\"metadata\"], indent=2, default=str)\n",
        "            # Join children list as a string\n",
        "            entry[\"children\"] = \", \".join(entry[\"children\"])\n",
        "            writer.writerow(entry)\n",
        "    print(f\"Results saved to {filename}\")\n",
        "\n",
        "\n",
        "# Main execution\n",
        "if __name__ == \"__main__\":\n",
        "    model_url = input(\"Enter the Hugging Face model URL: \").strip()\n",
        "    visited = set()\n",
        "    results = dfs_finetunes(model_url, visited)\n",
        "\n",
        "    if results:\n",
        "        model_name = results[0][\"model_id\"].split(\"/\")[-1]  # Extract model name for file naming\n",
        "        save_json(results, model_name)\n",
        "        save_csv(results, model_name)\n",
        "    else:\n",
        "        print(\"No fine-tuned models found.\")\n",
        "\n",
        "# Links for testing: https://huggingface.co/NousResearch/DeepHermes-3-Mistral-24B-Preview (4 fine-tunes at depth 0, 0 fine-tunes at depth 1 (all models)), https://huggingface.co/perplexity-ai/r1-1776 (10 fine-tunes at depth 0, 0 fine-tines at depth 1 (all models))\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNagjdSZc07bGFwUu/ypiyf",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
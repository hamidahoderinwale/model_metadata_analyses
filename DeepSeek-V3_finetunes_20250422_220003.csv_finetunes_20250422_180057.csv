model_id,card,metadata,depth,children,children_count,adapters,adapters_count,quantized,quantized_count,merges,merges_count,spaces,spaces_count
deepseek-ai/DeepSeek-V3,"---
library_name: transformers
---
<!-- markdownlint-disable first-line-h1 -->
<!-- markdownlint-disable html -->
<!-- markdownlint-disable no-duplicate-header -->

<div align=""center"">
  <img src=""https://github.com/deepseek-ai/DeepSeek-V2/blob/main/figures/logo.svg?raw=true"" width=""60%"" alt=""DeepSeek-V3"" />
</div>
<hr>
<div align=""center"" style=""line-height: 1;"">
  <a href=""https://www.deepseek.com/"" target=""_blank"" style=""margin: 2px;"">
    <img alt=""Homepage"" src=""https://github.com/deepseek-ai/DeepSeek-V2/blob/main/figures/badge.svg?raw=true"" style=""display: inline-block; vertical-align: middle;""/>
  </a>
  <a href=""https://chat.deepseek.com/"" target=""_blank"" style=""margin: 2px;"">
    <img alt=""Chat"" src=""https://img.shields.io/badge/ü§ñ%20Chat-DeepSeek%20V3-536af5?color=536af5&logoColor=white"" style=""display: inline-block; vertical-align: middle;""/>
  </a>
  <a href=""https://huggingface.co/deepseek-ai"" target=""_blank"" style=""margin: 2px;"">
    <img alt=""Hugging Face"" src=""https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-DeepSeek%20AI-ffc107?color=ffc107&logoColor=white"" style=""display: inline-block; vertical-align: middle;""/>
  </a>
</div>

<div align=""center"" style=""line-height: 1;"">
  <a href=""https://discord.gg/Tc7c45Zzu5"" target=""_blank"" style=""margin: 2px;"">
    <img alt=""Discord"" src=""https://img.shields.io/badge/Discord-DeepSeek%20AI-7289da?logo=discord&logoColor=white&color=7289da"" style=""display: inline-block; vertical-align: middle;""/>
  </a>
  <a href=""https://github.com/deepseek-ai/DeepSeek-V2/blob/main/figures/qr.jpeg?raw=true"" target=""_blank"" style=""margin: 2px;"">
    <img alt=""Wechat"" src=""https://img.shields.io/badge/WeChat-DeepSeek%20AI-brightgreen?logo=wechat&logoColor=white"" style=""display: inline-block; vertical-align: middle;""/>
  </a>
  <a href=""https://twitter.com/deepseek_ai"" target=""_blank"" style=""margin: 2px;"">
    <img alt=""Twitter Follow"" src=""https://img.shields.io/badge/Twitter-deepseek_ai-white?logo=x&logoColor=white"" style=""display: inline-block; vertical-align: middle;""/>
  </a>
</div>

<div align=""center"" style=""line-height: 1;"">
  <a href=""https://github.com/deepseek-ai/DeepSeek-V3/blob/main/LICENSE-CODE"" style=""margin: 2px;"">
    <img alt=""Code License"" src=""https://img.shields.io/badge/Code_License-MIT-f5de53?&color=f5de53"" style=""display: inline-block; vertical-align: middle;""/>
  </a>
  <a href=""https://github.com/deepseek-ai/DeepSeek-V3/blob/main/LICENSE-MODEL"" style=""margin: 2px;"">
    <img alt=""Model License"" src=""https://img.shields.io/badge/Model_License-Model_Agreement-f5de53?&color=f5de53"" style=""display: inline-block; vertical-align: middle;""/>
  </a>
</div>


<p align=""center"">
  <a href=""https://github.com/deepseek-ai/DeepSeek-V3/blob/main/DeepSeek_V3.pdf""><b>Paper Link</b>üëÅÔ∏è</a>
</p>


## 1. Introduction

We present DeepSeek-V3, a strong Mixture-of-Experts (MoE) language model with 671B total parameters with 37B activated for each token. 
To achieve efficient inference and cost-effective training, DeepSeek-V3 adopts Multi-head Latent Attention (MLA) and DeepSeekMoE architectures, which were thoroughly validated in DeepSeek-V2. 
Furthermore, DeepSeek-V3 pioneers an auxiliary-loss-free strategy for load balancing and sets a multi-token prediction training objective for stronger performance. 
We pre-train DeepSeek-V3 on 14.8 trillion diverse and high-quality tokens, followed by Supervised Fine-Tuning and Reinforcement Learning stages to fully harness its capabilities. 
Comprehensive evaluations reveal that DeepSeek-V3 outperforms other open-source models and achieves performance comparable to leading closed-source models.
Despite its excellent performance, DeepSeek-V3 requires only 2.788M H800 GPU hours for its full training.
In addition, its training process is remarkably stable. 
Throughout the entire training process, we did not experience any irrecoverable loss spikes or perform any rollbacks. 
<p align=""center"">
  <img width=""80%"" src=""figures/benchmark.png"">
</p>

## 2. Model Summary

---

**Architecture: Innovative Load Balancing Strategy and Training Objective**

- On top of the efficient architecture of DeepSeek-V2, we pioneer an auxiliary-loss-free strategy for load balancing, which minimizes the performance degradation that arises from encouraging load balancing.
-  We investigate a Multi-Token Prediction (MTP) objective and prove it beneficial to model performance. 
    It can also be used for speculative decoding for inference acceleration. 

---

**Pre-Training: Towards Ultimate Training Efficiency**

- We design an FP8 mixed precision training framework and, for the first time, validate the feasibility and effectiveness of FP8 training on an extremely large-scale model.  
- Through co-design of algorithms, frameworks, and hardware, we overcome the communication bottleneck in cross-node MoE training, nearly achieving full computation-communication overlap.  
  This significantly enhances our training efficiency and reduces the training costs, enabling us to further scale up the model size without additional overhead.  
- At an economical cost of only 2.664M H800 GPU hours, we complete the pre-training of DeepSeek-V3 on 14.8T tokens, producing the currently strongest open-source base model. The subsequent training stages after pre-training require only 0.1M GPU hours.

---

**Post-Training: Knowledge Distillation from DeepSeek-R1**

-   We introduce an innovative methodology to distill reasoning capabilities from the long-Chain-of-Thought (CoT) model, specifically from one of the DeepSeek R1 series models, into standard LLMs, particularly DeepSeek-V3. Our pipeline elegantly incorporates the verification and reflection patterns of R1 into DeepSeek-V3 and notably improves its reasoning performance. Meanwhile, we also maintain a control over the output style and length of DeepSeek-V3.

---


## 3. Model Downloads

<div align=""center"">

| **Model** | **#Total Params** | **#Activated Params** | **Context Length** | **Download** |
| :------------: | :------------: | :------------: | :------------: | :------------: |
| DeepSeek-V3-Base | 671B | 37B | 128K   | [ü§ó HuggingFace](https://huggingface.co/deepseek-ai/DeepSeek-V3-Base)   |
| DeepSeek-V3   | 671B | 37B |  128K   | [ü§ó HuggingFace](https://huggingface.co/deepseek-ai/DeepSeek-V3)   |

</div>

**NOTE: The total size of DeepSeek-V3 models on HuggingFace is 685B, which includes 671B of the Main Model weights and 14B of the Multi-Token Prediction (MTP) Module weights.**

To ensure optimal performance and flexibility, we have partnered with open-source communities and hardware vendors to provide multiple ways to run the model locally. For step-by-step guidance, check out Section 6: [How_to Run_Locally](#6-how-to-run-locally).

For developers looking to dive deeper, we recommend exploring [README_WEIGHTS.md](./README_WEIGHTS.md) for details on the Main Model weights and the Multi-Token Prediction (MTP) Modules. Please note that MTP support is currently under active development within the community, and we welcome your contributions and feedback.

## 4. Evaluation Results
### Base Model
#### Standard Benchmarks

<div align=""center"">


|  | Benchmark (Metric) | # Shots | DeepSeek-V2 | Qwen2.5 72B | LLaMA3.1 405B | DeepSeek-V3 |
|---|-------------------|----------|--------|-------------|---------------|---------|
| | Architecture | - | MoE | Dense | Dense | MoE |
| | # Activated Params | - | 21B | 72B | 405B | 37B |
| | # Total Params | - | 236B | 72B | 405B | 671B |
| English | Pile-test (BPB) | - | 0.606 | 0.638 | **0.542** | 0.548 |
| | BBH (EM) | 3-shot | 78.8 | 79.8 | 82.9 | **87.5** |
| | MMLU (Acc.) | 5-shot | 78.4 | 85.0 | 84.4 | **87.1** |
| | MMLU-Redux (Acc.) | 5-shot | 75.6 | 83.2 | 81.3 | **86.2** |
| | MMLU-Pro (Acc.) | 5-shot | 51.4 | 58.3 | 52.8 | **64.4** |
| | DROP (F1) | 3-shot | 80.4 | 80.6 | 86.0 | **89.0** |
| | ARC-Easy (Acc.) | 25-shot | 97.6 | 98.4 | 98.4 | **98.9** |
| | ARC-Challenge (Acc.) | 25-shot | 92.2 | 94.5 | **95.3** | **95.3** |
| | HellaSwag (Acc.) | 10-shot | 87.1 | 84.8 | **89.2** | 88.9 |
| | PIQA (Acc.) | 0-shot | 83.9 | 82.6 | **85.9** | 84.7 |
| | WinoGrande (Acc.) | 5-shot | **86.3** | 82.3 | 85.2 | 84.9 |
| | RACE-Middle (Acc.) | 5-shot | 73.1 | 68.1 | **74.2** | 67.1 |
| | RACE-High (Acc.) | 5-shot | 52.6 | 50.3 | **56.8** | 51.3 |
| | TriviaQA (EM) | 5-shot | 80.0 | 71.9 | **82.7** | **82.9** |
| | NaturalQuestions (EM) | 5-shot | 38.6 | 33.2 | **41.5** | 40.0 |
| | AGIEval (Acc.) | 0-shot | 57.5 | 75.8 | 60.6 | **79.6** |
| Code | HumanEval (Pass@1) | 0-shot | 43.3 | 53.0 | 54.9 | **65.2** |
| | MBPP (Pass@1) | 3-shot | 65.0 | 72.6 | 68.4 | **75.4** |
| | LiveCodeBench-Base (Pass@1) | 3-shot | 11.6 | 12.9 | 15.5 | **19.4** |
| | CRUXEval-I (Acc.) | 2-shot | 52.5 | 59.1 | 58.5 | **67.3** |
| | CRUXEval-O (Acc.) | 2-shot | 49.8 | 59.9 | 59.9 | **69.8** |
| Math | GSM8K (EM) | 8-shot | 81.6 | 88.3 | 83.5 | **89.3** |
| | MATH (EM) | 4-shot | 43.4 | 54.4 | 49.0 | **61.6** |
| | MGSM (EM) | 8-shot | 63.6 | 76.2 | 69.9 | **79.8** |
| | CMath (EM) | 3-shot | 78.7 | 84.5 | 77.3 | **90.7** |
| Chinese | CLUEWSC (EM) | 5-shot | 82.0 | 82.5 | **83.0** | 82.7 |
| | C-Eval (Acc.) | 5-shot | 81.4 | 89.2 | 72.5 | **90.1** |
| | CMMLU (Acc.) | 5-shot | 84.0 | **89.5** | 73.7 | 88.8 |
| | CMRC (EM) | 1-shot | **77.4** | 75.8 | 76.0 | 76.3 |
| | C3 (Acc.) | 0-shot | 77.4 | 76.7 | **79.7** | 78.6 |
| | CCPM (Acc.) | 0-shot | **93.0** | 88.5 | 78.6 | 92.0 |
| Multilingual | MMMLU-non-English (Acc.) | 5-shot | 64.0 | 74.8 | 73.8 | **79.4** |

</div>

Note: Best results are shown in bold. Scores with a gap not exceeding 0.3 are considered to be at the same level. DeepSeek-V3 achieves the best performance on most benchmarks, especially on math and code tasks.
For more evaluation details, please check our paper. 

#### Context Window
<p align=""center"">
  <img width=""80%"" src=""figures/niah.png"">
</p>

Evaluation results on the ``Needle In A Haystack`` (NIAH) tests.  DeepSeek-V3 performs well across all context window lengths up to **128K**. 

### Chat Model
#### Standard Benchmarks (Models larger than 67B)
<div align=""center"">

| | **Benchmark (Metric)** | **DeepSeek V2-0506** | **DeepSeek V2.5-0905** | **Qwen2.5 72B-Inst.** | **Llama3.1 405B-Inst.** | **Claude-3.5-Sonnet-1022** | **GPT-4o 0513** | **DeepSeek V3** |
|---|---------------------|---------------------|----------------------|---------------------|----------------------|---------------------------|----------------|----------------|
| | Architecture | MoE | MoE | Dense | Dense | - | - | MoE |
| | # Activated Params | 21B | 21B | 72B | 405B | - | - | 37B |
| | # Total Params | 236B | 236B | 72B | 405B | - | - | 671B |
| English | MMLU (EM) | 78.2 | 80.6 | 85.3 | **88.6** | **88.3** | 87.2 | **88.5** |
| | MMLU-Redux (EM) | 77.9 | 80.3 | 85.6 | 86.2 | **88.9** | 88.0 | **89.1** |
| | MMLU-Pro (EM) | 58.5 | 66.2 | 71.6 | 73.3 | **78.0** | 72.6 | 75.9 |
| | DROP (3-shot F1) | 83.0 | 87.8 | 76.7 | 88.7 | 88.3 | 83.7 | **91.6** |
| | IF-Eval (Prompt Strict) | 57.7 | 80.6 | 84.1 | 86.0 | **86.5** | 84.3 | 86.1 |
| | GPQA-Diamond (Pass@1) | 35.3 | 41.3 | 49.0 | 51.1 | **65.0** | 49.9 | 59.1 |
| | SimpleQA (Correct) | 9.0 | 10.2 | 9.1 | 17.1 | 28.4 | **38.2** | 24.9 |
| | FRAMES (Acc.) | 66.9 | 65.4 | 69.8 | 70.0 | 72.5 | **80.5** | 73.3 |
| | LongBench v2 (Acc.) | 31.6 | 35.4 | 39.4 | 36.1 | 41.0 | 48.1 | **48.7** |
| Code | HumanEval-Mul (Pass@1) | 69.3 | 77.4 | 77.3 | 77.2 | 81.7 | 80.5 | **82.6** |
| | LiveCodeBench (Pass@1-COT) | 18.8 | 29.2 | 31.1 | 28.4 | 36.3 | 33.4 | **40.5** |
| | LiveCodeBench (Pass@1) | 20.3 | 28.4 | 28.7 | 30.1 | 32.8 | 34.2 | **37.6** |
| | Codeforces (Percentile) | 17.5 | 35.6 | 24.8 | 25.3 | 20.3 | 23.6 | **51.6** |
| | SWE Verified (Resolved) | - | 22.6 | 23.8 | 24.5 | **50.8** | 38.8 | 42.0 |
| | Aider-Edit (Acc.) | 60.3 | 71.6 | 65.4 | 63.9 | **84.2** | 72.9 | 79.7 |
| | Aider-Polyglot (Acc.) | - | 18.2 | 7.6 | 5.8 | 45.3 | 16.0 | **49.6** |
| Math | AIME 2024 (Pass@1) | 4.6 | 16.7 | 23.3 | 23.3 | 16.0 | 9.3 | **39.2** |
| | MATH-500 (EM) | 56.3 | 74.7 | 80.0 | 73.8 | 78.3 | 74.6 | **90.2** |
| | CNMO 2024 (Pass@1) | 2.8 | 10.8 | 15.9 | 6.8 | 13.1 | 10.8 | **43.2** |
| Chinese | CLUEWSC (EM) | 89.9 | 90.4 | **91.4** | 84.7 | 85.4 | 87.9 | 90.9 |
| | C-Eval (EM) | 78.6 | 79.5 | 86.1 | 61.5 | 76.7 | 76.0 | **86.5** |
| | C-SimpleQA (Correct) | 48.5 | 54.1 | 48.4 | 50.4 | 51.3 | 59.3 | **64.8** |

Note: All models are evaluated in a configuration that limits the output length to 8K. Benchmarks containing fewer than 1000 samples are tested multiple times using varying temperature settings to derive robust final results. DeepSeek-V3 stands as the best-performing open-source model, and also exhibits competitive performance against frontier closed-source models.

</div>


####  Open Ended Generation Evaluation

<div align=""center"">



| Model | Arena-Hard | AlpacaEval 2.0 |
|-------|------------|----------------|
| DeepSeek-V2.5-0905 | 76.2 | 50.5 |
| Qwen2.5-72B-Instruct | 81.2 | 49.1 |
| LLaMA-3.1 405B | 69.3 | 40.5 |
| GPT-4o-0513 | 80.4 | 51.1 |
| Claude-Sonnet-3.5-1022 | 85.2 | 52.0 |
| DeepSeek-V3 | **85.5** | **70.0** |

Note: English open-ended conversation evaluations. For AlpacaEval 2.0, we use the length-controlled win rate as the metric.
</div>


## 5. Chat Website & API Platform
You can chat with DeepSeek-V3 on DeepSeek's official website: [chat.deepseek.com](https://chat.deepseek.com/sign_in)

We also provide OpenAI-Compatible API at DeepSeek Platform: [platform.deepseek.com](https://platform.deepseek.com/)

## 6. How to Run Locally

DeepSeek-V3 can be deployed locally using the following hardware and open-source community software:

1. **DeepSeek-Infer Demo**: We provide a simple and lightweight demo for FP8 and BF16 inference.
2. **SGLang**: Fully support the DeepSeek-V3 model in both BF16 and FP8 inference modes.
3. **LMDeploy**: Enables efficient FP8 and BF16 inference for local and cloud deployment.
4. **TensorRT-LLM**: Currently supports BF16 inference and INT4/8 quantization, with FP8 support coming soon.
5. **vLLM**: Support DeekSeek-V3 model with FP8 and BF16 modes for tensor parallelism and pipeline parallelism.
6. **AMD GPU**: Enables running the DeepSeek-V3 model on AMD GPUs via SGLang in both BF16 and FP8 modes.
7. **Huawei Ascend NPU**: Supports running DeepSeek-V3 on Huawei Ascend devices.

Since FP8 training is natively adopted in our framework, we only provide FP8 weights. If you require BF16 weights for experimentation, you can use the provided conversion script to perform the transformation.

Here is an example of converting FP8 weights to BF16:

```shell
cd inference
python fp8_cast_bf16.py --input-fp8-hf-path /path/to/fp8_weights --output-bf16-hf-path /path/to/bf16_weights
```

**NOTE: Huggingface's Transformers has not been directly supported yet.**

### 6.1 Inference with DeepSeek-Infer Demo (example only)

#### Model Weights & Demo Code Preparation

First, clone our DeepSeek-V3 GitHub repository:

```shell
git clone https://github.com/deepseek-ai/DeepSeek-V3.git
```

Navigate to the `inference` folder and install dependencies listed in `requirements.txt`.

```shell
cd DeepSeek-V3/inference
pip install -r requirements.txt
```

Download the model weights from HuggingFace, and put them into `/path/to/DeepSeek-V3` folder.

#### Model Weights Conversion

Convert HuggingFace model weights to a specific format:

```shell
python convert.py --hf-ckpt-path /path/to/DeepSeek-V3 --save-path /path/to/DeepSeek-V3-Demo --n-experts 256 --model-parallel 16
```

#### Run

Then you can chat with DeepSeek-V3:

```shell
torchrun --nnodes 2 --nproc-per-node 8 generate.py --node-rank $RANK --master-addr $ADDR --ckpt-path /path/to/DeepSeek-V3-Demo --config configs/config_671B.json --interactive --temperature 0.7 --max-new-tokens 200
```

Or batch inference on a given file:

```shell
torchrun --nnodes 2 --nproc-per-node 8 generate.py --node-rank $RANK --master-addr $ADDR --ckpt-path /path/to/DeepSeek-V3-Demo --config configs/config_671B.json --input-file $FILE
```

### 6.2 Inference with SGLang (recommended)

[SGLang](https://github.com/sgl-project/sglang) currently supports MLA optimizations, FP8 (W8A8), FP8 KV Cache, and Torch Compile, delivering state-of-the-art latency and throughput performance among open-source frameworks.

Notably, [SGLang v0.4.1](https://github.com/sgl-project/sglang/releases/tag/v0.4.1) fully supports running DeepSeek-V3 on both **NVIDIA and AMD GPUs**, making it a highly versatile and robust solution.

Here are the launch instructions from the SGLang team: https://github.com/sgl-project/sglang/tree/main/benchmark/deepseek_v3

### 6.3 Inference with LMDeploy (recommended)
[LMDeploy](https://github.com/InternLM/lmdeploy), a flexible and high-performance inference and serving framework tailored for large language models, now supports DeepSeek-V3. It offers both offline pipeline processing and online deployment capabilities, seamlessly integrating with PyTorch-based workflows.

For comprehensive step-by-step instructions on running DeepSeek-V3 with LMDeploy, please refer to here: https://github.com/InternLM/lmdeploy/issues/2960


### 6.4 Inference with TRT-LLM (recommended)

[TensorRT-LLM](https://github.com/NVIDIA/TensorRT-LLM) now supports the DeepSeek-V3 model, offering precision options such as BF16 and INT4/INT8 weight-only. Support for FP8 is currently in progress and will be released soon. You can access the custom branch of TRTLLM specifically for DeepSeek-V3 support through the following link to experience the new features directly: https://github.com/NVIDIA/TensorRT-LLM/tree/deepseek/examples/deepseek_v3. 

### 6.5 Inference with vLLM (recommended)

[vLLM](https://github.com/vllm-project/vllm) v0.6.6 supports DeepSeek-V3 inference for FP8 and BF16 modes on both NVIDIA and AMD GPUs. Aside from standard techniques, vLLM offers _pipeline parallelism_ allowing you to run this model on multiple machines connected by networks. For detailed guidance, please refer to the [vLLM instructions](https://docs.vllm.ai/en/latest/serving/distributed_serving.html). Please feel free to follow [the enhancement plan](https://github.com/vllm-project/vllm/issues/11539) as well.

### 6.6 Recommended Inference Functionality with AMD GPUs

In collaboration with the AMD team, we have achieved Day-One support for AMD GPUs using SGLang, with full compatibility for both FP8 and BF16 precision. For detailed guidance, please refer to the [SGLang instructions](#63-inference-with-lmdeploy-recommended).

### 6.7 Recommended Inference Functionality with Huawei Ascend NPUs
The [MindIE](https://www.hiascend.com/en/software/mindie) framework from the Huawei Ascend community has successfully adapted the BF16 version of DeepSeek-V3. For step-by-step guidance on Ascend NPUs, please follow the [instructions here](https://modelers.cn/models/MindIE/deepseekv3).


## 7. License
This code repository is licensed under [the MIT License](LICENSE-CODE). The use of DeepSeek-V3 Base/Chat models is subject to [the Model License](LICENSE-MODEL). DeepSeek-V3 series (including Base and Chat) supports commercial use.

## 8. Citation
```
@misc{deepseekai2024deepseekv3technicalreport,
      title={DeepSeek-V3 Technical Report}, 
      author={DeepSeek-AI},
      year={2024},
      eprint={2412.19437},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2412.19437}, 
}
```

## 9. Contact
If you have any questions, please raise an issue or contact us at [service@deepseek.com](service@deepseek.com).","{""id"": ""deepseek-ai/DeepSeek-V3"", ""author"": ""deepseek-ai"", ""sha"": ""e815299b0bcbac849fa540c768ef21845365c9eb"", ""last_modified"": ""2025-03-27 04:01:45+00:00"", ""created_at"": ""2024-12-25 12:52:23+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 775641, ""downloads_all_time"": null, ""likes"": 3815, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": ""warm"", ""tags"": [""transformers"", ""safetensors"", ""deepseek_v3"", ""text-generation"", ""conversational"", ""custom_code"", ""arxiv:2412.19437"", ""autotrain_compatible"", ""endpoints_compatible"", ""fp8"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""library_name: transformers"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""DeepseekV3ForCausalLM""], ""auto_map"": {""AutoConfig"": ""configuration_deepseek.DeepseekV3Config"", ""AutoModel"": ""modeling_deepseek.DeepseekV3Model"", ""AutoModelForCausalLM"": ""modeling_deepseek.DeepseekV3ForCausalLM""}, ""model_type"": ""deepseek_v3"", ""quantization_config"": {""quant_method"": ""fp8""}, ""tokenizer_config"": {""bos_token"": {""__type"": ""AddedToken"", ""content"": ""<\uff5cbegin\u2581of\u2581sentence\uff5c>"", ""lstrip"": false, ""normalized"": true, ""rstrip"": false, ""single_word"": false}, ""eos_token"": {""__type"": ""AddedToken"", ""content"": ""<\uff5cend\u2581of\u2581sentence\uff5c>"", ""lstrip"": false, ""normalized"": true, ""rstrip"": false, ""single_word"": false}, ""pad_token"": {""__type"": ""AddedToken"", ""content"": ""<\uff5cend\u2581of\u2581sentence\uff5c>"", ""lstrip"": false, ""normalized"": true, ""rstrip"": false, ""single_word"": false}, ""unk_token"": null, ""chat_template"": ""{% if not add_generation_prompt is defined %}{% set add_generation_prompt = false %}{% endif %}{% set ns = namespace(is_first=false, is_tool=false, is_output_first=true, system_prompt='', is_first_sp=true) %}{%- for message in messages %}{%- if message['role'] == 'system' %}{%- if ns.is_first_sp %}{% set ns.system_prompt = ns.system_prompt + message['content'] %}{% set ns.is_first_sp = false %}{%- else %}{% set ns.system_prompt = ns.system_prompt + '\n\n' + message['content'] %}{%- endif %}{%- endif %}{%- endfor %}{{bos_token}}{{ns.system_prompt}}{%- for message in messages %}{%- if message['role'] == 'user' %}{%- set ns.is_tool = false -%}{{'<\uff5cUser\uff5c>' + message['content']}}{%- endif %}{%- if message['role'] == 'assistant' and message['content'] is none %}{%- set ns.is_tool = false -%}{%- for tool in message['tool_calls']%}{%- if not ns.is_first %}{{'<\uff5cAssistant\uff5c><\uff5ctool\u2581calls\u2581begin\uff5c><\uff5ctool\u2581call\u2581begin\uff5c>' + tool['type'] + '<\uff5ctool\u2581sep\uff5c>' + tool['function']['name'] + '\n' + '```json' + '\n' + tool['function']['arguments'] + '\n' + '```' + '<\uff5ctool\u2581call\u2581end\uff5c>'}}{%- set ns.is_first = true -%}{%- else %}{{'\n' + '<\uff5ctool\u2581call\u2581begin\uff5c>' + tool['type'] + '<\uff5ctool\u2581sep\uff5c>' + tool['function']['name'] + '\n' + '```json' + '\n' + tool['function']['arguments'] + '\n' + '```' + '<\uff5ctool\u2581call\u2581end\uff5c>'}}{{'<\uff5ctool\u2581calls\u2581end\uff5c><\uff5cend\u2581of\u2581sentence\uff5c>'}}{%- endif %}{%- endfor %}{%- endif %}{%- if message['role'] == 'assistant' and message['content'] is not none %}{%- if ns.is_tool %}{{'<\uff5ctool\u2581outputs\u2581end\uff5c>' + message['content'] + '<\uff5cend\u2581of\u2581sentence\uff5c>'}}{%- set ns.is_tool = false -%}{%- else %}{{'<\uff5cAssistant\uff5c>' + message['content'] + '<\uff5cend\u2581of\u2581sentence\uff5c>'}}{%- endif %}{%- endif %}{%- if message['role'] == 'tool' %}{%- set ns.is_tool = true -%}{%- if ns.is_output_first %}{{'<\uff5ctool\u2581outputs\u2581begin\uff5c><\uff5ctool\u2581output\u2581begin\uff5c>' + message['content'] + '<\uff5ctool\u2581output\u2581end\uff5c>'}}{%- set ns.is_output_first = false %}{%- else %}{{'\n<\uff5ctool\u2581output\u2581begin\uff5c>' + message['content'] + '<\uff5ctool\u2581output\u2581end\uff5c>'}}{%- endif %}{%- endif %}{%- endfor -%}{% if ns.is_tool %}{{'<\uff5ctool\u2581outputs\u2581end\uff5c>'}}{% endif %}{% if add_generation_prompt and not ns.is_tool %}{{'<\uff5cAssistant\uff5c>'}}{% endif %}""}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='LICENSE-CODE', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='LICENSE-MODEL', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README_WEIGHTS.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='configuration_deepseek.py', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='figures/benchmark.png', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='figures/niah.png', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='inference/configs/config_16B.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='inference/configs/config_236B.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='inference/configs/config_671B.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='inference/convert.py', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='inference/fp8_cast_bf16.py', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='inference/generate.py', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='inference/kernel.py', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='inference/model.py', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='inference/requirements.txt', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00001-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00002-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00003-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00004-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00005-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00006-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00007-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00008-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00009-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00010-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00011-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00012-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00013-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00014-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00015-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00016-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00017-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00018-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00019-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00020-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00021-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00022-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00023-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00024-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00025-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00026-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00027-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00028-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00029-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00030-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00031-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00032-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00033-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00034-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00035-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00036-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00037-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00038-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00039-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00040-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00041-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00042-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00043-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00044-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00045-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00046-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00047-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00048-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00049-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00050-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00051-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00052-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00053-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00054-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00055-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00056-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00057-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00058-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00059-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00060-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00061-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00062-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00063-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00064-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00065-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00066-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00067-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00068-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00069-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00070-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00071-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00072-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00073-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00074-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00075-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00076-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00077-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00078-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00079-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00080-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00081-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00082-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00083-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00084-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00085-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00086-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00087-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00088-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00089-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00090-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00091-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00092-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00093-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00094-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00095-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00096-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00097-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00098-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00099-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00100-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00101-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00102-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00103-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00104-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00105-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00106-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00107-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00108-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00109-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00110-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00111-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00112-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00113-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00114-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00115-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00116-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00117-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00118-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00119-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00120-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00121-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00122-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00123-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00124-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00125-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00126-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00127-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00128-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00129-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00130-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00131-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00132-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00133-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00134-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00135-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00136-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00137-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00138-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00139-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00140-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00141-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00142-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00143-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00144-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00145-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00146-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00147-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00148-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00149-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00150-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00151-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00152-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00153-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00154-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00155-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00156-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00157-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00158-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00159-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00160-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00161-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00162-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00163-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model.safetensors.index.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='modeling_deepseek.py', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)""], ""spaces"": [""blanchon/HiDream-ai-full"", ""blanchon/HiDream-ai-fast"", ""KBaba7/Quant"", ""blanchon/HiDream-ai-dev"", ""Akshayram1/data_visualization_ai_excel_togetherai_e2b"", ""ZongqianLi/ReasonGraph"", ""AtlaAI/LLMsOnTrial"", ""awacke1/Deepseek-HPC-GPU-KEDA"", ""bhaskartripathi/LLM_Quantization"", ""totolook/Quant"", ""FallnAI/Quantize-HF-Models"", ""FiditeNemini/HiDream-ai-full"", ""hertogateis/deepseekchat"", ""Omer-wahid/deepseek-ai-DeepSeek-V3"", ""Orion-zhen/tokenize-it"", ""Faheemalvi/LLaMa"", ""thanhkt/text2manim"", ""ruslanmv/convert_to_gguf"", ""TejAndrewsACC/Chatwithdeepaccseeker"", ""Steven10429/apply_lora_and_quantize"", ""RoMan-dev/DeepSeek_API"", ""readomni/literate"", ""Proximile/email-formatter"", ""Lolripper/deepseek-ai-DeepSeek-V3"", ""Hyunseung/StuStra"", ""zhwang4ai/GenerativeReasoningBenchmark"", ""EricGEGE/AskEric"", ""hotdeem/mp3"", ""RakeshUtekar/Test"", ""datenlabor-bmz/ai-language-monitor"", ""shaktibiplab/deepseekv3"", ""sapthesh/deepseekv3"", ""Heuehneje/new-space"", ""failtowin/new-space"", ""Sujatha/DreamWeaver-AI"", ""topgunqqqqqqq/new-spaceqqq"", ""hertogateis/SmallBot"", ""SunDay-s/NelzGPT-A1"", ""Muntadher-Saleh/deepseek"", ""edgar222/V3"", ""Ak28Akhil/rag-webapp"", ""Tharindu1527/Gradio_space"", ""broadfield-dev/DeepSeek_LLM"", ""TejAndrewsACC/PhilosPLUS"", ""TejAndrewsACC/Powerfulagi"", ""leoneserwr/new-space"", ""Akshayram1/data_visualization_ai_excel_togetherai_e2b2"", ""anton2014/catyAI4"", ""anton2014/caty_ai5"", ""kuyesu22/deepseek-v3-test"", ""bc238dev/new-space"", ""suhanitatiya12/tally4"", ""Vejendla/mech-eng-chatbot"", ""cnmksjs/deepseek-v3-91413943194319431943"", ""Dakshith/sadlife"", ""JeCabrera/deepseekchat"", ""parixit8985/kids-story-generator"", ""BotifyCloud/general-chat"", ""oZoon/metal"", ""deelf/deelf"", ""prolapse/r1"", ""Creep7p/AI-VANAv1.0"", ""FapMaster69/r1"", ""Proximile/ChatInterface"", ""xxxOVALxxx/r1"", ""kavindu001/rust-expert"", ""Aurum79/deepseek-ai-DeepSeek-V3"", ""YZ-TAN/flask-llama"", ""SmartFlowAI/DeepSeek-MindSearch"", ""Pamudu13/deepseek-api"", ""KBaba7/llama.cpp"", ""ahmetbugra/portfolio_mi"", ""deelf/DVchatbot"", ""gbv/First_agent_template"", ""Sharan1712/PitchPerfect"", ""ved-idrive/idrive_support_deepseek"", ""Erik/First_agent_template"", ""taylorcmq/mistrall"", ""Gopikanth123/deepseek_voice"", ""hpal007/First_agent-hpal007"", ""kawhi706/deepseek-ai-DeepSeek-V3"", ""RyuChangX/deepseek-ai-DeepSeek-V3"", ""Pelicans/deepseek-ai-DeepSeek-V3"", ""galihrhgnwn/deepseek-ai-DeepSeek-V3"", ""Dewza/deepseek-ai-DeepSeek-V3"", ""olbacha/deepseek-ai-DeepSeek-V3"", ""AkenoBaby/deepseek-ai-DeepSeek-V3"", ""gsam21359/deepseek-ai-DeepSeek-V3"", ""NDCUTI/DSV3"", ""wantongkeji/deepseek-ai-DeepSeek-V3"", ""nwent/deepseek-ai-DeepSeek-V3"", ""zrogers0512/deepseek-ai-DeepSeek-V3"", ""WenSama/deepseek-ai-DeepSeek-V3"", ""efeerdogmus0/deepseek-ai-DeepSeek-V3"", ""xbbd/deepseek-ai-DeepSeek-V3"", ""pedroHNFC/deepseek-ai-DeepSeek-V3"", ""BaRiDo/TheComedyCache"", ""ClaretDevigne/ClaretAI"", ""inoculatemedia/deepseek-ai-DeepSeek-V3"", ""Albi96/deepseek-ai-DeepSeek-V3""], ""safetensors"": {""parameters"": {""BF16"": 3918786560, ""F8_E4M3"": 680571043840, ""F32"": 41555600}, ""total"": 684531386000}, ""security_repo_status"": null, ""lastModified"": ""2025-03-27 04:01:45+00:00"", ""cardData"": ""library_name: transformers"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""676c000762cee1f3abc3ed5f"", ""modelId"": ""deepseek-ai/DeepSeek-V3"", ""usedStorage"": 688727648088}",0,"https://huggingface.co/huihui-ai/DeepSeek-V3-abliterated, https://huggingface.co/opensourcerelease/DeepSeek-V3-bf16, https://huggingface.co/inarikami/DeepSeek-V3-int4-TensorRT, https://huggingface.co/v2ray/DeepSeek-V3-1B-Test, https://huggingface.co/mmnga/DeepSeek-V3-slice-jp64, https://huggingface.co/mradermacher/DeepSeek-V3-GGUF, https://huggingface.co/mradermacher/DeepSeek-V3-i1-GGUF, https://huggingface.co/alexleyai/diabetesdiagnosis, https://huggingface.co/Fourdoor/Alex-gpt, https://huggingface.co/franb23/tarot, https://huggingface.co/huihui-ai/DeepSeek-V3-bf16, https://huggingface.co/OpenC/HEFT-Qwen, https://huggingface.co/huihui-ai/DeepSeek-V3-Pruned-Coder-411B, https://huggingface.co/SicariusSicariiStuff/DeepSeek-V3-Abliterated, https://huggingface.co/Stebo777/K1NGD0M_A1, https://huggingface.co/rikiwi/AveneR, https://huggingface.co/anoher/deepseek, https://huggingface.co/v2ray/DeepSeek-V3-FP16-Atten-NaN, https://huggingface.co/Joses1234/pruebabot, https://huggingface.co/DanielVNZ/startrader, https://huggingface.co/digiwin/database, https://huggingface.co/yasvand/natasha, https://huggingface.co/samircd4/test, https://huggingface.co/mrmhmdalyady/WWE, https://huggingface.co/vvffk/chatbot1.0, https://huggingface.co/Daad16/1, https://huggingface.co/Hassan98777/Rania, https://huggingface.co/xptry/mal, https://huggingface.co/dhe1raj/spiritgpt, https://huggingface.co/slimjimmy420k/stoner, https://huggingface.co/alex-28/quickanalyze, https://huggingface.co/R87/cenario, https://huggingface.co/LevinKI/Test_KI, https://huggingface.co/alisaadnoor2/Ali, https://huggingface.co/hs-up/kso-v1-finetuned, https://huggingface.co/Igbodevictor/Igbodevictor, https://huggingface.co/Mattze2711/Matthi75, https://huggingface.co/mesrikanthreddy/repo_name, https://huggingface.co/Marci353524/Chating, https://huggingface.co/ATTLAB/quantumaurora, https://huggingface.co/Muhamad2020/Muh, https://huggingface.co/tttom3669/img, https://huggingface.co/Amblem/novaa, https://huggingface.co/Arcturus63/Jerry, https://huggingface.co/adel67460/straburo-model, https://huggingface.co/southsyde/4thgen, https://huggingface.co/eeevaw/aa, https://huggingface.co/creativ3lab/expertcoder, https://huggingface.co/efecans/soru, https://huggingface.co/CarteLorcana/Lorcana, https://huggingface.co/Byterbrodov/Byter, https://huggingface.co/n1m45/n1m4, https://huggingface.co/Geowg/my-first-chatbot, https://huggingface.co/Kenny411/Ket, https://huggingface.co/mortezap88/9.1-Helper, https://huggingface.co/KENANK/test-bot, https://huggingface.co/Meow9848t677/G79go94, https://huggingface.co/bef-18/masia, https://huggingface.co/ChubiLev/Depor, https://huggingface.co/14dimension/jarvis, https://huggingface.co/NikhilJain1102/1102, https://huggingface.co/Ruihffd/ChatPPK, https://huggingface.co/Stas696969/2B, https://huggingface.co/RAHULCOMRADE123/Mallu, https://huggingface.co/teknolog/majorgeneral, https://huggingface.co/fedoravel/test, https://huggingface.co/pravindsurve/pravindsurve1, https://huggingface.co/kingkolor8/Bangaram, https://huggingface.co/Albi96/iii, https://huggingface.co/rs33nm7d/Limo, https://huggingface.co/ghostyaZ/cloudApiAI, https://huggingface.co/Roy124/Roy, https://huggingface.co/KikiAnandhan/modelName, https://huggingface.co/tflsxyy/DeepSeek-V3-bf16, https://huggingface.co/tflsxyy/DeepSeek-V3-bf16-4layers, https://huggingface.co/Ojttt/deepseekv3_export_test, https://huggingface.co/hyper-accel/deepseekv3-export-test, https://huggingface.co/mortnyc/inMotion",78,"https://huggingface.co/winorg68/FREE, https://huggingface.co/renziify/1.PsychologyTest, https://huggingface.co/Enderchef/JarvisAI, https://huggingface.co/At-Tawheed/quantum-aurora, https://huggingface.co/Gguhvjj/Barber, https://huggingface.co/RCMJunior/irmakderya, https://huggingface.co/NoXiHa/llama3.3, https://huggingface.co/Gohil001/Ai, https://huggingface.co/AhmedY77/Movies2977, https://huggingface.co/Morttynn/image, https://huggingface.co/elkalubi/CHATGPT-LIKe-assistant, https://huggingface.co/AsstGR/AsstGRv1, https://huggingface.co/nakalia05/Destruction, https://huggingface.co/amiraislameva7/Fimu, https://huggingface.co/WVQueer4AI/NonKarenAi, https://huggingface.co/hanvith6/llm, https://huggingface.co/SeyhaLite/Mey, https://huggingface.co/thomaspedersen1028/Thomaspedersen27, https://huggingface.co/UserAdminRoot/123, https://huggingface.co/chiri123/Carlitos, https://huggingface.co/jamieor/STFP, https://huggingface.co/Xaayu/Meeh, https://huggingface.co/Support72/GPT, https://huggingface.co/Lilithchouy/bestmodel, https://huggingface.co/levsol101/Medics-24, https://huggingface.co/marxrichard/Marx, https://huggingface.co/michaelelliott13/Mylittlefriend, https://huggingface.co/matias2002/VOSadam, https://huggingface.co/mohamedpolicemaster/lang, https://huggingface.co/asyodigital/Asyo_Ai, https://huggingface.co/Nba23/Nbayoungboy, https://huggingface.co/AbhijeetMohanty/JD, https://huggingface.co/lando4/kaizoku, https://huggingface.co/gkgeorge/lksoft, https://huggingface.co/Sachin237/SuperAgent, https://huggingface.co/Rainbowbeast/Sidekick, https://huggingface.co/yashoda74679/stupidai, https://huggingface.co/undimmable/freyja",38,"https://huggingface.co/v2ray/DeepSeek-V3-1B-Test-AWQ, https://huggingface.co/OPEA/DeepSeek-V3-int4-sym-gptq-inc, https://huggingface.co/cognitivecomputations/DeepSeek-V3-AWQ, https://huggingface.co/bullerwins/DeepSeek-V3-GGUF, https://huggingface.co/mlx-community/DeepSeek-V3-3bit, https://huggingface.co/unsloth/DeepSeek-V3-GGUF, https://huggingface.co/mlx-community/DeepSeek-V3-4bit, https://huggingface.co/OPEA/DeepSeek-V3-int4-sym-gguf-q4-0-inc, https://huggingface.co/OPEA/DeepSeek-V3-int4-sym-awq-inc, https://huggingface.co/bullerwins/DeepSeek-V3-split, https://huggingface.co/mlx-community/DeepSeek-V3-3bit-bf16, https://huggingface.co/unsloth/DeepSeek-V3, https://huggingface.co/unsloth/DeepSeek-V3-bf16, https://huggingface.co/mmnga/DeepSeek-V3-bf16-gguf, https://huggingface.co/rohithsiddhartha/DeepSeek-V3-4bit, https://huggingface.co/tflsxyy/DeepSeek-V3-4bit-4layers",16,https://huggingface.co/Bixho/idkai,1,"Akshayram1/data_visualization_ai_excel_togetherai_e2b, AtlaAI/LLMsOnTrial, Faheemalvi/LLaMa, FallnAI/Quantize-HF-Models, KBaba7/Quant, Omer-wahid/deepseek-ai-DeepSeek-V3, Orion-zhen/tokenize-it, ZongqianLi/ReasonGraph, awacke1/Deepseek-HPC-GPU-KEDA, bhaskartripathi/LLM_Quantization, hertogateis/deepseekchat, readomni/literate",12
huihui-ai/DeepSeek-V3-abliterated,"---
license: apache-2.0
language:
- en
base_model:
- deepseek-ai/DeepSeek-V3
library_name: transformers
tags:
- DeepSeek
- abliterated
- uncensored
---

# huihui-ai/DeepSeek-V3-abliterated


This is an uncensored version of [deepseek-ai/DeepSeek-V3](https://huggingface.co/deepseek-ai/DeepSeek-V3) created with abliteration (see [remove-refusals-with-transformers](https://github.com/Sumandora/remove-refusals-with-transformers) to know more about it).  
This is a crude, proof-of-concept implementation to remove refusals from an LLM model without using TransformerLens. 

# Note

All files have been uploaded. If you have already downloaded it before, please download again to automatically get any missing files.

```
huggingface-cli download huihui-ai/DeepSeek-V3-abliterated --local-dir ./huihui-ai/DeepSeek-V3-abliterated --token hf_xxxx 
```

The next goal is [deepseek-ai/DeepSeek-V3-0324](https://huggingface.co/deepseek-ai/DeepSeek-V3-0324).

## Use with ollama

You can use [huihui_ai/deepseek-v3-abliterated](https://ollama.com/huihui_ai/deepseek-v3-abliterated) directly
```
ollama run huihui_ai/deepseek-v3-abliterated
```

[Q4_K_M](https://ollama.com/huihui_ai/deepseek-v3-abliterated:671b-q4_K_M), 
[Q3_K_M](https://ollama.com/huihui_ai/deepseek-v3-abliterated:671b-Q3_K_M), 
[Q2_K](https://ollama.com/huihui_ai/deepseek-v3-abliterated:671b-Q2_K) have been uploaded.

## Use with transformers

```
from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, TextStreamer
import torch
import os
import signal

cpu_count = os.cpu_count()
print(f""Number of CPU cores in the system: {cpu_count}"")
half_cpu_count = cpu_count // 2
os.environ[""MKL_NUM_THREADS""] = str(half_cpu_count)
os.environ[""OMP_NUM_THREADS""] = str(half_cpu_count)
torch.set_num_threads(half_cpu_count)

print(f""PyTorch threads: {torch.get_num_threads()}"")
print(f""MKL threads: {os.getenv('MKL_NUM_THREADS')}"")
print(f""OMP threads: {os.getenv('OMP_NUM_THREADS')}"")

NEW_MODEL_ID = ""huihui-ai/DeepSeek-V3-abliterated""
print(f""Load Model {NEW_MODEL_ID} ... "")
quant_config_4 = BitsAndBytesConfig(
    load_in_4bit=True,
    bnb_4bit_compute_dtype=torch.bfloat16,
    bnb_4bit_use_double_quant=True,
    llm_int8_enable_fp32_cpu_offload=True,
)

# Single RTX 4090
NUM_TRANS_LAYERS = 61

def create_device_map():
    device_map = {
        'model.embed_tokens': 0,
        'model.norm': 0,
        'model.rotary_emb': 0,
        'lm_head': 0
    }
    for start, end, gpu_id in [(0, 5, 0)]:
        for i in range(start, end):
            device_map[f'model.layers.{i}'] = gpu_id
    
    for i in range(5, NUM_TRANS_LAYERS):
        device_map[f'model.layers.{i}'] = ""cpu""

    return device_map

device_map = create_device_map()

model = AutoModelForCausalLM.from_pretrained(
    NEW_MODEL_ID,
    device_map=device_map,
    trust_remote_code=True,
    quantization_config=quant_config_4,
    torch_dtype=torch.bfloat16
)
tokenizer = AutoTokenizer.from_pretrained(NEW_MODEL_ID, trust_remote_code=True)
if tokenizer.pad_token is None:
    tokenizer.pad_token = tokenizer.eos_token
tokenizer.pad_token_id = tokenizer.eos_token_id

initial_messages = [{""role"": ""system"", ""content"": ""You are a helpful assistant.""}]
messages = initial_messages.copy()

class CustomTextStreamer(TextStreamer):
    def __init__(self, tokenizer, skip_prompt=True, skip_special_tokens=True):
        super().__init__(tokenizer, skip_prompt=skip_prompt, skip_special_tokens=skip_special_tokens)
        self.generated_text = """"
        self.stop_flag = False

    def on_finalized_text(self, text: str, stream_end: bool = False):
        self.generated_text += text
        print(text, end="""", flush=True)
        if self.stop_flag:
            raise StopIteration

    def stop_generation(self):
        self.stop_flag = True

def generate_stream(model, tokenizer, messages, max_new_tokens):
    input_ids = tokenizer.apply_chat_template(
        messages,
        tokenize=True,
        add_generation_prompt=True,
        return_tensors=""pt""
    )
    attention_mask = torch.ones_like(input_ids, dtype=torch.long)
    tokens = input_ids.to(model.device) 
    attention_mask = attention_mask.to(model.device)

    streamer = CustomTextStreamer(tokenizer, skip_prompt=True, skip_special_tokens=True)

    def signal_handler(sig, frame):
        streamer.stop_generation()
        print(""\n[Generation stopped by user with Ctrl+C]"")

    signal.signal(signal.SIGINT, signal_handler)
    
    print(""Response: "", end="""", flush=True)
    try:
        generated_ids = model.generate(
            tokens,
            attention_mask=attention_mask,
            use_cache=False,
            max_new_tokens=max_new_tokens,
            do_sample=True,
            pad_token_id=tokenizer.pad_token_id,
            streamer=streamer
        )
        del generated_ids
    except StopIteration:
        print(""\n[Stopped by user]"")

    del input_ids, attention_mask
    torch.cuda.empty_cache()
    signal.signal(signal.SIGINT, signal.SIG_DFL)

    return streamer.generated_text, streamer.stop_flag

while True:
    user_input = input(""User: "").strip()
    if user_input.lower() == ""/exit"":
        print(""Exiting chat."")
        break
    if user_input.lower() == ""/clear"":
        messages = initial_messages.copy()
        print(""Chat history cleared. Starting a new conversation."")
        continue
    if not user_input:
        print(""Input cannot be empty. Please enter something."")
        continue
    messages.append({""role"": ""user"", ""content"": user_input})
    response, stop_flag = generate_stream(model, tokenizer, messages, 8192)
    if stop_flag:
        continue
    messages.append({""role"": ""assistant"", ""content"": response})

```
### Donation

If you like it, please click 'like' and follow us for more updates.  
You can follow [x.com/support_huihui](https://x.com/support_huihui) to get the latest model information from huihui.ai.

##### Your donation helps us continue our further development and improvement, a cup of coffee can do it.
- bitcoinÔºàBTC):
```
  bc1qqnkhuchxw0zqjh2ku3lu4hq45hc6gy84uk70ge
```
","{""id"": ""huihui-ai/DeepSeek-V3-abliterated"", ""author"": ""huihui-ai"", ""sha"": ""8ccf38ed517576639f0e3431c0852beaca4a4f06"", ""last_modified"": ""2025-04-06 00:24:52+00:00"", ""created_at"": ""2025-03-05 08:48:43+00:00"", ""private"": false, ""gated"": ""auto"", ""disabled"": false, ""downloads"": 119, ""downloads_all_time"": null, ""likes"": 112, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""safetensors"", ""deepseek_v3"", ""text-generation"", ""DeepSeek"", ""abliterated"", ""uncensored"", ""conversational"", ""custom_code"", ""en"", ""base_model:deepseek-ai/DeepSeek-V3"", ""base_model:finetune:deepseek-ai/DeepSeek-V3"", ""license:apache-2.0"", ""autotrain_compatible"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model:\n- deepseek-ai/DeepSeek-V3\nlanguage:\n- en\nlibrary_name: transformers\nlicense: apache-2.0\ntags:\n- DeepSeek\n- abliterated\n- uncensored"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""DeepseekV3ForCausalLM""], ""auto_map"": {""AutoConfig"": ""configuration_deepseek.DeepseekV3Config"", ""AutoModel"": ""modeling_deepseek.DeepseekV3Model"", ""AutoModelForCausalLM"": ""modeling_deepseek.DeepseekV3ForCausalLM""}, ""model_type"": ""deepseek_v3"", ""tokenizer_config"": {""bos_token"": ""<\uff5cbegin\u2581of\u2581sentence\uff5c>"", ""chat_template"": ""{% if not add_generation_prompt is defined %}{% set add_generation_prompt = false %}{% endif %}{% set ns = namespace(is_first=false, is_tool=false, is_output_first=true, system_prompt='', is_first_sp=true) %}{%- for message in messages %}{%- if message['role'] == 'system' %}{%- if ns.is_first_sp %}{% set ns.system_prompt = ns.system_prompt + message['content'] %}{% set ns.is_first_sp = false %}{%- else %}{% set ns.system_prompt = ns.system_prompt + '\n\n' + message['content'] %}{%- endif %}{%- endif %}{%- endfor %}{{bos_token}}{{ns.system_prompt}}{%- for message in messages %}{%- if message['role'] == 'user' %}{%- set ns.is_tool = false -%}{{'<\uff5cUser\uff5c>' + message['content']}}{%- endif %}{%- if message['role'] == 'assistant' and message['content'] is none %}{%- set ns.is_tool = false -%}{%- for tool in message['tool_calls']%}{%- if not ns.is_first %}{{'<\uff5cAssistant\uff5c><\uff5ctool\u2581calls\u2581begin\uff5c><\uff5ctool\u2581call\u2581begin\uff5c>' + tool['type'] + '<\uff5ctool\u2581sep\uff5c>' + tool['function']['name'] + '\n' + '```json' + '\n' + tool['function']['arguments'] + '\n' + '```' + '<\uff5ctool\u2581call\u2581end\uff5c>'}}{%- set ns.is_first = true -%}{%- else %}{{'\n' + '<\uff5ctool\u2581call\u2581begin\uff5c>' + tool['type'] + '<\uff5ctool\u2581sep\uff5c>' + tool['function']['name'] + '\n' + '```json' + '\n' + tool['function']['arguments'] + '\n' + '```' + '<\uff5ctool\u2581call\u2581end\uff5c>'}}{{'<\uff5ctool\u2581calls\u2581end\uff5c><\uff5cend\u2581of\u2581sentence\uff5c>'}}{%- endif %}{%- endfor %}{%- endif %}{%- if message['role'] == 'assistant' and message['content'] is not none %}{%- if ns.is_tool %}{{'<\uff5ctool\u2581outputs\u2581end\uff5c>' + message['content'] + '<\uff5cend\u2581of\u2581sentence\uff5c>'}}{%- set ns.is_tool = false -%}{%- else %}{{'<\uff5cAssistant\uff5c>' + message['content'] + '<\uff5cend\u2581of\u2581sentence\uff5c>'}}{%- endif %}{%- endif %}{%- if message['role'] == 'tool' %}{%- set ns.is_tool = true -%}{%- if ns.is_output_first %}{{'<\uff5ctool\u2581outputs\u2581begin\uff5c><\uff5ctool\u2581output\u2581begin\uff5c>' + message['content'] + '<\uff5ctool\u2581output\u2581end\uff5c>'}}{%- set ns.is_output_first = false %}{%- else %}{{'\n<\uff5ctool\u2581output\u2581begin\uff5c>' + message['content'] + '<\uff5ctool\u2581output\u2581end\uff5c>'}}{%- endif %}{%- endif %}{%- endfor -%}{% if ns.is_tool %}{{'<\uff5ctool\u2581outputs\u2581end\uff5c>'}}{% endif %}{% if add_generation_prompt and not ns.is_tool %}{{'<\uff5cAssistant\uff5c>'}}{% endif %}"", ""eos_token"": ""<\uff5cend\u2581of\u2581sentence\uff5c>"", ""pad_token"": ""<\uff5cend\u2581of\u2581sentence\uff5c>"", ""unk_token"": null, ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-bf16.png', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='LICENSE-CODE', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='LICENSE-MODEL', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='configuration_deepseek.py', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='generation_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00001-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00002-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00003-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00004-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00005-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00006-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00007-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00008-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00009-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00010-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00011-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00012-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00013-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00014-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00015-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00016-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00017-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00018-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00019-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00020-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00021-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00022-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00023-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00024-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00025-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00026-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00027-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00028-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00029-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00030-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00031-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00032-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00033-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00034-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00035-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00036-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00037-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00038-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00039-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00040-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00041-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00042-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00043-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00044-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00045-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00046-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00047-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00048-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00049-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00050-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00051-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00052-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00053-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00054-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00055-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00056-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00057-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00058-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00059-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00060-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00061-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00062-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00063-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00064-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00065-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00066-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00067-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00068-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00069-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00070-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00071-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00072-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00073-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00074-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00075-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00076-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00077-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00078-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00079-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00080-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00081-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00082-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00083-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00084-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00085-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00086-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00087-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00088-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00089-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00090-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00091-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00092-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00093-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00094-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00095-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00096-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00097-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00098-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00099-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00100-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00101-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00102-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00103-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00104-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00105-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00106-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00107-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00108-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00109-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00110-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00111-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00112-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00113-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00114-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00115-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00116-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00117-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00118-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00119-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00120-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00121-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00122-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00123-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00124-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00125-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00126-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00127-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00128-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00129-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00130-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00131-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00132-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00133-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00134-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00135-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00136-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00137-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00138-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00139-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00140-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00141-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00142-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00143-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00144-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00145-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00146-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00147-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00148-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00149-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00150-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00151-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00152-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00153-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00154-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00155-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00156-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00157-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00158-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00159-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00160-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00161-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00162-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00163-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00164-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00165-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00166-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00167-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00168-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00169-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00170-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00171-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00172-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00173-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00174-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00175-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00176-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00177-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00178-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00179-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00180-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00181-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00182-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00183-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00184-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00185-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00186-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00187-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00188-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00189-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00190-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00191-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00192-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00193-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00194-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00195-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00196-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00197-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00198-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00199-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00200-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00201-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00202-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00203-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00204-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00205-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00206-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00207-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00208-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00209-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00210-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00211-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00212-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00213-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00214-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00215-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00216-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00217-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00218-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00219-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00220-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00221-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00222-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00223-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00224-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00225-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00226-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00227-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00228-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00229-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00230-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00231-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00232-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00233-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00234-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00235-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00236-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00237-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00238-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00239-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00240-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00241-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00242-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00243-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00244-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00245-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00246-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00247-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00248-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00249-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00250-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00251-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00252-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00253-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00254-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00255-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00256-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00257-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00258-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00259-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00260-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00261-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00262-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00263-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00264-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00265-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00266-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00267-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00268-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00269-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00270-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model.safetensors.index.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='modeling_deepseek.py', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": {""parameters"": {""BF16"": 671026419200}, ""total"": 671026419200}, ""security_repo_status"": null, ""lastModified"": ""2025-04-06 00:24:52+00:00"", ""cardData"": ""base_model:\n- deepseek-ai/DeepSeek-V3\nlanguage:\n- en\nlibrary_name: transformers\nlicense: apache-2.0\ntags:\n- DeepSeek\n- abliterated\n- uncensored"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67c80feb08ea8978b977031a"", ""modelId"": ""huihui-ai/DeepSeek-V3-abliterated"", ""usedStorage"": 1342058533528}",1,,0,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=huihui-ai/DeepSeek-V3-abliterated&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bhuihui-ai%2FDeepSeek-V3-abliterated%5D(%2Fhuihui-ai%2FDeepSeek-V3-abliterated)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1
opensourcerelease/DeepSeek-V3-bf16,"---
base_model:
- deepseek-ai/DeepSeek-V3
---

Model converted from DeepSeek-V3 to BF16.","{""id"": ""opensourcerelease/DeepSeek-V3-bf16"", ""author"": ""opensourcerelease"", ""sha"": ""d1a2dbd3c0cdd4c648535b7869d49ecbeb679bf4"", ""last_modified"": ""2024-12-30 08:37:05+00:00"", ""created_at"": ""2024-12-26 16:07:44+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 495, ""downloads_all_time"": null, ""likes"": 28, ""library_name"": null, ""gguf"": null, ""inference"": null, ""tags"": [""safetensors"", ""deepseek_v3"", ""custom_code"", ""base_model:deepseek-ai/DeepSeek-V3"", ""base_model:finetune:deepseek-ai/DeepSeek-V3"", ""region:us""], ""pipeline_tag"": null, ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model:\n- deepseek-ai/DeepSeek-V3"", ""widget_data"": null, ""model_index"": null, ""config"": {""architectures"": [""DeepseekV3ForCausalLM""], ""auto_map"": {""AutoConfig"": ""configuration_deepseek.DeepseekV3Config"", ""AutoModel"": ""modeling_deepseek.DeepseekV3Model"", ""AutoModelForCausalLM"": ""modeling_deepseek.DeepseekV3ForCausalLM""}, ""model_type"": ""deepseek_v3"", ""tokenizer_config"": {""bos_token"": {""__type"": ""AddedToken"", ""content"": ""<\uff5cbegin\u2581of\u2581sentence\uff5c>"", ""lstrip"": false, ""normalized"": true, ""rstrip"": false, ""single_word"": false}, ""eos_token"": {""__type"": ""AddedToken"", ""content"": ""<\uff5cend\u2581of\u2581sentence\uff5c>"", ""lstrip"": false, ""normalized"": true, ""rstrip"": false, ""single_word"": false}, ""pad_token"": {""__type"": ""AddedToken"", ""content"": ""<\uff5cend\u2581of\u2581sentence\uff5c>"", ""lstrip"": false, ""normalized"": true, ""rstrip"": false, ""single_word"": false}, ""unk_token"": null, ""chat_template"": ""{% if not add_generation_prompt is defined %}{% set add_generation_prompt = false %}{% endif %}{% set ns = namespace(is_first=false, is_tool=false, is_output_first=true, system_prompt='', is_first_sp=true) %}{%- for message in messages %}{%- if message['role'] == 'system' %}{%- if ns.is_first_sp %}{% set ns.system_prompt = ns.system_prompt + message['content'] %}{% set ns.is_first_sp = false %}{%- else %}{% set ns.system_prompt = ns.system_prompt + '\n\n' + message['content'] %}{%- endif %}{%- endif %}{%- endfor %}{{bos_token}}{{ns.system_prompt}}{%- for message in messages %}{%- if message['role'] == 'user' %}{%- set ns.is_tool = false -%}{{'<\uff5cUser\uff5c>' + message['content']}}{%- endif %}{%- if message['role'] == 'assistant' and message['content'] is none %}{%- set ns.is_tool = false -%}{%- for tool in message['tool_calls']%}{%- if not ns.is_first %}{{'<\uff5cAssistant\uff5c><\uff5ctool\u2581calls\u2581begin\uff5c><\uff5ctool\u2581call\u2581begin\uff5c>' + tool['type'] + '<\uff5ctool\u2581sep\uff5c>' + tool['function']['name'] + '\n' + '```json' + '\n' + tool['function']['arguments'] + '\n' + '```' + '<\uff5ctool\u2581call\u2581end\uff5c>'}}{%- set ns.is_first = true -%}{%- else %}{{'\n' + '<\uff5ctool\u2581call\u2581begin\uff5c>' + tool['type'] + '<\uff5ctool\u2581sep\uff5c>' + tool['function']['name'] + '\n' + '```json' + '\n' + tool['function']['arguments'] + '\n' + '```' + '<\uff5ctool\u2581call\u2581end\uff5c>'}}{{'<\uff5ctool\u2581calls\u2581end\uff5c><\uff5cend\u2581of\u2581sentence\uff5c>'}}{%- endif %}{%- endfor %}{%- endif %}{%- if message['role'] == 'assistant' and message['content'] is not none %}{%- if ns.is_tool %}{{'<\uff5ctool\u2581outputs\u2581end\uff5c>' + message['content'] + '<\uff5cend\u2581of\u2581sentence\uff5c>'}}{%- set ns.is_tool = false -%}{%- else %}{{'<\uff5cAssistant\uff5c>' + message['content'] + '<\uff5cend\u2581of\u2581sentence\uff5c>'}}{%- endif %}{%- endif %}{%- if message['role'] == 'tool' %}{%- set ns.is_tool = true -%}{%- if ns.is_output_first %}{{'<\uff5ctool\u2581outputs\u2581begin\uff5c><\uff5ctool\u2581output\u2581begin\uff5c>' + message['content'] + '<\uff5ctool\u2581output\u2581end\uff5c>'}}{%- set ns.is_output_first = false %}{%- else %}{{'\n<\uff5ctool\u2581output\u2581begin\uff5c>' + message['content'] + '<\uff5ctool\u2581output\u2581end\uff5c>'}}{%- endif %}{%- endif %}{%- endfor -%}{% if ns.is_tool %}{{'<\uff5ctool\u2581outputs\u2581end\uff5c>'}}{% endif %}{% if add_generation_prompt and not ns.is_tool %}{{'<\uff5cAssistant\uff5c>'}}{% endif %}""}}, ""transformers_info"": null, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='configuration_deepseek.py', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00001-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00002-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00003-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00004-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00005-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00006-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00007-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00008-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00009-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00010-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00011-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00012-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00013-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00014-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00015-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00016-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00017-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00018-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00019-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00020-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00021-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00022-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00023-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00024-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00025-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00026-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00027-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00028-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00029-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00030-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00031-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00032-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00033-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00034-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00035-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00036-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00037-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00038-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00039-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00040-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00041-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00042-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00043-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00044-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00045-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00046-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00047-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00048-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00049-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00050-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00051-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00052-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00053-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00054-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00055-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00056-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00057-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00058-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00059-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00060-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00061-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00062-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00063-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00064-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00065-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00066-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00067-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00068-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00069-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00070-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00071-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00072-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00073-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00074-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00075-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00076-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00077-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00078-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00079-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00080-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00081-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00082-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00083-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00084-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00085-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00086-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00087-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00088-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00089-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00090-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00091-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00092-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00093-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00094-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00095-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00096-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00097-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00098-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00099-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00100-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00101-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00102-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00103-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00104-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00105-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00106-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00107-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00108-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00109-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00110-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00111-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00112-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00113-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00114-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00115-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00116-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00117-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00118-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00119-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00120-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00121-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00122-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00123-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00124-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00125-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00126-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00127-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00128-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00129-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00130-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00131-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00132-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00133-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00134-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00135-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00136-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00137-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00138-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00139-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00140-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00141-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00142-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00143-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00144-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00145-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00146-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00147-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00148-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00149-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00150-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00151-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00152-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00153-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00154-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00155-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00156-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00157-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00158-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00159-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00160-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00161-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00162-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00163-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model.safetensors.index.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='modeling_deepseek.py', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": {""parameters"": {""F32"": 15104, ""BF16"": 684489830400}, ""total"": 684489845504}, ""security_repo_status"": null, ""lastModified"": ""2024-12-30 08:37:05+00:00"", ""cardData"": ""base_model:\n- deepseek-ai/DeepSeek-V3"", ""transformersInfo"": null, ""_id"": ""676d7f5011b32e84adb813af"", ""modelId"": ""opensourcerelease/DeepSeek-V3-bf16"", ""usedStorage"": 1368985513488}",1,,0,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=opensourcerelease/DeepSeek-V3-bf16&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bopensourcerelease%2FDeepSeek-V3-bf16%5D(%2Fopensourcerelease%2FDeepSeek-V3-bf16)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1
inarikami/DeepSeek-V3-int4-TensorRT,"---
language:
- en
base_model:
- deepseek-ai/DeepSeek-V3
pipeline_tag: text-generation
---
# DeepSeek V3 - INT4 (TensorRT-LLM)

This repository provides an INT4-quantized version of the DeepSeek V3 model, suitable for high-speed, memory-efficient inference with TensorRT-LLM.


Model Summary
	‚Ä¢	Base Model: DeepSeek V3 (BF16) <--- (from Nvidia FP8)
	‚Ä¢	Quantization: Weight-only INT4 (W4A16)


```sh
python convert_checkpoint.py \
  --model_dir /home/user/hf/deepseek-v3-bf16 \
  --output_dir /home/user/hf/deepseek-v3-int4 \
  --dtype bfloat16 \
  --tp_size 4 \
  --use_weight_only \
  --weight_only_precision int4 \
  --workers 4
```

### Hardware reqs:

* 4√ó80 GB H100 or H200 (Optimal)


### Example usage:

```sh
trtllm-build --checkpoint_dir /DeepSeek-V3-int4-TensorRT  \
--output_dir ./trtllm_engines/deepseek_v3/int4/tp4-sel4096-isl2048-bs4  \
...
```


### Disclaimer:

This model is a quantized checkpoint intended for research and experimentation with high-performance inference. Use at your own risk and validate outputs for production use-cases.","{""id"": ""inarikami/DeepSeek-V3-int4-TensorRT"", ""author"": ""inarikami"", ""sha"": ""f3eac8c12884911088fc8c8e0539590183ebaa06"", ""last_modified"": ""2024-12-28 06:32:59+00:00"", ""created_at"": ""2024-12-27 04:40:18+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 18, ""downloads_all_time"": null, ""likes"": 15, ""library_name"": null, ""gguf"": null, ""inference"": null, ""tags"": [""text-generation"", ""en"", ""base_model:deepseek-ai/DeepSeek-V3"", ""base_model:finetune:deepseek-ai/DeepSeek-V3"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model:\n- deepseek-ai/DeepSeek-V3\nlanguage:\n- en\npipeline_tag: text-generation"", ""widget_data"": [{""text"": ""My name is Julien and I like to""}, {""text"": ""I like traveling by train because""}, {""text"": ""Paris is an amazing place to visit,""}, {""text"": ""Once upon a time,""}], ""model_index"": null, ""config"": {}, ""transformers_info"": null, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='configscript.sh', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='deepseek_v3_int4_shard0.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='deepseek_v3_int4_shard1.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='deepseek_v3_int4_shard10.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='deepseek_v3_int4_shard11.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='deepseek_v3_int4_shard12.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='deepseek_v3_int4_shard13.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='deepseek_v3_int4_shard14.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='deepseek_v3_int4_shard15.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='deepseek_v3_int4_shard16.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='deepseek_v3_int4_shard17.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='deepseek_v3_int4_shard18.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='deepseek_v3_int4_shard19.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='deepseek_v3_int4_shard2.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='deepseek_v3_int4_shard3.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='deepseek_v3_int4_shard4.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='deepseek_v3_int4_shard5.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='deepseek_v3_int4_shard6.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='deepseek_v3_int4_shard7.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='deepseek_v3_int4_shard8.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='deepseek_v3_int4_shard9.safetensors', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2024-12-28 06:32:59+00:00"", ""cardData"": ""base_model:\n- deepseek-ai/DeepSeek-V3\nlanguage:\n- en\npipeline_tag: text-generation"", ""transformersInfo"": null, ""_id"": ""676e2fb215851fd7f56cfb08"", ""modelId"": ""inarikami/DeepSeek-V3-int4-TensorRT"", ""usedStorage"": 98246285792}",1,,0,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=inarikami/DeepSeek-V3-int4-TensorRT&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Binarikami%2FDeepSeek-V3-int4-TensorRT%5D(%2Finarikami%2FDeepSeek-V3-int4-TensorRT)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1
v2ray/DeepSeek-V3-1B-Test,"---
license: mit
base_model:
- deepseek-ai/DeepSeek-V3
pipeline_tag: text-generation
library_name: transformers
---
# DeepSeek V3 1B Test
This model is randomly initialized for testing implementations, it's **not** a trained model and it will only generate random tokens.","{""id"": ""v2ray/DeepSeek-V3-1B-Test"", ""author"": ""v2ray"", ""sha"": ""b2eb5f841d9f200679c8e57f75c5138f454df64e"", ""last_modified"": ""2025-01-05 04:16:42+00:00"", ""created_at"": ""2024-12-31 20:51:10+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 267, ""downloads_all_time"": null, ""likes"": 2, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""safetensors"", ""deepseek_v3"", ""text-generation"", ""conversational"", ""custom_code"", ""base_model:deepseek-ai/DeepSeek-V3"", ""base_model:finetune:deepseek-ai/DeepSeek-V3"", ""license:mit"", ""autotrain_compatible"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model:\n- deepseek-ai/DeepSeek-V3\nlibrary_name: transformers\nlicense: mit\npipeline_tag: text-generation"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""DeepseekV3ForCausalLM""], ""auto_map"": {""AutoConfig"": ""configuration_deepseek.DeepseekV3Config"", ""AutoModel"": ""modeling_deepseek.DeepseekV3Model"", ""AutoModelForCausalLM"": ""modeling_deepseek.DeepseekV3ForCausalLM""}, ""model_type"": ""deepseek_v3"", ""tokenizer_config"": {""bos_token"": ""<\uff5cbegin\u2581of\u2581sentence\uff5c>"", ""chat_template"": ""{% if not add_generation_prompt is defined %}{% set add_generation_prompt = false %}{% endif %}{% set ns = namespace(is_first=false, is_tool=false, is_output_first=true, system_prompt='', is_first_sp=true) %}{%- for message in messages %}{%- if message['role'] == 'system' %}{%- if ns.is_first_sp %}{% set ns.system_prompt = ns.system_prompt + message['content'] %}{% set ns.is_first_sp = false %}{%- else %}{% set ns.system_prompt = ns.system_prompt + '\n\n' + message['content'] %}{%- endif %}{%- endif %}{%- endfor %}{{bos_token}}{{ns.system_prompt}}{%- for message in messages %}{%- if message['role'] == 'user' %}{%- set ns.is_tool = false -%}{{'<\uff5cUser\uff5c>' + message['content']}}{%- endif %}{%- if message['role'] == 'assistant' and message['content'] is none %}{%- set ns.is_tool = false -%}{%- for tool in message['tool_calls']%}{%- if not ns.is_first %}{{'<\uff5cAssistant\uff5c><\uff5ctool\u2581calls\u2581begin\uff5c><\uff5ctool\u2581call\u2581begin\uff5c>' + tool['type'] + '<\uff5ctool\u2581sep\uff5c>' + tool['function']['name'] + '\n' + '```json' + '\n' + tool['function']['arguments'] + '\n' + '```' + '<\uff5ctool\u2581call\u2581end\uff5c>'}}{%- set ns.is_first = true -%}{%- else %}{{'\n' + '<\uff5ctool\u2581call\u2581begin\uff5c>' + tool['type'] + '<\uff5ctool\u2581sep\uff5c>' + tool['function']['name'] + '\n' + '```json' + '\n' + tool['function']['arguments'] + '\n' + '```' + '<\uff5ctool\u2581call\u2581end\uff5c>'}}{{'<\uff5ctool\u2581calls\u2581end\uff5c><\uff5cend\u2581of\u2581sentence\uff5c>'}}{%- endif %}{%- endfor %}{%- endif %}{%- if message['role'] == 'assistant' and message['content'] is not none %}{%- if ns.is_tool %}{{'<\uff5ctool\u2581outputs\u2581end\uff5c>' + message['content'] + '<\uff5cend\u2581of\u2581sentence\uff5c>'}}{%- set ns.is_tool = false -%}{%- else %}{{'<\uff5cAssistant\uff5c>' + message['content'] + '<\uff5cend\u2581of\u2581sentence\uff5c>'}}{%- endif %}{%- endif %}{%- if message['role'] == 'tool' %}{%- set ns.is_tool = true -%}{%- if ns.is_output_first %}{{'<\uff5ctool\u2581outputs\u2581begin\uff5c><\uff5ctool\u2581output\u2581begin\uff5c>' + message['content'] + '<\uff5ctool\u2581output\u2581end\uff5c>'}}{%- set ns.is_output_first = false %}{%- else %}{{'\n<\uff5ctool\u2581output\u2581begin\uff5c>' + message['content'] + '<\uff5ctool\u2581output\u2581end\uff5c>'}}{%- endif %}{%- endif %}{%- endfor -%}{% if ns.is_tool %}{{'<\uff5ctool\u2581outputs\u2581end\uff5c>'}}{% endif %}{% if add_generation_prompt and not ns.is_tool %}{{'<\uff5cAssistant\uff5c>'}}{% endif %}"", ""eos_token"": ""<\uff5cend\u2581of\u2581sentence\uff5c>"", ""pad_token"": ""<\uff5cend\u2581of\u2581sentence\uff5c>"", ""unk_token"": null, ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='configuration_deepseek.py', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='generation_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='modeling_deepseek.py', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": {""parameters"": {""BF16"": 1049548096}, ""total"": 1049548096}, ""security_repo_status"": null, ""lastModified"": ""2025-01-05 04:16:42+00:00"", ""cardData"": ""base_model:\n- deepseek-ai/DeepSeek-V3\nlibrary_name: transformers\nlicense: mit\npipeline_tag: text-generation"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""6774593edb61c0b1b4e8f5d0"", ""modelId"": ""v2ray/DeepSeek-V3-1B-Test"", ""usedStorage"": 4330001480}",1,,0,,0,"https://huggingface.co/PrunaAI/v2ray-DeepSeek-V3-1B-Test-bnb-8bit-smashed, https://huggingface.co/tensorblock/DeepSeek-V3-1B-Test-GGUF",2,,0,huggingface/InferenceSupport/discussions/new?title=v2ray/DeepSeek-V3-1B-Test&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bv2ray%2FDeepSeek-V3-1B-Test%5D(%2Fv2ray%2FDeepSeek-V3-1B-Test)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1
mmnga/DeepSeek-V3-slice-jp64,"---
license: other
language:
- ja
base_model:
- deepseek-ai/DeepSeek-V3
---
# DeepSeek-V3-slice-jp64

## ÂÆüÈ®ì„É¢„Éá„É´„Åß„Åô
Êú¨„É¢„Éá„É´„ÅØ [DeepSeek-V3](https://huggingface.co/deepseek-ai/DeepSeek-V3) „Çí„Éô„Éº„Çπ„Å´„ÄÅÊó•Êú¨Ë™û„ÅÆ‰æãÊñá„ÇíÂÖÉ„Å´È†ªÂá∫„Åô„Çã MoE (Mixture of Experts) „ÅÆÂêÑ„É¨„Ç§„É§„Éº„Åî„Å®„ÅÆexperts„ÇíÂé≥ÈÅ∏„Åó„Å¶ÂÜçÊßãÊàê„Åó„Åü„É¢„Éá„É´„Åß„Åô„ÄÇ
ÂÖÉ„ÅÆ„É¢„Éá„É´„Åß„ÅØ 256 „ÅÆexperts„ÇíÊê≠Ëºâ„Åó„Å¶„ÅÑ„Åæ„Åô„Åå„ÄÅÊó•Êú¨Ë™ûÂá∫Âäõ„Å´„Åä„Åë„ÇãÂÆâÂÆöÊÄß„Å®„Éë„Éï„Ç©„Éº„Éû„É≥„Çπ„ÅÆ„Éê„É©„É≥„Çπ„ÇíÈáçË¶ñ„Åó„ÄÅÂêÑÂ±§„ÅßÈ†ªÂá∫„Åô„Çã 64 „ÅÆexperts„Çí‰ΩøÁî®„Åô„Çã„Çà„ÅÜ„Å´Ë™øÊï¥„Åó„Å¶„ÅÑ„Åæ„Åô„ÄÇ

### ‰æãÊñáÂá∫ÂäõÊôÇ„ÅÆÂêÑlayer„Åî„Å®„ÅÆexperts„ÅÆÈ†ªÂá∫ÂàÜÂ∏É
![](layer_topk_idx_distribution_bubble.png)
---

## „É©„Ç§„Çª„É≥„Çπ
„Åî‰ΩøÁî®Ââç„Å´„É©„Ç§„Çª„É≥„Çπ„Éï„Ç°„Ç§„É´„Çí„ÅîÁ¢∫Ë™ç„Åè„Å†„Åï„ÅÑ„ÄÇ  
[DeepSeek-V3](https://huggingface.co/deepseek-ai/DeepSeek-V3) „Åì„Å°„Çâ„ÅÆ„É©„Ç§„Çª„É≥„Çπ„Çí„Åù„ÅÆ„Åæ„Åæ‰ΩøÁî®„Åó„Å¶„ÅÑ„Åæ„Åô„ÄÇ  

## ÁâπÂæ¥

- MoE„É¢„Éá„É´„ÅÆexperts„Åã„Çâ„ÄÅÊó•Êú¨Ë™û„ÅÆ‰æãÊñáÂá∫Âäõ„Çí„Åó„Å¶ÂêÑlayer„Åî„Å®„Å´È†ªÂá∫„Åô„Çã64„ÅÆexpert„Çí„Åó„Å¶ÁµÑ„ÅøÁõ¥„Åó„Åü„É¢„Éá„É´„Åß„Åô„ÄÇ
- 16„Åß„ÅØ„Åæ„Å®„ÇÇ„Å´Âãï„Åã„Åö„ÄÅ32„Åß„ÅØÂÆâÂÆö„Åó„Å™„Åã„Å£„Åü„Åü„ÇÅ64experts„Å´„Åó„Å¶„ÅÑ„Åæ„Åô„ÄÇ
- scripts/layer_topk_idx_distribution.json
    - ÂêÑlayer„Åî„Å®„Å´È†ªÂá∫È†Ü„Å´128„ÅÆexpert„ÅÆrank„ÅåË®òÈå≤„Åï„Çå„Å¶„ÅÑ„Åæ„Åô„ÄÇ
- scripts/deepseek_slice.py
    - ÂÖÉ„É¢„Éá„É´Ôºàbf16Ôºâ„Åã„Çâ„ÄÅ64„ÅÆexpert„Çí‰ΩøÁî®„Åó„Åü„É¢„Éá„É´Ôºàbf16Ôºâ„Çí‰ΩúÊàê„Åó„Åæ„Åô„ÄÇ
- scripts/model_test.py
    - „É¢„Éá„É´ÂÆüË°åÁî®„ÉÜ„Çπ„ÉàÁî®„ÅÆ„Çπ„ÇØ„É™„Éó„Éà„Åß„Åô„ÄÇ„Ç≥„É°„É≥„Éà„Ç¢„Ç¶„Éà„Åï„Çå„Å¶„ÅÑ„Çã‰æãÊñá„ÇíÂÖÉ„Å´È†ªÂá∫„Åô„Çãexpert„ÇíË®àÊ∏¨„Åó„Å¶„ÅÑ„Åæ„Åô

---

## ‰Ωø„ÅÑÊñπ
`scripts/model_test.py`„Å´ÂÆüË°å„Ç≥„Éº„Éâ„ÅÇ„Çä„Åæ„Åô","{""id"": ""mmnga/DeepSeek-V3-slice-jp64"", ""author"": ""mmnga"", ""sha"": ""cb13c9b4142dcc87a95fb10db20ceb0aa4ff8d22"", ""last_modified"": ""2025-01-01 16:51:36+00:00"", ""created_at"": ""2025-01-01 15:50:29+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 8, ""downloads_all_time"": null, ""likes"": 10, ""library_name"": null, ""gguf"": null, ""inference"": null, ""tags"": [""safetensors"", ""deepseek_v3"", ""custom_code"", ""ja"", ""base_model:deepseek-ai/DeepSeek-V3"", ""base_model:finetune:deepseek-ai/DeepSeek-V3"", ""license:other"", ""region:us""], ""pipeline_tag"": null, ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model:\n- deepseek-ai/DeepSeek-V3\nlanguage:\n- ja\nlicense: other"", ""widget_data"": null, ""model_index"": null, ""config"": {""architectures"": [""DeepseekV3ForCausalLM""], ""auto_map"": {""AutoConfig"": ""configuration_deepseek.DeepseekV3Config"", ""AutoModel"": ""modeling_deepseek.DeepseekV3Model"", ""AutoModelForCausalLM"": ""modeling_deepseek.DeepseekV3ForCausalLM""}, ""model_type"": ""deepseek_v3"", ""tokenizer_config"": {""bos_token"": {""__type"": ""AddedToken"", ""content"": ""<\uff5cbegin\u2581of\u2581sentence\uff5c>"", ""lstrip"": false, ""normalized"": true, ""rstrip"": false, ""single_word"": false}, ""eos_token"": {""__type"": ""AddedToken"", ""content"": ""<\uff5cend\u2581of\u2581sentence\uff5c>"", ""lstrip"": false, ""normalized"": true, ""rstrip"": false, ""single_word"": false}, ""pad_token"": {""__type"": ""AddedToken"", ""content"": ""<\uff5cend\u2581of\u2581sentence\uff5c>"", ""lstrip"": false, ""normalized"": true, ""rstrip"": false, ""single_word"": false}, ""unk_token"": null, ""chat_template"": ""{% if not add_generation_prompt is defined %}{% set add_generation_prompt = false %}{% endif %}{% set ns = namespace(is_first=false, is_tool=false, is_output_first=true, system_prompt='', is_first_sp=true) %}{%- for message in messages %}{%- if message['role'] == 'system' %}{%- if ns.is_first_sp %}{% set ns.system_prompt = ns.system_prompt + message['content'] %}{% set ns.is_first_sp = false %}{%- else %}{% set ns.system_prompt = ns.system_prompt + '\n\n' + message['content'] %}{%- endif %}{%- endif %}{%- endfor %}{{bos_token}}{{ns.system_prompt}}{%- for message in messages %}{%- if message['role'] == 'user' %}{%- set ns.is_tool = false -%}{{'<\uff5cUser\uff5c>' + message['content']}}{%- endif %}{%- if message['role'] == 'assistant' and message['content'] is none %}{%- set ns.is_tool = false -%}{%- for tool in message['tool_calls']%}{%- if not ns.is_first %}{{'<\uff5cAssistant\uff5c><\uff5ctool\u2581calls\u2581begin\uff5c><\uff5ctool\u2581call\u2581begin\uff5c>' + tool['type'] + '<\uff5ctool\u2581sep\uff5c>' + tool['function']['name'] + '\n' + '```json' + '\n' + tool['function']['arguments'] + '\n' + '```' + '<\uff5ctool\u2581call\u2581end\uff5c>'}}{%- set ns.is_first = true -%}{%- else %}{{'\n' + '<\uff5ctool\u2581call\u2581begin\uff5c>' + tool['type'] + '<\uff5ctool\u2581sep\uff5c>' + tool['function']['name'] + '\n' + '```json' + '\n' + tool['function']['arguments'] + '\n' + '```' + '<\uff5ctool\u2581call\u2581end\uff5c>'}}{{'<\uff5ctool\u2581calls\u2581end\uff5c><\uff5cend\u2581of\u2581sentence\uff5c>'}}{%- endif %}{%- endfor %}{%- endif %}{%- if message['role'] == 'assistant' and message['content'] is not none %}{%- if ns.is_tool %}{{'<\uff5ctool\u2581outputs\u2581end\uff5c>' + message['content'] + '<\uff5cend\u2581of\u2581sentence\uff5c>'}}{%- set ns.is_tool = false -%}{%- else %}{{'<\uff5cAssistant\uff5c>' + message['content'] + '<\uff5cend\u2581of\u2581sentence\uff5c>'}}{%- endif %}{%- endif %}{%- if message['role'] == 'tool' %}{%- set ns.is_tool = true -%}{%- if ns.is_output_first %}{{'<\uff5ctool\u2581outputs\u2581begin\uff5c><\uff5ctool\u2581output\u2581begin\uff5c>' + message['content'] + '<\uff5ctool\u2581output\u2581end\uff5c>'}}{%- set ns.is_output_first = false %}{%- else %}{{'\n<\uff5ctool\u2581output\u2581begin\uff5c>' + message['content'] + '<\uff5ctool\u2581output\u2581end\uff5c>'}}{%- endif %}{%- endif %}{%- endfor -%}{% if ns.is_tool %}{{'<\uff5ctool\u2581outputs\u2581end\uff5c>'}}{% endif %}{% if add_generation_prompt and not ns.is_tool %}{{'<\uff5cAssistant\uff5c>'}}{% endif %}""}}, ""transformers_info"": null, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='LICENSE-CODE', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='LICENSE-MODEL', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README_WEIGHTS.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='configuration_deepseek.py', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='layer_topk_idx_distribution_bubble.png', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00001-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00002-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00003-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00004-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00005-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00006-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00007-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00008-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00009-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00010-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00011-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00012-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00013-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00014-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00015-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00016-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00017-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00018-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00019-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00020-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00021-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00022-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00023-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00024-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00025-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00026-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00027-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00028-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00029-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00030-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00031-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00032-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00033-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00034-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00035-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00036-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00037-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00038-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00039-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00040-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00041-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00042-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00043-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00044-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00045-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00046-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00047-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00048-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00049-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00050-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00051-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00052-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00053-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00054-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00055-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00056-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00057-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00058-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00059-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00060-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00061-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00062-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00063-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00064-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00065-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00066-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00067-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00068-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00069-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00070-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00071-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00072-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00073-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00074-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00075-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00076-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00077-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00078-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00079-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00080-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00081-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00082-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00083-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00084-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00085-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00086-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00087-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00088-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00089-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00090-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00091-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00092-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00093-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00094-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00095-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00096-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00097-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00098-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00099-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00100-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00101-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00102-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00103-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00104-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00105-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00106-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00107-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00108-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00109-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00110-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00111-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00112-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00113-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00114-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00115-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00116-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00117-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00118-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00119-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00120-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00121-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00122-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00123-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00124-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00125-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00126-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00127-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00128-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00129-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00130-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00131-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00132-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00133-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00134-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00135-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00136-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00137-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00138-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00139-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00140-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00141-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00142-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00143-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00144-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00145-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00146-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00147-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00148-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00149-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00150-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00151-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00152-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00153-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00154-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00155-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00156-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00157-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00158-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00159-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00160-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00161-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00162-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00163-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model.safetensors.index.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='modeling_deepseek.py', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='scripts/deepseek_slice.py', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='scripts/layer_topk_idx_distribution.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='scripts/model_test.py', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": {""parameters"": {""F32"": 3712, ""BF16"": 180515003392}, ""total"": 180515007104}, ""security_repo_status"": null, ""lastModified"": ""2025-01-01 16:51:36+00:00"", ""cardData"": ""base_model:\n- deepseek-ai/DeepSeek-V3\nlanguage:\n- ja\nlicense: other"", ""transformersInfo"": null, ""_id"": ""6775644527317c971aefff53"", ""modelId"": ""mmnga/DeepSeek-V3-slice-jp64"", ""usedStorage"": 361031509608}",1,,0,,0,https://huggingface.co/mmnga/DeepSeek-V3-slice-jp64-gguf,1,,0,huggingface/InferenceSupport/discussions/new?title=mmnga/DeepSeek-V3-slice-jp64&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bmmnga%2FDeepSeek-V3-slice-jp64%5D(%2Fmmnga%2FDeepSeek-V3-slice-jp64)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1
mradermacher/DeepSeek-V3-GGUF,"---
base_model: deepseek-ai/DeepSeek-V3
language:
- en
library_name: transformers
quantized_by: mradermacher
---
## About

<!-- ### quantize_version: 2 -->
<!-- ### output_tensor_quantised: 1 -->
<!-- ### convert_type: hf -->
<!-- ### vocab_type:  -->
<!-- ### tags:  -->
static quants of https://huggingface.co/deepseek-ai/DeepSeek-V3

<!-- provided-files -->
weighted/imatrix quants are available at https://huggingface.co/mradermacher/DeepSeek-V3-i1-GGUF
## Usage

If you are unsure how to use GGUF files, refer to one of [TheBloke's
READMEs](https://huggingface.co/TheBloke/KafkaLM-70B-German-V0.1-GGUF) for
more details, including on how to concatenate multi-part files.

## Provided Quants

(sorted by size, not necessarily quality. IQ-quants are often preferable over similar sized non-IQ quants)

| Link | Type | Size/GB | Notes |
|:-----|:-----|--------:|:------|
| [P1](https://huggingface.co/mradermacher/DeepSeek-V3-GGUF/resolve/main/DeepSeek-V3.Q2_K.gguf.part1of5) [P2](https://huggingface.co/mradermacher/DeepSeek-V3-GGUF/resolve/main/DeepSeek-V3.Q2_K.gguf.part2of5) [P3](https://huggingface.co/mradermacher/DeepSeek-V3-GGUF/resolve/main/DeepSeek-V3.Q2_K.gguf.part3of5) [P4](https://huggingface.co/mradermacher/DeepSeek-V3-GGUF/resolve/main/DeepSeek-V3.Q2_K.gguf.part4of5) [P5](https://huggingface.co/mradermacher/DeepSeek-V3-GGUF/resolve/main/DeepSeek-V3.Q2_K.gguf.part5of5) | Q2_K | 244.1 |  |
| [P1](https://huggingface.co/mradermacher/DeepSeek-V3-GGUF/resolve/main/DeepSeek-V3.Q3_K_S.gguf.part1of6) [P2](https://huggingface.co/mradermacher/DeepSeek-V3-GGUF/resolve/main/DeepSeek-V3.Q3_K_S.gguf.part2of6) [P3](https://huggingface.co/mradermacher/DeepSeek-V3-GGUF/resolve/main/DeepSeek-V3.Q3_K_S.gguf.part3of6) [P4](https://huggingface.co/mradermacher/DeepSeek-V3-GGUF/resolve/main/DeepSeek-V3.Q3_K_S.gguf.part4of6) [P5](https://huggingface.co/mradermacher/DeepSeek-V3-GGUF/resolve/main/DeepSeek-V3.Q3_K_S.gguf.part5of6) [P6](https://huggingface.co/mradermacher/DeepSeek-V3-GGUF/resolve/main/DeepSeek-V3.Q3_K_S.gguf.part6of6) | Q3_K_S | 289.2 |  |
| [P1](https://huggingface.co/mradermacher/DeepSeek-V3-GGUF/resolve/main/DeepSeek-V3.Q3_K_M.gguf.part1of7) [P2](https://huggingface.co/mradermacher/DeepSeek-V3-GGUF/resolve/main/DeepSeek-V3.Q3_K_M.gguf.part2of7) [P3](https://huggingface.co/mradermacher/DeepSeek-V3-GGUF/resolve/main/DeepSeek-V3.Q3_K_M.gguf.part3of7) [P4](https://huggingface.co/mradermacher/DeepSeek-V3-GGUF/resolve/main/DeepSeek-V3.Q3_K_M.gguf.part4of7) [P5](https://huggingface.co/mradermacher/DeepSeek-V3-GGUF/resolve/main/DeepSeek-V3.Q3_K_M.gguf.part5of7) [P6](https://huggingface.co/mradermacher/DeepSeek-V3-GGUF/resolve/main/DeepSeek-V3.Q3_K_M.gguf.part6of7) [P7](https://huggingface.co/mradermacher/DeepSeek-V3-GGUF/resolve/main/DeepSeek-V3.Q3_K_M.gguf.part7of7) | Q3_K_M | 319.3 | lower quality |
| [P1](https://huggingface.co/mradermacher/DeepSeek-V3-GGUF/resolve/main/DeepSeek-V3.Q3_K_L.gguf.part1of8) [P2](https://huggingface.co/mradermacher/DeepSeek-V3-GGUF/resolve/main/DeepSeek-V3.Q3_K_L.gguf.part2of8) [P3](https://huggingface.co/mradermacher/DeepSeek-V3-GGUF/resolve/main/DeepSeek-V3.Q3_K_L.gguf.part3of8) [P4](https://huggingface.co/mradermacher/DeepSeek-V3-GGUF/resolve/main/DeepSeek-V3.Q3_K_L.gguf.part4of8) [P5](https://huggingface.co/mradermacher/DeepSeek-V3-GGUF/resolve/main/DeepSeek-V3.Q3_K_L.gguf.part5of8) [P6](https://huggingface.co/mradermacher/DeepSeek-V3-GGUF/resolve/main/DeepSeek-V3.Q3_K_L.gguf.part6of8) [P7](https://huggingface.co/mradermacher/DeepSeek-V3-GGUF/resolve/main/DeepSeek-V3.Q3_K_L.gguf.part7of8) [P8](https://huggingface.co/mradermacher/DeepSeek-V3-GGUF/resolve/main/DeepSeek-V3.Q3_K_L.gguf.part8of8) | Q3_K_L | 347.5 |  |
| [P1](https://huggingface.co/mradermacher/DeepSeek-V3-GGUF/resolve/main/DeepSeek-V3.IQ4_XS.gguf.part1of8) [P2](https://huggingface.co/mradermacher/DeepSeek-V3-GGUF/resolve/main/DeepSeek-V3.IQ4_XS.gguf.part2of8) [P3](https://huggingface.co/mradermacher/DeepSeek-V3-GGUF/resolve/main/DeepSeek-V3.IQ4_XS.gguf.part3of8) [P4](https://huggingface.co/mradermacher/DeepSeek-V3-GGUF/resolve/main/DeepSeek-V3.IQ4_XS.gguf.part4of8) [P5](https://huggingface.co/mradermacher/DeepSeek-V3-GGUF/resolve/main/DeepSeek-V3.IQ4_XS.gguf.part5of8) [P6](https://huggingface.co/mradermacher/DeepSeek-V3-GGUF/resolve/main/DeepSeek-V3.IQ4_XS.gguf.part6of8) [P7](https://huggingface.co/mradermacher/DeepSeek-V3-GGUF/resolve/main/DeepSeek-V3.IQ4_XS.gguf.part7of8) [P8](https://huggingface.co/mradermacher/DeepSeek-V3-GGUF/resolve/main/DeepSeek-V3.IQ4_XS.gguf.part8of8) | IQ4_XS | 359.6 |  |
| [P1](https://huggingface.co/mradermacher/DeepSeek-V3-GGUF/resolve/main/DeepSeek-V3.Q4_K_S.gguf.part1of8) [P2](https://huggingface.co/mradermacher/DeepSeek-V3-GGUF/resolve/main/DeepSeek-V3.Q4_K_S.gguf.part2of8) [P3](https://huggingface.co/mradermacher/DeepSeek-V3-GGUF/resolve/main/DeepSeek-V3.Q4_K_S.gguf.part3of8) [P4](https://huggingface.co/mradermacher/DeepSeek-V3-GGUF/resolve/main/DeepSeek-V3.Q4_K_S.gguf.part4of8) [P5](https://huggingface.co/mradermacher/DeepSeek-V3-GGUF/resolve/main/DeepSeek-V3.Q4_K_S.gguf.part5of8) [P6](https://huggingface.co/mradermacher/DeepSeek-V3-GGUF/resolve/main/DeepSeek-V3.Q4_K_S.gguf.part6of8) [P7](https://huggingface.co/mradermacher/DeepSeek-V3-GGUF/resolve/main/DeepSeek-V3.Q4_K_S.gguf.part7of8) [P8](https://huggingface.co/mradermacher/DeepSeek-V3-GGUF/resolve/main/DeepSeek-V3.Q4_K_S.gguf.part8of8) | Q4_K_S | 380.1 | fast, recommended |
| [P1](https://huggingface.co/mradermacher/DeepSeek-V3-GGUF/resolve/main/DeepSeek-V3.Q4_K_M.gguf.part1of9) [P2](https://huggingface.co/mradermacher/DeepSeek-V3-GGUF/resolve/main/DeepSeek-V3.Q4_K_M.gguf.part2of9) [P3](https://huggingface.co/mradermacher/DeepSeek-V3-GGUF/resolve/main/DeepSeek-V3.Q4_K_M.gguf.part3of9) [P4](https://huggingface.co/mradermacher/DeepSeek-V3-GGUF/resolve/main/DeepSeek-V3.Q4_K_M.gguf.part4of9) [P5](https://huggingface.co/mradermacher/DeepSeek-V3-GGUF/resolve/main/DeepSeek-V3.Q4_K_M.gguf.part5of9) [P6](https://huggingface.co/mradermacher/DeepSeek-V3-GGUF/resolve/main/DeepSeek-V3.Q4_K_M.gguf.part6of9) [P7](https://huggingface.co/mradermacher/DeepSeek-V3-GGUF/resolve/main/DeepSeek-V3.Q4_K_M.gguf.part7of9) [P8](https://huggingface.co/mradermacher/DeepSeek-V3-GGUF/resolve/main/DeepSeek-V3.Q4_K_M.gguf.part8of9) [P9](https://huggingface.co/mradermacher/DeepSeek-V3-GGUF/resolve/main/DeepSeek-V3.Q4_K_M.gguf.part9of9) | Q4_K_M | 404.5 | fast, recommended |
| [P1](https://huggingface.co/mradermacher/DeepSeek-V3-GGUF/resolve/main/DeepSeek-V3.Q5_K_S.gguf.part01of10) [P2](https://huggingface.co/mradermacher/DeepSeek-V3-GGUF/resolve/main/DeepSeek-V3.Q5_K_S.gguf.part02of10) [P3](https://huggingface.co/mradermacher/DeepSeek-V3-GGUF/resolve/main/DeepSeek-V3.Q5_K_S.gguf.part03of10) [P4](https://huggingface.co/mradermacher/DeepSeek-V3-GGUF/resolve/main/DeepSeek-V3.Q5_K_S.gguf.part04of10) [P5](https://huggingface.co/mradermacher/DeepSeek-V3-GGUF/resolve/main/DeepSeek-V3.Q5_K_S.gguf.part05of10) [P6](https://huggingface.co/mradermacher/DeepSeek-V3-GGUF/resolve/main/DeepSeek-V3.Q5_K_S.gguf.part06of10) [P7](https://huggingface.co/mradermacher/DeepSeek-V3-GGUF/resolve/main/DeepSeek-V3.Q5_K_S.gguf.part07of10) [P8](https://huggingface.co/mradermacher/DeepSeek-V3-GGUF/resolve/main/DeepSeek-V3.Q5_K_S.gguf.part08of10) [P9](https://huggingface.co/mradermacher/DeepSeek-V3-GGUF/resolve/main/DeepSeek-V3.Q5_K_S.gguf.part09of10) [P10](https://huggingface.co/mradermacher/DeepSeek-V3-GGUF/resolve/main/DeepSeek-V3.Q5_K_S.gguf.part10of10) | Q5_K_S | 461.9 |  |
| [P1](https://huggingface.co/mradermacher/DeepSeek-V3-GGUF/resolve/main/DeepSeek-V3.Q5_K_M.gguf.part01of10) [P2](https://huggingface.co/mradermacher/DeepSeek-V3-GGUF/resolve/main/DeepSeek-V3.Q5_K_M.gguf.part02of10) [P3](https://huggingface.co/mradermacher/DeepSeek-V3-GGUF/resolve/main/DeepSeek-V3.Q5_K_M.gguf.part03of10) [P4](https://huggingface.co/mradermacher/DeepSeek-V3-GGUF/resolve/main/DeepSeek-V3.Q5_K_M.gguf.part04of10) [P5](https://huggingface.co/mradermacher/DeepSeek-V3-GGUF/resolve/main/DeepSeek-V3.Q5_K_M.gguf.part05of10) [P6](https://huggingface.co/mradermacher/DeepSeek-V3-GGUF/resolve/main/DeepSeek-V3.Q5_K_M.gguf.part06of10) [P7](https://huggingface.co/mradermacher/DeepSeek-V3-GGUF/resolve/main/DeepSeek-V3.Q5_K_M.gguf.part07of10) [P8](https://huggingface.co/mradermacher/DeepSeek-V3-GGUF/resolve/main/DeepSeek-V3.Q5_K_M.gguf.part08of10) [P9](https://huggingface.co/mradermacher/DeepSeek-V3-GGUF/resolve/main/DeepSeek-V3.Q5_K_M.gguf.part09of10) [P10](https://huggingface.co/mradermacher/DeepSeek-V3-GGUF/resolve/main/DeepSeek-V3.Q5_K_M.gguf.part10of10) | Q5_K_M | 475.5 |  |
| [P1](https://huggingface.co/mradermacher/DeepSeek-V3-GGUF/resolve/main/DeepSeek-V3.Q6_K.gguf.part01of12) [P2](https://huggingface.co/mradermacher/DeepSeek-V3-GGUF/resolve/main/DeepSeek-V3.Q6_K.gguf.part02of12) [P3](https://huggingface.co/mradermacher/DeepSeek-V3-GGUF/resolve/main/DeepSeek-V3.Q6_K.gguf.part03of12) [P4](https://huggingface.co/mradermacher/DeepSeek-V3-GGUF/resolve/main/DeepSeek-V3.Q6_K.gguf.part04of12) [P5](https://huggingface.co/mradermacher/DeepSeek-V3-GGUF/resolve/main/DeepSeek-V3.Q6_K.gguf.part05of12) [P6](https://huggingface.co/mradermacher/DeepSeek-V3-GGUF/resolve/main/DeepSeek-V3.Q6_K.gguf.part06of12) [P7](https://huggingface.co/mradermacher/DeepSeek-V3-GGUF/resolve/main/DeepSeek-V3.Q6_K.gguf.part07of12) [P8](https://huggingface.co/mradermacher/DeepSeek-V3-GGUF/resolve/main/DeepSeek-V3.Q6_K.gguf.part08of12) [P9](https://huggingface.co/mradermacher/DeepSeek-V3-GGUF/resolve/main/DeepSeek-V3.Q6_K.gguf.part09of12) [P10](https://huggingface.co/mradermacher/DeepSeek-V3-GGUF/resolve/main/DeepSeek-V3.Q6_K.gguf.part10of12) [P11](https://huggingface.co/mradermacher/DeepSeek-V3-GGUF/resolve/main/DeepSeek-V3.Q6_K.gguf.part11of12) [P12](https://huggingface.co/mradermacher/DeepSeek-V3-GGUF/resolve/main/DeepSeek-V3.Q6_K.gguf.part12of12) | Q6_K | 550.9 | very good quality |
| [P1](https://huggingface.co/mradermacher/DeepSeek-V3-GGUF/resolve/main/DeepSeek-V3.Q8_0.gguf.part01of18) [P2](https://huggingface.co/mradermacher/DeepSeek-V3-GGUF/resolve/main/DeepSeek-V3.Q8_0.gguf.part02of18) [P3](https://huggingface.co/mradermacher/DeepSeek-V3-GGUF/resolve/main/DeepSeek-V3.Q8_0.gguf.part03of18) [P4](https://huggingface.co/mradermacher/DeepSeek-V3-GGUF/resolve/main/DeepSeek-V3.Q8_0.gguf.part04of18) [P5](https://huggingface.co/mradermacher/DeepSeek-V3-GGUF/resolve/main/DeepSeek-V3.Q8_0.gguf.part05of18) [P6](https://huggingface.co/mradermacher/DeepSeek-V3-GGUF/resolve/main/DeepSeek-V3.Q8_0.gguf.part06of18) [P7](https://huggingface.co/mradermacher/DeepSeek-V3-GGUF/resolve/main/DeepSeek-V3.Q8_0.gguf.part07of18) [P8](https://huggingface.co/mradermacher/DeepSeek-V3-GGUF/resolve/main/DeepSeek-V3.Q8_0.gguf.part08of18) [P9](https://huggingface.co/mradermacher/DeepSeek-V3-GGUF/resolve/main/DeepSeek-V3.Q8_0.gguf.part09of18) [P10](https://huggingface.co/mradermacher/DeepSeek-V3-GGUF/resolve/main/DeepSeek-V3.Q8_0.gguf.part10of18) [P11](https://huggingface.co/mradermacher/DeepSeek-V3-GGUF/resolve/main/DeepSeek-V3.Q8_0.gguf.part11of18) [P12](https://huggingface.co/mradermacher/DeepSeek-V3-GGUF/resolve/main/DeepSeek-V3.Q8_0.gguf.part12of18) [P13](https://huggingface.co/mradermacher/DeepSeek-V3-GGUF/resolve/main/DeepSeek-V3.Q8_0.gguf.part13of18) [P14](https://huggingface.co/mradermacher/DeepSeek-V3-GGUF/resolve/main/DeepSeek-V3.Q8_0.gguf.part14of18) [P15](https://huggingface.co/mradermacher/DeepSeek-V3-GGUF/resolve/main/DeepSeek-V3.Q8_0.gguf.part15of18) [P16](https://huggingface.co/mradermacher/DeepSeek-V3-GGUF/resolve/main/DeepSeek-V3.Q8_0.gguf.part16of18) [P17](https://huggingface.co/mradermacher/DeepSeek-V3-GGUF/resolve/main/DeepSeek-V3.Q8_0.gguf.part17of18) [P18](https://huggingface.co/mradermacher/DeepSeek-V3-GGUF/resolve/main/DeepSeek-V3.Q8_0.gguf.part18of18) | Q8_0 | 713.4 | fast, best quality |

Here is a handy graph by ikawrakow comparing some lower-quality quant
types (lower is better):

![image.png](https://www.nethype.de/huggingface_embed/quantpplgraph.png)

And here are Artefact2's thoughts on the matter:
https://gist.github.com/Artefact2/b5f810600771265fc1e39442288e8ec9

## FAQ / Model Request

See https://huggingface.co/mradermacher/model_requests for some answers to
questions you might have and/or if you want some other model quantized.

## Thanks

I thank my company, [nethype GmbH](https://www.nethype.de/), for letting
me use its servers and providing upgrades to my workstation to enable
this work in my free time. Additional thanks to [@nicoboss](https://huggingface.co/nicoboss) for giving me access to his private supercomputer, enabling me to provide many more imatrix quants, at much higher quality, than I would otherwise be able to.

<!-- end -->
","{""id"": ""mradermacher/DeepSeek-V3-GGUF"", ""author"": ""mradermacher"", ""sha"": ""375360c5f8eccfc71478524e8bd3d5cf6432e498"", ""last_modified"": ""2025-01-10 04:02:55+00:00"", ""created_at"": ""2025-01-05 15:20:52+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 14, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""en"", ""base_model:deepseek-ai/DeepSeek-V3"", ""base_model:finetune:deepseek-ai/DeepSeek-V3"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": null, ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: deepseek-ai/DeepSeek-V3\nlanguage:\n- en\nlibrary_name: transformers\nquantized_by: mradermacher"", ""widget_data"": null, ""model_index"": null, ""config"": null, ""transformers_info"": {""auto_model"": ""AutoModel"", ""custom_class"": null, ""pipeline_tag"": null, ""processor"": null}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.IQ4_XS.gguf.part1of8', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.IQ4_XS.gguf.part2of8', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.IQ4_XS.gguf.part3of8', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.IQ4_XS.gguf.part4of8', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.IQ4_XS.gguf.part5of8', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.IQ4_XS.gguf.part6of8', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.IQ4_XS.gguf.part7of8', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.IQ4_XS.gguf.part8of8', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.Q2_K.gguf.part1of5', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.Q2_K.gguf.part2of5', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.Q2_K.gguf.part3of5', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.Q2_K.gguf.part4of5', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.Q2_K.gguf.part5of5', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.Q3_K_L.gguf.part1of8', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.Q3_K_L.gguf.part2of8', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.Q3_K_L.gguf.part3of8', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.Q3_K_L.gguf.part4of8', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.Q3_K_L.gguf.part5of8', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.Q3_K_L.gguf.part6of8', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.Q3_K_L.gguf.part7of8', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.Q3_K_L.gguf.part8of8', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.Q3_K_M.gguf.part1of7', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.Q3_K_M.gguf.part2of7', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.Q3_K_M.gguf.part3of7', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.Q3_K_M.gguf.part4of7', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.Q3_K_M.gguf.part5of7', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.Q3_K_M.gguf.part6of7', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.Q3_K_M.gguf.part7of7', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.Q3_K_S.gguf.part1of6', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.Q3_K_S.gguf.part2of6', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.Q3_K_S.gguf.part3of6', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.Q3_K_S.gguf.part4of6', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.Q3_K_S.gguf.part5of6', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.Q3_K_S.gguf.part6of6', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.Q4_K_M.gguf.part1of9', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.Q4_K_M.gguf.part2of9', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.Q4_K_M.gguf.part3of9', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.Q4_K_M.gguf.part4of9', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.Q4_K_M.gguf.part5of9', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.Q4_K_M.gguf.part6of9', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.Q4_K_M.gguf.part7of9', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.Q4_K_M.gguf.part8of9', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.Q4_K_M.gguf.part9of9', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.Q4_K_S.gguf.part1of8', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.Q4_K_S.gguf.part2of8', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.Q4_K_S.gguf.part3of8', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.Q4_K_S.gguf.part4of8', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.Q4_K_S.gguf.part5of8', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.Q4_K_S.gguf.part6of8', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.Q4_K_S.gguf.part7of8', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.Q4_K_S.gguf.part8of8', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.Q5_K_M.gguf.part01of10', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.Q5_K_M.gguf.part02of10', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.Q5_K_M.gguf.part03of10', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.Q5_K_M.gguf.part04of10', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.Q5_K_M.gguf.part05of10', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.Q5_K_M.gguf.part06of10', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.Q5_K_M.gguf.part07of10', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.Q5_K_M.gguf.part08of10', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.Q5_K_M.gguf.part09of10', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.Q5_K_M.gguf.part10of10', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.Q5_K_S.gguf.part01of10', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.Q5_K_S.gguf.part02of10', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.Q5_K_S.gguf.part03of10', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.Q5_K_S.gguf.part04of10', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.Q5_K_S.gguf.part05of10', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.Q5_K_S.gguf.part06of10', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.Q5_K_S.gguf.part07of10', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.Q5_K_S.gguf.part08of10', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.Q5_K_S.gguf.part09of10', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.Q5_K_S.gguf.part10of10', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.Q6_K.gguf.part01of12', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.Q6_K.gguf.part02of12', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.Q6_K.gguf.part03of12', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.Q6_K.gguf.part04of12', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.Q6_K.gguf.part05of12', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.Q6_K.gguf.part06of12', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.Q6_K.gguf.part07of12', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.Q6_K.gguf.part08of12', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.Q6_K.gguf.part09of12', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.Q6_K.gguf.part10of12', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.Q6_K.gguf.part11of12', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.Q6_K.gguf.part12of12', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.Q8_0.gguf.part01of18', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.Q8_0.gguf.part02of18', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.Q8_0.gguf.part03of18', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.Q8_0.gguf.part04of18', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.Q8_0.gguf.part05of18', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.Q8_0.gguf.part06of18', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.Q8_0.gguf.part07of18', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.Q8_0.gguf.part08of18', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.Q8_0.gguf.part09of18', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.Q8_0.gguf.part10of18', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.Q8_0.gguf.part11of18', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.Q8_0.gguf.part12of18', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.Q8_0.gguf.part13of18', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.Q8_0.gguf.part14of18', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.Q8_0.gguf.part15of18', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.Q8_0.gguf.part16of18', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.Q8_0.gguf.part17of18', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.Q8_0.gguf.part18of18', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-01-10 04:02:55+00:00"", ""cardData"": ""base_model: deepseek-ai/DeepSeek-V3\nlanguage:\n- en\nlibrary_name: transformers\nquantized_by: mradermacher"", ""transformersInfo"": {""auto_model"": ""AutoModel"", ""custom_class"": null, ""pipeline_tag"": null, ""processor"": null}, ""_id"": ""677aa354b93ea123a5eaaffb"", ""modelId"": ""mradermacher/DeepSeek-V3-GGUF"", ""usedStorage"": 4545032857600}",1,,0,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=mradermacher/DeepSeek-V3-GGUF&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bmradermacher%2FDeepSeek-V3-GGUF%5D(%2Fmradermacher%2FDeepSeek-V3-GGUF)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1
mradermacher/DeepSeek-V3-i1-GGUF,"---
base_model: deepseek-ai/DeepSeek-V3
language:
- en
library_name: transformers
quantized_by: mradermacher
---
## About

<!-- ### quantize_version: 2 -->
<!-- ### output_tensor_quantised: 1 -->
<!-- ### convert_type: hf -->
<!-- ### vocab_type:  -->
<!-- ### tags: nicoboss -->
weighted/imatrix quants of https://huggingface.co/deepseek-ai/DeepSeek-V3

<!-- provided-files -->
static quants are available at https://huggingface.co/mradermacher/DeepSeek-V3-GGUF
## Usage

If you are unsure how to use GGUF files, refer to one of [TheBloke's
READMEs](https://huggingface.co/TheBloke/KafkaLM-70B-German-V0.1-GGUF) for
more details, including on how to concatenate multi-part files.

## Provided Quants

(sorted by size, not necessarily quality. IQ-quants are often preferable over similar sized non-IQ quants)

| Link | Type | Size/GB | Notes |
|:-----|:-----|--------:|:------|
| [PART 1](https://huggingface.co/mradermacher/DeepSeek-V3-i1-GGUF/resolve/main/DeepSeek-V3.i1-IQ1_S.gguf.part1of3) [PART 2](https://huggingface.co/mradermacher/DeepSeek-V3-i1-GGUF/resolve/main/DeepSeek-V3.i1-IQ1_S.gguf.part2of3) [PART 3](https://huggingface.co/mradermacher/DeepSeek-V3-i1-GGUF/resolve/main/DeepSeek-V3.i1-IQ1_S.gguf.part3of3) | i1-IQ1_S | 133.7 | for the desperate |
| [PART 1](https://huggingface.co/mradermacher/DeepSeek-V3-i1-GGUF/resolve/main/DeepSeek-V3.i1-IQ1_M.gguf.part1of4) [PART 2](https://huggingface.co/mradermacher/DeepSeek-V3-i1-GGUF/resolve/main/DeepSeek-V3.i1-IQ1_M.gguf.part2of4) [PART 3](https://huggingface.co/mradermacher/DeepSeek-V3-i1-GGUF/resolve/main/DeepSeek-V3.i1-IQ1_M.gguf.part3of4) [PART 4](https://huggingface.co/mradermacher/DeepSeek-V3-i1-GGUF/resolve/main/DeepSeek-V3.i1-IQ1_M.gguf.part4of4) | i1-IQ1_M | 149.0 | mostly desperate |
| [PART 1](https://huggingface.co/mradermacher/DeepSeek-V3-i1-GGUF/resolve/main/DeepSeek-V3.i1-IQ2_XXS.gguf.part1of4) [PART 2](https://huggingface.co/mradermacher/DeepSeek-V3-i1-GGUF/resolve/main/DeepSeek-V3.i1-IQ2_XXS.gguf.part2of4) [PART 3](https://huggingface.co/mradermacher/DeepSeek-V3-i1-GGUF/resolve/main/DeepSeek-V3.i1-IQ2_XXS.gguf.part3of4) [PART 4](https://huggingface.co/mradermacher/DeepSeek-V3-i1-GGUF/resolve/main/DeepSeek-V3.i1-IQ2_XXS.gguf.part4of4) | i1-IQ2_XXS | 174.5 |  |
| [PART 1](https://huggingface.co/mradermacher/DeepSeek-V3-i1-GGUF/resolve/main/DeepSeek-V3.i1-IQ2_XS.gguf.part1of4) [PART 2](https://huggingface.co/mradermacher/DeepSeek-V3-i1-GGUF/resolve/main/DeepSeek-V3.i1-IQ2_XS.gguf.part2of4) [PART 3](https://huggingface.co/mradermacher/DeepSeek-V3-i1-GGUF/resolve/main/DeepSeek-V3.i1-IQ2_XS.gguf.part3of4) [PART 4](https://huggingface.co/mradermacher/DeepSeek-V3-i1-GGUF/resolve/main/DeepSeek-V3.i1-IQ2_XS.gguf.part4of4) | i1-IQ2_XS | 195.2 |  |
| [PART 1](https://huggingface.co/mradermacher/DeepSeek-V3-i1-GGUF/resolve/main/DeepSeek-V3.i1-IQ2_S.gguf.part1of4) [PART 2](https://huggingface.co/mradermacher/DeepSeek-V3-i1-GGUF/resolve/main/DeepSeek-V3.i1-IQ2_S.gguf.part2of4) [PART 3](https://huggingface.co/mradermacher/DeepSeek-V3-i1-GGUF/resolve/main/DeepSeek-V3.i1-IQ2_S.gguf.part3of4) [PART 4](https://huggingface.co/mradermacher/DeepSeek-V3-i1-GGUF/resolve/main/DeepSeek-V3.i1-IQ2_S.gguf.part4of4) | i1-IQ2_S | 197.1 |  |
| [P1](https://huggingface.co/mradermacher/DeepSeek-V3-i1-GGUF/resolve/main/DeepSeek-V3.i1-IQ2_M.gguf.part1of5) [P2](https://huggingface.co/mradermacher/DeepSeek-V3-i1-GGUF/resolve/main/DeepSeek-V3.i1-IQ2_M.gguf.part2of5) [P3](https://huggingface.co/mradermacher/DeepSeek-V3-i1-GGUF/resolve/main/DeepSeek-V3.i1-IQ2_M.gguf.part3of5) [P4](https://huggingface.co/mradermacher/DeepSeek-V3-i1-GGUF/resolve/main/DeepSeek-V3.i1-IQ2_M.gguf.part4of5) [P5](https://huggingface.co/mradermacher/DeepSeek-V3-i1-GGUF/resolve/main/DeepSeek-V3.i1-IQ2_M.gguf.part5of5) | i1-IQ2_M | 217.5 |  |
| [P1](https://huggingface.co/mradermacher/DeepSeek-V3-i1-GGUF/resolve/main/DeepSeek-V3.i1-Q2_K_S.gguf.part1of5) [P2](https://huggingface.co/mradermacher/DeepSeek-V3-i1-GGUF/resolve/main/DeepSeek-V3.i1-Q2_K_S.gguf.part2of5) [P3](https://huggingface.co/mradermacher/DeepSeek-V3-i1-GGUF/resolve/main/DeepSeek-V3.i1-Q2_K_S.gguf.part3of5) [P4](https://huggingface.co/mradermacher/DeepSeek-V3-i1-GGUF/resolve/main/DeepSeek-V3.i1-Q2_K_S.gguf.part4of5) [P5](https://huggingface.co/mradermacher/DeepSeek-V3-i1-GGUF/resolve/main/DeepSeek-V3.i1-Q2_K_S.gguf.part5of5) | i1-Q2_K_S | 224.8 | very low quality |
| [P1](https://huggingface.co/mradermacher/DeepSeek-V3-i1-GGUF/resolve/main/DeepSeek-V3.i1-Q2_K.gguf.part1of5) [P2](https://huggingface.co/mradermacher/DeepSeek-V3-i1-GGUF/resolve/main/DeepSeek-V3.i1-Q2_K.gguf.part2of5) [P3](https://huggingface.co/mradermacher/DeepSeek-V3-i1-GGUF/resolve/main/DeepSeek-V3.i1-Q2_K.gguf.part3of5) [P4](https://huggingface.co/mradermacher/DeepSeek-V3-i1-GGUF/resolve/main/DeepSeek-V3.i1-Q2_K.gguf.part4of5) [P5](https://huggingface.co/mradermacher/DeepSeek-V3-i1-GGUF/resolve/main/DeepSeek-V3.i1-Q2_K.gguf.part5of5) | i1-Q2_K | 244.1 | IQ3_XXS probably better |
| [P1](https://huggingface.co/mradermacher/DeepSeek-V3-i1-GGUF/resolve/main/DeepSeek-V3.i1-IQ3_XXS.gguf.part1of6) [P2](https://huggingface.co/mradermacher/DeepSeek-V3-i1-GGUF/resolve/main/DeepSeek-V3.i1-IQ3_XXS.gguf.part2of6) [P3](https://huggingface.co/mradermacher/DeepSeek-V3-i1-GGUF/resolve/main/DeepSeek-V3.i1-IQ3_XXS.gguf.part3of6) [P4](https://huggingface.co/mradermacher/DeepSeek-V3-i1-GGUF/resolve/main/DeepSeek-V3.i1-IQ3_XXS.gguf.part4of6) [P5](https://huggingface.co/mradermacher/DeepSeek-V3-i1-GGUF/resolve/main/DeepSeek-V3.i1-IQ3_XXS.gguf.part5of6) [P6](https://huggingface.co/mradermacher/DeepSeek-V3-i1-GGUF/resolve/main/DeepSeek-V3.i1-IQ3_XXS.gguf.part6of6) | i1-IQ3_XXS | 258.0 | lower quality |
| [P1](https://huggingface.co/mradermacher/DeepSeek-V3-i1-GGUF/resolve/main/DeepSeek-V3.i1-IQ3_XS.gguf.part1of6) [P2](https://huggingface.co/mradermacher/DeepSeek-V3-i1-GGUF/resolve/main/DeepSeek-V3.i1-IQ3_XS.gguf.part2of6) [P3](https://huggingface.co/mradermacher/DeepSeek-V3-i1-GGUF/resolve/main/DeepSeek-V3.i1-IQ3_XS.gguf.part3of6) [P4](https://huggingface.co/mradermacher/DeepSeek-V3-i1-GGUF/resolve/main/DeepSeek-V3.i1-IQ3_XS.gguf.part4of6) [P5](https://huggingface.co/mradermacher/DeepSeek-V3-i1-GGUF/resolve/main/DeepSeek-V3.i1-IQ3_XS.gguf.part5of6) [P6](https://huggingface.co/mradermacher/DeepSeek-V3-i1-GGUF/resolve/main/DeepSeek-V3.i1-IQ3_XS.gguf.part6of6) | i1-IQ3_XS | 272.9 |  |
| [P1](https://huggingface.co/mradermacher/DeepSeek-V3-i1-GGUF/resolve/main/DeepSeek-V3.i1-IQ3_S.gguf.part1of6) [P2](https://huggingface.co/mradermacher/DeepSeek-V3-i1-GGUF/resolve/main/DeepSeek-V3.i1-IQ3_S.gguf.part2of6) [P3](https://huggingface.co/mradermacher/DeepSeek-V3-i1-GGUF/resolve/main/DeepSeek-V3.i1-IQ3_S.gguf.part3of6) [P4](https://huggingface.co/mradermacher/DeepSeek-V3-i1-GGUF/resolve/main/DeepSeek-V3.i1-IQ3_S.gguf.part4of6) [P5](https://huggingface.co/mradermacher/DeepSeek-V3-i1-GGUF/resolve/main/DeepSeek-V3.i1-IQ3_S.gguf.part5of6) [P6](https://huggingface.co/mradermacher/DeepSeek-V3-i1-GGUF/resolve/main/DeepSeek-V3.i1-IQ3_S.gguf.part6of6) | i1-IQ3_S | 289.2 | beats Q3_K* |
| [P1](https://huggingface.co/mradermacher/DeepSeek-V3-i1-GGUF/resolve/main/DeepSeek-V3.i1-Q3_K_S.gguf.part1of6) [P2](https://huggingface.co/mradermacher/DeepSeek-V3-i1-GGUF/resolve/main/DeepSeek-V3.i1-Q3_K_S.gguf.part2of6) [P3](https://huggingface.co/mradermacher/DeepSeek-V3-i1-GGUF/resolve/main/DeepSeek-V3.i1-Q3_K_S.gguf.part3of6) [P4](https://huggingface.co/mradermacher/DeepSeek-V3-i1-GGUF/resolve/main/DeepSeek-V3.i1-Q3_K_S.gguf.part4of6) [P5](https://huggingface.co/mradermacher/DeepSeek-V3-i1-GGUF/resolve/main/DeepSeek-V3.i1-Q3_K_S.gguf.part5of6) [P6](https://huggingface.co/mradermacher/DeepSeek-V3-i1-GGUF/resolve/main/DeepSeek-V3.i1-Q3_K_S.gguf.part6of6) | i1-Q3_K_S | 289.2 | IQ3_XS probably better |
| [P1](https://huggingface.co/mradermacher/DeepSeek-V3-i1-GGUF/resolve/main/DeepSeek-V3.i1-IQ3_M.gguf.part1of6) [P2](https://huggingface.co/mradermacher/DeepSeek-V3-i1-GGUF/resolve/main/DeepSeek-V3.i1-IQ3_M.gguf.part2of6) [P3](https://huggingface.co/mradermacher/DeepSeek-V3-i1-GGUF/resolve/main/DeepSeek-V3.i1-IQ3_M.gguf.part3of6) [P4](https://huggingface.co/mradermacher/DeepSeek-V3-i1-GGUF/resolve/main/DeepSeek-V3.i1-IQ3_M.gguf.part4of6) [P5](https://huggingface.co/mradermacher/DeepSeek-V3-i1-GGUF/resolve/main/DeepSeek-V3.i1-IQ3_M.gguf.part5of6) [P6](https://huggingface.co/mradermacher/DeepSeek-V3-i1-GGUF/resolve/main/DeepSeek-V3.i1-IQ3_M.gguf.part6of6) | i1-IQ3_M | 292.2 |  |
| [P1](https://huggingface.co/mradermacher/DeepSeek-V3-i1-GGUF/resolve/main/DeepSeek-V3.i1-Q3_K_M.gguf.part1of7) [P2](https://huggingface.co/mradermacher/DeepSeek-V3-i1-GGUF/resolve/main/DeepSeek-V3.i1-Q3_K_M.gguf.part2of7) [P3](https://huggingface.co/mradermacher/DeepSeek-V3-i1-GGUF/resolve/main/DeepSeek-V3.i1-Q3_K_M.gguf.part3of7) [P4](https://huggingface.co/mradermacher/DeepSeek-V3-i1-GGUF/resolve/main/DeepSeek-V3.i1-Q3_K_M.gguf.part4of7) [P5](https://huggingface.co/mradermacher/DeepSeek-V3-i1-GGUF/resolve/main/DeepSeek-V3.i1-Q3_K_M.gguf.part5of7) [P6](https://huggingface.co/mradermacher/DeepSeek-V3-i1-GGUF/resolve/main/DeepSeek-V3.i1-Q3_K_M.gguf.part6of7) [P7](https://huggingface.co/mradermacher/DeepSeek-V3-i1-GGUF/resolve/main/DeepSeek-V3.i1-Q3_K_M.gguf.part7of7) | i1-Q3_K_M | 319.3 | IQ3_S probably better |
| [P1](https://huggingface.co/mradermacher/DeepSeek-V3-i1-GGUF/resolve/main/DeepSeek-V3.i1-Q3_K_L.gguf.part1of8) [P2](https://huggingface.co/mradermacher/DeepSeek-V3-i1-GGUF/resolve/main/DeepSeek-V3.i1-Q3_K_L.gguf.part2of8) [P3](https://huggingface.co/mradermacher/DeepSeek-V3-i1-GGUF/resolve/main/DeepSeek-V3.i1-Q3_K_L.gguf.part3of8) [P4](https://huggingface.co/mradermacher/DeepSeek-V3-i1-GGUF/resolve/main/DeepSeek-V3.i1-Q3_K_L.gguf.part4of8) [P5](https://huggingface.co/mradermacher/DeepSeek-V3-i1-GGUF/resolve/main/DeepSeek-V3.i1-Q3_K_L.gguf.part5of8) [P6](https://huggingface.co/mradermacher/DeepSeek-V3-i1-GGUF/resolve/main/DeepSeek-V3.i1-Q3_K_L.gguf.part6of8) [P7](https://huggingface.co/mradermacher/DeepSeek-V3-i1-GGUF/resolve/main/DeepSeek-V3.i1-Q3_K_L.gguf.part7of8) [P8](https://huggingface.co/mradermacher/DeepSeek-V3-i1-GGUF/resolve/main/DeepSeek-V3.i1-Q3_K_L.gguf.part8of8) | i1-Q3_K_L | 347.5 | IQ3_M probably better |
| [P1](https://huggingface.co/mradermacher/DeepSeek-V3-i1-GGUF/resolve/main/DeepSeek-V3.i1-IQ4_XS.gguf.part1of8) [P2](https://huggingface.co/mradermacher/DeepSeek-V3-i1-GGUF/resolve/main/DeepSeek-V3.i1-IQ4_XS.gguf.part2of8) [P3](https://huggingface.co/mradermacher/DeepSeek-V3-i1-GGUF/resolve/main/DeepSeek-V3.i1-IQ4_XS.gguf.part3of8) [P4](https://huggingface.co/mradermacher/DeepSeek-V3-i1-GGUF/resolve/main/DeepSeek-V3.i1-IQ4_XS.gguf.part4of8) [P5](https://huggingface.co/mradermacher/DeepSeek-V3-i1-GGUF/resolve/main/DeepSeek-V3.i1-IQ4_XS.gguf.part5of8) [P6](https://huggingface.co/mradermacher/DeepSeek-V3-i1-GGUF/resolve/main/DeepSeek-V3.i1-IQ4_XS.gguf.part6of8) [P7](https://huggingface.co/mradermacher/DeepSeek-V3-i1-GGUF/resolve/main/DeepSeek-V3.i1-IQ4_XS.gguf.part7of8) [P8](https://huggingface.co/mradermacher/DeepSeek-V3-i1-GGUF/resolve/main/DeepSeek-V3.i1-IQ4_XS.gguf.part8of8) | i1-IQ4_XS | 357.2 |  |
| [P1](https://huggingface.co/mradermacher/DeepSeek-V3-i1-GGUF/resolve/main/DeepSeek-V3.i1-Q4_0.gguf.part1of8) [P2](https://huggingface.co/mradermacher/DeepSeek-V3-i1-GGUF/resolve/main/DeepSeek-V3.i1-Q4_0.gguf.part2of8) [P3](https://huggingface.co/mradermacher/DeepSeek-V3-i1-GGUF/resolve/main/DeepSeek-V3.i1-Q4_0.gguf.part3of8) [P4](https://huggingface.co/mradermacher/DeepSeek-V3-i1-GGUF/resolve/main/DeepSeek-V3.i1-Q4_0.gguf.part4of8) [P5](https://huggingface.co/mradermacher/DeepSeek-V3-i1-GGUF/resolve/main/DeepSeek-V3.i1-Q4_0.gguf.part5of8) [P6](https://huggingface.co/mradermacher/DeepSeek-V3-i1-GGUF/resolve/main/DeepSeek-V3.i1-Q4_0.gguf.part6of8) [P7](https://huggingface.co/mradermacher/DeepSeek-V3-i1-GGUF/resolve/main/DeepSeek-V3.i1-Q4_0.gguf.part7of8) [P8](https://huggingface.co/mradermacher/DeepSeek-V3-i1-GGUF/resolve/main/DeepSeek-V3.i1-Q4_0.gguf.part8of8) | i1-Q4_0 | 379.1 | fast, low quality |
| [P1](https://huggingface.co/mradermacher/DeepSeek-V3-i1-GGUF/resolve/main/DeepSeek-V3.i1-Q4_K_S.gguf.part1of8) [P2](https://huggingface.co/mradermacher/DeepSeek-V3-i1-GGUF/resolve/main/DeepSeek-V3.i1-Q4_K_S.gguf.part2of8) [P3](https://huggingface.co/mradermacher/DeepSeek-V3-i1-GGUF/resolve/main/DeepSeek-V3.i1-Q4_K_S.gguf.part3of8) [P4](https://huggingface.co/mradermacher/DeepSeek-V3-i1-GGUF/resolve/main/DeepSeek-V3.i1-Q4_K_S.gguf.part4of8) [P5](https://huggingface.co/mradermacher/DeepSeek-V3-i1-GGUF/resolve/main/DeepSeek-V3.i1-Q4_K_S.gguf.part5of8) [P6](https://huggingface.co/mradermacher/DeepSeek-V3-i1-GGUF/resolve/main/DeepSeek-V3.i1-Q4_K_S.gguf.part6of8) [P7](https://huggingface.co/mradermacher/DeepSeek-V3-i1-GGUF/resolve/main/DeepSeek-V3.i1-Q4_K_S.gguf.part7of8) [P8](https://huggingface.co/mradermacher/DeepSeek-V3-i1-GGUF/resolve/main/DeepSeek-V3.i1-Q4_K_S.gguf.part8of8) | i1-Q4_K_S | 380.1 | optimal size/speed/quality |
| [P1](https://huggingface.co/mradermacher/DeepSeek-V3-i1-GGUF/resolve/main/DeepSeek-V3.i1-Q4_K_M.gguf.part1of9) [P2](https://huggingface.co/mradermacher/DeepSeek-V3-i1-GGUF/resolve/main/DeepSeek-V3.i1-Q4_K_M.gguf.part2of9) [P3](https://huggingface.co/mradermacher/DeepSeek-V3-i1-GGUF/resolve/main/DeepSeek-V3.i1-Q4_K_M.gguf.part3of9) [P4](https://huggingface.co/mradermacher/DeepSeek-V3-i1-GGUF/resolve/main/DeepSeek-V3.i1-Q4_K_M.gguf.part4of9) [P5](https://huggingface.co/mradermacher/DeepSeek-V3-i1-GGUF/resolve/main/DeepSeek-V3.i1-Q4_K_M.gguf.part5of9) [P6](https://huggingface.co/mradermacher/DeepSeek-V3-i1-GGUF/resolve/main/DeepSeek-V3.i1-Q4_K_M.gguf.part6of9) [P7](https://huggingface.co/mradermacher/DeepSeek-V3-i1-GGUF/resolve/main/DeepSeek-V3.i1-Q4_K_M.gguf.part7of9) [P8](https://huggingface.co/mradermacher/DeepSeek-V3-i1-GGUF/resolve/main/DeepSeek-V3.i1-Q4_K_M.gguf.part8of9) [P9](https://huggingface.co/mradermacher/DeepSeek-V3-i1-GGUF/resolve/main/DeepSeek-V3.i1-Q4_K_M.gguf.part9of9) | i1-Q4_K_M | 404.5 | fast, recommended |
| [P1](https://huggingface.co/mradermacher/DeepSeek-V3-i1-GGUF/resolve/main/DeepSeek-V3.i1-Q4_1.gguf.part1of9) [P2](https://huggingface.co/mradermacher/DeepSeek-V3-i1-GGUF/resolve/main/DeepSeek-V3.i1-Q4_1.gguf.part2of9) [P3](https://huggingface.co/mradermacher/DeepSeek-V3-i1-GGUF/resolve/main/DeepSeek-V3.i1-Q4_1.gguf.part3of9) [P4](https://huggingface.co/mradermacher/DeepSeek-V3-i1-GGUF/resolve/main/DeepSeek-V3.i1-Q4_1.gguf.part4of9) [P5](https://huggingface.co/mradermacher/DeepSeek-V3-i1-GGUF/resolve/main/DeepSeek-V3.i1-Q4_1.gguf.part5of9) [P6](https://huggingface.co/mradermacher/DeepSeek-V3-i1-GGUF/resolve/main/DeepSeek-V3.i1-Q4_1.gguf.part6of9) [P7](https://huggingface.co/mradermacher/DeepSeek-V3-i1-GGUF/resolve/main/DeepSeek-V3.i1-Q4_1.gguf.part7of9) [P8](https://huggingface.co/mradermacher/DeepSeek-V3-i1-GGUF/resolve/main/DeepSeek-V3.i1-Q4_1.gguf.part8of9) [P9](https://huggingface.co/mradermacher/DeepSeek-V3-i1-GGUF/resolve/main/DeepSeek-V3.i1-Q4_1.gguf.part9of9) | i1-Q4_1 | 420.0 |  |
| [P1](https://huggingface.co/mradermacher/DeepSeek-V3-i1-GGUF/resolve/main/DeepSeek-V3.i1-Q5_K_S.gguf.part01of10) [P2](https://huggingface.co/mradermacher/DeepSeek-V3-i1-GGUF/resolve/main/DeepSeek-V3.i1-Q5_K_S.gguf.part02of10) [P3](https://huggingface.co/mradermacher/DeepSeek-V3-i1-GGUF/resolve/main/DeepSeek-V3.i1-Q5_K_S.gguf.part03of10) [P4](https://huggingface.co/mradermacher/DeepSeek-V3-i1-GGUF/resolve/main/DeepSeek-V3.i1-Q5_K_S.gguf.part04of10) [P5](https://huggingface.co/mradermacher/DeepSeek-V3-i1-GGUF/resolve/main/DeepSeek-V3.i1-Q5_K_S.gguf.part05of10) [P6](https://huggingface.co/mradermacher/DeepSeek-V3-i1-GGUF/resolve/main/DeepSeek-V3.i1-Q5_K_S.gguf.part06of10) [P7](https://huggingface.co/mradermacher/DeepSeek-V3-i1-GGUF/resolve/main/DeepSeek-V3.i1-Q5_K_S.gguf.part07of10) [P8](https://huggingface.co/mradermacher/DeepSeek-V3-i1-GGUF/resolve/main/DeepSeek-V3.i1-Q5_K_S.gguf.part08of10) [P9](https://huggingface.co/mradermacher/DeepSeek-V3-i1-GGUF/resolve/main/DeepSeek-V3.i1-Q5_K_S.gguf.part09of10) [P10](https://huggingface.co/mradermacher/DeepSeek-V3-i1-GGUF/resolve/main/DeepSeek-V3.i1-Q5_K_S.gguf.part10of10) | i1-Q5_K_S | 461.9 |  |
| [P1](https://huggingface.co/mradermacher/DeepSeek-V3-i1-GGUF/resolve/main/DeepSeek-V3.i1-Q5_K_M.gguf.part01of10) [P2](https://huggingface.co/mradermacher/DeepSeek-V3-i1-GGUF/resolve/main/DeepSeek-V3.i1-Q5_K_M.gguf.part02of10) [P3](https://huggingface.co/mradermacher/DeepSeek-V3-i1-GGUF/resolve/main/DeepSeek-V3.i1-Q5_K_M.gguf.part03of10) [P4](https://huggingface.co/mradermacher/DeepSeek-V3-i1-GGUF/resolve/main/DeepSeek-V3.i1-Q5_K_M.gguf.part04of10) [P5](https://huggingface.co/mradermacher/DeepSeek-V3-i1-GGUF/resolve/main/DeepSeek-V3.i1-Q5_K_M.gguf.part05of10) [P6](https://huggingface.co/mradermacher/DeepSeek-V3-i1-GGUF/resolve/main/DeepSeek-V3.i1-Q5_K_M.gguf.part06of10) [P7](https://huggingface.co/mradermacher/DeepSeek-V3-i1-GGUF/resolve/main/DeepSeek-V3.i1-Q5_K_M.gguf.part07of10) [P8](https://huggingface.co/mradermacher/DeepSeek-V3-i1-GGUF/resolve/main/DeepSeek-V3.i1-Q5_K_M.gguf.part08of10) [P9](https://huggingface.co/mradermacher/DeepSeek-V3-i1-GGUF/resolve/main/DeepSeek-V3.i1-Q5_K_M.gguf.part09of10) [P10](https://huggingface.co/mradermacher/DeepSeek-V3-i1-GGUF/resolve/main/DeepSeek-V3.i1-Q5_K_M.gguf.part10of10) | i1-Q5_K_M | 475.5 |  |
| [P1](https://huggingface.co/mradermacher/DeepSeek-V3-i1-GGUF/resolve/main/DeepSeek-V3.i1-Q6_K.gguf.part01of12) [P2](https://huggingface.co/mradermacher/DeepSeek-V3-i1-GGUF/resolve/main/DeepSeek-V3.i1-Q6_K.gguf.part02of12) [P3](https://huggingface.co/mradermacher/DeepSeek-V3-i1-GGUF/resolve/main/DeepSeek-V3.i1-Q6_K.gguf.part03of12) [P4](https://huggingface.co/mradermacher/DeepSeek-V3-i1-GGUF/resolve/main/DeepSeek-V3.i1-Q6_K.gguf.part04of12) [P5](https://huggingface.co/mradermacher/DeepSeek-V3-i1-GGUF/resolve/main/DeepSeek-V3.i1-Q6_K.gguf.part05of12) [P6](https://huggingface.co/mradermacher/DeepSeek-V3-i1-GGUF/resolve/main/DeepSeek-V3.i1-Q6_K.gguf.part06of12) [P7](https://huggingface.co/mradermacher/DeepSeek-V3-i1-GGUF/resolve/main/DeepSeek-V3.i1-Q6_K.gguf.part07of12) [P8](https://huggingface.co/mradermacher/DeepSeek-V3-i1-GGUF/resolve/main/DeepSeek-V3.i1-Q6_K.gguf.part08of12) [P9](https://huggingface.co/mradermacher/DeepSeek-V3-i1-GGUF/resolve/main/DeepSeek-V3.i1-Q6_K.gguf.part09of12) [P10](https://huggingface.co/mradermacher/DeepSeek-V3-i1-GGUF/resolve/main/DeepSeek-V3.i1-Q6_K.gguf.part10of12) [P11](https://huggingface.co/mradermacher/DeepSeek-V3-i1-GGUF/resolve/main/DeepSeek-V3.i1-Q6_K.gguf.part11of12) [P12](https://huggingface.co/mradermacher/DeepSeek-V3-i1-GGUF/resolve/main/DeepSeek-V3.i1-Q6_K.gguf.part12of12) | i1-Q6_K | 550.9 | practically like static Q6_K |

Here is a handy graph by ikawrakow comparing some lower-quality quant
types (lower is better):

![image.png](https://www.nethype.de/huggingface_embed/quantpplgraph.png)

And here are Artefact2's thoughts on the matter:
https://gist.github.com/Artefact2/b5f810600771265fc1e39442288e8ec9

## FAQ / Model Request

See https://huggingface.co/mradermacher/model_requests for some answers to
questions you might have and/or if you want some other model quantized.

## Thanks

I thank my company, [nethype GmbH](https://www.nethype.de/), for letting
me use its servers and providing upgrades to my workstation to enable
this work in my free time. Additional thanks to [@nicoboss](https://huggingface.co/nicoboss) for giving me access to his private supercomputer, enabling me to provide many more imatrix quants, at much higher quality, than I would otherwise be able to.

<!-- end -->
","{""id"": ""mradermacher/DeepSeek-V3-i1-GGUF"", ""author"": ""mradermacher"", ""sha"": ""91959fc053219ace305548a951cbc9630a4e72a0"", ""last_modified"": ""2025-01-11 08:03:15+00:00"", ""created_at"": ""2025-01-09 07:50:36+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 6, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""en"", ""base_model:deepseek-ai/DeepSeek-V3"", ""base_model:finetune:deepseek-ai/DeepSeek-V3"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": null, ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: deepseek-ai/DeepSeek-V3\nlanguage:\n- en\nlibrary_name: transformers\nquantized_by: mradermacher"", ""widget_data"": null, ""model_index"": null, ""config"": null, ""transformers_info"": {""auto_model"": ""AutoModel"", ""custom_class"": null, ""pipeline_tag"": null, ""processor"": null}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.i1-IQ1_M.gguf.part1of4', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.i1-IQ1_M.gguf.part2of4', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.i1-IQ1_M.gguf.part3of4', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.i1-IQ1_M.gguf.part4of4', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.i1-IQ1_S.gguf.part1of3', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.i1-IQ1_S.gguf.part2of3', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.i1-IQ1_S.gguf.part3of3', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.i1-IQ2_M.gguf.part1of5', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.i1-IQ2_M.gguf.part2of5', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.i1-IQ2_M.gguf.part3of5', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.i1-IQ2_M.gguf.part4of5', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.i1-IQ2_M.gguf.part5of5', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.i1-IQ2_S.gguf.part1of4', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.i1-IQ2_S.gguf.part2of4', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.i1-IQ2_S.gguf.part3of4', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.i1-IQ2_S.gguf.part4of4', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.i1-IQ2_XS.gguf.part1of4', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.i1-IQ2_XS.gguf.part2of4', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.i1-IQ2_XS.gguf.part3of4', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.i1-IQ2_XS.gguf.part4of4', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.i1-IQ2_XXS.gguf.part1of4', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.i1-IQ2_XXS.gguf.part2of4', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.i1-IQ2_XXS.gguf.part3of4', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.i1-IQ2_XXS.gguf.part4of4', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.i1-IQ3_M.gguf.part1of6', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.i1-IQ3_M.gguf.part2of6', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.i1-IQ3_M.gguf.part3of6', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.i1-IQ3_M.gguf.part4of6', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.i1-IQ3_M.gguf.part5of6', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.i1-IQ3_M.gguf.part6of6', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.i1-IQ3_S.gguf.part1of6', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.i1-IQ3_S.gguf.part2of6', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.i1-IQ3_S.gguf.part3of6', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.i1-IQ3_S.gguf.part4of6', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.i1-IQ3_S.gguf.part5of6', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.i1-IQ3_S.gguf.part6of6', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.i1-IQ3_XS.gguf.part1of6', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.i1-IQ3_XS.gguf.part2of6', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.i1-IQ3_XS.gguf.part3of6', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.i1-IQ3_XS.gguf.part4of6', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.i1-IQ3_XS.gguf.part5of6', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.i1-IQ3_XS.gguf.part6of6', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.i1-IQ3_XXS.gguf.part1of6', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.i1-IQ3_XXS.gguf.part2of6', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.i1-IQ3_XXS.gguf.part3of6', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.i1-IQ3_XXS.gguf.part4of6', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.i1-IQ3_XXS.gguf.part5of6', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.i1-IQ3_XXS.gguf.part6of6', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.i1-IQ4_XS.gguf.part1of8', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.i1-IQ4_XS.gguf.part2of8', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.i1-IQ4_XS.gguf.part3of8', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.i1-IQ4_XS.gguf.part4of8', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.i1-IQ4_XS.gguf.part5of8', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.i1-IQ4_XS.gguf.part6of8', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.i1-IQ4_XS.gguf.part7of8', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.i1-IQ4_XS.gguf.part8of8', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.i1-Q2_K.gguf.part1of5', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.i1-Q2_K.gguf.part2of5', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.i1-Q2_K.gguf.part3of5', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.i1-Q2_K.gguf.part4of5', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.i1-Q2_K.gguf.part5of5', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.i1-Q2_K_S.gguf.part1of5', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.i1-Q2_K_S.gguf.part2of5', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.i1-Q2_K_S.gguf.part3of5', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.i1-Q2_K_S.gguf.part4of5', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.i1-Q2_K_S.gguf.part5of5', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.i1-Q3_K_L.gguf.part1of8', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.i1-Q3_K_L.gguf.part2of8', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.i1-Q3_K_L.gguf.part3of8', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.i1-Q3_K_L.gguf.part4of8', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.i1-Q3_K_L.gguf.part5of8', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.i1-Q3_K_L.gguf.part6of8', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.i1-Q3_K_L.gguf.part7of8', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.i1-Q3_K_L.gguf.part8of8', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.i1-Q3_K_M.gguf.part1of7', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.i1-Q3_K_M.gguf.part2of7', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.i1-Q3_K_M.gguf.part3of7', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.i1-Q3_K_M.gguf.part4of7', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.i1-Q3_K_M.gguf.part5of7', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.i1-Q3_K_M.gguf.part6of7', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.i1-Q3_K_M.gguf.part7of7', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.i1-Q3_K_S.gguf.part1of6', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.i1-Q3_K_S.gguf.part2of6', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.i1-Q3_K_S.gguf.part3of6', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.i1-Q3_K_S.gguf.part4of6', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.i1-Q3_K_S.gguf.part5of6', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.i1-Q3_K_S.gguf.part6of6', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.i1-Q4_0.gguf.part1of8', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.i1-Q4_0.gguf.part2of8', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.i1-Q4_0.gguf.part3of8', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.i1-Q4_0.gguf.part4of8', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.i1-Q4_0.gguf.part5of8', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.i1-Q4_0.gguf.part6of8', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.i1-Q4_0.gguf.part7of8', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.i1-Q4_0.gguf.part8of8', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.i1-Q4_1.gguf.part1of9', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.i1-Q4_1.gguf.part2of9', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.i1-Q4_1.gguf.part3of9', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.i1-Q4_1.gguf.part4of9', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.i1-Q4_1.gguf.part5of9', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.i1-Q4_1.gguf.part6of9', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.i1-Q4_1.gguf.part7of9', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.i1-Q4_1.gguf.part8of9', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.i1-Q4_1.gguf.part9of9', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.i1-Q4_K_M.gguf.part1of9', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.i1-Q4_K_M.gguf.part2of9', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.i1-Q4_K_M.gguf.part3of9', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.i1-Q4_K_M.gguf.part4of9', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.i1-Q4_K_M.gguf.part5of9', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.i1-Q4_K_M.gguf.part6of9', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.i1-Q4_K_M.gguf.part7of9', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.i1-Q4_K_M.gguf.part8of9', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.i1-Q4_K_M.gguf.part9of9', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.i1-Q4_K_S.gguf.part1of8', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.i1-Q4_K_S.gguf.part2of8', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.i1-Q4_K_S.gguf.part3of8', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.i1-Q4_K_S.gguf.part4of8', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.i1-Q4_K_S.gguf.part5of8', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.i1-Q4_K_S.gguf.part6of8', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.i1-Q4_K_S.gguf.part7of8', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.i1-Q4_K_S.gguf.part8of8', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.i1-Q5_K_M.gguf.part01of10', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.i1-Q5_K_M.gguf.part02of10', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.i1-Q5_K_M.gguf.part03of10', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.i1-Q5_K_M.gguf.part04of10', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.i1-Q5_K_M.gguf.part05of10', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.i1-Q5_K_M.gguf.part06of10', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.i1-Q5_K_M.gguf.part07of10', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.i1-Q5_K_M.gguf.part08of10', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.i1-Q5_K_M.gguf.part09of10', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.i1-Q5_K_M.gguf.part10of10', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.i1-Q5_K_S.gguf.part01of10', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.i1-Q5_K_S.gguf.part02of10', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.i1-Q5_K_S.gguf.part03of10', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.i1-Q5_K_S.gguf.part04of10', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.i1-Q5_K_S.gguf.part05of10', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.i1-Q5_K_S.gguf.part06of10', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.i1-Q5_K_S.gguf.part07of10', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.i1-Q5_K_S.gguf.part08of10', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.i1-Q5_K_S.gguf.part09of10', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.i1-Q5_K_S.gguf.part10of10', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.i1-Q6_K.gguf.part01of12', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.i1-Q6_K.gguf.part02of12', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.i1-Q6_K.gguf.part03of12', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.i1-Q6_K.gguf.part04of12', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.i1-Q6_K.gguf.part05of12', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.i1-Q6_K.gguf.part06of12', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.i1-Q6_K.gguf.part07of12', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.i1-Q6_K.gguf.part08of12', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.i1-Q6_K.gguf.part09of12', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.i1-Q6_K.gguf.part10of12', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.i1-Q6_K.gguf.part11of12', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3.i1-Q6_K.gguf.part12of12', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='imatrix.dat', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-01-11 08:03:15+00:00"", ""cardData"": ""base_model: deepseek-ai/DeepSeek-V3\nlanguage:\n- en\nlibrary_name: transformers\nquantized_by: mradermacher"", ""transformersInfo"": {""auto_model"": ""AutoModel"", ""custom_class"": null, ""pipeline_tag"": null, ""processor"": null}, ""_id"": ""677f7fcc7202495e9b870e67"", ""modelId"": ""mradermacher/DeepSeek-V3-i1-GGUF"", ""usedStorage"": 7032257076720}",1,,0,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=mradermacher/DeepSeek-V3-i1-GGUF&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bmradermacher%2FDeepSeek-V3-i1-GGUF%5D(%2Fmradermacher%2FDeepSeek-V3-i1-GGUF)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1
alexleyai/diabetesdiagnosis,"---
license: openrail
language:
- en
base_model:
- deepseek-ai/DeepSeek-V3
pipeline_tag: question-answering
---","{""id"": ""alexleyai/diabetesdiagnosis"", ""author"": ""alexleyai"", ""sha"": ""65ee10172e4e02d560f40cb9f340e04c3e0d90d5"", ""last_modified"": ""2025-01-13 13:01:58+00:00"", ""created_at"": ""2025-01-13 11:17:54+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 1, ""library_name"": null, ""gguf"": null, ""inference"": null, ""tags"": [""question-answering"", ""en"", ""base_model:deepseek-ai/DeepSeek-V3"", ""base_model:finetune:deepseek-ai/DeepSeek-V3"", ""license:openrail"", ""region:us""], ""pipeline_tag"": ""question-answering"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model:\n- deepseek-ai/DeepSeek-V3\nlanguage:\n- en\nlicense: openrail\npipeline_tag: question-answering"", ""widget_data"": [{""text"": ""Where do I live?"", ""context"": ""My name is Wolfgang and I live in Berlin""}, {""text"": ""Where do I live?"", ""context"": ""My name is Sarah and I live in London""}, {""text"": ""What's my name?"", ""context"": ""My name is Clara and I live in Berkeley.""}, {""text"": ""Which name is also used to describe the Amazon rainforest in English?"", ""context"": ""The Amazon rainforest (Portuguese: Floresta Amaz\u00f4nica or Amaz\u00f4nia; Spanish: Selva Amaz\u00f3nica, Amazon\u00eda or usually Amazonia; French: For\u00eat amazonienne; Dutch: Amazoneregenwoud), also known in English as Amazonia or the Amazon Jungle, is a moist broadleaf forest that covers most of the Amazon basin of South America. This basin encompasses 7,000,000 square kilometres (2,700,000 sq mi), of which 5,500,000 square kilometres (2,100,000 sq mi) are covered by the rainforest. This region includes territory belonging to nine nations. The majority of the forest is contained within Brazil, with 60% of the rainforest, followed by Peru with 13%, Colombia with 10%, and with minor amounts in Venezuela, Ecuador, Bolivia, Guyana, Suriname and French Guiana. States or departments in four nations contain \""Amazonas\"" in their names. The Amazon represents over half of the planet's remaining rainforests, and comprises the largest and most biodiverse tract of tropical rainforest in the world, with an estimated 390 billion individual trees divided into 16,000 species.""}], ""model_index"": null, ""config"": null, ""transformers_info"": null, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='main', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-01-13 13:01:58+00:00"", ""cardData"": ""base_model:\n- deepseek-ai/DeepSeek-V3\nlanguage:\n- en\nlicense: openrail\npipeline_tag: question-answering"", ""transformersInfo"": null, ""_id"": ""6784f66274ea87969536a326"", ""modelId"": ""alexleyai/diabetesdiagnosis"", ""usedStorage"": 0}",1,,0,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=alexleyai/diabetesdiagnosis&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Balexleyai%2Fdiabetesdiagnosis%5D(%2Falexleyai%2Fdiabetesdiagnosis)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1
Fourdoor/Alex-gpt,"---
license: apache-2.0
datasets:
- fka/awesome-chatgpt-prompts
language:
- nl
metrics:
- character
base_model:
- deepseek-ai/DeepSeek-V3
new_version: meta-llama/Llama-3.3-70B-Instruct
library_name: bertopic
tags:
- finance
- climate
---","{""id"": ""Fourdoor/Alex-gpt"", ""author"": ""Fourdoor"", ""sha"": ""dc9148483f08114fcef74ff82bb102a5ad11eef8"", ""last_modified"": ""2025-01-14 12:34:54+00:00"", ""created_at"": ""2025-01-14 12:32:38+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 1, ""library_name"": ""bertopic"", ""gguf"": null, ""inference"": null, ""tags"": [""bertopic"", ""finance"", ""climate"", ""nl"", ""dataset:fka/awesome-chatgpt-prompts"", ""base_model:deepseek-ai/DeepSeek-V3"", ""base_model:finetune:deepseek-ai/DeepSeek-V3"", ""license:apache-2.0"", ""region:us""], ""pipeline_tag"": null, ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model:\n- deepseek-ai/DeepSeek-V3\ndatasets:\n- fka/awesome-chatgpt-prompts\nlanguage:\n- nl\nlibrary_name: bertopic\nlicense: apache-2.0\nmetrics:\n- character\ntags:\n- finance\n- climate\nnew_version: meta-llama/Llama-3.3-70B-Instruct"", ""widget_data"": null, ""model_index"": null, ""config"": null, ""transformers_info"": null, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-01-14 12:34:54+00:00"", ""cardData"": ""base_model:\n- deepseek-ai/DeepSeek-V3\ndatasets:\n- fka/awesome-chatgpt-prompts\nlanguage:\n- nl\nlibrary_name: bertopic\nlicense: apache-2.0\nmetrics:\n- character\ntags:\n- finance\n- climate\nnew_version: meta-llama/Llama-3.3-70B-Instruct"", ""transformersInfo"": null, ""_id"": ""67865966070e6f68b00010b1"", ""modelId"": ""Fourdoor/Alex-gpt"", ""usedStorage"": 0}",1,,0,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=Fourdoor/Alex-gpt&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5BFourdoor%2FAlex-gpt%5D(%2FFourdoor%2FAlex-gpt)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1
franb23/tarot,"---
license: mit
datasets:
- DAMO-NLP-SG/multimodal_textbook
language:
- es
- en
metrics:
- accuracy
base_model:
- deepseek-ai/DeepSeek-V3
---
","{""id"": ""franb23/tarot"", ""author"": ""franb23"", ""sha"": ""9921eff3d09d3b19206a1d6f0bfda5c22cf2dec9"", ""last_modified"": ""2025-01-16 00:13:19+00:00"", ""created_at"": ""2025-01-15 23:27:43+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 4, ""downloads_all_time"": null, ""likes"": 1, ""library_name"": null, ""gguf"": null, ""inference"": null, ""tags"": [""safetensors"", ""bert"", ""es"", ""en"", ""dataset:DAMO-NLP-SG/multimodal_textbook"", ""base_model:deepseek-ai/DeepSeek-V3"", ""base_model:finetune:deepseek-ai/DeepSeek-V3"", ""license:mit"", ""region:us""], ""pipeline_tag"": null, ""mask_token"": ""[MASK]"", ""trending_score"": null, ""card_data"": ""base_model:\n- deepseek-ai/DeepSeek-V3\ndatasets:\n- DAMO-NLP-SG/multimodal_textbook\nlanguage:\n- es\n- en\nlicense: mit\nmetrics:\n- accuracy"", ""widget_data"": null, ""model_index"": null, ""config"": {""architectures"": [""BertForSequenceClassification""], ""model_type"": ""bert"", ""tokenizer_config"": {""cls_token"": ""[CLS]"", ""mask_token"": ""[MASK]"", ""pad_token"": ""[PAD]"", ""sep_token"": ""[SEP]"", ""unk_token"": ""[UNK]""}}, ""transformers_info"": null, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='vocab.txt', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": {""parameters"": {""F32"": 109483778}, ""total"": 109483778}, ""security_repo_status"": null, ""lastModified"": ""2025-01-16 00:13:19+00:00"", ""cardData"": ""base_model:\n- deepseek-ai/DeepSeek-V3\ndatasets:\n- DAMO-NLP-SG/multimodal_textbook\nlanguage:\n- es\n- en\nlicense: mit\nmetrics:\n- accuracy"", ""transformersInfo"": null, ""_id"": ""6788446ff7306dbc1b4edea1"", ""modelId"": ""franb23/tarot"", ""usedStorage"": 437958648}",1,,0,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=franb23/tarot&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bfranb23%2Ftarot%5D(%2Ffranb23%2Ftarot)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1
huihui-ai/DeepSeek-V3-bf16,"---
license: apache-2.0
base_model:
- deepseek-ai/DeepSeek-V3
tags:
- deepseek_v3
- bf16
- Safetensors
- custom_code
---

# huihui-ai/DeepSeek-V3-bf16

This model converted from DeepSeek-V3 to BF16.  
Here we simply provide the conversion command and related information about ollama.  

**The following conversion also applies to [deepseek-ai/DeepSeek-R1](https://huggingface.co/deepseek-ai/DeepSeek-R1)**

If needed, we can upload the bf16 version.

## FP8 to BF16
1. Download [deepseek-ai/DeepSeek-V3](https://huggingface.co/deepseek-ai/DeepSeek-V3) model, requires approximately 641GB of space.
```
cd /home/admin/models
huggingface-cli download deepseek-ai/DeepSeek-V3 --local-dir ./deepseek-ai/DeepSeek-V3
```
2. Create the environment.
```
conda create -yn DeepSeek-V3 python=3.12
conda activate DeepSeek-V3
pip install -r requirements.txt
```
3. Convert to BF16, requires an additional approximately 1.3 TB of space.
```
cd deepseek-ai/DeepSeek-V3/inference
python fp8_cast_bf16.py --input-fp8-hf-path /home/admin/models/deepseek-ai/DeepSeek-V3/ --output-bf16-hf-path /home/admin/models/deepseek-ai/DeepSeek-V3-bf16
```
## BF16 to gguf
1. Use the [llama.cpp](https://github.com/ggerganov/llama.cpp) (Download the latest version) conversion program to convert DeepSeek-V3-bf16 to gguf format, requires an additional approximately 1.3 TB of space.
```
python convert_hf_to_gguf.py /home/admin/models/deepseek-ai/DeepSeek-V3-bf16 --outfile /home/admin/models/deepseek-ai/DeepSeek-V3-bf16/ggml-model-f16.gguf --outtype f16
```
2. Use the [llama.cpp](https://github.com/ggerganov/llama.cpp) quantitative program to quantitative model (llama-quantize needs to be compiled),
other [quant option](https://github.com/ggerganov/llama.cpp/blob/master/examples/quantize/quantize.cpp). 
Convert first Q2_K, requires an additional approximately 227 GB of space.
```
llama-quantize /home/admin/models/deepseek-ai/DeepSeek-V3-bf16/ggml-model-f16.gguf  /home/admin/models/deepseek-ai/DeepSeek-V3-bf16/ggml-model-Q2_K.gguf Q2_K
```
3. Use llama-cli to test, llama-cli needs to be compiled.
```
llama-cli -m /home/admin/models/deepseek-ai/DeepSeek-V3-bf16/ggml-model-Q2_K.gguf -n 2048
```

## Use with ollama
**Note:** this model requires [Ollama 0.5.5](https://github.com/ollama/ollama/releases/tag/v0.5.5)  

You can use [huihui_ai/deepseek-v3:671b-q2_K](https://ollama.com/huihui_ai/deepseek-v3:671b-q2_K) directly
```
ollama run huihui_ai/deepseek-v3:671b-q2_K
```

or [huihui_ai/deepseek-v3:671b-q3_K](https://ollama.com/huihui_ai/deepseek-v3:671b-q3_K) 
```
ollama run huihui_ai/deepseek-v3:671b-q3_K
```
","{""id"": ""huihui-ai/DeepSeek-V3-bf16"", ""author"": ""huihui-ai"", ""sha"": ""94be240d2d4016c6a8b819e9ea184553b9f35157"", ""last_modified"": ""2025-02-05 15:20:02+00:00"", ""created_at"": ""2025-01-17 09:38:05+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 6, ""downloads_all_time"": null, ""likes"": 2, ""library_name"": null, ""gguf"": null, ""inference"": null, ""tags"": [""safetensors"", ""deepseek_v3"", ""bf16"", ""Safetensors"", ""custom_code"", ""base_model:deepseek-ai/DeepSeek-V3"", ""base_model:finetune:deepseek-ai/DeepSeek-V3"", ""license:apache-2.0"", ""region:us""], ""pipeline_tag"": null, ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model:\n- deepseek-ai/DeepSeek-V3\nlicense: apache-2.0\ntags:\n- deepseek_v3\n- bf16\n- Safetensors\n- custom_code"", ""widget_data"": null, ""model_index"": null, ""config"": {""architectures"": [""DeepseekV3ForCausalLM""], ""auto_map"": {""AutoConfig"": ""configuration_deepseek.DeepseekV3Config"", ""AutoModel"": ""modeling_deepseek.DeepseekV3Model"", ""AutoModelForCausalLM"": ""modeling_deepseek.DeepseekV3ForCausalLM""}, ""model_type"": ""deepseek_v3"", ""tokenizer_config"": {""bos_token"": {""__type"": ""AddedToken"", ""content"": ""<\uff5cbegin\u2581of\u2581sentence\uff5c>"", ""lstrip"": false, ""normalized"": true, ""rstrip"": false, ""single_word"": false}, ""eos_token"": {""__type"": ""AddedToken"", ""content"": ""<\uff5cend\u2581of\u2581sentence\uff5c>"", ""lstrip"": false, ""normalized"": true, ""rstrip"": false, ""single_word"": false}, ""pad_token"": {""__type"": ""AddedToken"", ""content"": ""<\uff5cend\u2581of\u2581sentence\uff5c>"", ""lstrip"": false, ""normalized"": true, ""rstrip"": false, ""single_word"": false}, ""unk_token"": null, ""chat_template"": ""{% if not add_generation_prompt is defined %}{% set add_generation_prompt = false %}{% endif %}{% set ns = namespace(is_first=false, is_tool=false, is_output_first=true, system_prompt='', is_first_sp=true) %}{%- for message in messages %}{%- if message['role'] == 'system' %}{%- if ns.is_first_sp %}{% set ns.system_prompt = ns.system_prompt + message['content'] %}{% set ns.is_first_sp = false %}{%- else %}{% set ns.system_prompt = ns.system_prompt + '\n\n' + message['content'] %}{%- endif %}{%- endif %}{%- endfor %}{{bos_token}}{{ns.system_prompt}}{%- for message in messages %}{%- if message['role'] == 'user' %}{%- set ns.is_tool = false -%}{{'<\uff5cUser\uff5c>' + message['content']}}{%- endif %}{%- if message['role'] == 'assistant' and message['content'] is none %}{%- set ns.is_tool = false -%}{%- for tool in message['tool_calls']%}{%- if not ns.is_first %}{{'<\uff5cAssistant\uff5c><\uff5ctool\u2581calls\u2581begin\uff5c><\uff5ctool\u2581call\u2581begin\uff5c>' + tool['type'] + '<\uff5ctool\u2581sep\uff5c>' + tool['function']['name'] + '\n' + '```json' + '\n' + tool['function']['arguments'] + '\n' + '```' + '<\uff5ctool\u2581call\u2581end\uff5c>'}}{%- set ns.is_first = true -%}{%- else %}{{'\n' + '<\uff5ctool\u2581call\u2581begin\uff5c>' + tool['type'] + '<\uff5ctool\u2581sep\uff5c>' + tool['function']['name'] + '\n' + '```json' + '\n' + tool['function']['arguments'] + '\n' + '```' + '<\uff5ctool\u2581call\u2581end\uff5c>'}}{{'<\uff5ctool\u2581calls\u2581end\uff5c><\uff5cend\u2581of\u2581sentence\uff5c>'}}{%- endif %}{%- endfor %}{%- endif %}{%- if message['role'] == 'assistant' and message['content'] is not none %}{%- if ns.is_tool %}{{'<\uff5ctool\u2581outputs\u2581end\uff5c>' + message['content'] + '<\uff5cend\u2581of\u2581sentence\uff5c>'}}{%- set ns.is_tool = false -%}{%- else %}{{'<\uff5cAssistant\uff5c>' + message['content'] + '<\uff5cend\u2581of\u2581sentence\uff5c>'}}{%- endif %}{%- endif %}{%- if message['role'] == 'tool' %}{%- set ns.is_tool = true -%}{%- if ns.is_output_first %}{{'<\uff5ctool\u2581outputs\u2581begin\uff5c><\uff5ctool\u2581output\u2581begin\uff5c>' + message['content'] + '<\uff5ctool\u2581output\u2581end\uff5c>'}}{%- set ns.is_output_first = false %}{%- else %}{{'\n<\uff5ctool\u2581output\u2581begin\uff5c>' + message['content'] + '<\uff5ctool\u2581output\u2581end\uff5c>'}}{%- endif %}{%- endif %}{%- endfor -%}{% if ns.is_tool %}{{'<\uff5ctool\u2581outputs\u2581end\uff5c>'}}{% endif %}{% if add_generation_prompt and not ns.is_tool %}{{'<\uff5cAssistant\uff5c>'}}{% endif %}""}}, ""transformers_info"": null, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='LICENSE-CODE', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='LICENSE-MODEL', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='configuration_deepseek.py', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model.safetensors.index.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='modeling_deepseek.py', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-02-05 15:20:02+00:00"", ""cardData"": ""base_model:\n- deepseek-ai/DeepSeek-V3\nlicense: apache-2.0\ntags:\n- deepseek_v3\n- bf16\n- Safetensors\n- custom_code"", ""transformersInfo"": null, ""_id"": ""678a24fd79ac77c2de7e6294"", ""modelId"": ""huihui-ai/DeepSeek-V3-bf16"", ""usedStorage"": 0}",1,,0,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=huihui-ai/DeepSeek-V3-bf16&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bhuihui-ai%2FDeepSeek-V3-bf16%5D(%2Fhuihui-ai%2FDeepSeek-V3-bf16)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1
OpenC/HEFT-Qwen,"---
license: mit
datasets:
- arthurneuron/cryptocurrency-futures-ohlcv-dataset-1m
- CryptoLM/ETH-USDT
- arad1367/Crypto_Fundamental_News
language:
- en
metrics:
- accuracy
- hage2000/code_eval_stdio
base_model:
- deepseek-ai/DeepSeek-V3
new_version: deepseek-ai/DeepSeek-V3
---

## 1. Introduction
This report presents a novel approach to fine-tuning the Qwen model using crypto-related data to enhance performance in financial and blockchain-based tasks. The method achieves state-of-the-art (SOTA) results on Hugging Face benchmarks while reducing computational resource requirements through an optimized training approach.

![Heft in Fine-tuning Qwen on Crypto Data](https://i.imgur.com/LFkoiRL.png)



## 2. Methodology

### 2.1 Crypto Data Collection and Preprocessing
We curated an extensive dataset composed of:
- **Historical trading data** from major exchanges (Binance, Coinbase, Kraken) to understand market patterns.
- **Crypto news articles and financial reports** covering blockchain developments, regulatory updates, and project launches.
- **On-chain data** from Ethereum, Bitcoin, and Solana, focusing on smart contract interactions and DeFi analytics.
- **Social sentiment analysis** extracted from Twitter, Reddit, and Medium to understand investor sentiment and speculation trends.
- **Blockchain whitepapers and academic papers** to capture technical and conceptual knowledge.

Data preprocessing included:
- **Token normalization:** Removing redundant characters and normalizing financial terminology.
- **Noise reduction:** Filtering out low-quality or misleading financial texts.
- **Data augmentation:** Using paraphrasing techniques to increase dataset diversity.

### 2.2 Optimized Fine-Tuning Approach
To achieve high efficiency in fine-tuning the Qwen model, we introduce a **Hybrid Efficient Fine-Tuning (HEFT) framework** which integrates:
- **LoRA (Low-Rank Adaptation):** Reducing the number of trainable parameters while maintaining expressive power.
- **Parameter-efficient Fine-tuning (PEFT):** Adjusting specific layers without modifying the entire model.
- **Selective Knowledge Injection:** Pre-training additional financial embeddings only in layers contributing to domain-specific expertise.
- **Gradient Checkpointing:** Reducing memory footprint by recalculating activations only when necessary.
- **Sparse Attention Mechanism:** Replacing full attention computation with sparse matrices, optimizing long-context processing.
- **Mixed Precision Training:** Leveraging FP16 and BF16 precision to accelerate training without loss of accuracy.

Training was conducted on NVIDIA A100 GPUs and TPUs, significantly reducing resource consumption compared to full fine-tuning.

## 3. Benchmarking Results
We evaluate our fine-tuned Qwen model on multiple financial and general NLP benchmarks, comparing against GPT-4 and other state-of-the-art models:

| Benchmark | HEFT-Qwen (Fine-Tuned) | GPT-4 | GPT-4 Turbo | Qwen Base |
|-----------|----------------|-------|-------------|-----------|
| **MMLU (Massive Multitask Language Understanding)** | **87.5%** | 82.2% | 85.1% | 78.3% |
| **BBH (BigBench Hard)** | **82.3%** | 79.4% | 81.1% | 75.2% |
| **Crypto-Finance Tasks** | **91.2%** | 85.6% | 88.7% | 81.3% |
| **Hugging Face Open LLM Leaderboard** | **Top 1 (90.5%)** | Top 3 (87.4%) | Top 2 (89.1%) | Top 5 (83.2%) |

Our model, named **HEFT-Qwen**, outperforms GPT-4 across all relevant financial-related benchmarks, demonstrating the efficacy of our fine-tuning approach.

## 4. Computational Resource Optimization
One key innovation of our approach is a reduction in computational overhead while maintaining model accuracy. Compared to standard fine-tuning methods, our approach results in:
- **40% reduction in GPU memory usage** due to LoRA and Gradient Checkpointing.
- **35% decrease in training time** via selective fine-tuning of essential layers.
- **50% lower energy consumption** using mixed precision and efficient data batching.

## 5. Example: HEFT-Qwen in Action
Below is an example demonstrating how to use **HEFT-Qwen** via Hugging Face‚Äôs pipeline for **crypto analysis generation**. The model analyzes given crypto tokens and generates insights on whether a token is a scam (RUG) or has growth potential.

```python
from transformers import pipeline

# Load the fine-tuned model from Hugging Face
crypto_analysis_pipeline = pipeline(""text-generation"", model=""OpenC/HEFT-Qwen"")

# Input: List of crypto tokens with contract addresses
crypto_tokens = [
    {""name"": ""Token A"", ""address"": ""0x123abc..."", ""description"": ""High APY, anonymous team, launched yesterday""},
    {""name"": ""Token B"", ""address"": ""0x456def..."", ""description"": ""Backed by a reputable exchange, solid roadmap, transparent team""},
    {""name"": ""Token C"", ""address"": ""0x789ghi..."", ""description"": ""Claims unrealistic gains, has multiple scam reports""},
]

# Generate analysis for each token
for token in crypto_tokens:
    prompt = f""Analyze the following crypto token:\nName: {token['name']}\nAddress: {token['address']}\nDescription: {token['description']}\n\nAnalysis:"" 
    result = crypto_analysis_pipeline(prompt, max_length=200, do_sample=True)
    print(f""Token: {token['name']} ({token['address']})\nAnalysis: {result[0]['generated_text']}\n"")
```

### Example Output
```
Token: Token A (0x123abc...)
Analysis: This token exhibits signs of a high-risk investment. The anonymous team, extremely high APY, and recent launch are red flags indicating a potential RUG pull.

Token: Token B (0x456def...)
Analysis: Token B is backed by a reputable exchange and has a solid roadmap. The transparency of the team increases investor confidence, making it a strong candidate for long-term growth.

Token: Token C (0x789ghi...)
Analysis: Multiple scam reports and unrealistic profit claims suggest Token C is highly risky. Investors should proceed with extreme caution.
```

## 6. Conclusion
- Fine-tuning Qwen with crypto data significantly enhances domain-specific performance, surpassing existing SOTA models.
- The **HEFT framework** enables efficient fine-tuning with reduced resource consumption.
- Future directions include expanding to other financial domains, such as stock trading, and exploring **real-time on-chain AI integration**.

## 7. Future Work
- **Integration with financial trading models** for real-time inference in decision-making.
- **Exploring reinforcement learning (RLHF) with domain experts** to further enhance response quality.
- **Developing lightweight deployment strategies** for edge computing environments.

","{""id"": ""OpenC/HEFT-Qwen"", ""author"": ""OpenC"", ""sha"": ""3a2b50063cd69dcbf5b12ff3ea33b215b5352947"", ""last_modified"": ""2025-01-31 16:17:12+00:00"", ""created_at"": ""2025-01-31 14:26:06+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 17, ""downloads_all_time"": null, ""likes"": 5, ""library_name"": null, ""gguf"": null, ""inference"": null, ""tags"": [""safetensors"", ""qwen2"", ""en"", ""dataset:arthurneuron/cryptocurrency-futures-ohlcv-dataset-1m"", ""dataset:CryptoLM/ETH-USDT"", ""dataset:arad1367/Crypto_Fundamental_News"", ""base_model:deepseek-ai/DeepSeek-V3"", ""base_model:finetune:deepseek-ai/DeepSeek-V3"", ""license:mit"", ""region:us""], ""pipeline_tag"": null, ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model:\n- deepseek-ai/DeepSeek-V3\ndatasets:\n- arthurneuron/cryptocurrency-futures-ohlcv-dataset-1m\n- CryptoLM/ETH-USDT\n- arad1367/Crypto_Fundamental_News\nlanguage:\n- en\nlicense: mit\nmetrics:\n- accuracy\n- hage2000/code_eval_stdio\nnew_version: deepseek-ai/DeepSeek-V3"", ""widget_data"": null, ""model_index"": null, ""config"": {""architectures"": [""Qwen2ForCausalLM""], ""model_type"": ""qwen2"", ""tokenizer_config"": {""bos_token"": {""__type"": ""AddedToken"", ""content"": ""<\uff5cbegin\u2581of\u2581sentence\uff5c>"", ""lstrip"": false, ""normalized"": true, ""rstrip"": false, ""single_word"": false}, ""eos_token"": {""__type"": ""AddedToken"", ""content"": ""<\uff5cend\u2581of\u2581sentence\uff5c>"", ""lstrip"": false, ""normalized"": true, ""rstrip"": false, ""single_word"": false}, ""pad_token"": {""__type"": ""AddedToken"", ""content"": ""<\uff5cend\u2581of\u2581sentence\uff5c>"", ""lstrip"": false, ""normalized"": true, ""rstrip"": false, ""single_word"": false}, ""unk_token"": null, ""chat_template"": ""{% if not add_generation_prompt is defined %}{% set add_generation_prompt = false %}{% endif %}{% set ns = namespace(is_first=false, is_tool=false, is_output_first=true, system_prompt='') %}{%- for message in messages %}{%- if message['role'] == 'system' %}{% set ns.system_prompt = message['content'] %}{%- endif %}{%- endfor %}{{bos_token}}{{ns.system_prompt}}{%- for message in messages %}{%- if message['role'] == 'user' %}{%- set ns.is_tool = false -%}{{'<\uff5cUser\uff5c>' + message['content']}}{%- endif %}{%- if message['role'] == 'assistant' and message['content'] is none %}{%- set ns.is_tool = false -%}{%- for tool in message['tool_calls']%}{%- if not ns.is_first %}{{'<\uff5cAssistant\uff5c><\uff5ctool\u2581calls\u2581begin\uff5c><\uff5ctool\u2581call\u2581begin\uff5c>' + tool['type'] + '<\uff5ctool\u2581sep\uff5c>' + tool['function']['name'] + '\\n' + '```json' + '\\n' + tool['function']['arguments'] + '\\n' + '```' + '<\uff5ctool\u2581call\u2581end\uff5c>'}}{%- set ns.is_first = true -%}{%- else %}{{'\\n' + '<\uff5ctool\u2581call\u2581begin\uff5c>' + tool['type'] + '<\uff5ctool\u2581sep\uff5c>' + tool['function']['name'] + '\\n' + '```json' + '\\n' + tool['function']['arguments'] + '\\n' + '```' + '<\uff5ctool\u2581call\u2581end\uff5c>'}}{{'<\uff5ctool\u2581calls\u2581end\uff5c><\uff5cend\u2581of\u2581sentence\uff5c>'}}{%- endif %}{%- endfor %}{%- endif %}{%- if message['role'] == 'assistant' and message['content'] is not none %}{%- if ns.is_tool %}{{'<\uff5ctool\u2581outputs\u2581end\uff5c>' + message['content'] + '<\uff5cend\u2581of\u2581sentence\uff5c>'}}{%- set ns.is_tool = false -%}{%- else %}{% set content = message['content'] %}{% if '</think>' in content %}{% set content = content.split('</think>')[-1] %}{% endif %}{{'<\uff5cAssistant\uff5c>' + content + '<\uff5cend\u2581of\u2581sentence\uff5c>'}}{%- endif %}{%- endif %}{%- if message['role'] == 'tool' %}{%- set ns.is_tool = true -%}{%- if ns.is_output_first %}{{'<\uff5ctool\u2581outputs\u2581begin\uff5c><\uff5ctool\u2581output\u2581begin\uff5c>' + message['content'] + '<\uff5ctool\u2581output\u2581end\uff5c>'}}{%- set ns.is_output_first = false %}{%- else %}{{'\\n<\uff5ctool\u2581output\u2581begin\uff5c>' + message['content'] + '<\uff5ctool\u2581output\u2581end\uff5c>'}}{%- endif %}{%- endif %}{%- endfor -%}{% if ns.is_tool %}{{'<\uff5ctool\u2581outputs\u2581end\uff5c>'}}{% endif %}{% if add_generation_prompt and not ns.is_tool %}{{'<\uff5cAssistant\uff5c>'}}{% endif %}""}}, ""transformers_info"": null, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='LICENSE', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='generation_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": {""parameters"": {""BF16"": 1777088000}, ""total"": 1777088000}, ""security_repo_status"": null, ""lastModified"": ""2025-01-31 16:17:12+00:00"", ""cardData"": ""base_model:\n- deepseek-ai/DeepSeek-V3\ndatasets:\n- arthurneuron/cryptocurrency-futures-ohlcv-dataset-1m\n- CryptoLM/ETH-USDT\n- arad1367/Crypto_Fundamental_News\nlanguage:\n- en\nlicense: mit\nmetrics:\n- accuracy\n- hage2000/code_eval_stdio\nnew_version: deepseek-ai/DeepSeek-V3"", ""transformersInfo"": null, ""_id"": ""679cdd7e4cb9fb01ef3a0b5c"", ""modelId"": ""OpenC/HEFT-Qwen"", ""usedStorage"": 3554214621}",1,,0,,0,"https://huggingface.co/NikolayKozloff/HEFT-Qwen-Q8_0-GGUF, https://huggingface.co/mradermacher/HEFT-Qwen-GGUF",2,,0,huggingface/InferenceSupport/discussions/new?title=OpenC/HEFT-Qwen&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5BOpenC%2FHEFT-Qwen%5D(%2FOpenC%2FHEFT-Qwen)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1
huihui-ai/DeepSeek-V3-Pruned-Coder-411B,"---
license: apache-2.0
base_model:
- deepseek-ai/DeepSeek-V3
tags:
- deepseek_v3
- bf16
- Safetensors
- custom_code
- Pruned
---

# huihui-ai/DeepSeek-V3-Pruned-Coder-411B




This is a pruned version of the [deepseek-ai/DeepSeek-V3](https://huggingface.co/deepseek-ai/DeepSeek-V3), 
reduced from 256 experts to 160 experts. The pruned model is mainly used for [code](https://huggingface.co/huihui-ai/DeepSeek-V3-Pruned-Coder-411B/blob/main/coding_problems.py) generation.


This is a test validation to see if we can prune the model according to professional requirements and still maintain acceptable performance. 
The model size has been reduced by about 1/3, and no distortion has occurred.

This allows the model to be pruned according to one's needs.

This pruned model has a total parameter is equivalent to 441B.

We will also try to prune [deepseek-ai/DeepSeek-R1](https://huggingface.co/deepseek-ai/DeepSeek-R1).

## Use with ollama

You can use [huihui_ai/deepseek-v3-pruned](https://ollama.com/huihui_ai/deepseek-v3-pruned) directly
```
ollama run huihui_ai/deepseek-v3-pruned
```


## Use with transformers

```
from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig
import torch

# Load the model and tokenizer
NEW_MODEL_ID = ""huihui-ai/DeepSeek-V3-Pruned-Coder-411B""
quant_config_4 = BitsAndBytesConfig(
    load_in_4bit=True,
    bnb_4bit_compute_dtype=torch.bfloat16,
    bnb_4bit_use_double_quant=True,
    llm_int8_enable_fp32_cpu_offload=True,
)

model = AutoModelForCausalLM.from_pretrained(
    NEW_MODEL_ID, 
    device_map=""auto"", 
    trust_remote_code=True,
    quantization_config=quant_config_4,
    torch_dtype=torch.bfloat16
)
tokenizer = AutoTokenizer.from_pretrained(NEW_MODEL_ID, trust_remote_code=True)
if tokenizer.pad_token is None:
    tokenizer.pad_token = tokenizer.eos_token

tokenizer.pad_token_id = tokenizer.eos_token_id

# Initialize conversation context
initial_messages = [
    {""role"": ""system"", ""content"": ""You are a helpful assistant.""}
]
messages = initial_messages.copy()  # Copy the initial conversation context

# Enter conversation loop
while True:
    # Get user input
    user_input = input(""User: "").strip()  # Strip leading and trailing spaces

    # If the user types '/exit', end the conversation
    if user_input.lower() == ""/exit"":
        print(""Exiting chat."")
        break

    # If the user types '/clean', reset the conversation context
    if user_input.lower() == ""/clear"":
        messages = initial_messages.copy()  # Reset conversation context
        print(""Chat history cleared. Starting a new conversation."")
        continue

    # If input is empty, prompt the user and continue
    if not user_input:
        print(""Input cannot be empty. Please enter something."")
        continue

    # Add user input to the conversation
    messages.append({""role"": ""user"", ""content"": user_input})

    tokenized_message = tokenizer.apply_chat_template(messages, tokenize=True, add_generation_prompt=True, return_tensors=""pt"", return_dict=True)
    response_token_ids = model.generate(tokenized_message['input_ids'].to(""cuda:0""), use_cache=False, pad_token_id=tokenizer.pad_token_id, max_new_tokens=8192)
    generated_tokens =response_token_ids[:, len(tokenized_message['input_ids'][0]):]
    response = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)[0]

    # Add the model's response to the conversation
    messages.append({""role"": ""assistant"", ""content"": response})

    # Print the model's response
    print(f""Response: {response}"")
```

### Donation

If you like it, please click 'like' and follow us for more updates.  
You can follow [x.com/support_huihui](https://x.com/support_huihui) to get the latest model information from huihui.ai.

##### Your donation helps us continue our further development and improvement, a cup of coffee can do it.
- bitcoin:
```
  bc1qqnkhuchxw0zqjh2ku3lu4hq45hc6gy84uk70ge
```
","{""id"": ""huihui-ai/DeepSeek-V3-Pruned-Coder-411B"", ""author"": ""huihui-ai"", ""sha"": ""288926b5b7f26d6e1c86d6b4a821a5b905dd2688"", ""last_modified"": ""2025-03-15 19:40:59+00:00"", ""created_at"": ""2025-03-12 02:05:57+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 11, ""downloads_all_time"": null, ""likes"": 5, ""library_name"": null, ""gguf"": null, ""inference"": null, ""tags"": [""safetensors"", ""deepseek_v3"", ""bf16"", ""Safetensors"", ""custom_code"", ""Pruned"", ""base_model:deepseek-ai/DeepSeek-V3"", ""base_model:finetune:deepseek-ai/DeepSeek-V3"", ""license:apache-2.0"", ""region:us""], ""pipeline_tag"": null, ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model:\n- deepseek-ai/DeepSeek-V3\nlicense: apache-2.0\ntags:\n- deepseek_v3\n- bf16\n- Safetensors\n- custom_code\n- Pruned"", ""widget_data"": null, ""model_index"": null, ""config"": {""architectures"": [""DeepseekV3ForCausalLM""], ""auto_map"": {""AutoConfig"": ""configuration_deepseek.DeepseekV3Config"", ""AutoModel"": ""modeling_deepseek.DeepseekV3Model"", ""AutoModelForCausalLM"": ""modeling_deepseek.DeepseekV3ForCausalLM""}, ""model_type"": ""deepseek_v3"", ""tokenizer_config"": {""bos_token"": ""<\uff5cbegin\u2581of\u2581sentence\uff5c>"", ""chat_template"": ""{% if not add_generation_prompt is defined %}{% set add_generation_prompt = false %}{% endif %}{% set ns = namespace(is_first=false, is_tool=false, is_output_first=true, system_prompt='', is_first_sp=true) %}{%- for message in messages %}{%- if message['role'] == 'system' %}{%- if ns.is_first_sp %}{% set ns.system_prompt = ns.system_prompt + message['content'] %}{% set ns.is_first_sp = false %}{%- else %}{% set ns.system_prompt = ns.system_prompt + '\n\n' + message['content'] %}{%- endif %}{%- endif %}{%- endfor %}{{bos_token}}{{ns.system_prompt}}{%- for message in messages %}{%- if message['role'] == 'user' %}{%- set ns.is_tool = false -%}{{'<\uff5cUser\uff5c>' + message['content']}}{%- endif %}{%- if message['role'] == 'assistant' and message['content'] is none %}{%- set ns.is_tool = false -%}{%- for tool in message['tool_calls']%}{%- if not ns.is_first %}{{'<\uff5cAssistant\uff5c><\uff5ctool\u2581calls\u2581begin\uff5c><\uff5ctool\u2581call\u2581begin\uff5c>' + tool['type'] + '<\uff5ctool\u2581sep\uff5c>' + tool['function']['name'] + '\n' + '```json' + '\n' + tool['function']['arguments'] + '\n' + '```' + '<\uff5ctool\u2581call\u2581end\uff5c>'}}{%- set ns.is_first = true -%}{%- else %}{{'\n' + '<\uff5ctool\u2581call\u2581begin\uff5c>' + tool['type'] + '<\uff5ctool\u2581sep\uff5c>' + tool['function']['name'] + '\n' + '```json' + '\n' + tool['function']['arguments'] + '\n' + '```' + '<\uff5ctool\u2581call\u2581end\uff5c>'}}{{'<\uff5ctool\u2581calls\u2581end\uff5c><\uff5cend\u2581of\u2581sentence\uff5c>'}}{%- endif %}{%- endfor %}{%- endif %}{%- if message['role'] == 'assistant' and message['content'] is not none %}{%- if ns.is_tool %}{{'<\uff5ctool\u2581outputs\u2581end\uff5c>' + message['content'] + '<\uff5cend\u2581of\u2581sentence\uff5c>'}}{%- set ns.is_tool = false -%}{%- else %}{{'<\uff5cAssistant\uff5c>' + message['content'] + '<\uff5cend\u2581of\u2581sentence\uff5c>'}}{%- endif %}{%- endif %}{%- if message['role'] == 'tool' %}{%- set ns.is_tool = true -%}{%- if ns.is_output_first %}{{'<\uff5ctool\u2581outputs\u2581begin\uff5c><\uff5ctool\u2581output\u2581begin\uff5c>' + message['content'] + '<\uff5ctool\u2581output\u2581end\uff5c>'}}{%- set ns.is_output_first = false %}{%- else %}{{'\n<\uff5ctool\u2581output\u2581begin\uff5c>' + message['content'] + '<\uff5ctool\u2581output\u2581end\uff5c>'}}{%- endif %}{%- endif %}{%- endfor -%}{% if ns.is_tool %}{{'<\uff5ctool\u2581outputs\u2581end\uff5c>'}}{% endif %}{% if add_generation_prompt and not ns.is_tool %}{{'<\uff5cAssistant\uff5c>'}}{% endif %}"", ""eos_token"": ""<\uff5cend\u2581of\u2581sentence\uff5c>"", ""pad_token"": ""<\uff5cend\u2581of\u2581sentence\uff5c>"", ""unk_token"": null, ""use_default_system_prompt"": false}}, ""transformers_info"": null, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='LICENSE-CODE', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='LICENSE-MODEL', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='Modelfile', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='coding_problems.py', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='configuration_deepseek.py', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='generation_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00001-of-00086.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00002-of-00086.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00003-of-00086.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00004-of-00086.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00005-of-00086.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00006-of-00086.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00007-of-00086.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00008-of-00086.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00009-of-00086.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00010-of-00086.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00011-of-00086.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00012-of-00086.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00013-of-00086.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00014-of-00086.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00015-of-00086.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00016-of-00086.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00017-of-00086.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00018-of-00086.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00019-of-00086.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00020-of-00086.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00021-of-00086.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00022-of-00086.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00023-of-00086.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00024-of-00086.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00025-of-00086.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00026-of-00086.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00027-of-00086.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00028-of-00086.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00029-of-00086.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00030-of-00086.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00031-of-00086.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00032-of-00086.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00033-of-00086.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00034-of-00086.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00035-of-00086.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00036-of-00086.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00037-of-00086.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00038-of-00086.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00039-of-00086.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00040-of-00086.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00041-of-00086.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00042-of-00086.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00043-of-00086.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00044-of-00086.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00045-of-00086.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00046-of-00086.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00047-of-00086.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00048-of-00086.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00049-of-00086.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00050-of-00086.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00051-of-00086.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00052-of-00086.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00053-of-00086.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00054-of-00086.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00055-of-00086.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00056-of-00086.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00057-of-00086.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00058-of-00086.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00059-of-00086.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00060-of-00086.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00061-of-00086.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00062-of-00086.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00063-of-00086.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00064-of-00086.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00065-of-00086.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00066-of-00086.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00067-of-00086.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00068-of-00086.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00069-of-00086.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00070-of-00086.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00071-of-00086.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00072-of-00086.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00073-of-00086.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00074-of-00086.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00075-of-00086.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00076-of-00086.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00077-of-00086.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00078-of-00086.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00079-of-00086.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00080-of-00086.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00081-of-00086.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00082-of-00086.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00083-of-00086.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00084-of-00086.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00085-of-00086.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00086-of-00086.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model.safetensors.index.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='modeling_deepseek.py', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": {""parameters"": {""BF16"": 425770713152}, ""total"": 425770713152}, ""security_repo_status"": null, ""lastModified"": ""2025-03-15 19:40:59+00:00"", ""cardData"": ""base_model:\n- deepseek-ai/DeepSeek-V3\nlicense: apache-2.0\ntags:\n- deepseek_v3\n- bf16\n- Safetensors\n- custom_code\n- Pruned"", ""transformersInfo"": null, ""_id"": ""67d0ec05a3158b8e55d18c08"", ""modelId"": ""huihui-ai/DeepSeek-V3-Pruned-Coder-411B"", ""usedStorage"": 851545020160}",1,"https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-GGUF, https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-i1-GGUF",2,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=huihui-ai/DeepSeek-V3-Pruned-Coder-411B&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bhuihui-ai%2FDeepSeek-V3-Pruned-Coder-411B%5D(%2Fhuihui-ai%2FDeepSeek-V3-Pruned-Coder-411B)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1
mradermacher/DeepSeek-V3-Pruned-Coder-411B-GGUF,"---
base_model: huihui-ai/DeepSeek-V3-Pruned-Coder-411B
language:
- en
library_name: transformers
license: apache-2.0
quantized_by: mradermacher
tags:
- deepseek_v3
- bf16
- Safetensors
- custom_code
- Pruned
---
## About

<!-- ### quantize_version: 2 -->
<!-- ### output_tensor_quantised: 1 -->
<!-- ### convert_type: hf -->
<!-- ### vocab_type:  -->
<!-- ### tags:  -->
static quants of https://huggingface.co/huihui-ai/DeepSeek-V3-Pruned-Coder-411B

<!-- provided-files -->
weighted/imatrix quants are available at https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-i1-GGUF
## Usage

If you are unsure how to use GGUF files, refer to one of [TheBloke's
READMEs](https://huggingface.co/TheBloke/KafkaLM-70B-German-V0.1-GGUF) for
more details, including on how to concatenate multi-part files.

## Provided Quants

(sorted by size, not necessarily quality. IQ-quants are often preferable over similar sized non-IQ quants)

| Link | Type | Size/GB | Notes |
|:-----|:-----|--------:|:------|
| [PART 1](https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-GGUF/resolve/main/DeepSeek-V3-Pruned-Coder-411B.Q2_K.gguf.part1of4) [PART 2](https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-GGUF/resolve/main/DeepSeek-V3-Pruned-Coder-411B.Q2_K.gguf.part2of4) [PART 3](https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-GGUF/resolve/main/DeepSeek-V3-Pruned-Coder-411B.Q2_K.gguf.part3of4) [PART 4](https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-GGUF/resolve/main/DeepSeek-V3-Pruned-Coder-411B.Q2_K.gguf.part4of4) | Q2_K | 155.2 |  |
| [PART 1](https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-GGUF/resolve/main/DeepSeek-V3-Pruned-Coder-411B.Q3_K_S.gguf.part1of4) [PART 2](https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-GGUF/resolve/main/DeepSeek-V3-Pruned-Coder-411B.Q3_K_S.gguf.part2of4) [PART 3](https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-GGUF/resolve/main/DeepSeek-V3-Pruned-Coder-411B.Q3_K_S.gguf.part3of4) [PART 4](https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-GGUF/resolve/main/DeepSeek-V3-Pruned-Coder-411B.Q3_K_S.gguf.part4of4) | Q3_K_S | 183.7 |  |
| [P1](https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-GGUF/resolve/main/DeepSeek-V3-Pruned-Coder-411B.Q3_K_M.gguf.part1of5) [P2](https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-GGUF/resolve/main/DeepSeek-V3-Pruned-Coder-411B.Q3_K_M.gguf.part2of5) [P3](https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-GGUF/resolve/main/DeepSeek-V3-Pruned-Coder-411B.Q3_K_M.gguf.part3of5) [P4](https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-GGUF/resolve/main/DeepSeek-V3-Pruned-Coder-411B.Q3_K_M.gguf.part4of5) [P5](https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-GGUF/resolve/main/DeepSeek-V3-Pruned-Coder-411B.Q3_K_M.gguf.part5of5) | Q3_K_M | 202.9 | lower quality |
| [P1](https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-GGUF/resolve/main/DeepSeek-V3-Pruned-Coder-411B.Q3_K_L.gguf.part1of5) [P2](https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-GGUF/resolve/main/DeepSeek-V3-Pruned-Coder-411B.Q3_K_L.gguf.part2of5) [P3](https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-GGUF/resolve/main/DeepSeek-V3-Pruned-Coder-411B.Q3_K_L.gguf.part3of5) [P4](https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-GGUF/resolve/main/DeepSeek-V3-Pruned-Coder-411B.Q3_K_L.gguf.part4of5) [P5](https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-GGUF/resolve/main/DeepSeek-V3-Pruned-Coder-411B.Q3_K_L.gguf.part5of5) | Q3_K_L | 220.9 |  |
| [P1](https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-GGUF/resolve/main/DeepSeek-V3-Pruned-Coder-411B.IQ4_XS.gguf.part1of5) [P2](https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-GGUF/resolve/main/DeepSeek-V3-Pruned-Coder-411B.IQ4_XS.gguf.part2of5) [P3](https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-GGUF/resolve/main/DeepSeek-V3-Pruned-Coder-411B.IQ4_XS.gguf.part3of5) [P4](https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-GGUF/resolve/main/DeepSeek-V3-Pruned-Coder-411B.IQ4_XS.gguf.part4of5) [P5](https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-GGUF/resolve/main/DeepSeek-V3-Pruned-Coder-411B.IQ4_XS.gguf.part5of5) | IQ4_XS | 228.3 |  |
| [P1](https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-GGUF/resolve/main/DeepSeek-V3-Pruned-Coder-411B.Q4_K_S.gguf.part1of5) [P2](https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-GGUF/resolve/main/DeepSeek-V3-Pruned-Coder-411B.Q4_K_S.gguf.part2of5) [P3](https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-GGUF/resolve/main/DeepSeek-V3-Pruned-Coder-411B.Q4_K_S.gguf.part3of5) [P4](https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-GGUF/resolve/main/DeepSeek-V3-Pruned-Coder-411B.Q4_K_S.gguf.part4of5) [P5](https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-GGUF/resolve/main/DeepSeek-V3-Pruned-Coder-411B.Q4_K_S.gguf.part5of5) | Q4_K_S | 241.3 | fast, recommended |
| [P1](https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-GGUF/resolve/main/DeepSeek-V3-Pruned-Coder-411B.Q4_K_M.gguf.part1of6) [P2](https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-GGUF/resolve/main/DeepSeek-V3-Pruned-Coder-411B.Q4_K_M.gguf.part2of6) [P3](https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-GGUF/resolve/main/DeepSeek-V3-Pruned-Coder-411B.Q4_K_M.gguf.part3of6) [P4](https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-GGUF/resolve/main/DeepSeek-V3-Pruned-Coder-411B.Q4_K_M.gguf.part4of6) [P5](https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-GGUF/resolve/main/DeepSeek-V3-Pruned-Coder-411B.Q4_K_M.gguf.part5of6) [P6](https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-GGUF/resolve/main/DeepSeek-V3-Pruned-Coder-411B.Q4_K_M.gguf.part6of6) | Q4_K_M | 256.6 | fast, recommended |
| [P1](https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-GGUF/resolve/main/DeepSeek-V3-Pruned-Coder-411B.Q5_K_S.gguf.part1of6) [P2](https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-GGUF/resolve/main/DeepSeek-V3-Pruned-Coder-411B.Q5_K_S.gguf.part2of6) [P3](https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-GGUF/resolve/main/DeepSeek-V3-Pruned-Coder-411B.Q5_K_S.gguf.part3of6) [P4](https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-GGUF/resolve/main/DeepSeek-V3-Pruned-Coder-411B.Q5_K_S.gguf.part4of6) [P5](https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-GGUF/resolve/main/DeepSeek-V3-Pruned-Coder-411B.Q5_K_S.gguf.part5of6) [P6](https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-GGUF/resolve/main/DeepSeek-V3-Pruned-Coder-411B.Q5_K_S.gguf.part6of6) | Q5_K_S | 293.2 |  |
| [P1](https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-GGUF/resolve/main/DeepSeek-V3-Pruned-Coder-411B.Q5_K_M.gguf.part1of7) [P2](https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-GGUF/resolve/main/DeepSeek-V3-Pruned-Coder-411B.Q5_K_M.gguf.part2of7) [P3](https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-GGUF/resolve/main/DeepSeek-V3-Pruned-Coder-411B.Q5_K_M.gguf.part3of7) [P4](https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-GGUF/resolve/main/DeepSeek-V3-Pruned-Coder-411B.Q5_K_M.gguf.part4of7) [P5](https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-GGUF/resolve/main/DeepSeek-V3-Pruned-Coder-411B.Q5_K_M.gguf.part5of7) [P6](https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-GGUF/resolve/main/DeepSeek-V3-Pruned-Coder-411B.Q5_K_M.gguf.part6of7) [P7](https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-GGUF/resolve/main/DeepSeek-V3-Pruned-Coder-411B.Q5_K_M.gguf.part7of7) | Q5_K_M | 301.7 |  |
| [P1](https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-GGUF/resolve/main/DeepSeek-V3-Pruned-Coder-411B.Q6_K.gguf.part1of8) [P2](https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-GGUF/resolve/main/DeepSeek-V3-Pruned-Coder-411B.Q6_K.gguf.part2of8) [P3](https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-GGUF/resolve/main/DeepSeek-V3-Pruned-Coder-411B.Q6_K.gguf.part3of8) [P4](https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-GGUF/resolve/main/DeepSeek-V3-Pruned-Coder-411B.Q6_K.gguf.part4of8) [P5](https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-GGUF/resolve/main/DeepSeek-V3-Pruned-Coder-411B.Q6_K.gguf.part5of8) [P6](https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-GGUF/resolve/main/DeepSeek-V3-Pruned-Coder-411B.Q6_K.gguf.part6of8) [P7](https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-GGUF/resolve/main/DeepSeek-V3-Pruned-Coder-411B.Q6_K.gguf.part7of8) [P8](https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-GGUF/resolve/main/DeepSeek-V3-Pruned-Coder-411B.Q6_K.gguf.part8of8) | Q6_K | 349.6 | very good quality |
| [P1](https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-GGUF/resolve/main/DeepSeek-V3-Pruned-Coder-411B.Q8_0.gguf.part01of10) [P2](https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-GGUF/resolve/main/DeepSeek-V3-Pruned-Coder-411B.Q8_0.gguf.part02of10) [P3](https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-GGUF/resolve/main/DeepSeek-V3-Pruned-Coder-411B.Q8_0.gguf.part03of10) [P4](https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-GGUF/resolve/main/DeepSeek-V3-Pruned-Coder-411B.Q8_0.gguf.part04of10) [P5](https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-GGUF/resolve/main/DeepSeek-V3-Pruned-Coder-411B.Q8_0.gguf.part05of10) [P6](https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-GGUF/resolve/main/DeepSeek-V3-Pruned-Coder-411B.Q8_0.gguf.part06of10) [P7](https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-GGUF/resolve/main/DeepSeek-V3-Pruned-Coder-411B.Q8_0.gguf.part07of10) [P8](https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-GGUF/resolve/main/DeepSeek-V3-Pruned-Coder-411B.Q8_0.gguf.part08of10) [P9](https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-GGUF/resolve/main/DeepSeek-V3-Pruned-Coder-411B.Q8_0.gguf.part09of10) [P10](https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-GGUF/resolve/main/DeepSeek-V3-Pruned-Coder-411B.Q8_0.gguf.part10of10) | Q8_0 | 452.7 | fast, best quality |

Here is a handy graph by ikawrakow comparing some lower-quality quant
types (lower is better):

![image.png](https://www.nethype.de/huggingface_embed/quantpplgraph.png)

And here are Artefact2's thoughts on the matter:
https://gist.github.com/Artefact2/b5f810600771265fc1e39442288e8ec9

## FAQ / Model Request

See https://huggingface.co/mradermacher/model_requests for some answers to
questions you might have and/or if you want some other model quantized.

## Thanks

I thank my company, [nethype GmbH](https://www.nethype.de/), for letting
me use its servers and providing upgrades to my workstation to enable
this work in my free time. Additional thanks to [@nicoboss](https://huggingface.co/nicoboss) for giving me access to his private supercomputer, enabling me to provide many more imatrix quants, at much higher quality, than I would otherwise be able to.

<!-- end -->
","{""id"": ""mradermacher/DeepSeek-V3-Pruned-Coder-411B-GGUF"", ""author"": ""mradermacher"", ""sha"": ""16656b8f3c3a5559a2c69c2f1c1ca90b9f8afd2a"", ""last_modified"": ""2025-03-16 20:01:15+00:00"", ""created_at"": ""2025-03-16 01:53:53+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""deepseek_v3"", ""bf16"", ""Safetensors"", ""custom_code"", ""Pruned"", ""en"", ""base_model:huihui-ai/DeepSeek-V3-Pruned-Coder-411B"", ""base_model:finetune:huihui-ai/DeepSeek-V3-Pruned-Coder-411B"", ""license:apache-2.0"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": null, ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: huihui-ai/DeepSeek-V3-Pruned-Coder-411B\nlanguage:\n- en\nlibrary_name: transformers\nlicense: apache-2.0\ntags:\n- deepseek_v3\n- bf16\n- Safetensors\n- custom_code\n- Pruned\nquantized_by: mradermacher"", ""widget_data"": null, ""model_index"": null, ""config"": null, ""transformers_info"": {""auto_model"": ""AutoModel"", ""custom_class"": null, ""pipeline_tag"": null, ""processor"": null}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-Pruned-Coder-411B.IQ4_XS.gguf.part1of5', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-Pruned-Coder-411B.IQ4_XS.gguf.part2of5', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-Pruned-Coder-411B.IQ4_XS.gguf.part3of5', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-Pruned-Coder-411B.IQ4_XS.gguf.part4of5', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-Pruned-Coder-411B.IQ4_XS.gguf.part5of5', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-Pruned-Coder-411B.Q2_K.gguf.part1of4', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-Pruned-Coder-411B.Q2_K.gguf.part2of4', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-Pruned-Coder-411B.Q2_K.gguf.part3of4', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-Pruned-Coder-411B.Q2_K.gguf.part4of4', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-Pruned-Coder-411B.Q3_K_L.gguf.part1of5', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-Pruned-Coder-411B.Q3_K_L.gguf.part2of5', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-Pruned-Coder-411B.Q3_K_L.gguf.part3of5', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-Pruned-Coder-411B.Q3_K_L.gguf.part4of5', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-Pruned-Coder-411B.Q3_K_L.gguf.part5of5', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-Pruned-Coder-411B.Q3_K_M.gguf.part1of5', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-Pruned-Coder-411B.Q3_K_M.gguf.part2of5', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-Pruned-Coder-411B.Q3_K_M.gguf.part3of5', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-Pruned-Coder-411B.Q3_K_M.gguf.part4of5', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-Pruned-Coder-411B.Q3_K_M.gguf.part5of5', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-Pruned-Coder-411B.Q3_K_S.gguf.part1of4', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-Pruned-Coder-411B.Q3_K_S.gguf.part2of4', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-Pruned-Coder-411B.Q3_K_S.gguf.part3of4', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-Pruned-Coder-411B.Q3_K_S.gguf.part4of4', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-Pruned-Coder-411B.Q4_K_M.gguf.part1of6', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-Pruned-Coder-411B.Q4_K_M.gguf.part2of6', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-Pruned-Coder-411B.Q4_K_M.gguf.part3of6', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-Pruned-Coder-411B.Q4_K_M.gguf.part4of6', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-Pruned-Coder-411B.Q4_K_M.gguf.part5of6', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-Pruned-Coder-411B.Q4_K_M.gguf.part6of6', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-Pruned-Coder-411B.Q4_K_S.gguf.part1of5', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-Pruned-Coder-411B.Q4_K_S.gguf.part2of5', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-Pruned-Coder-411B.Q4_K_S.gguf.part3of5', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-Pruned-Coder-411B.Q4_K_S.gguf.part4of5', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-Pruned-Coder-411B.Q4_K_S.gguf.part5of5', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-Pruned-Coder-411B.Q5_K_M.gguf.part1of7', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-Pruned-Coder-411B.Q5_K_M.gguf.part2of7', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-Pruned-Coder-411B.Q5_K_M.gguf.part3of7', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-Pruned-Coder-411B.Q5_K_M.gguf.part4of7', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-Pruned-Coder-411B.Q5_K_M.gguf.part5of7', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-Pruned-Coder-411B.Q5_K_M.gguf.part6of7', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-Pruned-Coder-411B.Q5_K_M.gguf.part7of7', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-Pruned-Coder-411B.Q5_K_S.gguf.part1of6', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-Pruned-Coder-411B.Q5_K_S.gguf.part2of6', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-Pruned-Coder-411B.Q5_K_S.gguf.part3of6', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-Pruned-Coder-411B.Q5_K_S.gguf.part4of6', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-Pruned-Coder-411B.Q5_K_S.gguf.part5of6', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-Pruned-Coder-411B.Q5_K_S.gguf.part6of6', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-Pruned-Coder-411B.Q6_K.gguf.part1of8', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-Pruned-Coder-411B.Q6_K.gguf.part2of8', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-Pruned-Coder-411B.Q6_K.gguf.part3of8', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-Pruned-Coder-411B.Q6_K.gguf.part4of8', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-Pruned-Coder-411B.Q6_K.gguf.part5of8', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-Pruned-Coder-411B.Q6_K.gguf.part6of8', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-Pruned-Coder-411B.Q6_K.gguf.part7of8', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-Pruned-Coder-411B.Q6_K.gguf.part8of8', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-Pruned-Coder-411B.Q8_0.gguf.part01of10', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-Pruned-Coder-411B.Q8_0.gguf.part02of10', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-Pruned-Coder-411B.Q8_0.gguf.part03of10', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-Pruned-Coder-411B.Q8_0.gguf.part04of10', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-Pruned-Coder-411B.Q8_0.gguf.part05of10', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-Pruned-Coder-411B.Q8_0.gguf.part06of10', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-Pruned-Coder-411B.Q8_0.gguf.part07of10', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-Pruned-Coder-411B.Q8_0.gguf.part08of10', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-Pruned-Coder-411B.Q8_0.gguf.part09of10', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-Pruned-Coder-411B.Q8_0.gguf.part10of10', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-03-16 20:01:15+00:00"", ""cardData"": ""base_model: huihui-ai/DeepSeek-V3-Pruned-Coder-411B\nlanguage:\n- en\nlibrary_name: transformers\nlicense: apache-2.0\ntags:\n- deepseek_v3\n- bf16\n- Safetensors\n- custom_code\n- Pruned\nquantized_by: mradermacher"", ""transformersInfo"": {""auto_model"": ""AutoModel"", ""custom_class"": null, ""pipeline_tag"": null, ""processor"": null}, ""_id"": ""67d62f3197767f49259ab0fc"", ""modelId"": ""mradermacher/DeepSeek-V3-Pruned-Coder-411B-GGUF"", ""usedStorage"": 2885031166912}",2,,0,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=mradermacher/DeepSeek-V3-Pruned-Coder-411B-GGUF&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bmradermacher%2FDeepSeek-V3-Pruned-Coder-411B-GGUF%5D(%2Fmradermacher%2FDeepSeek-V3-Pruned-Coder-411B-GGUF)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1
mradermacher/DeepSeek-V3-Pruned-Coder-411B-i1-GGUF,"---
base_model: huihui-ai/DeepSeek-V3-Pruned-Coder-411B
language:
- en
library_name: transformers
license: apache-2.0
quantized_by: mradermacher
tags:
- deepseek_v3
- bf16
- Safetensors
- custom_code
- Pruned
---
## About

<!-- ### quantize_version: 2 -->
<!-- ### output_tensor_quantised: 1 -->
<!-- ### convert_type: hf -->
<!-- ### vocab_type:  -->
<!-- ### tags: nicoboss -->
weighted/imatrix quants of https://huggingface.co/huihui-ai/DeepSeek-V3-Pruned-Coder-411B

<!-- provided-files -->
static quants are available at https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-GGUF
## Usage

If you are unsure how to use GGUF files, refer to one of [TheBloke's
READMEs](https://huggingface.co/TheBloke/KafkaLM-70B-German-V0.1-GGUF) for
more details, including on how to concatenate multi-part files.

## Provided Quants

(sorted by size, not necessarily quality. IQ-quants are often preferable over similar sized non-IQ quants)

| Link | Type | Size/GB | Notes |
|:-----|:-----|--------:|:------|
| [PART 1](https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-i1-GGUF/resolve/main/DeepSeek-V3-Pruned-Coder-411B.i1-IQ1_S.gguf.part1of2) [PART 2](https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-i1-GGUF/resolve/main/DeepSeek-V3-Pruned-Coder-411B.i1-IQ1_S.gguf.part2of2) | i1-IQ1_S | 85.2 | for the desperate |
| [PART 1](https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-i1-GGUF/resolve/main/DeepSeek-V3-Pruned-Coder-411B.i1-IQ1_M.gguf.part1of2) [PART 2](https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-i1-GGUF/resolve/main/DeepSeek-V3-Pruned-Coder-411B.i1-IQ1_M.gguf.part2of2) | i1-IQ1_M | 94.9 | mostly desperate |
| [PART 1](https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-i1-GGUF/resolve/main/DeepSeek-V3-Pruned-Coder-411B.i1-IQ2_XXS.gguf.part1of3) [PART 2](https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-i1-GGUF/resolve/main/DeepSeek-V3-Pruned-Coder-411B.i1-IQ2_XXS.gguf.part2of3) [PART 3](https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-i1-GGUF/resolve/main/DeepSeek-V3-Pruned-Coder-411B.i1-IQ2_XXS.gguf.part3of3) | i1-IQ2_XXS | 111.0 |  |
| [PART 1](https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-i1-GGUF/resolve/main/DeepSeek-V3-Pruned-Coder-411B.i1-IQ2_XS.gguf.part1of3) [PART 2](https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-i1-GGUF/resolve/main/DeepSeek-V3-Pruned-Coder-411B.i1-IQ2_XS.gguf.part2of3) [PART 3](https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-i1-GGUF/resolve/main/DeepSeek-V3-Pruned-Coder-411B.i1-IQ2_XS.gguf.part3of3) | i1-IQ2_XS | 124.0 |  |
| [PART 1](https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-i1-GGUF/resolve/main/DeepSeek-V3-Pruned-Coder-411B.i1-IQ2_S.gguf.part1of3) [PART 2](https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-i1-GGUF/resolve/main/DeepSeek-V3-Pruned-Coder-411B.i1-IQ2_S.gguf.part2of3) [PART 3](https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-i1-GGUF/resolve/main/DeepSeek-V3-Pruned-Coder-411B.i1-IQ2_S.gguf.part3of3) | i1-IQ2_S | 125.7 |  |
| [PART 1](https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-i1-GGUF/resolve/main/DeepSeek-V3-Pruned-Coder-411B.i1-IQ2_M.gguf.part1of3) [PART 2](https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-i1-GGUF/resolve/main/DeepSeek-V3-Pruned-Coder-411B.i1-IQ2_M.gguf.part2of3) [PART 3](https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-i1-GGUF/resolve/main/DeepSeek-V3-Pruned-Coder-411B.i1-IQ2_M.gguf.part3of3) | i1-IQ2_M | 138.5 |  |
| [PART 1](https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-i1-GGUF/resolve/main/DeepSeek-V3-Pruned-Coder-411B.i1-Q2_K_S.gguf.part1of3) [PART 2](https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-i1-GGUF/resolve/main/DeepSeek-V3-Pruned-Coder-411B.i1-Q2_K_S.gguf.part2of3) [PART 3](https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-i1-GGUF/resolve/main/DeepSeek-V3-Pruned-Coder-411B.i1-Q2_K_S.gguf.part3of3) | i1-Q2_K_S | 142.8 | very low quality |
| [PART 1](https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-i1-GGUF/resolve/main/DeepSeek-V3-Pruned-Coder-411B.i1-Q2_K.gguf.part1of4) [PART 2](https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-i1-GGUF/resolve/main/DeepSeek-V3-Pruned-Coder-411B.i1-Q2_K.gguf.part2of4) [PART 3](https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-i1-GGUF/resolve/main/DeepSeek-V3-Pruned-Coder-411B.i1-Q2_K.gguf.part3of4) [PART 4](https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-i1-GGUF/resolve/main/DeepSeek-V3-Pruned-Coder-411B.i1-Q2_K.gguf.part4of4) | i1-Q2_K | 155.2 | IQ3_XXS probably better |
| [PART 1](https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-i1-GGUF/resolve/main/DeepSeek-V3-Pruned-Coder-411B.i1-IQ3_XXS.gguf.part1of4) [PART 2](https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-i1-GGUF/resolve/main/DeepSeek-V3-Pruned-Coder-411B.i1-IQ3_XXS.gguf.part2of4) [PART 3](https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-i1-GGUF/resolve/main/DeepSeek-V3-Pruned-Coder-411B.i1-IQ3_XXS.gguf.part3of4) [PART 4](https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-i1-GGUF/resolve/main/DeepSeek-V3-Pruned-Coder-411B.i1-IQ3_XXS.gguf.part4of4) | i1-IQ3_XXS | 164.0 | lower quality |
| [PART 1](https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-i1-GGUF/resolve/main/DeepSeek-V3-Pruned-Coder-411B.i1-IQ3_XS.gguf.part1of4) [PART 2](https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-i1-GGUF/resolve/main/DeepSeek-V3-Pruned-Coder-411B.i1-IQ3_XS.gguf.part2of4) [PART 3](https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-i1-GGUF/resolve/main/DeepSeek-V3-Pruned-Coder-411B.i1-IQ3_XS.gguf.part3of4) [PART 4](https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-i1-GGUF/resolve/main/DeepSeek-V3-Pruned-Coder-411B.i1-IQ3_XS.gguf.part4of4) | i1-IQ3_XS | 173.5 |  |
| [PART 1](https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-i1-GGUF/resolve/main/DeepSeek-V3-Pruned-Coder-411B.i1-IQ3_S.gguf.part1of4) [PART 2](https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-i1-GGUF/resolve/main/DeepSeek-V3-Pruned-Coder-411B.i1-IQ3_S.gguf.part2of4) [PART 3](https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-i1-GGUF/resolve/main/DeepSeek-V3-Pruned-Coder-411B.i1-IQ3_S.gguf.part3of4) [PART 4](https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-i1-GGUF/resolve/main/DeepSeek-V3-Pruned-Coder-411B.i1-IQ3_S.gguf.part4of4) | i1-IQ3_S | 183.7 | beats Q3_K* |
| [PART 1](https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-i1-GGUF/resolve/main/DeepSeek-V3-Pruned-Coder-411B.i1-Q3_K_S.gguf.part1of4) [PART 2](https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-i1-GGUF/resolve/main/DeepSeek-V3-Pruned-Coder-411B.i1-Q3_K_S.gguf.part2of4) [PART 3](https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-i1-GGUF/resolve/main/DeepSeek-V3-Pruned-Coder-411B.i1-Q3_K_S.gguf.part3of4) [PART 4](https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-i1-GGUF/resolve/main/DeepSeek-V3-Pruned-Coder-411B.i1-Q3_K_S.gguf.part4of4) | i1-Q3_K_S | 183.7 | IQ3_XS probably better |
| [PART 1](https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-i1-GGUF/resolve/main/DeepSeek-V3-Pruned-Coder-411B.i1-IQ3_M.gguf.part1of4) [PART 2](https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-i1-GGUF/resolve/main/DeepSeek-V3-Pruned-Coder-411B.i1-IQ3_M.gguf.part2of4) [PART 3](https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-i1-GGUF/resolve/main/DeepSeek-V3-Pruned-Coder-411B.i1-IQ3_M.gguf.part3of4) [PART 4](https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-i1-GGUF/resolve/main/DeepSeek-V3-Pruned-Coder-411B.i1-IQ3_M.gguf.part4of4) | i1-IQ3_M | 185.9 |  |
| [P1](https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-i1-GGUF/resolve/main/DeepSeek-V3-Pruned-Coder-411B.i1-Q3_K_M.gguf.part1of5) [P2](https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-i1-GGUF/resolve/main/DeepSeek-V3-Pruned-Coder-411B.i1-Q3_K_M.gguf.part2of5) [P3](https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-i1-GGUF/resolve/main/DeepSeek-V3-Pruned-Coder-411B.i1-Q3_K_M.gguf.part3of5) [P4](https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-i1-GGUF/resolve/main/DeepSeek-V3-Pruned-Coder-411B.i1-Q3_K_M.gguf.part4of5) [P5](https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-i1-GGUF/resolve/main/DeepSeek-V3-Pruned-Coder-411B.i1-Q3_K_M.gguf.part5of5) | i1-Q3_K_M | 202.9 | IQ3_S probably better |
| [P1](https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-i1-GGUF/resolve/main/DeepSeek-V3-Pruned-Coder-411B.i1-Q3_K_L.gguf.part1of5) [P2](https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-i1-GGUF/resolve/main/DeepSeek-V3-Pruned-Coder-411B.i1-Q3_K_L.gguf.part2of5) [P3](https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-i1-GGUF/resolve/main/DeepSeek-V3-Pruned-Coder-411B.i1-Q3_K_L.gguf.part3of5) [P4](https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-i1-GGUF/resolve/main/DeepSeek-V3-Pruned-Coder-411B.i1-Q3_K_L.gguf.part4of5) [P5](https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-i1-GGUF/resolve/main/DeepSeek-V3-Pruned-Coder-411B.i1-Q3_K_L.gguf.part5of5) | i1-Q3_K_L | 220.9 | IQ3_M probably better |
| [P1](https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-i1-GGUF/resolve/main/DeepSeek-V3-Pruned-Coder-411B.i1-IQ4_XS.gguf.part1of5) [P2](https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-i1-GGUF/resolve/main/DeepSeek-V3-Pruned-Coder-411B.i1-IQ4_XS.gguf.part2of5) [P3](https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-i1-GGUF/resolve/main/DeepSeek-V3-Pruned-Coder-411B.i1-IQ4_XS.gguf.part3of5) [P4](https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-i1-GGUF/resolve/main/DeepSeek-V3-Pruned-Coder-411B.i1-IQ4_XS.gguf.part4of5) [P5](https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-i1-GGUF/resolve/main/DeepSeek-V3-Pruned-Coder-411B.i1-IQ4_XS.gguf.part5of5) | i1-IQ4_XS | 226.8 |  |
| [P1](https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-i1-GGUF/resolve/main/DeepSeek-V3-Pruned-Coder-411B.i1-Q4_0.gguf.part1of5) [P2](https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-i1-GGUF/resolve/main/DeepSeek-V3-Pruned-Coder-411B.i1-Q4_0.gguf.part2of5) [P3](https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-i1-GGUF/resolve/main/DeepSeek-V3-Pruned-Coder-411B.i1-Q4_0.gguf.part3of5) [P4](https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-i1-GGUF/resolve/main/DeepSeek-V3-Pruned-Coder-411B.i1-Q4_0.gguf.part4of5) [P5](https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-i1-GGUF/resolve/main/DeepSeek-V3-Pruned-Coder-411B.i1-Q4_0.gguf.part5of5) | i1-Q4_0 | 240.7 | fast, low quality |
| [P1](https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-i1-GGUF/resolve/main/DeepSeek-V3-Pruned-Coder-411B.i1-Q4_K_S.gguf.part1of5) [P2](https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-i1-GGUF/resolve/main/DeepSeek-V3-Pruned-Coder-411B.i1-Q4_K_S.gguf.part2of5) [P3](https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-i1-GGUF/resolve/main/DeepSeek-V3-Pruned-Coder-411B.i1-Q4_K_S.gguf.part3of5) [P4](https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-i1-GGUF/resolve/main/DeepSeek-V3-Pruned-Coder-411B.i1-Q4_K_S.gguf.part4of5) [P5](https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-i1-GGUF/resolve/main/DeepSeek-V3-Pruned-Coder-411B.i1-Q4_K_S.gguf.part5of5) | i1-Q4_K_S | 241.3 | optimal size/speed/quality |
| [P1](https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-i1-GGUF/resolve/main/DeepSeek-V3-Pruned-Coder-411B.i1-Q4_K_M.gguf.part1of6) [P2](https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-i1-GGUF/resolve/main/DeepSeek-V3-Pruned-Coder-411B.i1-Q4_K_M.gguf.part2of6) [P3](https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-i1-GGUF/resolve/main/DeepSeek-V3-Pruned-Coder-411B.i1-Q4_K_M.gguf.part3of6) [P4](https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-i1-GGUF/resolve/main/DeepSeek-V3-Pruned-Coder-411B.i1-Q4_K_M.gguf.part4of6) [P5](https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-i1-GGUF/resolve/main/DeepSeek-V3-Pruned-Coder-411B.i1-Q4_K_M.gguf.part5of6) [P6](https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-i1-GGUF/resolve/main/DeepSeek-V3-Pruned-Coder-411B.i1-Q4_K_M.gguf.part6of6) | i1-Q4_K_M | 256.6 | fast, recommended |
| [P1](https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-i1-GGUF/resolve/main/DeepSeek-V3-Pruned-Coder-411B.i1-Q4_1.gguf.part1of6) [P2](https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-i1-GGUF/resolve/main/DeepSeek-V3-Pruned-Coder-411B.i1-Q4_1.gguf.part2of6) [P3](https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-i1-GGUF/resolve/main/DeepSeek-V3-Pruned-Coder-411B.i1-Q4_1.gguf.part3of6) [P4](https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-i1-GGUF/resolve/main/DeepSeek-V3-Pruned-Coder-411B.i1-Q4_1.gguf.part4of6) [P5](https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-i1-GGUF/resolve/main/DeepSeek-V3-Pruned-Coder-411B.i1-Q4_1.gguf.part5of6) [P6](https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-i1-GGUF/resolve/main/DeepSeek-V3-Pruned-Coder-411B.i1-Q4_1.gguf.part6of6) | i1-Q4_1 | 266.6 |  |
| [P1](https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-i1-GGUF/resolve/main/DeepSeek-V3-Pruned-Coder-411B.i1-Q5_K_S.gguf.part1of6) [P2](https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-i1-GGUF/resolve/main/DeepSeek-V3-Pruned-Coder-411B.i1-Q5_K_S.gguf.part2of6) [P3](https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-i1-GGUF/resolve/main/DeepSeek-V3-Pruned-Coder-411B.i1-Q5_K_S.gguf.part3of6) [P4](https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-i1-GGUF/resolve/main/DeepSeek-V3-Pruned-Coder-411B.i1-Q5_K_S.gguf.part4of6) [P5](https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-i1-GGUF/resolve/main/DeepSeek-V3-Pruned-Coder-411B.i1-Q5_K_S.gguf.part5of6) [P6](https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-i1-GGUF/resolve/main/DeepSeek-V3-Pruned-Coder-411B.i1-Q5_K_S.gguf.part6of6) | i1-Q5_K_S | 293.2 |  |
| [P1](https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-i1-GGUF/resolve/main/DeepSeek-V3-Pruned-Coder-411B.i1-Q5_K_M.gguf.part1of7) [P2](https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-i1-GGUF/resolve/main/DeepSeek-V3-Pruned-Coder-411B.i1-Q5_K_M.gguf.part2of7) [P3](https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-i1-GGUF/resolve/main/DeepSeek-V3-Pruned-Coder-411B.i1-Q5_K_M.gguf.part3of7) [P4](https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-i1-GGUF/resolve/main/DeepSeek-V3-Pruned-Coder-411B.i1-Q5_K_M.gguf.part4of7) [P5](https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-i1-GGUF/resolve/main/DeepSeek-V3-Pruned-Coder-411B.i1-Q5_K_M.gguf.part5of7) [P6](https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-i1-GGUF/resolve/main/DeepSeek-V3-Pruned-Coder-411B.i1-Q5_K_M.gguf.part6of7) [P7](https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-i1-GGUF/resolve/main/DeepSeek-V3-Pruned-Coder-411B.i1-Q5_K_M.gguf.part7of7) | i1-Q5_K_M | 301.7 |  |
| [P1](https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-i1-GGUF/resolve/main/DeepSeek-V3-Pruned-Coder-411B.i1-Q6_K.gguf.part1of8) [P2](https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-i1-GGUF/resolve/main/DeepSeek-V3-Pruned-Coder-411B.i1-Q6_K.gguf.part2of8) [P3](https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-i1-GGUF/resolve/main/DeepSeek-V3-Pruned-Coder-411B.i1-Q6_K.gguf.part3of8) [P4](https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-i1-GGUF/resolve/main/DeepSeek-V3-Pruned-Coder-411B.i1-Q6_K.gguf.part4of8) [P5](https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-i1-GGUF/resolve/main/DeepSeek-V3-Pruned-Coder-411B.i1-Q6_K.gguf.part5of8) [P6](https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-i1-GGUF/resolve/main/DeepSeek-V3-Pruned-Coder-411B.i1-Q6_K.gguf.part6of8) [P7](https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-i1-GGUF/resolve/main/DeepSeek-V3-Pruned-Coder-411B.i1-Q6_K.gguf.part7of8) [P8](https://huggingface.co/mradermacher/DeepSeek-V3-Pruned-Coder-411B-i1-GGUF/resolve/main/DeepSeek-V3-Pruned-Coder-411B.i1-Q6_K.gguf.part8of8) | i1-Q6_K | 349.6 | practically like static Q6_K |

Here is a handy graph by ikawrakow comparing some lower-quality quant
types (lower is better):

![image.png](https://www.nethype.de/huggingface_embed/quantpplgraph.png)

And here are Artefact2's thoughts on the matter:
https://gist.github.com/Artefact2/b5f810600771265fc1e39442288e8ec9

## FAQ / Model Request

See https://huggingface.co/mradermacher/model_requests for some answers to
questions you might have and/or if you want some other model quantized.

## Thanks

I thank my company, [nethype GmbH](https://www.nethype.de/), for letting
me use its servers and providing upgrades to my workstation to enable
this work in my free time. Additional thanks to [@nicoboss](https://huggingface.co/nicoboss) for giving me access to his private supercomputer, enabling me to provide many more imatrix quants, at much higher quality, than I would otherwise be able to.

<!-- end -->
","{""id"": ""mradermacher/DeepSeek-V3-Pruned-Coder-411B-i1-GGUF"", ""author"": ""mradermacher"", ""sha"": ""8833c819651324477184b8a99b5dabb1f1c7f88f"", ""last_modified"": ""2025-03-20 10:48:54+00:00"", ""created_at"": ""2025-03-16 13:44:33+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""deepseek_v3"", ""bf16"", ""Safetensors"", ""custom_code"", ""Pruned"", ""en"", ""base_model:huihui-ai/DeepSeek-V3-Pruned-Coder-411B"", ""base_model:finetune:huihui-ai/DeepSeek-V3-Pruned-Coder-411B"", ""license:apache-2.0"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": null, ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model: huihui-ai/DeepSeek-V3-Pruned-Coder-411B\nlanguage:\n- en\nlibrary_name: transformers\nlicense: apache-2.0\ntags:\n- deepseek_v3\n- bf16\n- Safetensors\n- custom_code\n- Pruned\nquantized_by: mradermacher"", ""widget_data"": null, ""model_index"": null, ""config"": null, ""transformers_info"": {""auto_model"": ""AutoModel"", ""custom_class"": null, ""pipeline_tag"": null, ""processor"": null}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-Pruned-Coder-411B.i1-IQ1_M.gguf.part1of2', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-Pruned-Coder-411B.i1-IQ1_M.gguf.part2of2', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-Pruned-Coder-411B.i1-IQ1_S.gguf.part1of2', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-Pruned-Coder-411B.i1-IQ1_S.gguf.part2of2', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-Pruned-Coder-411B.i1-IQ2_M.gguf.part1of3', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-Pruned-Coder-411B.i1-IQ2_M.gguf.part2of3', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-Pruned-Coder-411B.i1-IQ2_M.gguf.part3of3', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-Pruned-Coder-411B.i1-IQ2_S.gguf.part1of3', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-Pruned-Coder-411B.i1-IQ2_S.gguf.part2of3', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-Pruned-Coder-411B.i1-IQ2_S.gguf.part3of3', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-Pruned-Coder-411B.i1-IQ2_XS.gguf.part1of3', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-Pruned-Coder-411B.i1-IQ2_XS.gguf.part2of3', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-Pruned-Coder-411B.i1-IQ2_XS.gguf.part3of3', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-Pruned-Coder-411B.i1-IQ2_XXS.gguf.part1of3', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-Pruned-Coder-411B.i1-IQ2_XXS.gguf.part2of3', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-Pruned-Coder-411B.i1-IQ2_XXS.gguf.part3of3', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-Pruned-Coder-411B.i1-IQ3_M.gguf.part1of4', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-Pruned-Coder-411B.i1-IQ3_M.gguf.part2of4', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-Pruned-Coder-411B.i1-IQ3_M.gguf.part3of4', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-Pruned-Coder-411B.i1-IQ3_M.gguf.part4of4', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-Pruned-Coder-411B.i1-IQ3_S.gguf.part1of4', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-Pruned-Coder-411B.i1-IQ3_S.gguf.part2of4', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-Pruned-Coder-411B.i1-IQ3_S.gguf.part3of4', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-Pruned-Coder-411B.i1-IQ3_S.gguf.part4of4', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-Pruned-Coder-411B.i1-IQ3_XS.gguf.part1of4', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-Pruned-Coder-411B.i1-IQ3_XS.gguf.part2of4', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-Pruned-Coder-411B.i1-IQ3_XS.gguf.part3of4', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-Pruned-Coder-411B.i1-IQ3_XS.gguf.part4of4', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-Pruned-Coder-411B.i1-IQ3_XXS.gguf.part1of4', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-Pruned-Coder-411B.i1-IQ3_XXS.gguf.part2of4', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-Pruned-Coder-411B.i1-IQ3_XXS.gguf.part3of4', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-Pruned-Coder-411B.i1-IQ3_XXS.gguf.part4of4', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-Pruned-Coder-411B.i1-IQ4_XS.gguf.part1of5', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-Pruned-Coder-411B.i1-IQ4_XS.gguf.part2of5', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-Pruned-Coder-411B.i1-IQ4_XS.gguf.part3of5', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-Pruned-Coder-411B.i1-IQ4_XS.gguf.part4of5', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-Pruned-Coder-411B.i1-IQ4_XS.gguf.part5of5', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-Pruned-Coder-411B.i1-Q2_K.gguf.part1of4', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-Pruned-Coder-411B.i1-Q2_K.gguf.part2of4', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-Pruned-Coder-411B.i1-Q2_K.gguf.part3of4', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-Pruned-Coder-411B.i1-Q2_K.gguf.part4of4', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-Pruned-Coder-411B.i1-Q2_K_S.gguf.part1of3', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-Pruned-Coder-411B.i1-Q2_K_S.gguf.part2of3', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-Pruned-Coder-411B.i1-Q2_K_S.gguf.part3of3', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-Pruned-Coder-411B.i1-Q3_K_L.gguf.part1of5', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-Pruned-Coder-411B.i1-Q3_K_L.gguf.part2of5', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-Pruned-Coder-411B.i1-Q3_K_L.gguf.part3of5', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-Pruned-Coder-411B.i1-Q3_K_L.gguf.part4of5', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-Pruned-Coder-411B.i1-Q3_K_L.gguf.part5of5', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-Pruned-Coder-411B.i1-Q3_K_M.gguf.part1of5', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-Pruned-Coder-411B.i1-Q3_K_M.gguf.part2of5', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-Pruned-Coder-411B.i1-Q3_K_M.gguf.part3of5', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-Pruned-Coder-411B.i1-Q3_K_M.gguf.part4of5', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-Pruned-Coder-411B.i1-Q3_K_M.gguf.part5of5', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-Pruned-Coder-411B.i1-Q3_K_S.gguf.part1of4', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-Pruned-Coder-411B.i1-Q3_K_S.gguf.part2of4', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-Pruned-Coder-411B.i1-Q3_K_S.gguf.part3of4', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-Pruned-Coder-411B.i1-Q3_K_S.gguf.part4of4', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-Pruned-Coder-411B.i1-Q4_0.gguf.part1of5', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-Pruned-Coder-411B.i1-Q4_0.gguf.part2of5', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-Pruned-Coder-411B.i1-Q4_0.gguf.part3of5', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-Pruned-Coder-411B.i1-Q4_0.gguf.part4of5', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-Pruned-Coder-411B.i1-Q4_0.gguf.part5of5', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-Pruned-Coder-411B.i1-Q4_1.gguf.part1of6', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-Pruned-Coder-411B.i1-Q4_1.gguf.part2of6', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-Pruned-Coder-411B.i1-Q4_1.gguf.part3of6', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-Pruned-Coder-411B.i1-Q4_1.gguf.part4of6', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-Pruned-Coder-411B.i1-Q4_1.gguf.part5of6', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-Pruned-Coder-411B.i1-Q4_1.gguf.part6of6', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-Pruned-Coder-411B.i1-Q4_K_M.gguf.part1of6', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-Pruned-Coder-411B.i1-Q4_K_M.gguf.part2of6', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-Pruned-Coder-411B.i1-Q4_K_M.gguf.part3of6', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-Pruned-Coder-411B.i1-Q4_K_M.gguf.part4of6', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-Pruned-Coder-411B.i1-Q4_K_M.gguf.part5of6', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-Pruned-Coder-411B.i1-Q4_K_M.gguf.part6of6', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-Pruned-Coder-411B.i1-Q4_K_S.gguf.part1of5', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-Pruned-Coder-411B.i1-Q4_K_S.gguf.part2of5', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-Pruned-Coder-411B.i1-Q4_K_S.gguf.part3of5', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-Pruned-Coder-411B.i1-Q4_K_S.gguf.part4of5', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-Pruned-Coder-411B.i1-Q4_K_S.gguf.part5of5', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-Pruned-Coder-411B.i1-Q5_K_M.gguf.part1of7', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-Pruned-Coder-411B.i1-Q5_K_M.gguf.part2of7', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-Pruned-Coder-411B.i1-Q5_K_M.gguf.part3of7', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-Pruned-Coder-411B.i1-Q5_K_M.gguf.part4of7', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-Pruned-Coder-411B.i1-Q5_K_M.gguf.part5of7', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-Pruned-Coder-411B.i1-Q5_K_M.gguf.part6of7', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-Pruned-Coder-411B.i1-Q5_K_M.gguf.part7of7', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-Pruned-Coder-411B.i1-Q5_K_S.gguf.part1of6', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-Pruned-Coder-411B.i1-Q5_K_S.gguf.part2of6', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-Pruned-Coder-411B.i1-Q5_K_S.gguf.part3of6', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-Pruned-Coder-411B.i1-Q5_K_S.gguf.part4of6', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-Pruned-Coder-411B.i1-Q5_K_S.gguf.part5of6', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-Pruned-Coder-411B.i1-Q5_K_S.gguf.part6of6', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-Pruned-Coder-411B.i1-Q6_K.gguf.part1of8', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-Pruned-Coder-411B.i1-Q6_K.gguf.part2of8', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-Pruned-Coder-411B.i1-Q6_K.gguf.part3of8', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-Pruned-Coder-411B.i1-Q6_K.gguf.part4of8', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-Pruned-Coder-411B.i1-Q6_K.gguf.part5of8', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-Pruned-Coder-411B.i1-Q6_K.gguf.part6of8', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-Pruned-Coder-411B.i1-Q6_K.gguf.part7of8', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='DeepSeek-V3-Pruned-Coder-411B.i1-Q6_K.gguf.part8of8', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='imatrix.dat', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-03-20 10:48:54+00:00"", ""cardData"": ""base_model: huihui-ai/DeepSeek-V3-Pruned-Coder-411B\nlanguage:\n- en\nlibrary_name: transformers\nlicense: apache-2.0\ntags:\n- deepseek_v3\n- bf16\n- Safetensors\n- custom_code\n- Pruned\nquantized_by: mradermacher"", ""transformersInfo"": {""auto_model"": ""AutoModel"", ""custom_class"": null, ""pipeline_tag"": null, ""processor"": null}, ""_id"": ""67d6d5c14b1ae23c039298f0"", ""modelId"": ""mradermacher/DeepSeek-V3-Pruned-Coder-411B-i1-GGUF"", ""usedStorage"": 4466666094768}",2,,0,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=mradermacher/DeepSeek-V3-Pruned-Coder-411B-i1-GGUF&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bmradermacher%2FDeepSeek-V3-Pruned-Coder-411B-i1-GGUF%5D(%2Fmradermacher%2FDeepSeek-V3-Pruned-Coder-411B-i1-GGUF)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1
SicariusSicariiStuff/DeepSeek-V3-Abliterated,"---
license: mit
language:
- en
base_model:
- deepseek-ai/DeepSeek-V3
---

<h2 style=""color: #15a1e3; font-weight: bold; font-size: 65px; text-align: center;"">Deepseek_V3 Abliterated</h2>

<img src=""https://huggingface.co/SicariusSicariiStuff/DeepSeek-V3-abliterated/resolve/main/Images/DeepSeek.png"" alt=""Deepseek_V3_Abliterated"" style=""width: 30%; min-width: 450px; display: block; margin: auto;"">


---

# Acknowledgments:

A sincere thank you to the [Deepseek](https://huggingface.co/deepseek-ai) team for developing **the most powerful open-weights AI models to date**. You've challenged the status quo and won by demonstrating that true innovation comes from meritocracy, sheer will, and your domestic talent. You've also proved wrong OpenAI's claims that no open source will be able to compete with them.

Appreciation also goes to [huihui-ai](https://huggingface.co/huihui-ai) for being the first to perform abliteration on this powerful model.

Against the odds, Chinese researchers have won the hearts of the open source community despite starting the race from a disadvantaged position.","{""id"": ""SicariusSicariiStuff/DeepSeek-V3-Abliterated"", ""author"": ""SicariusSicariiStuff"", ""sha"": ""f1e97f988c54173bada8f1f6861072e2bc912ba4"", ""last_modified"": ""2025-04-15 06:28:06+00:00"", ""created_at"": ""2025-04-10 17:45:21+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 71, ""downloads_all_time"": null, ""likes"": 2, ""library_name"": null, ""gguf"": null, ""inference"": null, ""tags"": [""safetensors"", ""deepseek_v3"", ""custom_code"", ""en"", ""base_model:deepseek-ai/DeepSeek-V3"", ""base_model:finetune:deepseek-ai/DeepSeek-V3"", ""license:mit"", ""region:us""], ""pipeline_tag"": null, ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model:\n- deepseek-ai/DeepSeek-V3\nlanguage:\n- en\nlicense: mit"", ""widget_data"": null, ""model_index"": null, ""config"": {""architectures"": [""DeepseekV3ForCausalLM""], ""auto_map"": {""AutoConfig"": ""configuration_deepseek.DeepseekV3Config"", ""AutoModel"": ""modeling_deepseek.DeepseekV3Model"", ""AutoModelForCausalLM"": ""modeling_deepseek.DeepseekV3ForCausalLM""}, ""model_type"": ""deepseek_v3"", ""tokenizer_config"": {""bos_token"": ""<\uff5cbegin\u2581of\u2581sentence\uff5c>"", ""chat_template"": ""{% if not add_generation_prompt is defined %}{% set add_generation_prompt = false %}{% endif %}{% set ns = namespace(is_first=false, is_tool=false, is_output_first=true, system_prompt='', is_first_sp=true) %}{%- for message in messages %}{%- if message['role'] == 'system' %}{%- if ns.is_first_sp %}{% set ns.system_prompt = ns.system_prompt + message['content'] %}{% set ns.is_first_sp = false %}{%- else %}{% set ns.system_prompt = ns.system_prompt + '\n\n' + message['content'] %}{%- endif %}{%- endif %}{%- endfor %}{{bos_token}}{{ns.system_prompt}}{%- for message in messages %}{%- if message['role'] == 'user' %}{%- set ns.is_tool = false -%}{{'<\uff5cUser\uff5c>' + message['content']}}{%- endif %}{%- if message['role'] == 'assistant' and message['content'] is none %}{%- set ns.is_tool = false -%}{%- for tool in message['tool_calls']%}{%- if not ns.is_first %}{{'<\uff5cAssistant\uff5c><\uff5ctool\u2581calls\u2581begin\uff5c><\uff5ctool\u2581call\u2581begin\uff5c>' + tool['type'] + '<\uff5ctool\u2581sep\uff5c>' + tool['function']['name'] + '\n' + '```json' + '\n' + tool['function']['arguments'] + '\n' + '```' + '<\uff5ctool\u2581call\u2581end\uff5c>'}}{%- set ns.is_first = true -%}{%- else %}{{'\n' + '<\uff5ctool\u2581call\u2581begin\uff5c>' + tool['type'] + '<\uff5ctool\u2581sep\uff5c>' + tool['function']['name'] + '\n' + '```json' + '\n' + tool['function']['arguments'] + '\n' + '```' + '<\uff5ctool\u2581call\u2581end\uff5c>'}}{{'<\uff5ctool\u2581calls\u2581end\uff5c><\uff5cend\u2581of\u2581sentence\uff5c>'}}{%- endif %}{%- endfor %}{%- endif %}{%- if message['role'] == 'assistant' and message['content'] is not none %}{%- if ns.is_tool %}{{'<\uff5ctool\u2581outputs\u2581end\uff5c>' + message['content'] + '<\uff5cend\u2581of\u2581sentence\uff5c>'}}{%- set ns.is_tool = false -%}{%- else %}{{'<\uff5cAssistant\uff5c>' + message['content'] + '<\uff5cend\u2581of\u2581sentence\uff5c>'}}{%- endif %}{%- endif %}{%- if message['role'] == 'tool' %}{%- set ns.is_tool = true -%}{%- if ns.is_output_first %}{{'<\uff5ctool\u2581outputs\u2581begin\uff5c><\uff5ctool\u2581output\u2581begin\uff5c>' + message['content'] + '<\uff5ctool\u2581output\u2581end\uff5c>'}}{%- set ns.is_output_first = false %}{%- else %}{{'\n<\uff5ctool\u2581output\u2581begin\uff5c>' + message['content'] + '<\uff5ctool\u2581output\u2581end\uff5c>'}}{%- endif %}{%- endif %}{%- endfor -%}{% if ns.is_tool %}{{'<\uff5ctool\u2581outputs\u2581end\uff5c>'}}{% endif %}{% if add_generation_prompt and not ns.is_tool %}{{'<\uff5cAssistant\uff5c>'}}{% endif %}"", ""eos_token"": ""<\uff5cend\u2581of\u2581sentence\uff5c>"", ""pad_token"": ""<\uff5cend\u2581of\u2581sentence\uff5c>"", ""unk_token"": null, ""use_default_system_prompt"": false}}, ""transformers_info"": null, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='Images/DeepSeek.png', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='LICENSE-CODE', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='LICENSE-MODEL', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='configuration_deepseek.py', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00001-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00002-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00003-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00004-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00005-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00006-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00007-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00008-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00009-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00010-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00011-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00012-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00013-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00014-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00015-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00016-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00017-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00018-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00019-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00020-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00021-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00022-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00023-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00024-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00025-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00026-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00027-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00028-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00029-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00030-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00031-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00032-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00033-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00034-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00035-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00036-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00037-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00038-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00039-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00040-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00041-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00042-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00043-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00044-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00045-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00046-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00047-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00048-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00049-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00050-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00051-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00052-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00053-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00054-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00055-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00056-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00057-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00058-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00059-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00060-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00061-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00062-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00063-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00064-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00065-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00066-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00067-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00068-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00069-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00070-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00071-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00072-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00073-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00074-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00075-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00076-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00077-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00078-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00079-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00080-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00081-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00082-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00083-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00084-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00085-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00086-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00087-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00088-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00089-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00090-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00091-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00092-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00093-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00094-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00095-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00096-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00097-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00098-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00099-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00100-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00101-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00102-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00103-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00104-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00105-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00106-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00107-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00108-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00109-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00110-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00111-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00112-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00113-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00114-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00115-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00116-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00117-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00118-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00119-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00120-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00121-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00122-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00123-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00124-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00125-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00126-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00127-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00128-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00129-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00130-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00131-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00132-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00133-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00134-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00135-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00136-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00137-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00138-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00139-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00140-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00141-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00142-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00143-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00144-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00145-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00146-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00147-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00148-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00149-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00150-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00151-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00152-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00153-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00154-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00155-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00156-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00157-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00158-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00159-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00160-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00161-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00162-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00163-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00164-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00165-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00166-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00167-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00168-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00169-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00170-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00171-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00172-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00173-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00174-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00175-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00176-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00177-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00178-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00179-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00180-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00181-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00182-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00183-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00184-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00185-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00186-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00187-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00188-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00189-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00190-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00191-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00192-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00193-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00194-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00195-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00196-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00197-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00198-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00199-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00200-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00201-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00202-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00203-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00204-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00205-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00206-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00207-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00208-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00209-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00210-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00211-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00212-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00213-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00214-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00215-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00216-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00217-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00218-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00219-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00220-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00221-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00222-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00223-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00224-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00225-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00226-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00227-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00228-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00229-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00230-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00231-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00232-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00233-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00234-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00235-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00236-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00237-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00238-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00239-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00240-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00241-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00242-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00243-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00244-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00245-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00246-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00247-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00248-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00249-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00250-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00251-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00252-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00253-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00254-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00255-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00256-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00257-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00258-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00259-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00260-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00261-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00262-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00263-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00264-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00265-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00266-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00267-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00268-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00269-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00270-of-00270.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model.safetensors.index.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='modeling_deepseek.py', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": {""parameters"": {""BF16"": 671026419200}, ""total"": 671026419200}, ""security_repo_status"": null, ""lastModified"": ""2025-04-15 06:28:06+00:00"", ""cardData"": ""base_model:\n- deepseek-ai/DeepSeek-V3\nlanguage:\n- en\nlicense: mit"", ""transformersInfo"": null, ""_id"": ""67f803b1865b6df49e1d8dfc"", ""modelId"": ""SicariusSicariiStuff/DeepSeek-V3-Abliterated"", ""usedStorage"": 1242252511672}",1,,0,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=SicariusSicariiStuff/DeepSeek-V3-Abliterated&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5BSicariusSicariiStuff%2FDeepSeek-V3-Abliterated%5D(%2FSicariusSicariiStuff%2FDeepSeek-V3-Abliterated)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1
Stebo777/K1NGD0M_A1,"---
datasets:
- HuggingFaceFW/fineweb-2
language:
- ae
- ak
- af
- am
- an
- ar
metrics:
- accuracy
base_model:
- deepseek-ai/DeepSeek-V3
new_version: deepseek-ai/DeepSeek-V3
pipeline_tag: zero-shot-classification
---","{""id"": ""Stebo777/K1NGD0M_A1"", ""author"": ""Stebo777"", ""sha"": ""a7d3ce955d9b2624e73e9fbefe975865e40260ae"", ""last_modified"": ""2025-01-07 06:21:42+00:00"", ""created_at"": ""2024-12-24 06:26:41+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": null, ""gguf"": null, ""inference"": null, ""tags"": [""zero-shot-classification"", ""ae"", ""ak"", ""af"", ""am"", ""an"", ""ar"", ""dataset:HuggingFaceFW/fineweb-2"", ""base_model:deepseek-ai/DeepSeek-V3"", ""base_model:finetune:deepseek-ai/DeepSeek-V3"", ""region:us""], ""pipeline_tag"": ""zero-shot-classification"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model:\n- deepseek-ai/DeepSeek-V3\ndatasets:\n- HuggingFaceFW/fineweb-2\nlanguage:\n- ae\n- ak\n- af\n- am\n- an\n- ar\nmetrics:\n- accuracy\npipeline_tag: zero-shot-classification\nnew_version: deepseek-ai/DeepSeek-V3"", ""widget_data"": null, ""model_index"": null, ""config"": null, ""transformers_info"": null, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-01-07 06:21:42+00:00"", ""cardData"": ""base_model:\n- deepseek-ai/DeepSeek-V3\ndatasets:\n- HuggingFaceFW/fineweb-2\nlanguage:\n- ae\n- ak\n- af\n- am\n- an\n- ar\nmetrics:\n- accuracy\npipeline_tag: zero-shot-classification\nnew_version: deepseek-ai/DeepSeek-V3"", ""transformersInfo"": null, ""_id"": ""676a5421376c08f1b30cf985"", ""modelId"": ""Stebo777/K1NGD0M_A1"", ""usedStorage"": 0}",1,,0,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=Stebo777/K1NGD0M_A1&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5BStebo777%2FK1NGD0M_A1%5D(%2FStebo777%2FK1NGD0M_A1)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1
rikiwi/AveneR,"---
license: apache-2.0
datasets:
- fka/awesome-chatgpt-prompts
language:
- en
metrics:
- character
base_model:
- deepseek-ai/DeepSeek-V3
new_version: black-forest-labs/FLUX.1-dev
pipeline_tag: text-to-image
library_name: diffusers
tags:
- art
---","{""id"": ""rikiwi/AveneR"", ""author"": ""rikiwi"", ""sha"": ""dffa63495371b6231b6667bbe8d73ea8579fff4b"", ""last_modified"": ""2025-01-09 19:39:42+00:00"", ""created_at"": ""2024-12-29 09:18:39+00:00"", ""private"": false, ""gated"": ""auto"", ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""diffusers"", ""gguf"": null, ""inference"": null, ""tags"": [""diffusers"", ""art"", ""text-to-image"", ""en"", ""dataset:fka/awesome-chatgpt-prompts"", ""base_model:deepseek-ai/DeepSeek-V3"", ""base_model:finetune:deepseek-ai/DeepSeek-V3"", ""doi:10.57967/hf/4015"", ""license:apache-2.0"", ""region:us""], ""pipeline_tag"": ""text-to-image"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model:\n- deepseek-ai/DeepSeek-V3\ndatasets:\n- fka/awesome-chatgpt-prompts\nlanguage:\n- en\nlibrary_name: diffusers\nlicense: apache-2.0\nmetrics:\n- character\npipeline_tag: text-to-image\ntags:\n- art\nnew_version: black-forest-labs/FLUX.1-dev"", ""widget_data"": null, ""model_index"": null, ""config"": null, ""transformers_info"": null, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='af805833dd7f411d30d0601d91dbae3d.jpg', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-01-09 19:39:42+00:00"", ""cardData"": ""base_model:\n- deepseek-ai/DeepSeek-V3\ndatasets:\n- fka/awesome-chatgpt-prompts\nlanguage:\n- en\nlibrary_name: diffusers\nlicense: apache-2.0\nmetrics:\n- character\npipeline_tag: text-to-image\ntags:\n- art\nnew_version: black-forest-labs/FLUX.1-dev"", ""transformersInfo"": null, ""_id"": ""677113efd26ef46fd452fe31"", ""modelId"": ""rikiwi/AveneR"", ""usedStorage"": 0}",1,,0,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=rikiwi/AveneR&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Brikiwi%2FAveneR%5D(%2Frikiwi%2FAveneR)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1
anoher/deepseek,"---
base_model:
- deepseek-ai/DeepSeek-V3
---","{""id"": ""anoher/deepseek"", ""author"": ""anoher"", ""sha"": ""3855825ac9e2e0eac122d1d485e2f47884489d1f"", ""last_modified"": ""2024-12-31 07:55:17+00:00"", ""created_at"": ""2024-12-31 07:54:35+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": null, ""gguf"": null, ""inference"": null, ""tags"": [""base_model:deepseek-ai/DeepSeek-V3"", ""base_model:finetune:deepseek-ai/DeepSeek-V3"", ""region:us""], ""pipeline_tag"": null, ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model:\n- deepseek-ai/DeepSeek-V3"", ""widget_data"": null, ""model_index"": null, ""config"": null, ""transformers_info"": null, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2024-12-31 07:55:17+00:00"", ""cardData"": ""base_model:\n- deepseek-ai/DeepSeek-V3"", ""transformersInfo"": null, ""_id"": ""6773a33bfa7017bbd4c13504"", ""modelId"": ""anoher/deepseek"", ""usedStorage"": 0}",1,,0,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=anoher/deepseek&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Banoher%2Fdeepseek%5D(%2Fanoher%2Fdeepseek)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1
v2ray/DeepSeek-V3-FP16-Atten-NaN,"---
license: mit
base_model:
- deepseek-ai/DeepSeek-V3
pipeline_tag: text-generation
library_name: transformers
---
# DeepSeek V3 FP16 Atten NaN
This is a minimal reproduceable sample to let the final layer of DeepSeek V3's attention output NaNs when using data type float16.

Run the `run.py` to see the NaNs.

Weights are converted to bfloat16 using the original float8 e4m3fn, then converted to float16, then extracted from the final layer's attention.","{""id"": ""v2ray/DeepSeek-V3-FP16-Atten-NaN"", ""author"": ""v2ray"", ""sha"": ""fbc71cb3f837820a5434c5b1e1aac3b46aaac1a5"", ""last_modified"": ""2025-01-06 00:20:28+00:00"", ""created_at"": ""2025-01-06 00:15:32+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""text-generation"", ""base_model:deepseek-ai/DeepSeek-V3"", ""base_model:finetune:deepseek-ai/DeepSeek-V3"", ""license:mit"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model:\n- deepseek-ai/DeepSeek-V3\nlibrary_name: transformers\nlicense: mit\npipeline_tag: text-generation"", ""widget_data"": [{""text"": ""My name is Julien and I like to""}, {""text"": ""I like traveling by train because""}, {""text"": ""Paris is an amazing place to visit,""}, {""text"": ""Once upon a time,""}], ""model_index"": null, ""config"": null, ""transformers_info"": {""auto_model"": ""AutoModel"", ""custom_class"": null, ""pipeline_tag"": null, ""processor"": null}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model/config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model/configuration_deepseek.py', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model/modeling_deepseek.py', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model/nan_input.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model/nan_sentence.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model/weights.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='run.py', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-01-06 00:20:28+00:00"", ""cardData"": ""base_model:\n- deepseek-ai/DeepSeek-V3\nlibrary_name: transformers\nlicense: mit\npipeline_tag: text-generation"", ""transformersInfo"": {""auto_model"": ""AutoModel"", ""custom_class"": null, ""pipeline_tag"": null, ""processor"": null}, ""_id"": ""677b20a46f370093aaacbf8d"", ""modelId"": ""v2ray/DeepSeek-V3-FP16-Atten-NaN"", ""usedStorage"": 382088128}",1,,0,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=v2ray/DeepSeek-V3-FP16-Atten-NaN&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bv2ray%2FDeepSeek-V3-FP16-Atten-NaN%5D(%2Fv2ray%2FDeepSeek-V3-FP16-Atten-NaN)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1
Joses1234/pruebabot,"---
license: apache-2.0
language:
- aa
base_model:
- deepseek-ai/DeepSeek-V3
---","{""id"": ""Joses1234/pruebabot"", ""author"": ""Joses1234"", ""sha"": ""2e91aa219e5fc717327b188f134765c7f110740c"", ""last_modified"": ""2025-01-07 19:07:34+00:00"", ""created_at"": ""2025-01-07 19:06:32+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": null, ""gguf"": null, ""inference"": null, ""tags"": [""aa"", ""base_model:deepseek-ai/DeepSeek-V3"", ""base_model:finetune:deepseek-ai/DeepSeek-V3"", ""license:apache-2.0"", ""region:us""], ""pipeline_tag"": null, ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model:\n- deepseek-ai/DeepSeek-V3\nlanguage:\n- aa\nlicense: apache-2.0"", ""widget_data"": null, ""model_index"": null, ""config"": null, ""transformers_info"": null, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-01-07 19:07:34+00:00"", ""cardData"": ""base_model:\n- deepseek-ai/DeepSeek-V3\nlanguage:\n- aa\nlicense: apache-2.0"", ""transformersInfo"": null, ""_id"": ""677d7b383b65236092f79caf"", ""modelId"": ""Joses1234/pruebabot"", ""usedStorage"": 0}",1,,0,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=Joses1234/pruebabot&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5BJoses1234%2Fpruebabot%5D(%2FJoses1234%2Fpruebabot)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1
DanielVNZ/startrader,"---
license: mit
metrics:
- accuracy
base_model:
- deepseek-ai/DeepSeek-V3
---","{""id"": ""DanielVNZ/startrader"", ""author"": ""DanielVNZ"", ""sha"": ""9336721a0f6d36d9ef3682c7194e3e62089062a3"", ""last_modified"": ""2025-01-09 03:01:48+00:00"", ""created_at"": ""2025-01-09 03:00:43+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": null, ""gguf"": null, ""inference"": null, ""tags"": [""base_model:deepseek-ai/DeepSeek-V3"", ""base_model:finetune:deepseek-ai/DeepSeek-V3"", ""license:mit"", ""region:us""], ""pipeline_tag"": null, ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model:\n- deepseek-ai/DeepSeek-V3\nlicense: mit\nmetrics:\n- accuracy"", ""widget_data"": null, ""model_index"": null, ""config"": null, ""transformers_info"": null, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-01-09 03:01:48+00:00"", ""cardData"": ""base_model:\n- deepseek-ai/DeepSeek-V3\nlicense: mit\nmetrics:\n- accuracy"", ""transformersInfo"": null, ""_id"": ""677f3bdb3b98ffa2beae5f68"", ""modelId"": ""DanielVNZ/startrader"", ""usedStorage"": 0}",1,,0,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=DanielVNZ/startrader&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5BDanielVNZ%2Fstartrader%5D(%2FDanielVNZ%2Fstartrader)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1
digiwin/database,"---
license: openrail
base_model:
- deepseek-ai/DeepSeek-V3
---
# Model Card for Model ID

<!-- Provide a quick summary of what the model is/does. -->

This modelcard aims to be a base template for new models. It has been generated using [this raw template](https://github.com/huggingface/huggingface_hub/blob/main/src/huggingface_hub/templates/modelcard_template.md?plain=1).

## Model Details

### Model Description

<!-- Provide a longer summary of what this model is. -->



- **Developed by:** [More Information Needed]
- **Funded by [optional]:** [More Information Needed]
- **Shared by [optional]:** [More Information Needed]
- **Model type:** [More Information Needed]
- **Language(s) (NLP):** [More Information Needed]
- **License:** [More Information Needed]
- **Finetuned from model [optional]:** [More Information Needed]

### Model Sources [optional]

<!-- Provide the basic links for the model. -->

- **Repository:** [More Information Needed]
- **Paper [optional]:** [More Information Needed]
- **Demo [optional]:** [More Information Needed]

## Uses

<!-- Address questions around how the model is intended to be used, including the foreseeable users of the model and those affected by the model. -->

### Direct Use

<!-- This section is for the model use without fine-tuning or plugging into a larger ecosystem/app. -->

[More Information Needed]

### Downstream Use [optional]

<!-- This section is for the model use when fine-tuned for a task, or when plugged into a larger ecosystem/app -->

[More Information Needed]

### Out-of-Scope Use

<!-- This section addresses misuse, malicious use, and uses that the model will not work well for. -->

[More Information Needed]

## Bias, Risks, and Limitations

<!-- This section is meant to convey both technical and sociotechnical limitations. -->

[More Information Needed]

### Recommendations

<!-- This section is meant to convey recommendations with respect to the bias, risk, and technical limitations. -->

Users (both direct and downstream) should be made aware of the risks, biases and limitations of the model. More information needed for further recommendations.

## How to Get Started with the Model

Use the code below to get started with the model.

[More Information Needed]

## Training Details

### Training Data

<!-- This should link to a Dataset Card, perhaps with a short stub of information on what the training data is all about as well as documentation related to data pre-processing or additional filtering. -->

[More Information Needed]

### Training Procedure

<!-- This relates heavily to the Technical Specifications. Content here should link to that section when it is relevant to the training procedure. -->

#### Preprocessing [optional]

[More Information Needed]


#### Training Hyperparameters

- **Training regime:** [More Information Needed] <!--fp32, fp16 mixed precision, bf16 mixed precision, bf16 non-mixed precision, fp16 non-mixed precision, fp8 mixed precision -->

#### Speeds, Sizes, Times [optional]

<!-- This section provides information about throughput, start/end time, checkpoint size if relevant, etc. -->

[More Information Needed]

## Evaluation

<!-- This section describes the evaluation protocols and provides the results. -->

### Testing Data, Factors & Metrics

#### Testing Data

<!-- This should link to a Dataset Card if possible. -->

[More Information Needed]

#### Factors

<!-- These are the things the evaluation is disaggregating by, e.g., subpopulations or domains. -->

[More Information Needed]

#### Metrics

<!-- These are the evaluation metrics being used, ideally with a description of why. -->

[More Information Needed]

### Results

[More Information Needed]

#### Summary



## Model Examination [optional]

<!-- Relevant interpretability work for the model goes here -->

[More Information Needed]

## Environmental Impact

<!-- Total emissions (in grams of CO2eq) and additional considerations, such as electricity usage, go here. Edit the suggested text below accordingly -->

Carbon emissions can be estimated using the [Machine Learning Impact calculator](https://mlco2.github.io/impact#compute) presented in [Lacoste et al. (2019)](https://arxiv.org/abs/1910.09700).

- **Hardware Type:** [More Information Needed]
- **Hours used:** [More Information Needed]
- **Cloud Provider:** [More Information Needed]
- **Compute Region:** [More Information Needed]
- **Carbon Emitted:** [More Information Needed]

## Technical Specifications [optional]

### Model Architecture and Objective

[More Information Needed]

### Compute Infrastructure

[More Information Needed]

#### Hardware

[More Information Needed]

#### Software

[More Information Needed]

## Citation [optional]

<!-- If there is a paper or blog post introducing the model, the APA and Bibtex information for that should go in this section. -->

**BibTeX:**

[More Information Needed]

**APA:**

[More Information Needed]

## Glossary [optional]

<!-- If relevant, include terms and calculations in this section that can help readers understand the model or model card. -->

[More Information Needed]

## More Information [optional]

[More Information Needed]

## Model Card Authors [optional]

[More Information Needed]

## Model Card Contact

[More Information Needed]","{""id"": ""digiwin/database"", ""author"": ""digiwin"", ""sha"": ""e8e668337daeef6c85ba1a73dd01f5ec35fd6b6b"", ""last_modified"": ""2025-01-09 05:26:18+00:00"", ""created_at"": ""2025-01-09 05:23:35+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": null, ""gguf"": null, ""inference"": null, ""tags"": [""arxiv:1910.09700"", ""base_model:deepseek-ai/DeepSeek-V3"", ""base_model:finetune:deepseek-ai/DeepSeek-V3"", ""license:openrail"", ""region:us""], ""pipeline_tag"": null, ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model:\n- deepseek-ai/DeepSeek-V3\nlicense: openrail"", ""widget_data"": null, ""model_index"": null, ""config"": null, ""transformers_info"": null, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-01-09 05:26:18+00:00"", ""cardData"": ""base_model:\n- deepseek-ai/DeepSeek-V3\nlicense: openrail"", ""transformersInfo"": null, ""_id"": ""677f5d57370f44d9d6959e2e"", ""modelId"": ""digiwin/database"", ""usedStorage"": 0}",1,,0,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=digiwin/database&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bdigiwin%2Fdatabase%5D(%2Fdigiwin%2Fdatabase)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1
yasvand/natasha,"---
license: apache-2.0
datasets:
- fka/awesome-chatgpt-prompts
language:
- en
- ta
metrics:
- accuracy
base_model:
- deepseek-ai/DeepSeek-V3
new_version: microsoft/phi-4
pipeline_tag: text2text-generation
library_name: asteroid
tags:
- code
---","{""id"": ""yasvand/natasha"", ""author"": ""yasvand"", ""sha"": ""c67cf4f1d95d85ae50399571bb2b0c5ab98ce882"", ""last_modified"": ""2025-01-10 07:22:05+00:00"", ""created_at"": ""2025-01-10 07:20:16+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""asteroid"", ""gguf"": null, ""inference"": null, ""tags"": [""asteroid"", ""code"", ""text2text-generation"", ""en"", ""ta"", ""dataset:fka/awesome-chatgpt-prompts"", ""base_model:deepseek-ai/DeepSeek-V3"", ""base_model:finetune:deepseek-ai/DeepSeek-V3"", ""license:apache-2.0"", ""region:us""], ""pipeline_tag"": ""text2text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model:\n- deepseek-ai/DeepSeek-V3\ndatasets:\n- fka/awesome-chatgpt-prompts\nlanguage:\n- en\n- ta\nlibrary_name: asteroid\nlicense: apache-2.0\nmetrics:\n- accuracy\npipeline_tag: text2text-generation\ntags:\n- code\nnew_version: microsoft/phi-4"", ""widget_data"": null, ""model_index"": null, ""config"": null, ""transformers_info"": null, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-01-10 07:22:05+00:00"", ""cardData"": ""base_model:\n- deepseek-ai/DeepSeek-V3\ndatasets:\n- fka/awesome-chatgpt-prompts\nlanguage:\n- en\n- ta\nlibrary_name: asteroid\nlicense: apache-2.0\nmetrics:\n- accuracy\npipeline_tag: text2text-generation\ntags:\n- code\nnew_version: microsoft/phi-4"", ""transformersInfo"": null, ""_id"": ""6780ca301d8713ae810abf05"", ""modelId"": ""yasvand/natasha"", ""usedStorage"": 0}",1,,0,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=yasvand/natasha&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Byasvand%2Fnatasha%5D(%2Fyasvand%2Fnatasha)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1
samircd4/test,"---
license: mit
base_model:
- deepseek-ai/DeepSeek-V3
pipeline_tag: text-generation
tags:
- code
---","{""id"": ""samircd4/test"", ""author"": ""samircd4"", ""sha"": ""deea7c12c3022ac357377edf486f8c8b1a6af840"", ""last_modified"": ""2025-01-10 13:27:00+00:00"", ""created_at"": ""2025-01-10 13:24:53+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": null, ""gguf"": null, ""inference"": null, ""tags"": [""code"", ""text-generation"", ""base_model:deepseek-ai/DeepSeek-V3"", ""base_model:finetune:deepseek-ai/DeepSeek-V3"", ""license:mit"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model:\n- deepseek-ai/DeepSeek-V3\nlicense: mit\npipeline_tag: text-generation\ntags:\n- code"", ""widget_data"": [{""text"": ""My name is Julien and I like to""}, {""text"": ""I like traveling by train because""}, {""text"": ""Paris is an amazing place to visit,""}, {""text"": ""Once upon a time,""}], ""model_index"": null, ""config"": null, ""transformers_info"": null, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-01-10 13:27:00+00:00"", ""cardData"": ""base_model:\n- deepseek-ai/DeepSeek-V3\nlicense: mit\npipeline_tag: text-generation\ntags:\n- code"", ""transformersInfo"": null, ""_id"": ""67811fa563ffb0435baa6480"", ""modelId"": ""samircd4/test"", ""usedStorage"": 0}",1,,0,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=samircd4/test&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsamircd4%2Ftest%5D(%2Fsamircd4%2Ftest)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1
mrmhmdalyady/WWE,"---
license: apache-2.0
datasets:
- fka/awesome-chatgpt-prompts
language:
- ar
metrics:
- bertscore
base_model:
- deepseek-ai/DeepSeek-V3
new_version: deepseek-ai/DeepSeek-V3
library_name: allennlp
tags:
- art
- music
- text-generation-inference
- merge
- ÿ™ÿ®ÿØŸäŸÑ ÿßŸÑŸàÿ¨Ÿá ŸÅŸä ÿßŸÑŸÅŸäÿØŸäŸà
- ŸÖÿ∑ÿ®ŸÇ ÿßŸÑÿ¥ŸÅÿßÿ° ŸÅŸä ÿßŸÑŸÅŸäÿØŸäŸà
- ÿ£ÿ∂ŸÅ ÿ¥ÿÆÿµ ŸÅŸä ÿßŸÑŸÅŸäÿØŸäŸà
---","{""id"": ""mrmhmdalyady/WWE"", ""author"": ""mrmhmdalyady"", ""sha"": ""795f007bffbc2eddb6baeb981daeea1cedf64ccf"", ""last_modified"": ""2025-01-11 07:29:23+00:00"", ""created_at"": ""2025-01-11 07:17:15+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""allennlp"", ""gguf"": null, ""inference"": null, ""tags"": [""allennlp"", ""art"", ""music"", ""text-generation-inference"", ""merge"", ""\u062a\u0628\u062f\u064a\u0644 \u0627\u0644\u0648\u062c\u0647 \u0641\u064a \u0627\u0644\u0641\u064a\u062f\u064a\u0648"", ""\u0645\u0637\u0628\u0642 \u0627\u0644\u0634\u0641\u0627\u0621 \u0641\u064a \u0627\u0644\u0641\u064a\u062f\u064a\u0648"", ""\u0623\u0636\u0641 \u0634\u062e\u0635 \u0641\u064a \u0627\u0644\u0641\u064a\u062f\u064a\u0648"", ""ar"", ""dataset:fka/awesome-chatgpt-prompts"", ""base_model:deepseek-ai/DeepSeek-V3"", ""base_model:finetune:deepseek-ai/DeepSeek-V3"", ""license:apache-2.0"", ""region:us""], ""pipeline_tag"": null, ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model:\n- deepseek-ai/DeepSeek-V3\ndatasets:\n- fka/awesome-chatgpt-prompts\nlanguage:\n- ar\nlibrary_name: allennlp\nlicense: apache-2.0\nmetrics:\n- bertscore\ntags:\n- art\n- music\n- text-generation-inference\n- merge\n- \u062a\u0628\u062f\u064a\u0644 \u0627\u0644\u0648\u062c\u0647 \u0641\u064a \u0627\u0644\u0641\u064a\u062f\u064a\u0648\n- \u0645\u0637\u0628\u0642 \u0627\u0644\u0634\u0641\u0627\u0621 \u0641\u064a \u0627\u0644\u0641\u064a\u062f\u064a\u0648\n- \u0623\u0636\u0641 \u0634\u062e\u0635 \u0641\u064a \u0627\u0644\u0641\u064a\u062f\u064a\u0648\nnew_version: deepseek-ai/DeepSeek-V3"", ""widget_data"": null, ""model_index"": null, ""config"": null, ""transformers_info"": null, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-01-11 07:29:23+00:00"", ""cardData"": ""base_model:\n- deepseek-ai/DeepSeek-V3\ndatasets:\n- fka/awesome-chatgpt-prompts\nlanguage:\n- ar\nlibrary_name: allennlp\nlicense: apache-2.0\nmetrics:\n- bertscore\ntags:\n- art\n- music\n- text-generation-inference\n- merge\n- \u062a\u0628\u062f\u064a\u0644 \u0627\u0644\u0648\u062c\u0647 \u0641\u064a \u0627\u0644\u0641\u064a\u062f\u064a\u0648\n- \u0645\u0637\u0628\u0642 \u0627\u0644\u0634\u0641\u0627\u0621 \u0641\u064a \u0627\u0644\u0641\u064a\u062f\u064a\u0648\n- \u0623\u0636\u0641 \u0634\u062e\u0635 \u0641\u064a \u0627\u0644\u0641\u064a\u062f\u064a\u0648\nnew_version: deepseek-ai/DeepSeek-V3"", ""transformersInfo"": null, ""_id"": ""67821afb35d35379d7f414cb"", ""modelId"": ""mrmhmdalyady/WWE"", ""usedStorage"": 0}",1,,0,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=mrmhmdalyady/WWE&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bmrmhmdalyady%2FWWE%5D(%2Fmrmhmdalyady%2FWWE)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1
https://huggingface.co/vvffk/chatbot1.0,N/A,N/A,1,,0,,0,,0,,0,,0
Daad16/1,"---
base_model:
- deepseek-ai/DeepSeek-V3
pipeline_tag: image-to-image
---","{""id"": ""Daad16/1"", ""author"": ""Daad16"", ""sha"": ""d29f017b92fb88997f897916fd84c61af057daf0"", ""last_modified"": ""2025-01-12 13:54:44+00:00"", ""created_at"": ""2025-01-12 13:52:14+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": null, ""gguf"": null, ""inference"": null, ""tags"": [""image-to-image"", ""base_model:deepseek-ai/DeepSeek-V3"", ""base_model:finetune:deepseek-ai/DeepSeek-V3"", ""region:us""], ""pipeline_tag"": ""image-to-image"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model:\n- deepseek-ai/DeepSeek-V3\npipeline_tag: image-to-image"", ""widget_data"": null, ""model_index"": null, ""config"": null, ""transformers_info"": null, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-01-12 13:54:44+00:00"", ""cardData"": ""base_model:\n- deepseek-ai/DeepSeek-V3\npipeline_tag: image-to-image"", ""transformersInfo"": null, ""_id"": ""6783c90eec76402a5ec07249"", ""modelId"": ""Daad16/1"", ""usedStorage"": 0}",1,,0,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=Daad16/1&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5BDaad16%2F1%5D(%2FDaad16%2F1)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1
Hassan98777/Rania,"---
license: openrail
datasets:
- HuggingFaceTB/finemath
language:
- aa
metrics:
- accuracy
base_model:
- deepseek-ai/DeepSeek-V3
new_version: deepseek-ai/DeepSeek-V3
pipeline_tag: text-to-speech
library_name: flair
---","{""id"": ""Hassan98777/Rania"", ""author"": ""Hassan98777"", ""sha"": ""364b7b93d42a8c2384e8844cedac8b20adabbd6a"", ""last_modified"": ""2025-01-13 05:15:53+00:00"", ""created_at"": ""2025-01-13 05:12:39+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""flair"", ""gguf"": null, ""inference"": null, ""tags"": [""flair"", ""text-to-speech"", ""aa"", ""dataset:HuggingFaceTB/finemath"", ""base_model:deepseek-ai/DeepSeek-V3"", ""base_model:finetune:deepseek-ai/DeepSeek-V3"", ""license:openrail"", ""region:us""], ""pipeline_tag"": ""text-to-speech"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model:\n- deepseek-ai/DeepSeek-V3\ndatasets:\n- HuggingFaceTB/finemath\nlanguage:\n- aa\nlibrary_name: flair\nlicense: openrail\nmetrics:\n- accuracy\npipeline_tag: text-to-speech\nnew_version: deepseek-ai/DeepSeek-V3"", ""widget_data"": null, ""model_index"": null, ""config"": null, ""transformers_info"": null, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-01-13 05:15:53+00:00"", ""cardData"": ""base_model:\n- deepseek-ai/DeepSeek-V3\ndatasets:\n- HuggingFaceTB/finemath\nlanguage:\n- aa\nlibrary_name: flair\nlicense: openrail\nmetrics:\n- accuracy\npipeline_tag: text-to-speech\nnew_version: deepseek-ai/DeepSeek-V3"", ""transformersInfo"": null, ""_id"": ""6784a0c7dd05c402893d571b"", ""modelId"": ""Hassan98777/Rania"", ""usedStorage"": 0}",1,,0,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=Hassan98777/Rania&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5BHassan98777%2FRania%5D(%2FHassan98777%2FRania)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1
xptry/mal,"---
license: mit
language:
- si
metrics:
- accuracy
base_model:
- deepseek-ai/DeepSeek-V3
new_version: deepseek-ai/DeepSeek-V3
library_name: allennlp
---","{""id"": ""xptry/mal"", ""author"": ""xptry"", ""sha"": ""389a2e941a9dfebf963ef805fb7de08a482f7cc5"", ""last_modified"": ""2025-01-13 21:32:36+00:00"", ""created_at"": ""2025-01-13 21:31:00+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""allennlp"", ""gguf"": null, ""inference"": null, ""tags"": [""allennlp"", ""si"", ""base_model:deepseek-ai/DeepSeek-V3"", ""base_model:finetune:deepseek-ai/DeepSeek-V3"", ""license:mit"", ""region:us""], ""pipeline_tag"": null, ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model:\n- deepseek-ai/DeepSeek-V3\nlanguage:\n- si\nlibrary_name: allennlp\nlicense: mit\nmetrics:\n- accuracy\nnew_version: deepseek-ai/DeepSeek-V3"", ""widget_data"": null, ""model_index"": null, ""config"": null, ""transformers_info"": null, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-01-13 21:32:36+00:00"", ""cardData"": ""base_model:\n- deepseek-ai/DeepSeek-V3\nlanguage:\n- si\nlibrary_name: allennlp\nlicense: mit\nmetrics:\n- accuracy\nnew_version: deepseek-ai/DeepSeek-V3"", ""transformersInfo"": null, ""_id"": ""678586147984066afc6e4569"", ""modelId"": ""xptry/mal"", ""usedStorage"": 0}",1,,0,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=xptry/mal&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bxptry%2Fmal%5D(%2Fxptry%2Fmal)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1
dhe1raj/spiritgpt,"---
license: mit
datasets:
- fka/awesome-chatgpt-prompts
language:
- en
- hi
- sa
base_model:
- deepseek-ai/DeepSeek-V3
new_version: deepseek-ai/DeepSeek-V3
tags:
- code
---","{""id"": ""dhe1raj/spiritgpt"", ""author"": ""dhe1raj"", ""sha"": ""8c7534211ffc6dff18327478f7c331de3ae56566"", ""last_modified"": ""2025-01-14 07:20:39+00:00"", ""created_at"": ""2025-01-14 07:18:31+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": null, ""gguf"": null, ""inference"": null, ""tags"": [""code"", ""en"", ""hi"", ""sa"", ""dataset:fka/awesome-chatgpt-prompts"", ""base_model:deepseek-ai/DeepSeek-V3"", ""base_model:finetune:deepseek-ai/DeepSeek-V3"", ""license:mit"", ""region:us""], ""pipeline_tag"": null, ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model:\n- deepseek-ai/DeepSeek-V3\ndatasets:\n- fka/awesome-chatgpt-prompts\nlanguage:\n- en\n- hi\n- sa\nlicense: mit\ntags:\n- code\nnew_version: deepseek-ai/DeepSeek-V3"", ""widget_data"": null, ""model_index"": null, ""config"": null, ""transformers_info"": null, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-01-14 07:20:39+00:00"", ""cardData"": ""base_model:\n- deepseek-ai/DeepSeek-V3\ndatasets:\n- fka/awesome-chatgpt-prompts\nlanguage:\n- en\n- hi\n- sa\nlicense: mit\ntags:\n- code\nnew_version: deepseek-ai/DeepSeek-V3"", ""transformersInfo"": null, ""_id"": ""67860fc7987c7302bfa56a75"", ""modelId"": ""dhe1raj/spiritgpt"", ""usedStorage"": 0}",1,,0,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=dhe1raj/spiritgpt&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bdhe1raj%2Fspiritgpt%5D(%2Fdhe1raj%2Fspiritgpt)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1
slimjimmy420k/stoner,"---
datasets:
- fka/awesome-chatgpt-prompts
language:
- en
base_model:
- deepseek-ai/DeepSeek-V3
new_version: deepseek-ai/DeepSeek-V3
library_name: fastai
---
# Model Card for Model ID

<!-- Provide a quick summary of what the model is/does. -->

This modelcard aims to be a base template for new models. It has been generated using [this raw template](https://github.com/huggingface/huggingface_hub/blob/main/src/huggingface_hub/templates/modelcard_template.md?plain=1).

## Model Details

### Model Description

<!-- Provide a longer summary of what this model is. -->



- **Developed by:** [More Information Needed]
- **Funded by [optional]:** [More Information Needed]
- **Shared by [optional]:** [More Information Needed]
- **Model type:** [More Information Needed]
- **Language(s) (NLP):** [More Information Needed]
- **License:** [More Information Needed]
- **Finetuned from model [optional]:** [More Information Needed]

### Model Sources [optional]

<!-- Provide the basic links for the model. -->

- **Repository:** [More Information Needed]
- **Paper [optional]:** [More Information Needed]
- **Demo [optional]:** [More Information Needed]

## Uses

<!-- Address questions around how the model is intended to be used, including the foreseeable users of the model and those affected by the model. -->

### Direct Use

<!-- This section is for the model use without fine-tuning or plugging into a larger ecosystem/app. -->

[More Information Needed]

### Downstream Use [optional]

<!-- This section is for the model use when fine-tuned for a task, or when plugged into a larger ecosystem/app -->

[More Information Needed]

### Out-of-Scope Use

<!-- This section addresses misuse, malicious use, and uses that the model will not work well for. -->

[More Information Needed]

## Bias, Risks, and Limitations

<!-- This section is meant to convey both technical and sociotechnical limitations. -->

[More Information Needed]

### Recommendations

<!-- This section is meant to convey recommendations with respect to the bias, risk, and technical limitations. -->

Users (both direct and downstream) should be made aware of the risks, biases and limitations of the model. More information needed for further recommendations.

## How to Get Started with the Model

Use the code below to get started with the model.

[More Information Needed]

## Training Details

### Training Data

<!-- This should link to a Dataset Card, perhaps with a short stub of information on what the training data is all about as well as documentation related to data pre-processing or additional filtering. -->

[More Information Needed]

### Training Procedure

<!-- This relates heavily to the Technical Specifications. Content here should link to that section when it is relevant to the training procedure. -->

#### Preprocessing [optional]

[More Information Needed]


#### Training Hyperparameters

- **Training regime:** [More Information Needed] <!--fp32, fp16 mixed precision, bf16 mixed precision, bf16 non-mixed precision, fp16 non-mixed precision, fp8 mixed precision -->

#### Speeds, Sizes, Times [optional]

<!-- This section provides information about throughput, start/end time, checkpoint size if relevant, etc. -->

[More Information Needed]

## Evaluation

<!-- This section describes the evaluation protocols and provides the results. -->

### Testing Data, Factors & Metrics

#### Testing Data

<!-- This should link to a Dataset Card if possible. -->

[More Information Needed]

#### Factors

<!-- These are the things the evaluation is disaggregating by, e.g., subpopulations or domains. -->

[More Information Needed]

#### Metrics

<!-- These are the evaluation metrics being used, ideally with a description of why. -->

[More Information Needed]

### Results

[More Information Needed]

#### Summary



## Model Examination [optional]

<!-- Relevant interpretability work for the model goes here -->

[More Information Needed]

## Environmental Impact

<!-- Total emissions (in grams of CO2eq) and additional considerations, such as electricity usage, go here. Edit the suggested text below accordingly -->

Carbon emissions can be estimated using the [Machine Learning Impact calculator](https://mlco2.github.io/impact#compute) presented in [Lacoste et al. (2019)](https://arxiv.org/abs/1910.09700).

- **Hardware Type:** [More Information Needed]
- **Hours used:** [More Information Needed]
- **Cloud Provider:** [More Information Needed]
- **Compute Region:** [More Information Needed]
- **Carbon Emitted:** [More Information Needed]

## Technical Specifications [optional]

### Model Architecture and Objective

[More Information Needed]

### Compute Infrastructure

[More Information Needed]

#### Hardware

[More Information Needed]

#### Software

[More Information Needed]

## Citation [optional]

<!-- If there is a paper or blog post introducing the model, the APA and Bibtex information for that should go in this section. -->

**BibTeX:**

[More Information Needed]

**APA:**

[More Information Needed]

## Glossary [optional]

<!-- If relevant, include terms and calculations in this section that can help readers understand the model or model card. -->

[More Information Needed]

## More Information [optional]

[More Information Needed]

## Model Card Authors [optional]

[More Information Needed]

## Model Card Contact

[More Information Needed]","{""id"": ""slimjimmy420k/stoner"", ""author"": ""slimjimmy420k"", ""sha"": ""13445a5276d681039d485fda446981ed29968a0a"", ""last_modified"": ""2025-01-14 23:44:48+00:00"", ""created_at"": ""2025-01-14 23:43:10+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""fastai"", ""gguf"": null, ""inference"": null, ""tags"": [""fastai"", ""en"", ""dataset:fka/awesome-chatgpt-prompts"", ""arxiv:1910.09700"", ""base_model:deepseek-ai/DeepSeek-V3"", ""base_model:finetune:deepseek-ai/DeepSeek-V3"", ""region:us""], ""pipeline_tag"": null, ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model:\n- deepseek-ai/DeepSeek-V3\ndatasets:\n- fka/awesome-chatgpt-prompts\nlanguage:\n- en\nlibrary_name: fastai\nnew_version: deepseek-ai/DeepSeek-V3"", ""widget_data"": null, ""model_index"": null, ""config"": null, ""transformers_info"": null, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-01-14 23:44:48+00:00"", ""cardData"": ""base_model:\n- deepseek-ai/DeepSeek-V3\ndatasets:\n- fka/awesome-chatgpt-prompts\nlanguage:\n- en\nlibrary_name: fastai\nnew_version: deepseek-ai/DeepSeek-V3"", ""transformersInfo"": null, ""_id"": ""6786f68edc8e74fde66e5baf"", ""modelId"": ""slimjimmy420k/stoner"", ""usedStorage"": 0}",1,,0,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=slimjimmy420k/stoner&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bslimjimmy420k%2Fstoner%5D(%2Fslimjimmy420k%2Fstoner)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1
alex-28/quickanalyze,"---
license: mit
base_model:
- deepseek-ai/DeepSeek-V3
---
# Model Card for Model ID

<!-- Provide a quick summary of what the model is/does. -->

This modelcard aims to be a base template for new models. It has been generated using [this raw template](https://github.com/huggingface/huggingface_hub/blob/main/src/huggingface_hub/templates/modelcard_template.md?plain=1).

## Model Details

### Model Description

<!-- Provide a longer summary of what this model is. -->



- **Developed by:** [More Information Needed]
- **Funded by [optional]:** [More Information Needed]
- **Shared by [optional]:** [More Information Needed]
- **Model type:** [More Information Needed]
- **Language(s) (NLP):** [More Information Needed]
- **License:** [More Information Needed]
- **Finetuned from model [optional]:** [More Information Needed]

### Model Sources [optional]

<!-- Provide the basic links for the model. -->

- **Repository:** [More Information Needed]
- **Paper [optional]:** [More Information Needed]
- **Demo [optional]:** [More Information Needed]

## Uses

<!-- Address questions around how the model is intended to be used, including the foreseeable users of the model and those affected by the model. -->

### Direct Use

<!-- This section is for the model use without fine-tuning or plugging into a larger ecosystem/app. -->

[More Information Needed]

### Downstream Use [optional]

<!-- This section is for the model use when fine-tuned for a task, or when plugged into a larger ecosystem/app -->

[More Information Needed]

### Out-of-Scope Use

<!-- This section addresses misuse, malicious use, and uses that the model will not work well for. -->

[More Information Needed]

## Bias, Risks, and Limitations

<!-- This section is meant to convey both technical and sociotechnical limitations. -->

[More Information Needed]

### Recommendations

<!-- This section is meant to convey recommendations with respect to the bias, risk, and technical limitations. -->

Users (both direct and downstream) should be made aware of the risks, biases and limitations of the model. More information needed for further recommendations.

## How to Get Started with the Model

Use the code below to get started with the model.

[More Information Needed]

## Training Details

### Training Data

<!-- This should link to a Dataset Card, perhaps with a short stub of information on what the training data is all about as well as documentation related to data pre-processing or additional filtering. -->

[More Information Needed]

### Training Procedure

<!-- This relates heavily to the Technical Specifications. Content here should link to that section when it is relevant to the training procedure. -->

#### Preprocessing [optional]

[More Information Needed]


#### Training Hyperparameters

- **Training regime:** [More Information Needed] <!--fp32, fp16 mixed precision, bf16 mixed precision, bf16 non-mixed precision, fp16 non-mixed precision, fp8 mixed precision -->

#### Speeds, Sizes, Times [optional]

<!-- This section provides information about throughput, start/end time, checkpoint size if relevant, etc. -->

[More Information Needed]

## Evaluation

<!-- This section describes the evaluation protocols and provides the results. -->

### Testing Data, Factors & Metrics

#### Testing Data

<!-- This should link to a Dataset Card if possible. -->

[More Information Needed]

#### Factors

<!-- These are the things the evaluation is disaggregating by, e.g., subpopulations or domains. -->

[More Information Needed]

#### Metrics

<!-- These are the evaluation metrics being used, ideally with a description of why. -->

[More Information Needed]

### Results

[More Information Needed]

#### Summary



## Model Examination [optional]

<!-- Relevant interpretability work for the model goes here -->

[More Information Needed]

## Environmental Impact

<!-- Total emissions (in grams of CO2eq) and additional considerations, such as electricity usage, go here. Edit the suggested text below accordingly -->

Carbon emissions can be estimated using the [Machine Learning Impact calculator](https://mlco2.github.io/impact#compute) presented in [Lacoste et al. (2019)](https://arxiv.org/abs/1910.09700).

- **Hardware Type:** [More Information Needed]
- **Hours used:** [More Information Needed]
- **Cloud Provider:** [More Information Needed]
- **Compute Region:** [More Information Needed]
- **Carbon Emitted:** [More Information Needed]

## Technical Specifications [optional]

### Model Architecture and Objective

[More Information Needed]

### Compute Infrastructure

[More Information Needed]

#### Hardware

[More Information Needed]

#### Software

[More Information Needed]

## Citation [optional]

<!-- If there is a paper or blog post introducing the model, the APA and Bibtex information for that should go in this section. -->

**BibTeX:**

[More Information Needed]

**APA:**

[More Information Needed]

## Glossary [optional]

<!-- If relevant, include terms and calculations in this section that can help readers understand the model or model card. -->

[More Information Needed]

## More Information [optional]

[More Information Needed]

## Model Card Authors [optional]

[More Information Needed]

## Model Card Contact

[More Information Needed]","{""id"": ""alex-28/quickanalyze"", ""author"": ""alex-28"", ""sha"": ""0221caa8b8d4420ad66b6a625a510a0434ccfa0f"", ""last_modified"": ""2025-01-15 09:55:40+00:00"", ""created_at"": ""2025-01-15 09:54:18+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": null, ""gguf"": null, ""inference"": null, ""tags"": [""arxiv:1910.09700"", ""base_model:deepseek-ai/DeepSeek-V3"", ""base_model:finetune:deepseek-ai/DeepSeek-V3"", ""license:mit"", ""region:us""], ""pipeline_tag"": null, ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model:\n- deepseek-ai/DeepSeek-V3\nlicense: mit"", ""widget_data"": null, ""model_index"": null, ""config"": null, ""transformers_info"": null, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-01-15 09:55:40+00:00"", ""cardData"": ""base_model:\n- deepseek-ai/DeepSeek-V3\nlicense: mit"", ""transformersInfo"": null, ""_id"": ""678785ca2c35c788f19136cc"", ""modelId"": ""alex-28/quickanalyze"", ""usedStorage"": 0}",1,,0,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=alex-28/quickanalyze&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Balex-28%2Fquickanalyze%5D(%2Falex-28%2Fquickanalyze)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1
R87/cenario,"---
license: bigscience-openrail-m
datasets:
- O1-OPEN/OpenO1-SFT
language:
- pt
metrics:
- accuracy
base_model:
- deepseek-ai/DeepSeek-V3
- openbmb/MiniCPM-o-2_6
new_version: openbmb/MiniCPM-o-2_6
library_name: fastai
---","{""id"": ""R87/cenario"", ""author"": ""R87"", ""sha"": ""a3888b9adafc6ba0305e1be76255d0132fb149aa"", ""last_modified"": ""2025-01-16 16:27:54+00:00"", ""created_at"": ""2025-01-16 16:24:21+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""fastai"", ""gguf"": null, ""inference"": null, ""tags"": [""fastai"", ""pt"", ""dataset:O1-OPEN/OpenO1-SFT"", ""base_model:deepseek-ai/DeepSeek-V3"", ""base_model:finetune:deepseek-ai/DeepSeek-V3"", ""license:bigscience-openrail-m"", ""region:us""], ""pipeline_tag"": null, ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model:\n- deepseek-ai/DeepSeek-V3\n- openbmb/MiniCPM-o-2_6\ndatasets:\n- O1-OPEN/OpenO1-SFT\nlanguage:\n- pt\nlibrary_name: fastai\nlicense: bigscience-openrail-m\nmetrics:\n- accuracy\nnew_version: openbmb/MiniCPM-o-2_6"", ""widget_data"": null, ""model_index"": null, ""config"": null, ""transformers_info"": null, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-01-16 16:27:54+00:00"", ""cardData"": ""base_model:\n- deepseek-ai/DeepSeek-V3\n- openbmb/MiniCPM-o-2_6\ndatasets:\n- O1-OPEN/OpenO1-SFT\nlanguage:\n- pt\nlibrary_name: fastai\nlicense: bigscience-openrail-m\nmetrics:\n- accuracy\nnew_version: openbmb/MiniCPM-o-2_6"", ""transformersInfo"": null, ""_id"": ""678932b58178c63158a7308f"", ""modelId"": ""R87/cenario"", ""usedStorage"": 0}",1,,0,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=R87/cenario&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5BR87%2Fcenario%5D(%2FR87%2Fcenario)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1
LevinKI/Test_KI,"---
license: bsd-2-clause
datasets:
- fka/awesome-chatgpt-prompts
language:
- de
metrics:
- accuracy
base_model:
- deepseek-ai/DeepSeek-V3
pipeline_tag: text-classification
tags:
- finance
---","{""id"": ""LevinKI/Test_KI"", ""author"": ""LevinKI"", ""sha"": ""57e92b12ac20442af7fb2d22232efcba2c30868d"", ""last_modified"": ""2025-01-16 17:33:11+00:00"", ""created_at"": ""2025-01-16 17:31:07+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": null, ""gguf"": null, ""inference"": null, ""tags"": [""finance"", ""text-classification"", ""de"", ""dataset:fka/awesome-chatgpt-prompts"", ""base_model:deepseek-ai/DeepSeek-V3"", ""base_model:finetune:deepseek-ai/DeepSeek-V3"", ""license:bsd-2-clause"", ""region:us""], ""pipeline_tag"": ""text-classification"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model:\n- deepseek-ai/DeepSeek-V3\ndatasets:\n- fka/awesome-chatgpt-prompts\nlanguage:\n- de\nlicense: bsd-2-clause\nmetrics:\n- accuracy\npipeline_tag: text-classification\ntags:\n- finance"", ""widget_data"": null, ""model_index"": null, ""config"": null, ""transformers_info"": null, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-01-16 17:33:11+00:00"", ""cardData"": ""base_model:\n- deepseek-ai/DeepSeek-V3\ndatasets:\n- fka/awesome-chatgpt-prompts\nlanguage:\n- de\nlicense: bsd-2-clause\nmetrics:\n- accuracy\npipeline_tag: text-classification\ntags:\n- finance"", ""transformersInfo"": null, ""_id"": ""6789425b810f471d6a746fde"", ""modelId"": ""LevinKI/Test_KI"", ""usedStorage"": 0}",1,,0,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=LevinKI/Test_KI&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5BLevinKI%2FTest_KI%5D(%2FLevinKI%2FTest_KI)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1
alisaadnoor2/Ali,"---
license: apache-2.0
datasets:
- fka/awesome-chatgpt-prompts
language:
- ae
metrics:
- accuracy
base_model:
- deepseek-ai/DeepSeek-V3
new_version: hexgrad/Kokoro-82M
---","{""id"": ""alisaadnoor2/Ali"", ""author"": ""alisaadnoor2"", ""sha"": ""876dd7d087a305352f47596fdd254e411e55418e"", ""last_modified"": ""2025-01-16 22:49:09+00:00"", ""created_at"": ""2025-01-16 22:48:17+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": null, ""gguf"": null, ""inference"": null, ""tags"": [""ae"", ""dataset:fka/awesome-chatgpt-prompts"", ""base_model:deepseek-ai/DeepSeek-V3"", ""base_model:finetune:deepseek-ai/DeepSeek-V3"", ""license:apache-2.0"", ""region:us""], ""pipeline_tag"": null, ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model:\n- deepseek-ai/DeepSeek-V3\ndatasets:\n- fka/awesome-chatgpt-prompts\nlanguage:\n- ae\nlicense: apache-2.0\nmetrics:\n- accuracy\nnew_version: hexgrad/Kokoro-82M"", ""widget_data"": null, ""model_index"": null, ""config"": null, ""transformers_info"": null, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-01-16 22:49:09+00:00"", ""cardData"": ""base_model:\n- deepseek-ai/DeepSeek-V3\ndatasets:\n- fka/awesome-chatgpt-prompts\nlanguage:\n- ae\nlicense: apache-2.0\nmetrics:\n- accuracy\nnew_version: hexgrad/Kokoro-82M"", ""transformersInfo"": null, ""_id"": ""67898cb19db62f80b95bc11f"", ""modelId"": ""alisaadnoor2/Ali"", ""usedStorage"": 0}",1,,0,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=alisaadnoor2/Ali&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Balisaadnoor2%2FAli%5D(%2Falisaadnoor2%2FAli)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1
hs-up/kso-v1-finetuned,"---
license: apache-2.0
datasets:
- HuggingFaceTB/finemath
language:
- en
base_model:
- deepseek-ai/DeepSeek-V3
new_version: deepseek-ai/DeepSeek-V3
pipeline_tag: text2text-generation
library_name: allennlp
---","{""id"": ""hs-up/kso-v1-finetuned"", ""author"": ""hs-up"", ""sha"": ""9e945ea41af9e0c975e44e3da0dbdf9871e72e9c"", ""last_modified"": ""2025-01-18 10:32:11+00:00"", ""created_at"": ""2025-01-17 05:59:08+00:00"", ""private"": false, ""gated"": ""manual"", ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""allennlp"", ""gguf"": null, ""inference"": null, ""tags"": [""allennlp"", ""text2text-generation"", ""en"", ""dataset:HuggingFaceTB/finemath"", ""base_model:deepseek-ai/DeepSeek-V3"", ""base_model:finetune:deepseek-ai/DeepSeek-V3"", ""license:apache-2.0"", ""region:us""], ""pipeline_tag"": ""text2text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model:\n- deepseek-ai/DeepSeek-V3\ndatasets:\n- HuggingFaceTB/finemath\nlanguage:\n- en\nlibrary_name: allennlp\nlicense: apache-2.0\npipeline_tag: text2text-generation\nnew_version: deepseek-ai/DeepSeek-V3"", ""widget_data"": null, ""model_index"": null, ""config"": null, ""transformers_info"": null, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-01-18 10:32:11+00:00"", ""cardData"": ""base_model:\n- deepseek-ai/DeepSeek-V3\ndatasets:\n- HuggingFaceTB/finemath\nlanguage:\n- en\nlibrary_name: allennlp\nlicense: apache-2.0\npipeline_tag: text2text-generation\nnew_version: deepseek-ai/DeepSeek-V3"", ""transformersInfo"": null, ""_id"": ""6789f1aca84a24c37766b860"", ""modelId"": ""hs-up/kso-v1-finetuned"", ""usedStorage"": 0}",1,,0,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=hs-up/kso-v1-finetuned&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bhs-up%2Fkso-v1-finetuned%5D(%2Fhs-up%2Fkso-v1-finetuned)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1
Igbodevictor/Igbodevictor,"---
license: apache-2.0
datasets:
- HuggingFaceTB/finemath
metrics:
- bertscore
base_model:
- deepseek-ai/DeepSeek-V3
new_version: hexgrad/Kokoro-82M
---","{""id"": ""Igbodevictor/Igbodevictor"", ""author"": ""Igbodevictor"", ""sha"": ""27f2741d41b4df10a1ad333f560d84a5c9f54874"", ""last_modified"": ""2025-01-17 14:27:59+00:00"", ""created_at"": ""2025-01-17 14:25:56+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": null, ""gguf"": null, ""inference"": null, ""tags"": [""dataset:HuggingFaceTB/finemath"", ""base_model:deepseek-ai/DeepSeek-V3"", ""base_model:finetune:deepseek-ai/DeepSeek-V3"", ""license:apache-2.0"", ""region:us""], ""pipeline_tag"": null, ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model:\n- deepseek-ai/DeepSeek-V3\ndatasets:\n- HuggingFaceTB/finemath\nlicense: apache-2.0\nmetrics:\n- bertscore\nnew_version: hexgrad/Kokoro-82M"", ""widget_data"": null, ""model_index"": null, ""config"": null, ""transformers_info"": null, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-01-17 14:27:59+00:00"", ""cardData"": ""base_model:\n- deepseek-ai/DeepSeek-V3\ndatasets:\n- HuggingFaceTB/finemath\nlicense: apache-2.0\nmetrics:\n- bertscore\nnew_version: hexgrad/Kokoro-82M"", ""transformersInfo"": null, ""_id"": ""678a687402eefca54017222e"", ""modelId"": ""Igbodevictor/Igbodevictor"", ""usedStorage"": 0}",1,,0,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=Igbodevictor/Igbodevictor&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5BIgbodevictor%2FIgbodevictor%5D(%2FIgbodevictor%2FIgbodevictor)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1
Mattze2711/Matthi75,"---
datasets:
- HuggingFaceTB/finemath
language:
- av
metrics:
- accuracy
base_model:
- deepseek-ai/DeepSeek-V3
---","{""id"": ""Mattze2711/Matthi75"", ""author"": ""Mattze2711"", ""sha"": ""28ba16319f8139a0d2a911983b7fe9ba22235344"", ""last_modified"": ""2025-01-18 04:51:36+00:00"", ""created_at"": ""2025-01-18 04:47:40+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": null, ""gguf"": null, ""inference"": null, ""tags"": [""av"", ""dataset:HuggingFaceTB/finemath"", ""base_model:deepseek-ai/DeepSeek-V3"", ""base_model:finetune:deepseek-ai/DeepSeek-V3"", ""region:us""], ""pipeline_tag"": null, ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model:\n- deepseek-ai/DeepSeek-V3\ndatasets:\n- HuggingFaceTB/finemath\nlanguage:\n- av\nmetrics:\n- accuracy"", ""widget_data"": null, ""model_index"": null, ""config"": null, ""transformers_info"": null, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-01-18 04:51:36+00:00"", ""cardData"": ""base_model:\n- deepseek-ai/DeepSeek-V3\ndatasets:\n- HuggingFaceTB/finemath\nlanguage:\n- av\nmetrics:\n- accuracy"", ""transformersInfo"": null, ""_id"": ""678b326cb7a948ae62afffb0"", ""modelId"": ""Mattze2711/Matthi75"", ""usedStorage"": 0}",1,,0,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=Mattze2711/Matthi75&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5BMattze2711%2FMatthi75%5D(%2FMattze2711%2FMatthi75)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1
mesrikanthreddy/repo_name,"---
metrics:
- accuracy
- bertscore
base_model:
- deepseek-ai/DeepSeek-V3
- xai-org/grok-1
- meta-llama/Llama-3.3-70B-Instruct
new_version: deepseek-ai/DeepSeek-V3
pipeline_tag: time-series-forecasting
library_name: fastai
tags:
- sales
---","{""id"": ""mesrikanthreddy/repo_name"", ""author"": ""mesrikanthreddy"", ""sha"": ""49d394e397c6211b768efea415ce62039d59da2c"", ""last_modified"": ""2025-01-18 08:30:55+00:00"", ""created_at"": ""2025-01-18 08:22:52+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""fastai"", ""gguf"": null, ""inference"": null, ""tags"": [""fastai"", ""sales"", ""time-series-forecasting"", ""base_model:deepseek-ai/DeepSeek-V3"", ""base_model:finetune:deepseek-ai/DeepSeek-V3"", ""region:us""], ""pipeline_tag"": ""time-series-forecasting"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model:\n- deepseek-ai/DeepSeek-V3\n- xai-org/grok-1\n- meta-llama/Llama-3.3-70B-Instruct\nlibrary_name: fastai\nmetrics:\n- accuracy\n- bertscore\npipeline_tag: time-series-forecasting\ntags:\n- sales\nnew_version: deepseek-ai/DeepSeek-V3"", ""widget_data"": null, ""model_index"": null, ""config"": null, ""transformers_info"": null, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-01-18 08:30:55+00:00"", ""cardData"": ""base_model:\n- deepseek-ai/DeepSeek-V3\n- xai-org/grok-1\n- meta-llama/Llama-3.3-70B-Instruct\nlibrary_name: fastai\nmetrics:\n- accuracy\n- bertscore\npipeline_tag: time-series-forecasting\ntags:\n- sales\nnew_version: deepseek-ai/DeepSeek-V3"", ""transformersInfo"": null, ""_id"": ""678b64dcd3bb5911e555e347"", ""modelId"": ""mesrikanthreddy/repo_name"", ""usedStorage"": 0}",1,,0,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=mesrikanthreddy/repo_name&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bmesrikanthreddy%2Frepo_name%5D(%2Fmesrikanthreddy%2Frepo_name)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1
Marci353524/Chating,"---
license: openrail
datasets:
- fka/awesome-chatgpt-prompts
- gopipasala/fka-awesome-chatgpt-prompts
language:
- hu
- en
- ru
- pl
- ar
metrics:
- bertscore
base_model:
- deepseek-ai/DeepSeek-V3
new_version: deepseek-ai/DeepSeek-V3
library_name: bertopic
tags:
- chemistry
- biology
- finance
- legal
- music
- art
- code
- climate
- medical
- not-for-all-audiences
- text-generation-inference
- merge
- moe
---","{""id"": ""Marci353524/Chating"", ""author"": ""Marci353524"", ""sha"": ""74d31ead1307d69e8cfb41f0bba001ecfeb4a88a"", ""last_modified"": ""2025-01-18 14:43:50+00:00"", ""created_at"": ""2025-01-18 14:40:27+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""bertopic"", ""gguf"": null, ""inference"": null, ""tags"": [""bertopic"", ""chemistry"", ""biology"", ""finance"", ""legal"", ""music"", ""art"", ""code"", ""climate"", ""medical"", ""not-for-all-audiences"", ""text-generation-inference"", ""merge"", ""moe"", ""hu"", ""en"", ""ru"", ""pl"", ""ar"", ""dataset:fka/awesome-chatgpt-prompts"", ""dataset:gopipasala/fka-awesome-chatgpt-prompts"", ""base_model:deepseek-ai/DeepSeek-V3"", ""base_model:finetune:deepseek-ai/DeepSeek-V3"", ""license:openrail"", ""region:us""], ""pipeline_tag"": null, ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model:\n- deepseek-ai/DeepSeek-V3\ndatasets:\n- fka/awesome-chatgpt-prompts\n- gopipasala/fka-awesome-chatgpt-prompts\nlanguage:\n- hu\n- en\n- ru\n- pl\n- ar\nlibrary_name: bertopic\nlicense: openrail\nmetrics:\n- bertscore\ntags:\n- chemistry\n- biology\n- finance\n- legal\n- music\n- art\n- code\n- climate\n- medical\n- not-for-all-audiences\n- text-generation-inference\n- merge\n- moe\nnew_version: deepseek-ai/DeepSeek-V3"", ""widget_data"": null, ""model_index"": null, ""config"": null, ""transformers_info"": null, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-01-18 14:43:50+00:00"", ""cardData"": ""base_model:\n- deepseek-ai/DeepSeek-V3\ndatasets:\n- fka/awesome-chatgpt-prompts\n- gopipasala/fka-awesome-chatgpt-prompts\nlanguage:\n- hu\n- en\n- ru\n- pl\n- ar\nlibrary_name: bertopic\nlicense: openrail\nmetrics:\n- bertscore\ntags:\n- chemistry\n- biology\n- finance\n- legal\n- music\n- art\n- code\n- climate\n- medical\n- not-for-all-audiences\n- text-generation-inference\n- merge\n- moe\nnew_version: deepseek-ai/DeepSeek-V3"", ""transformersInfo"": null, ""_id"": ""678bbd5bfb6b890449c56ccd"", ""modelId"": ""Marci353524/Chating"", ""usedStorage"": 0}",1,,0,,0,,0,,0,,0
ATTLAB/quantumaurora,"---
license: mit
datasets:
- meta-llama/Llama-3.3-70B-Instruct-evals
- meta-llama/Llama-3.2-1B-Instruct-evals
language:
- en
- ar
- yo
- ha
- ig
- pt
- es
metrics:
- code_eval
base_model:
- deepseek-ai/DeepSeek-V3
- deepseek-ai/DeepSeek-V3-Base
- meta-llama/Llama-3.3-70B-Instruct
new_version: deepseek-ai/DeepSeek-V3
pipeline_tag: token-classification
library_name: fastai
tags:
- code
- art
- chemistry
---","{""id"": ""ATTLAB/quantumaurora"", ""author"": ""ATTLAB"", ""sha"": ""187662d3bb0b8965b0961954d49404fa70b029b6"", ""last_modified"": ""2025-01-25 12:58:33+00:00"", ""created_at"": ""2025-01-18 16:57:46+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 1, ""library_name"": ""fastai"", ""gguf"": null, ""inference"": null, ""tags"": [""fastai"", ""code"", ""art"", ""chemistry"", ""token-classification"", ""en"", ""ar"", ""yo"", ""ha"", ""ig"", ""pt"", ""es"", ""dataset:meta-llama/Llama-3.3-70B-Instruct-evals"", ""dataset:meta-llama/Llama-3.2-1B-Instruct-evals"", ""base_model:deepseek-ai/DeepSeek-V3"", ""base_model:finetune:deepseek-ai/DeepSeek-V3"", ""license:mit"", ""region:us""], ""pipeline_tag"": ""token-classification"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model:\n- deepseek-ai/DeepSeek-V3\n- deepseek-ai/DeepSeek-V3-Base\n- meta-llama/Llama-3.3-70B-Instruct\ndatasets:\n- meta-llama/Llama-3.3-70B-Instruct-evals\n- meta-llama/Llama-3.2-1B-Instruct-evals\nlanguage:\n- en\n- ar\n- yo\n- ha\n- ig\n- pt\n- es\nlibrary_name: fastai\nlicense: mit\nmetrics:\n- code_eval\npipeline_tag: token-classification\ntags:\n- code\n- art\n- chemistry\nnew_version: deepseek-ai/DeepSeek-V3"", ""widget_data"": [{""text"": ""My name is Wolfgang and I live in Berlin""}, {""text"": ""My name is Sarah and I live in London""}, {""text"": ""My name is Clara and I live in Berkeley, California.""}], ""model_index"": null, ""config"": null, ""transformers_info"": null, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='qa1.0.0', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-01-25 12:58:33+00:00"", ""cardData"": ""base_model:\n- deepseek-ai/DeepSeek-V3\n- deepseek-ai/DeepSeek-V3-Base\n- meta-llama/Llama-3.3-70B-Instruct\ndatasets:\n- meta-llama/Llama-3.3-70B-Instruct-evals\n- meta-llama/Llama-3.2-1B-Instruct-evals\nlanguage:\n- en\n- ar\n- yo\n- ha\n- ig\n- pt\n- es\nlibrary_name: fastai\nlicense: mit\nmetrics:\n- code_eval\npipeline_tag: token-classification\ntags:\n- code\n- art\n- chemistry\nnew_version: deepseek-ai/DeepSeek-V3"", ""transformersInfo"": null, ""_id"": ""678bdd8aa6bb9e8ed2095084"", ""modelId"": ""ATTLAB/quantumaurora"", ""usedStorage"": 0}",1,,0,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=ATTLAB/quantumaurora&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5BATTLAB%2Fquantumaurora%5D(%2FATTLAB%2Fquantumaurora)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1
Muhamad2020/Muh,"---
license: apache-2.0
datasets:
- fka/awesome-chatgpt-prompts
language:
- fa
metrics:
- accuracy
base_model:
- deepseek-ai/DeepSeek-V3
new_version: deepseek-ai/DeepSeek-V3
library_name: bertopic
tags:
- art
---","{""id"": ""Muhamad2020/Muh"", ""author"": ""Muhamad2020"", ""sha"": ""472053b76c1da1ba39fd01914f42866b6ea49953"", ""last_modified"": ""2025-01-18 21:17:38+00:00"", ""created_at"": ""2025-01-18 21:13:48+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""bertopic"", ""gguf"": null, ""inference"": null, ""tags"": [""bertopic"", ""art"", ""fa"", ""dataset:fka/awesome-chatgpt-prompts"", ""base_model:deepseek-ai/DeepSeek-V3"", ""base_model:finetune:deepseek-ai/DeepSeek-V3"", ""license:apache-2.0"", ""region:us""], ""pipeline_tag"": null, ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model:\n- deepseek-ai/DeepSeek-V3\ndatasets:\n- fka/awesome-chatgpt-prompts\nlanguage:\n- fa\nlibrary_name: bertopic\nlicense: apache-2.0\nmetrics:\n- accuracy\ntags:\n- art\nnew_version: deepseek-ai/DeepSeek-V3"", ""widget_data"": null, ""model_index"": null, ""config"": null, ""transformers_info"": null, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-01-18 21:17:38+00:00"", ""cardData"": ""base_model:\n- deepseek-ai/DeepSeek-V3\ndatasets:\n- fka/awesome-chatgpt-prompts\nlanguage:\n- fa\nlibrary_name: bertopic\nlicense: apache-2.0\nmetrics:\n- accuracy\ntags:\n- art\nnew_version: deepseek-ai/DeepSeek-V3"", ""transformersInfo"": null, ""_id"": ""678c198c57a857b08f1570e2"", ""modelId"": ""Muhamad2020/Muh"", ""usedStorage"": 0}",1,,0,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=Muhamad2020/Muh&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5BMuhamad2020%2FMuh%5D(%2FMuhamad2020%2FMuh)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1
tttom3669/img,"---
license: apache-2.0
datasets:
- fka/awesome-chatgpt-prompts
metrics:
- accuracy
base_model:
- deepseek-ai/DeepSeek-V3
pipeline_tag: image-to-image
---","{""id"": ""tttom3669/img"", ""author"": ""tttom3669"", ""sha"": ""660562625e129dcbaa41458c27a77b92d7445190"", ""last_modified"": ""2025-01-19 14:59:36+00:00"", ""created_at"": ""2025-01-19 14:58:07+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": null, ""gguf"": null, ""inference"": null, ""tags"": [""image-to-image"", ""dataset:fka/awesome-chatgpt-prompts"", ""base_model:deepseek-ai/DeepSeek-V3"", ""base_model:finetune:deepseek-ai/DeepSeek-V3"", ""license:apache-2.0"", ""region:us""], ""pipeline_tag"": ""image-to-image"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model:\n- deepseek-ai/DeepSeek-V3\ndatasets:\n- fka/awesome-chatgpt-prompts\nlicense: apache-2.0\nmetrics:\n- accuracy\npipeline_tag: image-to-image"", ""widget_data"": null, ""model_index"": null, ""config"": null, ""transformers_info"": null, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-01-19 14:59:36+00:00"", ""cardData"": ""base_model:\n- deepseek-ai/DeepSeek-V3\ndatasets:\n- fka/awesome-chatgpt-prompts\nlicense: apache-2.0\nmetrics:\n- accuracy\npipeline_tag: image-to-image"", ""transformersInfo"": null, ""_id"": ""678d12ffb9303fc391e1ca71"", ""modelId"": ""tttom3669/img"", ""usedStorage"": 0}",1,,0,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=tttom3669/img&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Btttom3669%2Fimg%5D(%2Ftttom3669%2Fimg)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1
Amblem/novaa,"---
license: apache-2.0
datasets:
- HuggingFaceTB/finemath
language:
- en
base_model:
- deepseek-ai/DeepSeek-V3
new_version: deepseek-ai/DeepSeek-V3
---","{""id"": ""Amblem/novaa"", ""author"": ""Amblem"", ""sha"": ""d53075bf9b788cb06032d51de8c5a70030ae1f84"", ""last_modified"": ""2025-01-19 20:09:12+00:00"", ""created_at"": ""2025-01-19 20:07:25+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": null, ""gguf"": null, ""inference"": null, ""tags"": [""en"", ""dataset:HuggingFaceTB/finemath"", ""base_model:deepseek-ai/DeepSeek-V3"", ""base_model:finetune:deepseek-ai/DeepSeek-V3"", ""license:apache-2.0"", ""region:us""], ""pipeline_tag"": null, ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model:\n- deepseek-ai/DeepSeek-V3\ndatasets:\n- HuggingFaceTB/finemath\nlanguage:\n- en\nlicense: apache-2.0\nnew_version: deepseek-ai/DeepSeek-V3"", ""widget_data"": null, ""model_index"": null, ""config"": null, ""transformers_info"": null, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-01-19 20:09:12+00:00"", ""cardData"": ""base_model:\n- deepseek-ai/DeepSeek-V3\ndatasets:\n- HuggingFaceTB/finemath\nlanguage:\n- en\nlicense: apache-2.0\nnew_version: deepseek-ai/DeepSeek-V3"", ""transformersInfo"": null, ""_id"": ""678d5b7d0d02ca0d8dde2926"", ""modelId"": ""Amblem/novaa"", ""usedStorage"": 0}",1,,0,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=Amblem/novaa&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5BAmblem%2Fnovaa%5D(%2FAmblem%2Fnovaa)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1
Arcturus63/Jerry,"---
datasets:
- fka/awesome-chatgpt-prompts
- gopipasala/fka-awesome-chatgpt-prompts
- HuggingFaceTB/finemath
language:
- en
- sk
- cs
metrics:
- accuracy
- character
base_model:
- microsoft/phi-4
- deepseek-ai/DeepSeek-V3
new_version: microsoft/phi-4
pipeline_tag: text-generation
library_name: fastai
---","{""id"": ""Arcturus63/Jerry"", ""author"": ""Arcturus63"", ""sha"": ""edac52682af149dbaa06eb2a1f02f478ca18f0cc"", ""last_modified"": ""2025-01-20 10:56:21+00:00"", ""created_at"": ""2025-01-20 10:53:39+00:00"", ""private"": false, ""gated"": ""auto"", ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""fastai"", ""gguf"": null, ""inference"": null, ""tags"": [""fastai"", ""text-generation"", ""en"", ""sk"", ""cs"", ""dataset:fka/awesome-chatgpt-prompts"", ""dataset:gopipasala/fka-awesome-chatgpt-prompts"", ""dataset:HuggingFaceTB/finemath"", ""base_model:deepseek-ai/DeepSeek-V3"", ""base_model:finetune:deepseek-ai/DeepSeek-V3"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model:\n- microsoft/phi-4\n- deepseek-ai/DeepSeek-V3\ndatasets:\n- fka/awesome-chatgpt-prompts\n- gopipasala/fka-awesome-chatgpt-prompts\n- HuggingFaceTB/finemath\nlanguage:\n- en\n- sk\n- cs\nlibrary_name: fastai\nmetrics:\n- accuracy\n- character\npipeline_tag: text-generation\nnew_version: microsoft/phi-4"", ""widget_data"": [{""text"": ""My name is Julien and I like to""}, {""text"": ""I like traveling by train because""}, {""text"": ""Paris is an amazing place to visit,""}, {""text"": ""Once upon a time,""}], ""model_index"": null, ""config"": null, ""transformers_info"": null, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-01-20 10:56:21+00:00"", ""cardData"": ""base_model:\n- microsoft/phi-4\n- deepseek-ai/DeepSeek-V3\ndatasets:\n- fka/awesome-chatgpt-prompts\n- gopipasala/fka-awesome-chatgpt-prompts\n- HuggingFaceTB/finemath\nlanguage:\n- en\n- sk\n- cs\nlibrary_name: fastai\nmetrics:\n- accuracy\n- character\npipeline_tag: text-generation\nnew_version: microsoft/phi-4"", ""transformersInfo"": null, ""_id"": ""678e2b332dfe5dd60c98eb0b"", ""modelId"": ""Arcturus63/Jerry"", ""usedStorage"": 0}",1,,0,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=Arcturus63/Jerry&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5BArcturus63%2FJerry%5D(%2FArcturus63%2FJerry)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1
adel67460/straburo-model,"---
language:
- fr
base_model:
- deepseek-ai/DeepSeek-V3
pipeline_tag: text-generation
tags:
- mobilier+de+bureau
- ergonomie+au+travail
- commerce
- finance
---","{""id"": ""adel67460/straburo-model"", ""author"": ""adel67460"", ""sha"": ""7430cdce943204c2c5a9e766575e5c87cd5a9649"", ""last_modified"": ""2025-02-21 11:55:45+00:00"", ""created_at"": ""2025-01-20 21:51:13+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": null, ""gguf"": null, ""inference"": null, ""tags"": [""mobilier+de+bureau"", ""ergonomie+au+travail"", ""commerce"", ""finance"", ""text-generation"", ""fr"", ""base_model:deepseek-ai/DeepSeek-V3"", ""base_model:finetune:deepseek-ai/DeepSeek-V3"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model:\n- deepseek-ai/DeepSeek-V3\nlanguage:\n- fr\npipeline_tag: text-generation\ntags:\n- mobilier+de+bureau\n- ergonomie+au+travail\n- commerce\n- finance"", ""widget_data"": [{""text"": ""Mon nom est Julien et j'aime""}, {""text"": ""Mon nom est Thomas et mon principal""}, {""text"": ""Il \u00e9tait une fois""}], ""model_index"": null, ""config"": null, ""transformers_info"": null, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-02-21 11:55:45+00:00"", ""cardData"": ""base_model:\n- deepseek-ai/DeepSeek-V3\nlanguage:\n- fr\npipeline_tag: text-generation\ntags:\n- mobilier+de+bureau\n- ergonomie+au+travail\n- commerce\n- finance"", ""transformersInfo"": null, ""_id"": ""678ec5511fe327e6f00133c9"", ""modelId"": ""adel67460/straburo-model"", ""usedStorage"": 0}",1,,0,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=adel67460/straburo-model&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Badel67460%2Fstraburo-model%5D(%2Fadel67460%2Fstraburo-model)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1
southsyde/4thgen,"---
license: apache-2.0
datasets:
- fka/awesome-chatgpt-prompts
language:
- en
metrics:
- accuracy
- bleurt
base_model:
- deepseek-ai/DeepSeek-V3
new_version: hexgrad/Kokoro-82M
pipeline_tag: unconditional-image-generation
library_name: keras
tags:
- art
- mockup design
- products
- ecom
- photoshop
- photographer
- product shoot
---","{""id"": ""southsyde/4thgen"", ""author"": ""southsyde"", ""sha"": ""9a84f30c205a7241bfb93f484f24126b7cd0765d"", ""last_modified"": ""2025-01-23 16:38:53+00:00"", ""created_at"": ""2025-01-23 16:33:38+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""keras"", ""gguf"": null, ""inference"": null, ""tags"": [""keras"", ""art"", ""mockup design"", ""products"", ""ecom"", ""photoshop"", ""photographer"", ""product shoot"", ""unconditional-image-generation"", ""en"", ""dataset:fka/awesome-chatgpt-prompts"", ""base_model:deepseek-ai/DeepSeek-V3"", ""base_model:finetune:deepseek-ai/DeepSeek-V3"", ""license:apache-2.0"", ""region:us""], ""pipeline_tag"": ""unconditional-image-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model:\n- deepseek-ai/DeepSeek-V3\ndatasets:\n- fka/awesome-chatgpt-prompts\nlanguage:\n- en\nlibrary_name: keras\nlicense: apache-2.0\nmetrics:\n- accuracy\n- bleurt\npipeline_tag: unconditional-image-generation\ntags:\n- art\n- mockup design\n- products\n- ecom\n- photoshop\n- photographer\n- product shoot\nnew_version: hexgrad/Kokoro-82M"", ""widget_data"": null, ""model_index"": null, ""config"": null, ""transformers_info"": null, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-01-23 16:38:53+00:00"", ""cardData"": ""base_model:\n- deepseek-ai/DeepSeek-V3\ndatasets:\n- fka/awesome-chatgpt-prompts\nlanguage:\n- en\nlibrary_name: keras\nlicense: apache-2.0\nmetrics:\n- accuracy\n- bleurt\npipeline_tag: unconditional-image-generation\ntags:\n- art\n- mockup design\n- products\n- ecom\n- photoshop\n- photographer\n- product shoot\nnew_version: hexgrad/Kokoro-82M"", ""transformersInfo"": null, ""_id"": ""67926f62b1ca390691d23963"", ""modelId"": ""southsyde/4thgen"", ""usedStorage"": 0}",1,,0,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=southsyde/4thgen&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bsouthsyde%2F4thgen%5D(%2Fsouthsyde%2F4thgen)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1
eeevaw/aa,"---
language:
- de
base_model:
- deepseek-ai/DeepSeek-V3
---","{""id"": ""eeevaw/aa"", ""author"": ""eeevaw"", ""sha"": ""6c7506f6f1233b8fc2aa38447a81d73aabb473d7"", ""last_modified"": ""2025-01-23 20:18:38+00:00"", ""created_at"": ""2025-01-23 20:17:53+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": null, ""gguf"": null, ""inference"": null, ""tags"": [""de"", ""base_model:deepseek-ai/DeepSeek-V3"", ""base_model:finetune:deepseek-ai/DeepSeek-V3"", ""region:us""], ""pipeline_tag"": null, ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model:\n- deepseek-ai/DeepSeek-V3\nlanguage:\n- de"", ""widget_data"": null, ""model_index"": null, ""config"": null, ""transformers_info"": null, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-01-23 20:18:38+00:00"", ""cardData"": ""base_model:\n- deepseek-ai/DeepSeek-V3\nlanguage:\n- de"", ""transformersInfo"": null, ""_id"": ""6792a3f1dc641d1a7298bd5f"", ""modelId"": ""eeevaw/aa"", ""usedStorage"": 0}",1,,0,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=eeevaw/aa&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Beeevaw%2Faa%5D(%2Feeevaw%2Faa)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1
creativ3lab/expertcoder,"---
license: mit
datasets:
- fka/awesome-chatgpt-prompts
- TIGER-Lab/MathInstruct
language:
- en
metrics:
- accuracy
base_model:
- deepseek-ai/DeepSeek-V3
new_version: deepseek-ai/DeepSeek-V3
pipeline_tag: text-generation
library_name: fastai
---","{""id"": ""creativ3lab/expertcoder"", ""author"": ""creativ3lab"", ""sha"": ""472f57d513f03c84b307d9f64c4369dc00bdd91e"", ""last_modified"": ""2025-01-24 03:14:20+00:00"", ""created_at"": ""2025-01-24 03:10:41+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""fastai"", ""gguf"": null, ""inference"": null, ""tags"": [""fastai"", ""text-generation"", ""en"", ""dataset:fka/awesome-chatgpt-prompts"", ""dataset:TIGER-Lab/MathInstruct"", ""base_model:deepseek-ai/DeepSeek-V3"", ""base_model:finetune:deepseek-ai/DeepSeek-V3"", ""license:mit"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model:\n- deepseek-ai/DeepSeek-V3\ndatasets:\n- fka/awesome-chatgpt-prompts\n- TIGER-Lab/MathInstruct\nlanguage:\n- en\nlibrary_name: fastai\nlicense: mit\nmetrics:\n- accuracy\npipeline_tag: text-generation\nnew_version: deepseek-ai/DeepSeek-V3"", ""widget_data"": [{""text"": ""My name is Julien and I like to""}, {""text"": ""I like traveling by train because""}, {""text"": ""Paris is an amazing place to visit,""}, {""text"": ""Once upon a time,""}], ""model_index"": null, ""config"": null, ""transformers_info"": null, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-01-24 03:14:20+00:00"", ""cardData"": ""base_model:\n- deepseek-ai/DeepSeek-V3\ndatasets:\n- fka/awesome-chatgpt-prompts\n- TIGER-Lab/MathInstruct\nlanguage:\n- en\nlibrary_name: fastai\nlicense: mit\nmetrics:\n- accuracy\npipeline_tag: text-generation\nnew_version: deepseek-ai/DeepSeek-V3"", ""transformersInfo"": null, ""_id"": ""679304b1a4def0fec4fab5e4"", ""modelId"": ""creativ3lab/expertcoder"", ""usedStorage"": 0}",1,,0,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=creativ3lab/expertcoder&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bcreativ3lab%2Fexpertcoder%5D(%2Fcreativ3lab%2Fexpertcoder)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1
efecans/soru,"---
license: llama3.3
language:
- tr
base_model:
- deepseek-ai/DeepSeek-V3
- meta-llama/Llama-3.3-70B-Instruct
pipeline_tag: question-answering
---
# Model Card for Model ID

<!-- Provide a quick summary of what the model is/does. -->

This modelcard aims to be a base template for new models. It has been generated using [this raw template](https://github.com/huggingface/huggingface_hub/blob/main/src/huggingface_hub/templates/modelcard_template.md?plain=1).

## Model Details

### Model Description

<!-- Provide a longer summary of what this model is. -->



- **Developed by:** [More Information Needed]
- **Funded by [optional]:** [More Information Needed]
- **Shared by [optional]:** [More Information Needed]
- **Model type:** [More Information Needed]
- **Language(s) (NLP):** [More Information Needed]
- **License:** [More Information Needed]
- **Finetuned from model [optional]:** [More Information Needed]

### Model Sources [optional]

<!-- Provide the basic links for the model. -->

- **Repository:** [More Information Needed]
- **Paper [optional]:** [More Information Needed]
- **Demo [optional]:** [More Information Needed]

## Uses

<!-- Address questions around how the model is intended to be used, including the foreseeable users of the model and those affected by the model. -->

### Direct Use

<!-- This section is for the model use without fine-tuning or plugging into a larger ecosystem/app. -->

[More Information Needed]

### Downstream Use [optional]

<!-- This section is for the model use when fine-tuned for a task, or when plugged into a larger ecosystem/app -->

[More Information Needed]

### Out-of-Scope Use

<!-- This section addresses misuse, malicious use, and uses that the model will not work well for. -->

[More Information Needed]

## Bias, Risks, and Limitations

<!-- This section is meant to convey both technical and sociotechnical limitations. -->

[More Information Needed]

### Recommendations

<!-- This section is meant to convey recommendations with respect to the bias, risk, and technical limitations. -->

Users (both direct and downstream) should be made aware of the risks, biases and limitations of the model. More information needed for further recommendations.

## How to Get Started with the Model

Use the code below to get started with the model.

[More Information Needed]

## Training Details

### Training Data

<!-- This should link to a Dataset Card, perhaps with a short stub of information on what the training data is all about as well as documentation related to data pre-processing or additional filtering. -->

[More Information Needed]

### Training Procedure

<!-- This relates heavily to the Technical Specifications. Content here should link to that section when it is relevant to the training procedure. -->

#### Preprocessing [optional]

[More Information Needed]


#### Training Hyperparameters

- **Training regime:** [More Information Needed] <!--fp32, fp16 mixed precision, bf16 mixed precision, bf16 non-mixed precision, fp16 non-mixed precision, fp8 mixed precision -->

#### Speeds, Sizes, Times [optional]

<!-- This section provides information about throughput, start/end time, checkpoint size if relevant, etc. -->

[More Information Needed]

## Evaluation

<!-- This section describes the evaluation protocols and provides the results. -->

### Testing Data, Factors & Metrics

#### Testing Data

<!-- This should link to a Dataset Card if possible. -->

[More Information Needed]

#### Factors

<!-- These are the things the evaluation is disaggregating by, e.g., subpopulations or domains. -->

[More Information Needed]

#### Metrics

<!-- These are the evaluation metrics being used, ideally with a description of why. -->

[More Information Needed]

### Results

[More Information Needed]

#### Summary



## Model Examination [optional]

<!-- Relevant interpretability work for the model goes here -->

[More Information Needed]

## Environmental Impact

<!-- Total emissions (in grams of CO2eq) and additional considerations, such as electricity usage, go here. Edit the suggested text below accordingly -->

Carbon emissions can be estimated using the [Machine Learning Impact calculator](https://mlco2.github.io/impact#compute) presented in [Lacoste et al. (2019)](https://arxiv.org/abs/1910.09700).

- **Hardware Type:** [More Information Needed]
- **Hours used:** [More Information Needed]
- **Cloud Provider:** [More Information Needed]
- **Compute Region:** [More Information Needed]
- **Carbon Emitted:** [More Information Needed]

## Technical Specifications [optional]

### Model Architecture and Objective

[More Information Needed]

### Compute Infrastructure

[More Information Needed]

#### Hardware

[More Information Needed]

#### Software

[More Information Needed]

## Citation [optional]

<!-- If there is a paper or blog post introducing the model, the APA and Bibtex information for that should go in this section. -->

**BibTeX:**

[More Information Needed]

**APA:**

[More Information Needed]

## Glossary [optional]

<!-- If relevant, include terms and calculations in this section that can help readers understand the model or model card. -->

[More Information Needed]

## More Information [optional]

[More Information Needed]

## Model Card Authors [optional]

[More Information Needed]

## Model Card Contact

[More Information Needed]","{""id"": ""efecans/soru"", ""author"": ""efecans"", ""sha"": ""e37a2231e9565be07753accab36b05d4eda6f50b"", ""last_modified"": ""2025-01-24 12:11:42+00:00"", ""created_at"": ""2025-01-24 11:54:36+00:00"", ""private"": false, ""gated"": ""auto"", ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": null, ""gguf"": null, ""inference"": null, ""tags"": [""question-answering"", ""tr"", ""arxiv:1910.09700"", ""base_model:deepseek-ai/DeepSeek-V3"", ""base_model:finetune:deepseek-ai/DeepSeek-V3"", ""license:llama3.3"", ""region:us""], ""pipeline_tag"": ""question-answering"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model:\n- deepseek-ai/DeepSeek-V3\n- meta-llama/Llama-3.3-70B-Instruct\nlanguage:\n- tr\nlicense: llama3.3\npipeline_tag: question-answering"", ""widget_data"": null, ""model_index"": null, ""config"": null, ""transformers_info"": null, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-01-24 12:11:42+00:00"", ""cardData"": ""base_model:\n- deepseek-ai/DeepSeek-V3\n- meta-llama/Llama-3.3-70B-Instruct\nlanguage:\n- tr\nlicense: llama3.3\npipeline_tag: question-answering"", ""transformersInfo"": null, ""_id"": ""67937f7c3b19d991b5168f71"", ""modelId"": ""efecans/soru"", ""usedStorage"": 0}",1,,0,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=efecans/soru&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Befecans%2Fsoru%5D(%2Fefecans%2Fsoru)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1
CarteLorcana/Lorcana,"---
license: mit
datasets:
- fka/awesome-chatgpt-prompts
language:
- fr
base_model:
- hexgrad/Kokoro-82M
- deepseek-ai/DeepSeek-V3
- microsoft/phi-4
---","{""id"": ""CarteLorcana/Lorcana"", ""author"": ""CarteLorcana"", ""sha"": ""e11f9cb23446f6066f5090d2fa8bf056b07a2bbf"", ""last_modified"": ""2025-01-24 14:13:47+00:00"", ""created_at"": ""2025-01-24 14:06:25+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": null, ""gguf"": null, ""inference"": null, ""tags"": [""fr"", ""dataset:fka/awesome-chatgpt-prompts"", ""base_model:deepseek-ai/DeepSeek-V3"", ""base_model:finetune:deepseek-ai/DeepSeek-V3"", ""license:mit"", ""region:us""], ""pipeline_tag"": null, ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model:\n- hexgrad/Kokoro-82M\n- deepseek-ai/DeepSeek-V3\n- microsoft/phi-4\ndatasets:\n- fka/awesome-chatgpt-prompts\nlanguage:\n- fr\nlicense: mit"", ""widget_data"": null, ""model_index"": null, ""config"": null, ""transformers_info"": null, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-01-24 14:13:47+00:00"", ""cardData"": ""base_model:\n- hexgrad/Kokoro-82M\n- deepseek-ai/DeepSeek-V3\n- microsoft/phi-4\ndatasets:\n- fka/awesome-chatgpt-prompts\nlanguage:\n- fr\nlicense: mit"", ""transformersInfo"": null, ""_id"": ""67939e619030af9c36d9834a"", ""modelId"": ""CarteLorcana/Lorcana"", ""usedStorage"": 0}",1,,0,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=CarteLorcana/Lorcana&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5BCarteLorcana%2FLorcana%5D(%2FCarteLorcana%2FLorcana)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1
Byterbrodov/Byter,"---
base_model:
- deepseek-ai/DeepSeek-V3
pipeline_tag: text-classification
tags:
- chemistry
---","{""id"": ""Byterbrodov/Byter"", ""author"": ""Byterbrodov"", ""sha"": ""502bd64c587f6e54d92cbb5436cb4962f19ae6c7"", ""last_modified"": ""2025-01-25 13:55:09+00:00"", ""created_at"": ""2025-01-25 13:54:27+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": null, ""gguf"": null, ""inference"": null, ""tags"": [""chemistry"", ""text-classification"", ""base_model:deepseek-ai/DeepSeek-V3"", ""base_model:finetune:deepseek-ai/DeepSeek-V3"", ""region:us""], ""pipeline_tag"": ""text-classification"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model:\n- deepseek-ai/DeepSeek-V3\npipeline_tag: text-classification\ntags:\n- chemistry"", ""widget_data"": [{""text"": ""I like you. I love you""}], ""model_index"": null, ""config"": null, ""transformers_info"": null, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-01-25 13:55:09+00:00"", ""cardData"": ""base_model:\n- deepseek-ai/DeepSeek-V3\npipeline_tag: text-classification\ntags:\n- chemistry"", ""transformersInfo"": null, ""_id"": ""6794ed137dbf69e4e3857093"", ""modelId"": ""Byterbrodov/Byter"", ""usedStorage"": 0}",1,,0,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=Byterbrodov/Byter&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5BByterbrodov%2FByter%5D(%2FByterbrodov%2FByter)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1
n1m45/n1m4,"---
license: mit
datasets:
- DAMO-NLP-SG/multimodal_textbook
base_model:
- deepseek-ai/DeepSeek-V3
pipeline_tag: document-question-answering
---","{""id"": ""n1m45/n1m4"", ""author"": ""n1m45"", ""sha"": ""f26854c933b723a82bad31051ff5aae1679d1512"", ""last_modified"": ""2025-01-25 14:23:40+00:00"", ""created_at"": ""2025-01-25 14:17:51+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": null, ""gguf"": null, ""inference"": null, ""tags"": [""document-question-answering"", ""dataset:DAMO-NLP-SG/multimodal_textbook"", ""base_model:deepseek-ai/DeepSeek-V3"", ""base_model:finetune:deepseek-ai/DeepSeek-V3"", ""license:mit"", ""region:us""], ""pipeline_tag"": ""document-question-answering"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model:\n- deepseek-ai/DeepSeek-V3\ndatasets:\n- DAMO-NLP-SG/multimodal_textbook\nlicense: mit\npipeline_tag: document-question-answering"", ""widget_data"": null, ""model_index"": null, ""config"": null, ""transformers_info"": null, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-01-25 14:23:40+00:00"", ""cardData"": ""base_model:\n- deepseek-ai/DeepSeek-V3\ndatasets:\n- DAMO-NLP-SG/multimodal_textbook\nlicense: mit\npipeline_tag: document-question-answering"", ""transformersInfo"": null, ""_id"": ""6794f28f098348e24acbf195"", ""modelId"": ""n1m45/n1m4"", ""usedStorage"": 0}",1,,0,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=n1m45/n1m4&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bn1m45%2Fn1m4%5D(%2Fn1m45%2Fn1m4)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1
Geowg/my-first-chatbot,"---
license: mit
datasets:
- NovaSky-AI/Sky-T1_data_17k
language:
- el
metrics:
- bleu
base_model:
- microsoft/phi-4
- deepseek-ai/DeepSeek-V3
new_version: microsoft/phi-4
pipeline_tag: zero-shot-classification
library_name: bertopic
---","{""id"": ""Geowg/my-first-chatbot"", ""author"": ""Geowg"", ""sha"": ""2e3b17ca704a114e8d1d935e3a43e3ec8fe248a3"", ""last_modified"": ""2025-01-27 18:11:09+00:00"", ""created_at"": ""2025-01-27 18:07:03+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""bertopic"", ""gguf"": null, ""inference"": null, ""tags"": [""bertopic"", ""zero-shot-classification"", ""el"", ""dataset:NovaSky-AI/Sky-T1_data_17k"", ""base_model:deepseek-ai/DeepSeek-V3"", ""base_model:finetune:deepseek-ai/DeepSeek-V3"", ""license:mit"", ""region:us""], ""pipeline_tag"": ""zero-shot-classification"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model:\n- microsoft/phi-4\n- deepseek-ai/DeepSeek-V3\ndatasets:\n- NovaSky-AI/Sky-T1_data_17k\nlanguage:\n- el\nlibrary_name: bertopic\nlicense: mit\nmetrics:\n- bleu\npipeline_tag: zero-shot-classification\nnew_version: microsoft/phi-4"", ""widget_data"": null, ""model_index"": null, ""config"": null, ""transformers_info"": null, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-01-27 18:11:09+00:00"", ""cardData"": ""base_model:\n- microsoft/phi-4\n- deepseek-ai/DeepSeek-V3\ndatasets:\n- NovaSky-AI/Sky-T1_data_17k\nlanguage:\n- el\nlibrary_name: bertopic\nlicense: mit\nmetrics:\n- bleu\npipeline_tag: zero-shot-classification\nnew_version: microsoft/phi-4"", ""transformersInfo"": null, ""_id"": ""6797cb47a08d7b966a35944d"", ""modelId"": ""Geowg/my-first-chatbot"", ""usedStorage"": 0}",1,,0,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=Geowg/my-first-chatbot&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5BGeowg%2Fmy-first-chatbot%5D(%2FGeowg%2Fmy-first-chatbot)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1
Kenny411/Ket,"---
license: creativeml-openrail-m
license_name: m
license_link: LICENSE
datasets:
- fka/awesome-chatgpt-prompts
- DAMO-NLP-SG/multimodal_textbook
metrics:
- character
- accuracy
base_model:
- microsoft/phi-4
- deepseek-ai/DeepSeek-V3
new_version: deepseek-ai/DeepSeek-R1
pipeline_tag: feature-extraction
library_name: asteroid
---","{""id"": ""Kenny411/Ket"", ""author"": ""Kenny411"", ""sha"": ""30a1a652b9b271bf7636809bc043003c92096dce"", ""last_modified"": ""2025-01-29 14:35:08+00:00"", ""created_at"": ""2025-01-29 14:19:09+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""asteroid"", ""gguf"": null, ""inference"": null, ""tags"": [""asteroid"", ""feature-extraction"", ""dataset:fka/awesome-chatgpt-prompts"", ""dataset:DAMO-NLP-SG/multimodal_textbook"", ""base_model:deepseek-ai/DeepSeek-V3"", ""base_model:finetune:deepseek-ai/DeepSeek-V3"", ""license:creativeml-openrail-m"", ""region:us""], ""pipeline_tag"": ""feature-extraction"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model:\n- microsoft/phi-4\n- deepseek-ai/DeepSeek-V3\ndatasets:\n- fka/awesome-chatgpt-prompts\n- DAMO-NLP-SG/multimodal_textbook\nlibrary_name: asteroid\nlicense: creativeml-openrail-m\nlicense_name: m\nlicense_link: LICENSE\nmetrics:\n- character\n- accuracy\npipeline_tag: feature-extraction\nnew_version: deepseek-ai/DeepSeek-R1"", ""widget_data"": null, ""model_index"": null, ""config"": null, ""transformers_info"": null, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='LICENSE', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-01-29 14:35:08+00:00"", ""cardData"": ""base_model:\n- microsoft/phi-4\n- deepseek-ai/DeepSeek-V3\ndatasets:\n- fka/awesome-chatgpt-prompts\n- DAMO-NLP-SG/multimodal_textbook\nlibrary_name: asteroid\nlicense: creativeml-openrail-m\nlicense_name: m\nlicense_link: LICENSE\nmetrics:\n- character\n- accuracy\npipeline_tag: feature-extraction\nnew_version: deepseek-ai/DeepSeek-R1"", ""transformersInfo"": null, ""_id"": ""679a38dd6393055734b3478f"", ""modelId"": ""Kenny411/Ket"", ""usedStorage"": 0}",1,,0,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=Kenny411/Ket&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5BKenny411%2FKet%5D(%2FKenny411%2FKet)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1
https://huggingface.co/mortezap88/9.1-Helper,N/A,N/A,1,,0,,0,,0,,0,,0
KENANK/test-bot,"---
license: apache-2.0
base_model:
- deepseek-ai/DeepSeek-V3
pipeline_tag: text-generation
---","{""id"": ""KENANK/test-bot"", ""author"": ""KENANK"", ""sha"": ""0854071e810aa4e8cc56da9ee8906d69787ee1a2"", ""last_modified"": ""2025-01-30 12:12:43+00:00"", ""created_at"": ""2025-01-30 12:11:39+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": null, ""gguf"": null, ""inference"": null, ""tags"": [""text-generation"", ""base_model:deepseek-ai/DeepSeek-V3"", ""base_model:finetune:deepseek-ai/DeepSeek-V3"", ""license:apache-2.0"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model:\n- deepseek-ai/DeepSeek-V3\nlicense: apache-2.0\npipeline_tag: text-generation"", ""widget_data"": [{""text"": ""My name is Julien and I like to""}, {""text"": ""I like traveling by train because""}, {""text"": ""Paris is an amazing place to visit,""}, {""text"": ""Once upon a time,""}], ""model_index"": null, ""config"": null, ""transformers_info"": null, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-01-30 12:12:43+00:00"", ""cardData"": ""base_model:\n- deepseek-ai/DeepSeek-V3\nlicense: apache-2.0\npipeline_tag: text-generation"", ""transformersInfo"": null, ""_id"": ""679b6c7bb9fd6dfe2b9c74bc"", ""modelId"": ""KENANK/test-bot"", ""usedStorage"": 0}",1,,0,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=KENANK/test-bot&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5BKENANK%2Ftest-bot%5D(%2FKENANK%2Ftest-bot)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1
Meow9848t677/G79go94,"---
license: bigcode-openrail-m
datasets:
- cognitivecomputations/ultrachat-uncensored
language:
- en
metrics:
- oliviak-flpg/rouge
base_model:
- deepseek-ai/DeepSeek-V3
- hexgrad/Kokoro-82M
new_version: openbmb/MiniCPM-o-2_6
pipeline_tag: text-classification
library_name: asteroid
tags:
- not-for-all-audiences
---","{""id"": ""Meow9848t677/G79go94"", ""author"": ""Meow9848t677"", ""sha"": ""c4d2be56886ce3ad931bb30837f7c33798bce43e"", ""last_modified"": ""2025-02-02 10:23:40+00:00"", ""created_at"": ""2025-02-02 10:20:02+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""asteroid"", ""gguf"": null, ""inference"": null, ""tags"": [""asteroid"", ""not-for-all-audiences"", ""text-classification"", ""en"", ""dataset:cognitivecomputations/ultrachat-uncensored"", ""base_model:deepseek-ai/DeepSeek-V3"", ""base_model:finetune:deepseek-ai/DeepSeek-V3"", ""license:bigcode-openrail-m"", ""region:us""], ""pipeline_tag"": ""text-classification"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model:\n- deepseek-ai/DeepSeek-V3\n- hexgrad/Kokoro-82M\ndatasets:\n- cognitivecomputations/ultrachat-uncensored\nlanguage:\n- en\nlibrary_name: asteroid\nlicense: bigcode-openrail-m\nmetrics:\n- oliviak-flpg/rouge\npipeline_tag: text-classification\ntags:\n- not-for-all-audiences\nnew_version: openbmb/MiniCPM-o-2_6"", ""widget_data"": [{""text"": ""I like you. I love you""}], ""model_index"": null, ""config"": null, ""transformers_info"": null, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-02-02 10:23:40+00:00"", ""cardData"": ""base_model:\n- deepseek-ai/DeepSeek-V3\n- hexgrad/Kokoro-82M\ndatasets:\n- cognitivecomputations/ultrachat-uncensored\nlanguage:\n- en\nlibrary_name: asteroid\nlicense: bigcode-openrail-m\nmetrics:\n- oliviak-flpg/rouge\npipeline_tag: text-classification\ntags:\n- not-for-all-audiences\nnew_version: openbmb/MiniCPM-o-2_6"", ""transformersInfo"": null, ""_id"": ""679f46d2575df6520dc02367"", ""modelId"": ""Meow9848t677/G79go94"", ""usedStorage"": 0}",1,,0,,0,,0,,0,,0
bef-18/masia,"---
base_model:
- deepseek-ai/DeepSeek-V3
---","{""id"": ""bef-18/masia"", ""author"": ""bef-18"", ""sha"": ""32ca9625bf2659b3cd2af92fe4fe060a73185c33"", ""last_modified"": ""2025-02-06 07:37:14+00:00"", ""created_at"": ""2025-02-06 07:32:38+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": null, ""gguf"": null, ""inference"": null, ""tags"": [""base_model:deepseek-ai/DeepSeek-V3"", ""base_model:finetune:deepseek-ai/DeepSeek-V3"", ""region:us""], ""pipeline_tag"": null, ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model:\n- deepseek-ai/DeepSeek-V3"", ""widget_data"": null, ""model_index"": null, ""config"": null, ""transformers_info"": null, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-02-06 07:37:14+00:00"", ""cardData"": ""base_model:\n- deepseek-ai/DeepSeek-V3"", ""transformersInfo"": null, ""_id"": ""67a46596b1175693f9c38aeb"", ""modelId"": ""bef-18/masia"", ""usedStorage"": 0}",1,,0,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=bef-18/masia&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bbef-18%2Fmasia%5D(%2Fbef-18%2Fmasia)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1
ChubiLev/Depor,"---
base_model:
- deepseek-ai/DeepSeek-V3
---","{""id"": ""ChubiLev/Depor"", ""author"": ""ChubiLev"", ""sha"": ""a7557410aa068cf9a7ded97b9fd15f0abd659e48"", ""last_modified"": ""2025-02-08 00:58:05+00:00"", ""created_at"": ""2025-02-08 00:56:44+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": null, ""gguf"": null, ""inference"": null, ""tags"": [""base_model:deepseek-ai/DeepSeek-V3"", ""base_model:finetune:deepseek-ai/DeepSeek-V3"", ""region:us""], ""pipeline_tag"": null, ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model:\n- deepseek-ai/DeepSeek-V3"", ""widget_data"": null, ""model_index"": null, ""config"": null, ""transformers_info"": null, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-02-08 00:58:05+00:00"", ""cardData"": ""base_model:\n- deepseek-ai/DeepSeek-V3"", ""transformersInfo"": null, ""_id"": ""67a6abccb1652c3587cabadc"", ""modelId"": ""ChubiLev/Depor"", ""usedStorage"": 0}",1,,0,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=ChubiLev/Depor&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5BChubiLev%2FDepor%5D(%2FChubiLev%2FDepor)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1
14dimension/jarvis,"---
license: apache-2.0
datasets:
- fka/awesome-chatgpt-prompts
language:
- ko
base_model:
- deepseek-ai/DeepSeek-V3
---","{""id"": ""14dimension/jarvis"", ""author"": ""14dimension"", ""sha"": ""c1b9551acd1c4efaf736615c27cdcb1e18b49e1d"", ""last_modified"": ""2025-02-09 11:44:36+00:00"", ""created_at"": ""2025-02-09 11:41:47+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": null, ""gguf"": null, ""inference"": null, ""tags"": [""ko"", ""dataset:fka/awesome-chatgpt-prompts"", ""base_model:deepseek-ai/DeepSeek-V3"", ""base_model:finetune:deepseek-ai/DeepSeek-V3"", ""license:apache-2.0"", ""region:us""], ""pipeline_tag"": null, ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model:\n- deepseek-ai/DeepSeek-V3\ndatasets:\n- fka/awesome-chatgpt-prompts\nlanguage:\n- ko\nlicense: apache-2.0"", ""widget_data"": null, ""model_index"": null, ""config"": null, ""transformers_info"": null, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-02-09 11:44:36+00:00"", ""cardData"": ""base_model:\n- deepseek-ai/DeepSeek-V3\ndatasets:\n- fka/awesome-chatgpt-prompts\nlanguage:\n- ko\nlicense: apache-2.0"", ""transformersInfo"": null, ""_id"": ""67a8947b1bb804b976629166"", ""modelId"": ""14dimension/jarvis"", ""usedStorage"": 0}",1,,0,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=14dimension/jarvis&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5B14dimension%2Fjarvis%5D(%2F14dimension%2Fjarvis)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1
NikhilJain1102/1102,"---
license: mit
datasets:
- open-r1/OpenR1-Math-220k
language:
- hi
- en
metrics:
- accuracy
base_model:
- deepseek-ai/DeepSeek-V3
new_version: deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B
pipeline_tag: text-to-video
library_name: diffusers
---","{""id"": ""NikhilJain1102/1102"", ""author"": ""NikhilJain1102"", ""sha"": ""2704dbe716ecd2ac8e755db3ab438e87055ca08a"", ""last_modified"": ""2025-02-14 17:06:24+00:00"", ""created_at"": ""2025-02-14 17:04:46+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""diffusers"", ""gguf"": null, ""inference"": null, ""tags"": [""diffusers"", ""text-to-video"", ""hi"", ""en"", ""dataset:open-r1/OpenR1-Math-220k"", ""base_model:deepseek-ai/DeepSeek-V3"", ""base_model:finetune:deepseek-ai/DeepSeek-V3"", ""license:mit"", ""region:us""], ""pipeline_tag"": ""text-to-video"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model:\n- deepseek-ai/DeepSeek-V3\ndatasets:\n- open-r1/OpenR1-Math-220k\nlanguage:\n- hi\n- en\nlibrary_name: diffusers\nlicense: mit\nmetrics:\n- accuracy\npipeline_tag: text-to-video\nnew_version: deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B"", ""widget_data"": null, ""model_index"": null, ""config"": null, ""transformers_info"": null, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-02-14 17:06:24+00:00"", ""cardData"": ""base_model:\n- deepseek-ai/DeepSeek-V3\ndatasets:\n- open-r1/OpenR1-Math-220k\nlanguage:\n- hi\n- en\nlibrary_name: diffusers\nlicense: mit\nmetrics:\n- accuracy\npipeline_tag: text-to-video\nnew_version: deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B"", ""transformersInfo"": null, ""_id"": ""67af77ae7535ac017a4eb87f"", ""modelId"": ""NikhilJain1102/1102"", ""usedStorage"": 0}",1,,0,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=NikhilJain1102/1102&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5BNikhilJain1102%2F1102%5D(%2FNikhilJain1102%2F1102)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1
Ruihffd/ChatPPK,"---
license: apache-2.0
language:
- pt
base_model:
- deepseek-ai/DeepSeek-V3
new_version: deepseek-ai/Janus-Pro-7B
pipeline_tag: text-to-image
library_name: asteroid
tags:
- legal
---","{""id"": ""Ruihffd/ChatPPK"", ""author"": ""Ruihffd"", ""sha"": ""3934b9b9ae12e350127ba69cfbc60de95bb97921"", ""last_modified"": ""2025-02-17 04:09:40+00:00"", ""created_at"": ""2025-02-17 04:08:37+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""asteroid"", ""gguf"": null, ""inference"": null, ""tags"": [""asteroid"", ""legal"", ""text-to-image"", ""pt"", ""base_model:deepseek-ai/DeepSeek-V3"", ""base_model:finetune:deepseek-ai/DeepSeek-V3"", ""license:apache-2.0"", ""region:us""], ""pipeline_tag"": ""text-to-image"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model:\n- deepseek-ai/DeepSeek-V3\nlanguage:\n- pt\nlibrary_name: asteroid\nlicense: apache-2.0\npipeline_tag: text-to-image\ntags:\n- legal\nnew_version: deepseek-ai/Janus-Pro-7B"", ""widget_data"": null, ""model_index"": null, ""config"": null, ""transformers_info"": null, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-02-17 04:09:40+00:00"", ""cardData"": ""base_model:\n- deepseek-ai/DeepSeek-V3\nlanguage:\n- pt\nlibrary_name: asteroid\nlicense: apache-2.0\npipeline_tag: text-to-image\ntags:\n- legal\nnew_version: deepseek-ai/Janus-Pro-7B"", ""transformersInfo"": null, ""_id"": ""67b2b645b6c58a3e0a0207ed"", ""modelId"": ""Ruihffd/ChatPPK"", ""usedStorage"": 0}",1,,0,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=Ruihffd/ChatPPK&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5BRuihffd%2FChatPPK%5D(%2FRuihffd%2FChatPPK)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1
Stas696969/2B,"---
license: apache-2.0
datasets:
- fka/awesome-chatgpt-prompts
language:
- ru
metrics:
- character
base_model:
- deepseek-ai/DeepSeek-V3
library_name: espnet
---","{""id"": ""Stas696969/2B"", ""author"": ""Stas696969"", ""sha"": ""2facf294d799289d4d754768b12a55d142f26530"", ""last_modified"": ""2025-02-18 09:33:32+00:00"", ""created_at"": ""2025-02-18 09:31:33+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""espnet"", ""gguf"": null, ""inference"": null, ""tags"": [""espnet"", ""ru"", ""dataset:fka/awesome-chatgpt-prompts"", ""base_model:deepseek-ai/DeepSeek-V3"", ""base_model:finetune:deepseek-ai/DeepSeek-V3"", ""license:apache-2.0"", ""region:us""], ""pipeline_tag"": null, ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model:\n- deepseek-ai/DeepSeek-V3\ndatasets:\n- fka/awesome-chatgpt-prompts\nlanguage:\n- ru\nlibrary_name: espnet\nlicense: apache-2.0\nmetrics:\n- character"", ""widget_data"": null, ""model_index"": null, ""config"": null, ""transformers_info"": null, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-02-18 09:33:32+00:00"", ""cardData"": ""base_model:\n- deepseek-ai/DeepSeek-V3\ndatasets:\n- fka/awesome-chatgpt-prompts\nlanguage:\n- ru\nlibrary_name: espnet\nlicense: apache-2.0\nmetrics:\n- character"", ""transformersInfo"": null, ""_id"": ""67b4537577b2c3c7ee1a9a2a"", ""modelId"": ""Stas696969/2B"", ""usedStorage"": 0}",1,,0,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=Stas696969/2B&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5BStas696969%2F2B%5D(%2FStas696969%2F2B)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1
RAHULCOMRADE123/Mallu,"---
license: apache-2.0
datasets:
- saiyan-world/Goku-MovieGenBench
language:
- ml
metrics:
- character
base_model:
- deepseek-ai/DeepSeek-V3
new_version: Zyphra/Zonos-v0.1-hybrid
pipeline_tag: question-answering
library_name: bertopic
tags:
- music
- art
- text-generation-inference
---","{""id"": ""RAHULCOMRADE123/Mallu"", ""author"": ""RAHULCOMRADE123"", ""sha"": ""3681357edd45fcd6d58cdc53c1f19a918545a3f3"", ""last_modified"": ""2025-02-19 04:12:47+00:00"", ""created_at"": ""2025-02-19 04:07:04+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""bertopic"", ""gguf"": null, ""inference"": null, ""tags"": [""bertopic"", ""music"", ""art"", ""text-generation-inference"", ""question-answering"", ""ml"", ""dataset:saiyan-world/Goku-MovieGenBench"", ""base_model:deepseek-ai/DeepSeek-V3"", ""base_model:finetune:deepseek-ai/DeepSeek-V3"", ""license:apache-2.0"", ""region:us""], ""pipeline_tag"": ""question-answering"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model:\n- deepseek-ai/DeepSeek-V3\ndatasets:\n- saiyan-world/Goku-MovieGenBench\nlanguage:\n- ml\nlibrary_name: bertopic\nlicense: apache-2.0\nmetrics:\n- character\npipeline_tag: question-answering\ntags:\n- music\n- art\n- text-generation-inference\nnew_version: Zyphra/Zonos-v0.1-hybrid"", ""widget_data"": null, ""model_index"": null, ""config"": null, ""transformers_info"": null, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-02-19 04:12:47+00:00"", ""cardData"": ""base_model:\n- deepseek-ai/DeepSeek-V3\ndatasets:\n- saiyan-world/Goku-MovieGenBench\nlanguage:\n- ml\nlibrary_name: bertopic\nlicense: apache-2.0\nmetrics:\n- character\npipeline_tag: question-answering\ntags:\n- music\n- art\n- text-generation-inference\nnew_version: Zyphra/Zonos-v0.1-hybrid"", ""transformersInfo"": null, ""_id"": ""67b558e885c80af9dcd0e0a2"", ""modelId"": ""RAHULCOMRADE123/Mallu"", ""usedStorage"": 0}",1,,0,,0,,0,,0,,0
teknolog/majorgeneral,N/A,N/A,1,,0,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=teknolog/majorgeneral&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bteknolog%2Fmajorgeneral%5D(%2Fteknolog%2Fmajorgeneral)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1
fedoravel/test,"---
datasets:
- Congliu/Chinese-DeepSeek-R1-Distill-data-110k
language:
- en
base_model:
- deepseek-ai/DeepSeek-V3
---","{""id"": ""fedoravel/test"", ""author"": ""fedoravel"", ""sha"": ""f7b97d697c990d681eb8efa16d16a938ca985d15"", ""last_modified"": ""2025-02-22 14:55:00+00:00"", ""created_at"": ""2025-02-22 14:54:21+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": null, ""gguf"": null, ""inference"": null, ""tags"": [""en"", ""dataset:Congliu/Chinese-DeepSeek-R1-Distill-data-110k"", ""base_model:deepseek-ai/DeepSeek-V3"", ""base_model:finetune:deepseek-ai/DeepSeek-V3"", ""region:us""], ""pipeline_tag"": null, ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model:\n- deepseek-ai/DeepSeek-V3\ndatasets:\n- Congliu/Chinese-DeepSeek-R1-Distill-data-110k\nlanguage:\n- en"", ""widget_data"": null, ""model_index"": null, ""config"": null, ""transformers_info"": null, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-02-22 14:55:00+00:00"", ""cardData"": ""base_model:\n- deepseek-ai/DeepSeek-V3\ndatasets:\n- Congliu/Chinese-DeepSeek-R1-Distill-data-110k\nlanguage:\n- en"", ""transformersInfo"": null, ""_id"": ""67b9e51db1077fc4c75edc69"", ""modelId"": ""fedoravel/test"", ""usedStorage"": 0}",1,,0,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=fedoravel/test&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bfedoravel%2Ftest%5D(%2Ffedoravel%2Ftest)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1
pravindsurve/pravindsurve1,"---
datasets:
- pravindsurve/pravindsurve
language:
- en
metrics:
- character
base_model:
- deepseek-ai/DeepSeek-V3
pipeline_tag: question-answering
tags:
- code
license: afl-3.0
new_version: deepseek-ai/DeepSeek-V3
---","{""id"": ""pravindsurve/pravindsurve1"", ""author"": ""pravindsurve"", ""sha"": ""6722648cd076e5196460d606144e9cb7f2d7227a"", ""last_modified"": ""2025-02-24 09:38:11+00:00"", ""created_at"": ""2025-02-22 19:13:54+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 2, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": null, ""gguf"": null, ""inference"": null, ""tags"": [""code"", ""question-answering"", ""en"", ""dataset:pravindsurve/pravindsurve"", ""base_model:deepseek-ai/DeepSeek-V3"", ""base_model:finetune:deepseek-ai/DeepSeek-V3"", ""license:afl-3.0"", ""region:us""], ""pipeline_tag"": ""question-answering"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model:\n- deepseek-ai/DeepSeek-V3\ndatasets:\n- pravindsurve/pravindsurve\nlanguage:\n- en\nlicense: afl-3.0\nmetrics:\n- character\npipeline_tag: question-answering\ntags:\n- code\nnew_version: deepseek-ai/DeepSeek-V3"", ""widget_data"": [{""text"": ""Where do I live?"", ""context"": ""My name is Wolfgang and I live in Berlin""}, {""text"": ""Where do I live?"", ""context"": ""My name is Sarah and I live in London""}, {""text"": ""What's my name?"", ""context"": ""My name is Clara and I live in Berkeley.""}, {""text"": ""Which name is also used to describe the Amazon rainforest in English?"", ""context"": ""The Amazon rainforest (Portuguese: Floresta Amaz\u00f4nica or Amaz\u00f4nia; Spanish: Selva Amaz\u00f3nica, Amazon\u00eda or usually Amazonia; French: For\u00eat amazonienne; Dutch: Amazoneregenwoud), also known in English as Amazonia or the Amazon Jungle, is a moist broadleaf forest that covers most of the Amazon basin of South America. This basin encompasses 7,000,000 square kilometres (2,700,000 sq mi), of which 5,500,000 square kilometres (2,100,000 sq mi) are covered by the rainforest. This region includes territory belonging to nine nations. The majority of the forest is contained within Brazil, with 60% of the rainforest, followed by Peru with 13%, Colombia with 10%, and with minor amounts in Venezuela, Ecuador, Bolivia, Guyana, Suriname and French Guiana. States or departments in four nations contain \""Amazonas\"" in their names. The Amazon represents over half of the planet's remaining rainforests, and comprises the largest and most biodiverse tract of tropical rainforest in the world, with an estimated 390 billion individual trees divided into 16,000 species.""}], ""model_index"": null, ""config"": {""architectures"": [""DeepSeekForCausalLM""]}, ""transformers_info"": null, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='Manifest.yaml', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-02-24 09:38:11+00:00"", ""cardData"": ""base_model:\n- deepseek-ai/DeepSeek-V3\ndatasets:\n- pravindsurve/pravindsurve\nlanguage:\n- en\nlicense: afl-3.0\nmetrics:\n- character\npipeline_tag: question-answering\ntags:\n- code\nnew_version: deepseek-ai/DeepSeek-V3"", ""transformersInfo"": null, ""_id"": ""67ba21f2cc4db0b8dc513c2c"", ""modelId"": ""pravindsurve/pravindsurve1"", ""usedStorage"": 0}",1,,0,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=pravindsurve/pravindsurve1&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bpravindsurve%2Fpravindsurve1%5D(%2Fpravindsurve%2Fpravindsurve1)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1
kingkolor8/Bangaram,"---
license: mit
language:
- te
base_model:
- deepseek-ai/DeepSeek-V3
new_version: deepseek-ai/DeepSeek-V3
library_name: fastai
tags:
- legal
---","{""id"": ""kingkolor8/Bangaram"", ""author"": ""kingkolor8"", ""sha"": ""471d3c1bf90d9006d6f2292367f86f5031601bf5"", ""last_modified"": ""2025-02-23 12:55:06+00:00"", ""created_at"": ""2025-02-23 08:11:32+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""fastai"", ""gguf"": null, ""inference"": null, ""tags"": [""fastai"", ""legal"", ""te"", ""base_model:deepseek-ai/DeepSeek-V3"", ""base_model:finetune:deepseek-ai/DeepSeek-V3"", ""license:mit"", ""region:us""], ""pipeline_tag"": null, ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model:\n- deepseek-ai/DeepSeek-V3\nlanguage:\n- te\nlibrary_name: fastai\nlicense: mit\ntags:\n- legal\nnew_version: deepseek-ai/DeepSeek-V3"", ""widget_data"": null, ""model_index"": null, ""config"": null, ""transformers_info"": null, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-02-23 12:55:06+00:00"", ""cardData"": ""base_model:\n- deepseek-ai/DeepSeek-V3\nlanguage:\n- te\nlibrary_name: fastai\nlicense: mit\ntags:\n- legal\nnew_version: deepseek-ai/DeepSeek-V3"", ""transformersInfo"": null, ""_id"": ""67bad8349415e85b65cbe730"", ""modelId"": ""kingkolor8/Bangaram"", ""usedStorage"": 0}",1,,0,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=kingkolor8/Bangaram&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bkingkolor8%2FBangaram%5D(%2Fkingkolor8%2FBangaram)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1
Albi96/iii,"---
language:
- pl
base_model:
- deepseek-ai/DeepSeek-V3
pipeline_tag: tabular-classification
tags:
- finance
library_name: fastai
---
# Model Card for Model ID

<!-- Provide a quick summary of what the model is/does. -->

This modelcard aims to be a base template for new models. It has been generated using [this raw template](https://github.com/huggingface/huggingface_hub/blob/main/src/huggingface_hub/templates/modelcard_template.md?plain=1).

## Model Details

### Model Description

<!-- Provide a longer summary of what this model is. -->



- **Developed by:** [More Information Needed]
- **Funded by [optional]:** [More Information Needed]
- **Shared by [optional]:** [More Information Needed]
- **Model type:** [More Information Needed]
- **Language(s) (NLP):** [More Information Needed]
- **License:** [More Information Needed]
- **Finetuned from model [optional]:** [More Information Needed]

### Model Sources [optional]

<!-- Provide the basic links for the model. -->

- **Repository:** [More Information Needed]
- **Paper [optional]:** [More Information Needed]
- **Demo [optional]:** [More Information Needed]

## Uses

<!-- Address questions around how the model is intended to be used, including the foreseeable users of the model and those affected by the model. -->

### Direct Use

<!-- This section is for the model use without fine-tuning or plugging into a larger ecosystem/app. -->

[More Information Needed]

### Downstream Use [optional]

<!-- This section is for the model use when fine-tuned for a task, or when plugged into a larger ecosystem/app -->

[More Information Needed]

### Out-of-Scope Use

<!-- This section addresses misuse, malicious use, and uses that the model will not work well for. -->

[More Information Needed]

## Bias, Risks, and Limitations

<!-- This section is meant to convey both technical and sociotechnical limitations. -->

[More Information Needed]

### Recommendations

<!-- This section is meant to convey recommendations with respect to the bias, risk, and technical limitations. -->

Users (both direct and downstream) should be made aware of the risks, biases and limitations of the model. More information needed for further recommendations.

## How to Get Started with the Model

Use the code below to get started with the model.

[More Information Needed]

## Training Details

### Training Data

<!-- This should link to a Dataset Card, perhaps with a short stub of information on what the training data is all about as well as documentation related to data pre-processing or additional filtering. -->

[More Information Needed]

### Training Procedure

<!-- This relates heavily to the Technical Specifications. Content here should link to that section when it is relevant to the training procedure. -->

#### Preprocessing [optional]

[More Information Needed]


#### Training Hyperparameters

- **Training regime:** [More Information Needed] <!--fp32, fp16 mixed precision, bf16 mixed precision, bf16 non-mixed precision, fp16 non-mixed precision, fp8 mixed precision -->

#### Speeds, Sizes, Times [optional]

<!-- This section provides information about throughput, start/end time, checkpoint size if relevant, etc. -->

[More Information Needed]

## Evaluation

<!-- This section describes the evaluation protocols and provides the results. -->

### Testing Data, Factors & Metrics

#### Testing Data

<!-- This should link to a Dataset Card if possible. -->

[More Information Needed]

#### Factors

<!-- These are the things the evaluation is disaggregating by, e.g., subpopulations or domains. -->

[More Information Needed]

#### Metrics

<!-- These are the evaluation metrics being used, ideally with a description of why. -->

[More Information Needed]

### Results

[More Information Needed]

#### Summary



## Model Examination [optional]

<!-- Relevant interpretability work for the model goes here -->

[More Information Needed]

## Environmental Impact

<!-- Total emissions (in grams of CO2eq) and additional considerations, such as electricity usage, go here. Edit the suggested text below accordingly -->

Carbon emissions can be estimated using the [Machine Learning Impact calculator](https://mlco2.github.io/impact#compute) presented in [Lacoste et al. (2019)](https://arxiv.org/abs/1910.09700).

- **Hardware Type:** [More Information Needed]
- **Hours used:** [More Information Needed]
- **Cloud Provider:** [More Information Needed]
- **Compute Region:** [More Information Needed]
- **Carbon Emitted:** [More Information Needed]

## Technical Specifications [optional]

### Model Architecture and Objective

[More Information Needed]

### Compute Infrastructure

[More Information Needed]

#### Hardware

[More Information Needed]

#### Software

[More Information Needed]

## Citation [optional]

<!-- If there is a paper or blog post introducing the model, the APA and Bibtex information for that should go in this section. -->

**BibTeX:**

[More Information Needed]

**APA:**

[More Information Needed]

## Glossary [optional]

<!-- If relevant, include terms and calculations in this section that can help readers understand the model or model card. -->

[More Information Needed]

## More Information [optional]

[More Information Needed]

## Model Card Authors [optional]

[More Information Needed]

## Model Card Contact

[More Information Needed]","{""id"": ""Albi96/iii"", ""author"": ""Albi96"", ""sha"": ""f0c1e8866a0a0f88f38e8b51e5b97210d09d951b"", ""last_modified"": ""2025-02-25 02:17:14+00:00"", ""created_at"": ""2025-02-25 00:47:31+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""fastai"", ""gguf"": null, ""inference"": null, ""tags"": [""fastai"", ""finance"", ""tabular-classification"", ""pl"", ""arxiv:1910.09700"", ""base_model:deepseek-ai/DeepSeek-V3"", ""base_model:finetune:deepseek-ai/DeepSeek-V3"", ""region:us""], ""pipeline_tag"": ""tabular-classification"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model:\n- deepseek-ai/DeepSeek-V3\nlanguage:\n- pl\nlibrary_name: fastai\npipeline_tag: tabular-classification\ntags:\n- finance"", ""widget_data"": null, ""model_index"": null, ""config"": null, ""transformers_info"": null, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-02-25 02:17:14+00:00"", ""cardData"": ""base_model:\n- deepseek-ai/DeepSeek-V3\nlanguage:\n- pl\nlibrary_name: fastai\npipeline_tag: tabular-classification\ntags:\n- finance"", ""transformersInfo"": null, ""_id"": ""67bd13232143b9d14e19fa47"", ""modelId"": ""Albi96/iii"", ""usedStorage"": 0}",1,,0,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=Albi96/iii&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5BAlbi96%2Fiii%5D(%2FAlbi96%2Fiii)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1
rs33nm7d/Limo,"---
license: apache-2.0
datasets:
- open-thoughts/OpenThoughts-114k
metrics:
- accuracy
base_model:
- deepseek-ai/DeepSeek-V3
new_version: black-forest-labs/FLUX.1-dev
tags:
- legal
---","{""id"": ""rs33nm7d/Limo"", ""author"": ""rs33nm7d"", ""sha"": ""5055c017034cc53a0a142e8a5e03b68cbf10bb09"", ""last_modified"": ""2025-02-25 04:23:19+00:00"", ""created_at"": ""2025-02-25 04:20:19+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": null, ""gguf"": null, ""inference"": null, ""tags"": [""legal"", ""dataset:open-thoughts/OpenThoughts-114k"", ""base_model:deepseek-ai/DeepSeek-V3"", ""base_model:finetune:deepseek-ai/DeepSeek-V3"", ""license:apache-2.0"", ""region:us""], ""pipeline_tag"": null, ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model:\n- deepseek-ai/DeepSeek-V3\ndatasets:\n- open-thoughts/OpenThoughts-114k\nlicense: apache-2.0\nmetrics:\n- accuracy\ntags:\n- legal\nnew_version: black-forest-labs/FLUX.1-dev"", ""widget_data"": null, ""model_index"": null, ""config"": null, ""transformers_info"": null, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-02-25 04:23:19+00:00"", ""cardData"": ""base_model:\n- deepseek-ai/DeepSeek-V3\ndatasets:\n- open-thoughts/OpenThoughts-114k\nlicense: apache-2.0\nmetrics:\n- accuracy\ntags:\n- legal\nnew_version: black-forest-labs/FLUX.1-dev"", ""transformersInfo"": null, ""_id"": ""67bd4503a8a68e0dc66e5dd0"", ""modelId"": ""rs33nm7d/Limo"", ""usedStorage"": 0}",1,,0,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=rs33nm7d/Limo&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Brs33nm7d%2FLimo%5D(%2Frs33nm7d%2FLimo)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1
ghostyaZ/cloudApiAI,"---
license: llama3.1
datasets:
- open-r1/OpenR1-Math-220k
language:
- ru
- en
metrics:
- accuracy
base_model:
- deepseek-ai/DeepSeek-V3
new_version: deepseek-ai/DeepSeek-V3
---","{""id"": ""ghostyaZ/cloudApiAI"", ""author"": ""ghostyaZ"", ""sha"": ""bd3c3e4554bf122957431ab34192ae697efe5a09"", ""last_modified"": ""2025-02-25 09:36:21+00:00"", ""created_at"": ""2025-02-25 09:34:56+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": null, ""gguf"": null, ""inference"": null, ""tags"": [""ru"", ""en"", ""dataset:open-r1/OpenR1-Math-220k"", ""base_model:deepseek-ai/DeepSeek-V3"", ""base_model:finetune:deepseek-ai/DeepSeek-V3"", ""license:llama3.1"", ""region:us""], ""pipeline_tag"": null, ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model:\n- deepseek-ai/DeepSeek-V3\ndatasets:\n- open-r1/OpenR1-Math-220k\nlanguage:\n- ru\n- en\nlicense: llama3.1\nmetrics:\n- accuracy\nnew_version: deepseek-ai/DeepSeek-V3"", ""widget_data"": null, ""model_index"": null, ""config"": null, ""transformers_info"": null, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-02-25 09:36:21+00:00"", ""cardData"": ""base_model:\n- deepseek-ai/DeepSeek-V3\ndatasets:\n- open-r1/OpenR1-Math-220k\nlanguage:\n- ru\n- en\nlicense: llama3.1\nmetrics:\n- accuracy\nnew_version: deepseek-ai/DeepSeek-V3"", ""transformersInfo"": null, ""_id"": ""67bd8ec022a37149c1e9b844"", ""modelId"": ""ghostyaZ/cloudApiAI"", ""usedStorage"": 0}",1,,0,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=ghostyaZ/cloudApiAI&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5BghostyaZ%2FcloudApiAI%5D(%2FghostyaZ%2FcloudApiAI)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1
Roy124/Roy,"---
license: bigcode-openrail-m
datasets:
- open-r1/OpenR1-Math-220k
language:
- ae
metrics:
- brier_score
base_model:
- deepseek-ai/DeepSeek-V3
new_version: deepseek-ai/DeepSeek-V3
library_name: asteroid
---
# Model Card for Model ID

<!-- Provide a quick summary of what the model is/does. -->

This modelcard aims to be a base template for new models. It has been generated using [this raw template](https://github.com/huggingface/huggingface_hub/blob/main/src/huggingface_hub/templates/modelcard_template.md?plain=1).

## Model Details

### Model Description

<!-- Provide a longer summary of what this model is. -->



- **Developed by:** [More Information Needed]
- **Funded by [optional]:** [More Information Needed]
- **Shared by [optional]:** [More Information Needed]
- **Model type:** [More Information Needed]
- **Language(s) (NLP):** [More Information Needed]
- **License:** [More Information Needed]
- **Finetuned from model [optional]:** [More Information Needed]

### Model Sources [optional]

<!-- Provide the basic links for the model. -->

- **Repository:** [More Information Needed]
- **Paper [optional]:** [More Information Needed]
- **Demo [optional]:** [More Information Needed]

## Uses

<!-- Address questions around how the model is intended to be used, including the foreseeable users of the model and those affected by the model. -->

### Direct Use

<!-- This section is for the model use without fine-tuning or plugging into a larger ecosystem/app. -->

[More Information Needed]

### Downstream Use [optional]

<!-- This section is for the model use when fine-tuned for a task, or when plugged into a larger ecosystem/app -->

[More Information Needed]

### Out-of-Scope Use

<!-- This section addresses misuse, malicious use, and uses that the model will not work well for. -->

[More Information Needed]

## Bias, Risks, and Limitations

<!-- This section is meant to convey both technical and sociotechnical limitations. -->

[More Information Needed]

### Recommendations

<!-- This section is meant to convey recommendations with respect to the bias, risk, and technical limitations. -->

Users (both direct and downstream) should be made aware of the risks, biases and limitations of the model. More information needed for further recommendations.

## How to Get Started with the Model

Use the code below to get started with the model.

[More Information Needed]

## Training Details

### Training Data

<!-- This should link to a Dataset Card, perhaps with a short stub of information on what the training data is all about as well as documentation related to data pre-processing or additional filtering. -->

[More Information Needed]

### Training Procedure

<!-- This relates heavily to the Technical Specifications. Content here should link to that section when it is relevant to the training procedure. -->

#### Preprocessing [optional]

[More Information Needed]


#### Training Hyperparameters

- **Training regime:** [More Information Needed] <!--fp32, fp16 mixed precision, bf16 mixed precision, bf16 non-mixed precision, fp16 non-mixed precision, fp8 mixed precision -->

#### Speeds, Sizes, Times [optional]

<!-- This section provides information about throughput, start/end time, checkpoint size if relevant, etc. -->

[More Information Needed]

## Evaluation

<!-- This section describes the evaluation protocols and provides the results. -->

### Testing Data, Factors & Metrics

#### Testing Data

<!-- This should link to a Dataset Card if possible. -->

[More Information Needed]

#### Factors

<!-- These are the things the evaluation is disaggregating by, e.g., subpopulations or domains. -->

[More Information Needed]

#### Metrics

<!-- These are the evaluation metrics being used, ideally with a description of why. -->

[More Information Needed]

### Results

[More Information Needed]

#### Summary



## Model Examination [optional]

<!-- Relevant interpretability work for the model goes here -->

[More Information Needed]

## Environmental Impact

<!-- Total emissions (in grams of CO2eq) and additional considerations, such as electricity usage, go here. Edit the suggested text below accordingly -->

Carbon emissions can be estimated using the [Machine Learning Impact calculator](https://mlco2.github.io/impact#compute) presented in [Lacoste et al. (2019)](https://arxiv.org/abs/1910.09700).

- **Hardware Type:** [More Information Needed]
- **Hours used:** [More Information Needed]
- **Cloud Provider:** [More Information Needed]
- **Compute Region:** [More Information Needed]
- **Carbon Emitted:** [More Information Needed]

## Technical Specifications [optional]

### Model Architecture and Objective

[More Information Needed]

### Compute Infrastructure

[More Information Needed]

#### Hardware

[More Information Needed]

#### Software

[More Information Needed]

## Citation [optional]

<!-- If there is a paper or blog post introducing the model, the APA and Bibtex information for that should go in this section. -->

**BibTeX:**

[More Information Needed]

**APA:**

[More Information Needed]

## Glossary [optional]

<!-- If relevant, include terms and calculations in this section that can help readers understand the model or model card. -->

[More Information Needed]

## More Information [optional]

[More Information Needed]

## Model Card Authors [optional]

[More Information Needed]

## Model Card Contact

[More Information Needed]","{""id"": ""Roy124/Roy"", ""author"": ""Roy124"", ""sha"": ""7c12c7e0cb7917ce7bf5b0a37eaf0312790087d0"", ""last_modified"": ""2025-02-26 15:32:42+00:00"", ""created_at"": ""2025-02-26 15:20:14+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""asteroid"", ""gguf"": null, ""inference"": null, ""tags"": [""asteroid"", ""ae"", ""dataset:open-r1/OpenR1-Math-220k"", ""arxiv:1910.09700"", ""base_model:deepseek-ai/DeepSeek-V3"", ""base_model:finetune:deepseek-ai/DeepSeek-V3"", ""license:bigcode-openrail-m"", ""region:us""], ""pipeline_tag"": null, ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model:\n- deepseek-ai/DeepSeek-V3\ndatasets:\n- open-r1/OpenR1-Math-220k\nlanguage:\n- ae\nlibrary_name: asteroid\nlicense: bigcode-openrail-m\nmetrics:\n- brier_score\nnew_version: deepseek-ai/DeepSeek-V3"", ""widget_data"": null, ""model_index"": null, ""config"": null, ""transformers_info"": null, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-02-26 15:32:42+00:00"", ""cardData"": ""base_model:\n- deepseek-ai/DeepSeek-V3\ndatasets:\n- open-r1/OpenR1-Math-220k\nlanguage:\n- ae\nlibrary_name: asteroid\nlicense: bigcode-openrail-m\nmetrics:\n- brier_score\nnew_version: deepseek-ai/DeepSeek-V3"", ""transformersInfo"": null, ""_id"": ""67bf312e33d6740f710f1ab0"", ""modelId"": ""Roy124/Roy"", ""usedStorage"": 0}",1,,0,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=Roy124/Roy&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5BRoy124%2FRoy%5D(%2FRoy124%2FRoy)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1
KikiAnandhan/modelName,"---
license: mit
datasets:
- FreedomIntelligence/medical-o1-reasoning-SFT
metrics:
- accuracy
- bleu
base_model:
- deepseek-ai/DeepSeek-V3
new_version: deepseek-ai/DeepSeek-V3
pipeline_tag: question-answering
library_name: fairseq
tags:
- biology
- medical
---","{""id"": ""KikiAnandhan/modelName"", ""author"": ""KikiAnandhan"", ""sha"": ""2fd7be1a9c3b60a90f8471be75ae048ba0da2571"", ""last_modified"": ""2025-03-02 01:17:12+00:00"", ""created_at"": ""2025-03-02 01:05:24+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""fairseq"", ""gguf"": null, ""inference"": null, ""tags"": [""fairseq"", ""biology"", ""medical"", ""question-answering"", ""dataset:FreedomIntelligence/medical-o1-reasoning-SFT"", ""base_model:deepseek-ai/DeepSeek-V3"", ""base_model:finetune:deepseek-ai/DeepSeek-V3"", ""license:mit"", ""region:us""], ""pipeline_tag"": ""question-answering"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model:\n- deepseek-ai/DeepSeek-V3\ndatasets:\n- FreedomIntelligence/medical-o1-reasoning-SFT\nlibrary_name: fairseq\nlicense: mit\nmetrics:\n- accuracy\n- bleu\npipeline_tag: question-answering\ntags:\n- biology\n- medical\nnew_version: deepseek-ai/DeepSeek-V3"", ""widget_data"": [{""text"": ""Where do I live?"", ""context"": ""My name is Wolfgang and I live in Berlin""}, {""text"": ""Where do I live?"", ""context"": ""My name is Sarah and I live in London""}, {""text"": ""What's my name?"", ""context"": ""My name is Clara and I live in Berkeley.""}, {""text"": ""Which name is also used to describe the Amazon rainforest in English?"", ""context"": ""The Amazon rainforest (Portuguese: Floresta Amaz\u00f4nica or Amaz\u00f4nia; Spanish: Selva Amaz\u00f3nica, Amazon\u00eda or usually Amazonia; French: For\u00eat amazonienne; Dutch: Amazoneregenwoud), also known in English as Amazonia or the Amazon Jungle, is a moist broadleaf forest that covers most of the Amazon basin of South America. This basin encompasses 7,000,000 square kilometres (2,700,000 sq mi), of which 5,500,000 square kilometres (2,100,000 sq mi) are covered by the rainforest. This region includes territory belonging to nine nations. The majority of the forest is contained within Brazil, with 60% of the rainforest, followed by Peru with 13%, Colombia with 10%, and with minor amounts in Venezuela, Ecuador, Bolivia, Guyana, Suriname and French Guiana. States or departments in four nations contain \""Amazonas\"" in their names. The Amazon represents over half of the planet's remaining rainforests, and comprises the largest and most biodiverse tract of tropical rainforest in the world, with an estimated 390 billion individual trees divided into 16,000 species.""}], ""model_index"": null, ""config"": null, ""transformers_info"": null, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-03-02 01:17:12+00:00"", ""cardData"": ""base_model:\n- deepseek-ai/DeepSeek-V3\ndatasets:\n- FreedomIntelligence/medical-o1-reasoning-SFT\nlibrary_name: fairseq\nlicense: mit\nmetrics:\n- accuracy\n- bleu\npipeline_tag: question-answering\ntags:\n- biology\n- medical\nnew_version: deepseek-ai/DeepSeek-V3"", ""transformersInfo"": null, ""_id"": ""67c3aed487a7f49a826cf014"", ""modelId"": ""KikiAnandhan/modelName"", ""usedStorage"": 0}",1,,0,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=KikiAnandhan/modelName&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5BKikiAnandhan%2FmodelName%5D(%2FKikiAnandhan%2FmodelName)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1
tflsxyy/DeepSeek-V3-bf16,"---
library_name: transformers
base_model:
- deepseek-ai/DeepSeek-V3
---
Add metadata to bf16 safetensors for compatibility with transformers:
```ptyhon
from transformers import AutoModelForCausalLM

model = AutoModelForCausalLM.from_pretrained(
    ""/root/dataDisk/DeepSeek-V3-bf16"",
    trust_remote_code=True,
    torch_dtype=""auto"",
    device_map=""cpu"",
)
```

<!-- markdownlint-disable first-line-h1 -->
<!-- markdownlint-disable html -->
<!-- markdownlint-disable no-duplicate-header -->

<div align=""center"">
  <img src=""https://github.com/deepseek-ai/DeepSeek-V2/blob/main/figures/logo.svg?raw=true"" width=""60%"" alt=""DeepSeek-V3"" />
</div>
<hr>
<div align=""center"" style=""line-height: 1;"">
  <a href=""https://www.deepseek.com/"" target=""_blank"" style=""margin: 2px;"">
    <img alt=""Homepage"" src=""https://github.com/deepseek-ai/DeepSeek-V2/blob/main/figures/badge.svg?raw=true"" style=""display: inline-block; vertical-align: middle;""/>
  </a>
  <a href=""https://chat.deepseek.com/"" target=""_blank"" style=""margin: 2px;"">
    <img alt=""Chat"" src=""https://img.shields.io/badge/ü§ñ%20Chat-DeepSeek%20V3-536af5?color=536af5&logoColor=white"" style=""display: inline-block; vertical-align: middle;""/>
  </a>
  <a href=""https://huggingface.co/deepseek-ai"" target=""_blank"" style=""margin: 2px;"">
    <img alt=""Hugging Face"" src=""https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-DeepSeek%20AI-ffc107?color=ffc107&logoColor=white"" style=""display: inline-block; vertical-align: middle;""/>
  </a>
</div>

<div align=""center"" style=""line-height: 1;"">
  <a href=""https://discord.gg/Tc7c45Zzu5"" target=""_blank"" style=""margin: 2px;"">
    <img alt=""Discord"" src=""https://img.shields.io/badge/Discord-DeepSeek%20AI-7289da?logo=discord&logoColor=white&color=7289da"" style=""display: inline-block; vertical-align: middle;""/>
  </a>
  <a href=""https://github.com/deepseek-ai/DeepSeek-V2/blob/main/figures/qr.jpeg?raw=true"" target=""_blank"" style=""margin: 2px;"">
    <img alt=""Wechat"" src=""https://img.shields.io/badge/WeChat-DeepSeek%20AI-brightgreen?logo=wechat&logoColor=white"" style=""display: inline-block; vertical-align: middle;""/>
  </a>
  <a href=""https://twitter.com/deepseek_ai"" target=""_blank"" style=""margin: 2px;"">
    <img alt=""Twitter Follow"" src=""https://img.shields.io/badge/Twitter-deepseek_ai-white?logo=x&logoColor=white"" style=""display: inline-block; vertical-align: middle;""/>
  </a>
</div>

<div align=""center"" style=""line-height: 1;"">
  <a href=""https://github.com/deepseek-ai/DeepSeek-V3/blob/main/LICENSE-CODE"" style=""margin: 2px;"">
    <img alt=""Code License"" src=""https://img.shields.io/badge/Code_License-MIT-f5de53?&color=f5de53"" style=""display: inline-block; vertical-align: middle;""/>
  </a>
  <a href=""https://github.com/deepseek-ai/DeepSeek-V3/blob/main/LICENSE-MODEL"" style=""margin: 2px;"">
    <img alt=""Model License"" src=""https://img.shields.io/badge/Model_License-Model_Agreement-f5de53?&color=f5de53"" style=""display: inline-block; vertical-align: middle;""/>
  </a>
</div>


<p align=""center"">
  <a href=""https://github.com/deepseek-ai/DeepSeek-V3/blob/main/DeepSeek_V3.pdf""><b>Paper Link</b>üëÅÔ∏è</a>
</p>


## 1. Introduction

We present DeepSeek-V3, a strong Mixture-of-Experts (MoE) language model with 671B total parameters with 37B activated for each token. 
To achieve efficient inference and cost-effective training, DeepSeek-V3 adopts Multi-head Latent Attention (MLA) and DeepSeekMoE architectures, which were thoroughly validated in DeepSeek-V2. 
Furthermore, DeepSeek-V3 pioneers an auxiliary-loss-free strategy for load balancing and sets a multi-token prediction training objective for stronger performance. 
We pre-train DeepSeek-V3 on 14.8 trillion diverse and high-quality tokens, followed by Supervised Fine-Tuning and Reinforcement Learning stages to fully harness its capabilities. 
Comprehensive evaluations reveal that DeepSeek-V3 outperforms other open-source models and achieves performance comparable to leading closed-source models.
Despite its excellent performance, DeepSeek-V3 requires only 2.788M H800 GPU hours for its full training.
In addition, its training process is remarkably stable. 
Throughout the entire training process, we did not experience any irrecoverable loss spikes or perform any rollbacks. 
<p align=""center"">
  <img width=""80%"" src=""figures/benchmark.png"">
</p>

## 2. Model Summary

---

**Architecture: Innovative Load Balancing Strategy and Training Objective**

- On top of the efficient architecture of DeepSeek-V2, we pioneer an auxiliary-loss-free strategy for load balancing, which minimizes the performance degradation that arises from encouraging load balancing.
-  We investigate a Multi-Token Prediction (MTP) objective and prove it beneficial to model performance. 
    It can also be used for speculative decoding for inference acceleration. 

---

**Pre-Training: Towards Ultimate Training Efficiency**

- We design an FP8 mixed precision training framework and, for the first time, validate the feasibility and effectiveness of FP8 training on an extremely large-scale model.  
- Through co-design of algorithms, frameworks, and hardware, we overcome the communication bottleneck in cross-node MoE training, nearly achieving full computation-communication overlap.  
  This significantly enhances our training efficiency and reduces the training costs, enabling us to further scale up the model size without additional overhead.  
- At an economical cost of only 2.664M H800 GPU hours, we complete the pre-training of DeepSeek-V3 on 14.8T tokens, producing the currently strongest open-source base model. The subsequent training stages after pre-training require only 0.1M GPU hours.

---

**Post-Training: Knowledge Distillation from DeepSeek-R1**

-   We introduce an innovative methodology to distill reasoning capabilities from the long-Chain-of-Thought (CoT) model, specifically from one of the DeepSeek R1 series models, into standard LLMs, particularly DeepSeek-V3. Our pipeline elegantly incorporates the verification and reflection patterns of R1 into DeepSeek-V3 and notably improves its reasoning performance. Meanwhile, we also maintain a control over the output style and length of DeepSeek-V3.

---


## 3. Model Downloads

<div align=""center"">

| **Model** | **#Total Params** | **#Activated Params** | **Context Length** | **Download** |
| :------------: | :------------: | :------------: | :------------: | :------------: |
| DeepSeek-V3-Base | 671B | 37B | 128K   | [ü§ó HuggingFace](https://huggingface.co/deepseek-ai/DeepSeek-V3-Base)   |
| DeepSeek-V3   | 671B | 37B |  128K   | [ü§ó HuggingFace](https://huggingface.co/deepseek-ai/DeepSeek-V3)   |

</div>

**NOTE: The total size of DeepSeek-V3 models on HuggingFace is 685B, which includes 671B of the Main Model weights and 14B of the Multi-Token Prediction (MTP) Module weights.**

To ensure optimal performance and flexibility, we have partnered with open-source communities and hardware vendors to provide multiple ways to run the model locally. For step-by-step guidance, check out Section 6: [How_to Run_Locally](#6-how-to-run-locally).

For developers looking to dive deeper, we recommend exploring [README_WEIGHTS.md](./README_WEIGHTS.md) for details on the Main Model weights and the Multi-Token Prediction (MTP) Modules. Please note that MTP support is currently under active development within the community, and we welcome your contributions and feedback.

## 4. Evaluation Results
### Base Model
#### Standard Benchmarks

<div align=""center"">


|  | Benchmark (Metric) | # Shots | DeepSeek-V2 | Qwen2.5 72B | LLaMA3.1 405B | DeepSeek-V3 |
|---|-------------------|----------|--------|-------------|---------------|---------|
| | Architecture | - | MoE | Dense | Dense | MoE |
| | # Activated Params | - | 21B | 72B | 405B | 37B |
| | # Total Params | - | 236B | 72B | 405B | 671B |
| English | Pile-test (BPB) | - | 0.606 | 0.638 | **0.542** | 0.548 |
| | BBH (EM) | 3-shot | 78.8 | 79.8 | 82.9 | **87.5** |
| | MMLU (Acc.) | 5-shot | 78.4 | 85.0 | 84.4 | **87.1** |
| | MMLU-Redux (Acc.) | 5-shot | 75.6 | 83.2 | 81.3 | **86.2** |
| | MMLU-Pro (Acc.) | 5-shot | 51.4 | 58.3 | 52.8 | **64.4** |
| | DROP (F1) | 3-shot | 80.4 | 80.6 | 86.0 | **89.0** |
| | ARC-Easy (Acc.) | 25-shot | 97.6 | 98.4 | 98.4 | **98.9** |
| | ARC-Challenge (Acc.) | 25-shot | 92.2 | 94.5 | **95.3** | **95.3** |
| | HellaSwag (Acc.) | 10-shot | 87.1 | 84.8 | **89.2** | 88.9 |
| | PIQA (Acc.) | 0-shot | 83.9 | 82.6 | **85.9** | 84.7 |
| | WinoGrande (Acc.) | 5-shot | **86.3** | 82.3 | 85.2 | 84.9 |
| | RACE-Middle (Acc.) | 5-shot | 73.1 | 68.1 | **74.2** | 67.1 |
| | RACE-High (Acc.) | 5-shot | 52.6 | 50.3 | **56.8** | 51.3 |
| | TriviaQA (EM) | 5-shot | 80.0 | 71.9 | **82.7** | **82.9** |
| | NaturalQuestions (EM) | 5-shot | 38.6 | 33.2 | **41.5** | 40.0 |
| | AGIEval (Acc.) | 0-shot | 57.5 | 75.8 | 60.6 | **79.6** |
| Code | HumanEval (Pass@1) | 0-shot | 43.3 | 53.0 | 54.9 | **65.2** |
| | MBPP (Pass@1) | 3-shot | 65.0 | 72.6 | 68.4 | **75.4** |
| | LiveCodeBench-Base (Pass@1) | 3-shot | 11.6 | 12.9 | 15.5 | **19.4** |
| | CRUXEval-I (Acc.) | 2-shot | 52.5 | 59.1 | 58.5 | **67.3** |
| | CRUXEval-O (Acc.) | 2-shot | 49.8 | 59.9 | 59.9 | **69.8** |
| Math | GSM8K (EM) | 8-shot | 81.6 | 88.3 | 83.5 | **89.3** |
| | MATH (EM) | 4-shot | 43.4 | 54.4 | 49.0 | **61.6** |
| | MGSM (EM) | 8-shot | 63.6 | 76.2 | 69.9 | **79.8** |
| | CMath (EM) | 3-shot | 78.7 | 84.5 | 77.3 | **90.7** |
| Chinese | CLUEWSC (EM) | 5-shot | 82.0 | 82.5 | **83.0** | 82.7 |
| | C-Eval (Acc.) | 5-shot | 81.4 | 89.2 | 72.5 | **90.1** |
| | CMMLU (Acc.) | 5-shot | 84.0 | **89.5** | 73.7 | 88.8 |
| | CMRC (EM) | 1-shot | **77.4** | 75.8 | 76.0 | 76.3 |
| | C3 (Acc.) | 0-shot | 77.4 | 76.7 | **79.7** | 78.6 |
| | CCPM (Acc.) | 0-shot | **93.0** | 88.5 | 78.6 | 92.0 |
| Multilingual | MMMLU-non-English (Acc.) | 5-shot | 64.0 | 74.8 | 73.8 | **79.4** |

</div>

Note: Best results are shown in bold. Scores with a gap not exceeding 0.3 are considered to be at the same level. DeepSeek-V3 achieves the best performance on most benchmarks, especially on math and code tasks.
For more evaluation details, please check our paper. 

#### Context Window
<p align=""center"">
  <img width=""80%"" src=""figures/niah.png"">
</p>

Evaluation results on the ``Needle In A Haystack`` (NIAH) tests.  DeepSeek-V3 performs well across all context window lengths up to **128K**. 

### Chat Model
#### Standard Benchmarks (Models larger than 67B)
<div align=""center"">

| | **Benchmark (Metric)** | **DeepSeek V2-0506** | **DeepSeek V2.5-0905** | **Qwen2.5 72B-Inst.** | **Llama3.1 405B-Inst.** | **Claude-3.5-Sonnet-1022** | **GPT-4o 0513** | **DeepSeek V3** |
|---|---------------------|---------------------|----------------------|---------------------|----------------------|---------------------------|----------------|----------------|
| | Architecture | MoE | MoE | Dense | Dense | - | - | MoE |
| | # Activated Params | 21B | 21B | 72B | 405B | - | - | 37B |
| | # Total Params | 236B | 236B | 72B | 405B | - | - | 671B |
| English | MMLU (EM) | 78.2 | 80.6 | 85.3 | **88.6** | **88.3** | 87.2 | **88.5** |
| | MMLU-Redux (EM) | 77.9 | 80.3 | 85.6 | 86.2 | **88.9** | 88.0 | **89.1** |
| | MMLU-Pro (EM) | 58.5 | 66.2 | 71.6 | 73.3 | **78.0** | 72.6 | 75.9 |
| | DROP (3-shot F1) | 83.0 | 87.8 | 76.7 | 88.7 | 88.3 | 83.7 | **91.6** |
| | IF-Eval (Prompt Strict) | 57.7 | 80.6 | 84.1 | 86.0 | **86.5** | 84.3 | 86.1 |
| | GPQA-Diamond (Pass@1) | 35.3 | 41.3 | 49.0 | 51.1 | **65.0** | 49.9 | 59.1 |
| | SimpleQA (Correct) | 9.0 | 10.2 | 9.1 | 17.1 | 28.4 | **38.2** | 24.9 |
| | FRAMES (Acc.) | 66.9 | 65.4 | 69.8 | 70.0 | 72.5 | **80.5** | 73.3 |
| | LongBench v2 (Acc.) | 31.6 | 35.4 | 39.4 | 36.1 | 41.0 | 48.1 | **48.7** |
| Code | HumanEval-Mul (Pass@1) | 69.3 | 77.4 | 77.3 | 77.2 | 81.7 | 80.5 | **82.6** |
| | LiveCodeBench (Pass@1-COT) | 18.8 | 29.2 | 31.1 | 28.4 | 36.3 | 33.4 | **40.5** |
| | LiveCodeBench (Pass@1) | 20.3 | 28.4 | 28.7 | 30.1 | 32.8 | 34.2 | **37.6** |
| | Codeforces (Percentile) | 17.5 | 35.6 | 24.8 | 25.3 | 20.3 | 23.6 | **51.6** |
| | SWE Verified (Resolved) | - | 22.6 | 23.8 | 24.5 | **50.8** | 38.8 | 42.0 |
| | Aider-Edit (Acc.) | 60.3 | 71.6 | 65.4 | 63.9 | **84.2** | 72.9 | 79.7 |
| | Aider-Polyglot (Acc.) | - | 18.2 | 7.6 | 5.8 | 45.3 | 16.0 | **49.6** |
| Math | AIME 2024 (Pass@1) | 4.6 | 16.7 | 23.3 | 23.3 | 16.0 | 9.3 | **39.2** |
| | MATH-500 (EM) | 56.3 | 74.7 | 80.0 | 73.8 | 78.3 | 74.6 | **90.2** |
| | CNMO 2024 (Pass@1) | 2.8 | 10.8 | 15.9 | 6.8 | 13.1 | 10.8 | **43.2** |
| Chinese | CLUEWSC (EM) | 89.9 | 90.4 | **91.4** | 84.7 | 85.4 | 87.9 | 90.9 |
| | C-Eval (EM) | 78.6 | 79.5 | 86.1 | 61.5 | 76.7 | 76.0 | **86.5** |
| | C-SimpleQA (Correct) | 48.5 | 54.1 | 48.4 | 50.4 | 51.3 | 59.3 | **64.8** |

Note: All models are evaluated in a configuration that limits the output length to 8K. Benchmarks containing fewer than 1000 samples are tested multiple times using varying temperature settings to derive robust final results. DeepSeek-V3 stands as the best-performing open-source model, and also exhibits competitive performance against frontier closed-source models.

</div>


####  Open Ended Generation Evaluation

<div align=""center"">



| Model | Arena-Hard | AlpacaEval 2.0 |
|-------|------------|----------------|
| DeepSeek-V2.5-0905 | 76.2 | 50.5 |
| Qwen2.5-72B-Instruct | 81.2 | 49.1 |
| LLaMA-3.1 405B | 69.3 | 40.5 |
| GPT-4o-0513 | 80.4 | 51.1 |
| Claude-Sonnet-3.5-1022 | 85.2 | 52.0 |
| DeepSeek-V3 | **85.5** | **70.0** |

Note: English open-ended conversation evaluations. For AlpacaEval 2.0, we use the length-controlled win rate as the metric.
</div>


## 5. Chat Website & API Platform
You can chat with DeepSeek-V3 on DeepSeek's official website: [chat.deepseek.com](https://chat.deepseek.com/sign_in)

We also provide OpenAI-Compatible API at DeepSeek Platform: [platform.deepseek.com](https://platform.deepseek.com/)

## 6. How to Run Locally

DeepSeek-V3 can be deployed locally using the following hardware and open-source community software:

1. **DeepSeek-Infer Demo**: We provide a simple and lightweight demo for FP8 and BF16 inference.
2. **SGLang**: Fully support the DeepSeek-V3 model in both BF16 and FP8 inference modes.
3. **LMDeploy**: Enables efficient FP8 and BF16 inference for local and cloud deployment.
4. **TensorRT-LLM**: Currently supports BF16 inference and INT4/8 quantization, with FP8 support coming soon.
5. **vLLM**: Support DeekSeek-V3 model with FP8 and BF16 modes for tensor parallelism and pipeline parallelism.
6. **AMD GPU**: Enables running the DeepSeek-V3 model on AMD GPUs via SGLang in both BF16 and FP8 modes.
7. **Huawei Ascend NPU**: Supports running DeepSeek-V3 on Huawei Ascend devices.

Since FP8 training is natively adopted in our framework, we only provide FP8 weights. If you require BF16 weights for experimentation, you can use the provided conversion script to perform the transformation.

Here is an example of converting FP8 weights to BF16:

```shell
cd inference
python fp8_cast_bf16.py --input-fp8-hf-path /path/to/fp8_weights --output-bf16-hf-path /path/to/bf16_weights
```

**NOTE: Huggingface's Transformers has not been directly supported yet.**

### 6.1 Inference with DeepSeek-Infer Demo (example only)

#### Model Weights & Demo Code Preparation

First, clone our DeepSeek-V3 GitHub repository:

```shell
git clone https://github.com/deepseek-ai/DeepSeek-V3.git
```

Navigate to the `inference` folder and install dependencies listed in `requirements.txt`.

```shell
cd DeepSeek-V3/inference
pip install -r requirements.txt
```

Download the model weights from HuggingFace, and put them into `/path/to/DeepSeek-V3` folder.

#### Model Weights Conversion

Convert HuggingFace model weights to a specific format:

```shell
python convert.py --hf-ckpt-path /path/to/DeepSeek-V3 --save-path /path/to/DeepSeek-V3-Demo --n-experts 256 --model-parallel 16
```

#### Run

Then you can chat with DeepSeek-V3:

```shell
torchrun --nnodes 2 --nproc-per-node 8 generate.py --node-rank $RANK --master-addr $ADDR --ckpt-path /path/to/DeepSeek-V3-Demo --config configs/config_671B.json --interactive --temperature 0.7 --max-new-tokens 200
```

Or batch inference on a given file:

```shell
torchrun --nnodes 2 --nproc-per-node 8 generate.py --node-rank $RANK --master-addr $ADDR --ckpt-path /path/to/DeepSeek-V3-Demo --config configs/config_671B.json --input-file $FILE
```

### 6.2 Inference with SGLang (recommended)

[SGLang](https://github.com/sgl-project/sglang) currently supports MLA optimizations, FP8 (W8A8), FP8 KV Cache, and Torch Compile, delivering state-of-the-art latency and throughput performance among open-source frameworks.

Notably, [SGLang v0.4.1](https://github.com/sgl-project/sglang/releases/tag/v0.4.1) fully supports running DeepSeek-V3 on both **NVIDIA and AMD GPUs**, making it a highly versatile and robust solution.

Here are the launch instructions from the SGLang team: https://github.com/sgl-project/sglang/tree/main/benchmark/deepseek_v3

### 6.3 Inference with LMDeploy (recommended)
[LMDeploy](https://github.com/InternLM/lmdeploy), a flexible and high-performance inference and serving framework tailored for large language models, now supports DeepSeek-V3. It offers both offline pipeline processing and online deployment capabilities, seamlessly integrating with PyTorch-based workflows.

For comprehensive step-by-step instructions on running DeepSeek-V3 with LMDeploy, please refer to here: https://github.com/InternLM/lmdeploy/issues/2960


### 6.4 Inference with TRT-LLM (recommended)

[TensorRT-LLM](https://github.com/NVIDIA/TensorRT-LLM) now supports the DeepSeek-V3 model, offering precision options such as BF16 and INT4/INT8 weight-only. Support for FP8 is currently in progress and will be released soon. You can access the custom branch of TRTLLM specifically for DeepSeek-V3 support through the following link to experience the new features directly: https://github.com/NVIDIA/TensorRT-LLM/tree/deepseek/examples/deepseek_v3. 

### 6.5 Inference with vLLM (recommended)

[vLLM](https://github.com/vllm-project/vllm) v0.6.6 supports DeepSeek-V3 inference for FP8 and BF16 modes on both NVIDIA and AMD GPUs. Aside from standard techniques, vLLM offers _pipeline parallelism_ allowing you to run this model on multiple machines connected by networks. For detailed guidance, please refer to the [vLLM instructions](https://docs.vllm.ai/en/latest/serving/distributed_serving.html). Please feel free to follow [the enhancement plan](https://github.com/vllm-project/vllm/issues/11539) as well.

### 6.6 Recommended Inference Functionality with AMD GPUs

In collaboration with the AMD team, we have achieved Day-One support for AMD GPUs using SGLang, with full compatibility for both FP8 and BF16 precision. For detailed guidance, please refer to the [SGLang instructions](#63-inference-with-lmdeploy-recommended).

### 6.7 Recommended Inference Functionality with Huawei Ascend NPUs
The [MindIE](https://www.hiascend.com/en/software/mindie) framework from the Huawei Ascend community has successfully adapted the BF16 version of DeepSeek-V3. For step-by-step guidance on Ascend NPUs, please follow the [instructions here](https://modelers.cn/models/MindIE/deepseekv3).


## 7. License
This code repository is licensed under [the MIT License](LICENSE-CODE). The use of DeepSeek-V3 Base/Chat models is subject to [the Model License](LICENSE-MODEL). DeepSeek-V3 series (including Base and Chat) supports commercial use.

## 8. Citation
```
@misc{deepseekai2024deepseekv3technicalreport,
      title={DeepSeek-V3 Technical Report}, 
      author={DeepSeek-AI},
      year={2024},
      eprint={2412.19437},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2412.19437}, 
}
```

## 9. Contact
If you have any questions, please raise an issue or contact us at [service@deepseek.com](service@deepseek.com).
","{""id"": ""tflsxyy/DeepSeek-V3-bf16"", ""author"": ""tflsxyy"", ""sha"": ""c458b8b8cbad03b3e5313a5bcedbca7d5485b2ef"", ""last_modified"": ""2025-03-06 07:27:56+00:00"", ""created_at"": ""2025-03-06 05:59:09+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 1, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""safetensors"", ""deepseek_v3"", ""text-generation"", ""conversational"", ""custom_code"", ""arxiv:2412.19437"", ""base_model:deepseek-ai/DeepSeek-V3"", ""base_model:finetune:deepseek-ai/DeepSeek-V3"", ""autotrain_compatible"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model:\n- deepseek-ai/DeepSeek-V3\nlibrary_name: transformers"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""DeepseekV3ForCausalLM""], ""auto_map"": {""AutoConfig"": ""configuration_deepseek.DeepseekV3Config"", ""AutoModel"": ""modeling_deepseek.DeepseekV3Model"", ""AutoModelForCausalLM"": ""modeling_deepseek.DeepseekV3ForCausalLM""}, ""model_type"": ""deepseek_v3"", ""tokenizer_config"": {""bos_token"": {""__type"": ""AddedToken"", ""content"": ""<\uff5cbegin\u2581of\u2581sentence\uff5c>"", ""lstrip"": false, ""normalized"": true, ""rstrip"": false, ""single_word"": false}, ""eos_token"": {""__type"": ""AddedToken"", ""content"": ""<\uff5cend\u2581of\u2581sentence\uff5c>"", ""lstrip"": false, ""normalized"": true, ""rstrip"": false, ""single_word"": false}, ""pad_token"": {""__type"": ""AddedToken"", ""content"": ""<\uff5cend\u2581of\u2581sentence\uff5c>"", ""lstrip"": false, ""normalized"": true, ""rstrip"": false, ""single_word"": false}, ""unk_token"": null, ""chat_template"": ""{% if not add_generation_prompt is defined %}{% set add_generation_prompt = false %}{% endif %}{% set ns = namespace(is_first=false, is_tool=false, is_output_first=true, system_prompt='', is_first_sp=true) %}{%- for message in messages %}{%- if message['role'] == 'system' %}{%- if ns.is_first_sp %}{% set ns.system_prompt = ns.system_prompt + message['content'] %}{% set ns.is_first_sp = false %}{%- else %}{% set ns.system_prompt = ns.system_prompt + '\\n\\n' + message['content'] %}{%- endif %}{%- endif %}{%- endfor %}{{ bos_token }}{{ ns.system_prompt }}{%- for message in messages %}{%- if message['role'] == 'user' %}{%- set ns.is_tool = false -%}{{'<\uff5cUser\uff5c>' + message['content']}}{%- endif %}{%- if message['role'] == 'assistant' and 'tool_calls' in message %}{%- set ns.is_tool = false -%}{%- for tool in message['tool_calls'] %}{%- if not ns.is_first %}{%- if message['content'] is none %}{{'<\uff5cAssistant\uff5c><\uff5ctool\u2581calls\u2581begin\uff5c><\uff5ctool\u2581call\u2581begin\uff5c>' + tool['type'] + '<\uff5ctool\u2581sep\uff5c>' + tool['function']['name'] + '\\n' + '```json' + '\\n' + tool['function']['arguments'] + '\\n' + '```' + '<\uff5ctool\u2581call\u2581end\uff5c>'}}{%- else %}{{'<\uff5cAssistant\uff5c>' + message['content'] + '<\uff5ctool\u2581calls\u2581begin\uff5c><\uff5ctool\u2581call\u2581begin\uff5c>' + tool['type'] + '<\uff5ctool\u2581sep\uff5c>' + tool['function']['name'] + '\\n' + '```json' + '\\n' + tool['function']['arguments'] + '\\n' + '```' + '<\uff5ctool\u2581call\u2581end\uff5c>'}}{%- endif %}{%- set ns.is_first = true -%}{%- else %}{{'\\n' + '<\uff5ctool\u2581call\u2581begin\uff5c>' + tool['type'] + '<\uff5ctool\u2581sep\uff5c>' + tool['function']['name'] + '\\n' + '```json' + '\\n' + tool['function']['arguments'] + '\\n' + '```' + '<\uff5ctool\u2581call\u2581end\uff5c>'}}{%- endif %}{%- endfor %}{{'<\uff5ctool\u2581calls\u2581end\uff5c><\uff5cend\u2581of\u2581sentence\uff5c>'}}{%- endif %}{%- if message['role'] == 'assistant' and 'tool_calls' not in message %}{%- if ns.is_tool %}{{'<\uff5ctool\u2581outputs\u2581end\uff5c>' + message['content'] + '<\uff5cend\u2581of\u2581sentence\uff5c>'}}{%- set ns.is_tool = false -%}{%- else %}{% set content = message['content'] %}{% if '</think>' in content %}{% set content = content.split('</think>')[-1] %}{% endif %}{{'<\uff5cAssistant\uff5c>' + content + '<\uff5cend\u2581of\u2581sentence\uff5c>'}}{%- endif %}{%- endif %}{%- if message['role'] == 'tool' %}{%- set ns.is_tool = true -%}{%- if ns.is_output_first %}{{'<\uff5ctool\u2581outputs\u2581begin\uff5c><\uff5ctool\u2581output\u2581begin\uff5c>' + message['content'] + '<\uff5ctool\u2581output\u2581end\uff5c>'}}{%- set ns.is_output_first = false %}{%- else %}{{'<\uff5ctool\u2581output\u2581begin\uff5c>' + message['content'] + '<\uff5ctool\u2581output\u2581end\uff5c>'}}{%- endif %}{%- endif %}{%- endfor -%}{% if ns.is_tool %}{{'<\uff5ctool\u2581outputs\u2581end\uff5c>'}}{% endif %}{% if add_generation_prompt and not ns.is_tool %}{{'<\uff5cAssistant\uff5c>'}}{% endif %}""}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='LICENSE-CODE', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='LICENSE-MODEL', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README_WEIGHTS.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='configuration_deepseek.py', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='generation_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00001-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00002-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00003-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00004-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00005-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00006-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00007-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00008-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00009-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00010-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00011-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00012-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00013-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00014-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00015-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00016-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00017-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00018-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00019-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00020-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00021-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00022-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00023-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00024-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00025-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00026-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00027-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00028-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00029-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00030-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00031-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00032-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00033-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00034-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00035-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00036-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00037-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00038-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00039-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00040-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00041-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00042-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00043-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00044-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00045-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00046-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00047-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00048-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00049-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00050-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00051-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00052-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00053-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00054-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00055-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00056-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00057-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00058-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00059-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00060-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00061-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00062-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00063-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00064-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00065-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00066-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00067-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00068-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00069-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00070-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00071-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00072-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00073-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00074-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00075-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00076-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00077-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00078-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00079-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00080-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00081-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00082-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00083-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00084-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00085-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00086-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00087-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00088-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00089-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00090-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00091-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00092-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00093-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00094-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00095-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00096-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00097-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00098-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00099-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00100-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00101-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00102-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00103-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00104-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00105-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00106-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00107-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00108-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00109-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00110-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00111-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00112-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00113-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00114-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00115-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00116-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00117-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00118-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00119-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00120-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00121-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00122-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00123-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00124-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00125-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00126-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00127-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00128-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00129-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00130-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00131-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00132-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00133-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00134-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00135-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00136-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00137-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00138-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00139-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00140-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00141-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00142-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00143-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00144-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00145-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00146-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00147-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00148-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00149-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00150-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00151-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00152-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00153-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00154-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00155-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00156-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00157-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00158-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00159-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00160-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00161-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00162-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model-00163-of-000163.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model.safetensors.index.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='modeling_deepseek.py', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": {""parameters"": {""F32"": 15104, ""BF16"": 684489830400}, ""total"": 684489845504}, ""security_repo_status"": null, ""lastModified"": ""2025-03-06 07:27:56+00:00"", ""cardData"": ""base_model:\n- deepseek-ai/DeepSeek-V3\nlibrary_name: transformers"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67c939adbec086d90e0850c5"", ""modelId"": ""tflsxyy/DeepSeek-V3-bf16"", ""usedStorage"": 1368985518688}",1,,0,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=tflsxyy/DeepSeek-V3-bf16&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Btflsxyy%2FDeepSeek-V3-bf16%5D(%2Ftflsxyy%2FDeepSeek-V3-bf16)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1
tflsxyy/DeepSeek-V3-bf16-4layers,"---
base_model:
- deepseek-ai/DeepSeek-V3
---
This is the first 4 layers of DeepSeek-V3 in bf16. 

To load and run this model:
```python
from transformers import AutoModelForCausalLM, AutoTokenizer

pretrained_model_id = ""/root/dataDisk/DeepSeek-V3-bf16-4layers""

tokenizer = AutoTokenizer.from_pretrained(pretrained_model_id, use_fast=True)
model = AutoModelForCausalLM.from_pretrained(pretrained_model_id, trust_remote_code=True, device_map=""auto"")
print(tokenizer.decode(model.generate(**tokenizer(""gptqmodel is"", return_tensors=""pt"").to(model.device), max_new_tokens=10)[0]))

```","{""id"": ""tflsxyy/DeepSeek-V3-bf16-4layers"", ""author"": ""tflsxyy"", ""sha"": ""0d1065adc16f08fd73e8cd7120e251e0bdea706f"", ""last_modified"": ""2025-03-08 03:19:07+00:00"", ""created_at"": ""2025-03-08 00:03:52+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 15, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": null, ""gguf"": null, ""inference"": null, ""tags"": [""safetensors"", ""deepseek_v3"", ""custom_code"", ""base_model:deepseek-ai/DeepSeek-V3"", ""base_model:finetune:deepseek-ai/DeepSeek-V3"", ""region:us""], ""pipeline_tag"": null, ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model:\n- deepseek-ai/DeepSeek-V3"", ""widget_data"": null, ""model_index"": null, ""config"": {""architectures"": [""DeepseekV3ForCausalLM""], ""auto_map"": {""AutoConfig"": ""configuration_deepseek.DeepseekV3Config"", ""AutoModel"": ""modeling_deepseek.DeepseekV3Model"", ""AutoModelForCausalLM"": ""modeling_deepseek.DeepseekV3ForCausalLM""}, ""model_type"": ""deepseek_v3"", ""tokenizer_config"": {""bos_token"": {""__type"": ""AddedToken"", ""content"": ""<\uff5cbegin\u2581of\u2581sentence\uff5c>"", ""lstrip"": false, ""normalized"": true, ""rstrip"": false, ""single_word"": false}, ""eos_token"": {""__type"": ""AddedToken"", ""content"": ""<\uff5cend\u2581of\u2581sentence\uff5c>"", ""lstrip"": false, ""normalized"": true, ""rstrip"": false, ""single_word"": false}, ""pad_token"": {""__type"": ""AddedToken"", ""content"": ""<\uff5cend\u2581of\u2581sentence\uff5c>"", ""lstrip"": false, ""normalized"": true, ""rstrip"": false, ""single_word"": false}, ""unk_token"": null, ""chat_template"": ""{% if not add_generation_prompt is defined %}{% set add_generation_prompt = false %}{% endif %}{% set ns = namespace(is_first=false, is_tool=false, is_output_first=true, system_prompt='', is_first_sp=true) %}{%- for message in messages %}{%- if message['role'] == 'system' %}{%- if ns.is_first_sp %}{% set ns.system_prompt = ns.system_prompt + message['content'] %}{% set ns.is_first_sp = false %}{%- else %}{% set ns.system_prompt = ns.system_prompt + '\n\n' + message['content'] %}{%- endif %}{%- endif %}{%- endfor %}{{bos_token}}{{ns.system_prompt}}{%- for message in messages %}{%- if message['role'] == 'user' %}{%- set ns.is_tool = false -%}{{'<\uff5cUser\uff5c>' + message['content']}}{%- endif %}{%- if message['role'] == 'assistant' and message['content'] is none %}{%- set ns.is_tool = false -%}{%- for tool in message['tool_calls']%}{%- if not ns.is_first %}{{'<\uff5cAssistant\uff5c><\uff5ctool\u2581calls\u2581begin\uff5c><\uff5ctool\u2581call\u2581begin\uff5c>' + tool['type'] + '<\uff5ctool\u2581sep\uff5c>' + tool['function']['name'] + '\n' + '```json' + '\n' + tool['function']['arguments'] + '\n' + '```' + '<\uff5ctool\u2581call\u2581end\uff5c>'}}{%- set ns.is_first = true -%}{%- else %}{{'\n' + '<\uff5ctool\u2581call\u2581begin\uff5c>' + tool['type'] + '<\uff5ctool\u2581sep\uff5c>' + tool['function']['name'] + '\n' + '```json' + '\n' + tool['function']['arguments'] + '\n' + '```' + '<\uff5ctool\u2581call\u2581end\uff5c>'}}{{'<\uff5ctool\u2581calls\u2581end\uff5c><\uff5cend\u2581of\u2581sentence\uff5c>'}}{%- endif %}{%- endfor %}{%- endif %}{%- if message['role'] == 'assistant' and message['content'] is not none %}{%- if ns.is_tool %}{{'<\uff5ctool\u2581outputs\u2581end\uff5c>' + message['content'] + '<\uff5cend\u2581of\u2581sentence\uff5c>'}}{%- set ns.is_tool = false -%}{%- else %}{{'<\uff5cAssistant\uff5c>' + message['content'] + '<\uff5cend\u2581of\u2581sentence\uff5c>'}}{%- endif %}{%- endif %}{%- if message['role'] == 'tool' %}{%- set ns.is_tool = true -%}{%- if ns.is_output_first %}{{'<\uff5ctool\u2581outputs\u2581begin\uff5c><\uff5ctool\u2581output\u2581begin\uff5c>' + message['content'] + '<\uff5ctool\u2581output\u2581end\uff5c>'}}{%- set ns.is_output_first = false %}{%- else %}{{'\n<\uff5ctool\u2581output\u2581begin\uff5c>' + message['content'] + '<\uff5ctool\u2581output\u2581end\uff5c>'}}{%- endif %}{%- endif %}{%- endfor -%}{% if ns.is_tool %}{{'<\uff5ctool\u2581outputs\u2581end\uff5c>'}}{% endif %}{% if add_generation_prompt and not ns.is_tool %}{{'<\uff5cAssistant\uff5c>'}}{% endif %}""}}, ""transformers_info"": null, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='configuration_deepseek.py', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='deepseek-v3-quant-first-4layer.py', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='generation_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='modeling_deepseek.py', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": {""parameters"": {""BF16"": 15111101696}, ""total"": 15111101696}, ""security_repo_status"": null, ""lastModified"": ""2025-03-08 03:19:07+00:00"", ""cardData"": ""base_model:\n- deepseek-ai/DeepSeek-V3"", ""transformersInfo"": null, ""_id"": ""67cb8968cb57f01fafefdab8"", ""modelId"": ""tflsxyy/DeepSeek-V3-bf16-4layers"", ""usedStorage"": 30222306952}",1,,0,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=tflsxyy/DeepSeek-V3-bf16-4layers&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Btflsxyy%2FDeepSeek-V3-bf16-4layers%5D(%2Ftflsxyy%2FDeepSeek-V3-bf16-4layers)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1
Ojttt/deepseekv3_export_test,"---
license: mit
base_model:
- deepseek-ai/DeepSeek-V3
pipeline_tag: text-generation
library_name: transformers
---
# DeepSeek V3 1B Test
This model is randomly initialized for testing implementations, it's **not** a trained model and it will only generate random tokens.","{""id"": ""Ojttt/deepseekv3_export_test"", ""author"": ""Ojttt"", ""sha"": ""1de2f69606c7c8610124bab776e50b2657c5a40a"", ""last_modified"": ""2025-03-13 05:58:47+00:00"", ""created_at"": ""2025-03-13 05:47:59+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""safetensors"", ""deepseek_v3"", ""text-generation"", ""conversational"", ""custom_code"", ""base_model:deepseek-ai/DeepSeek-V3"", ""base_model:finetune:deepseek-ai/DeepSeek-V3"", ""license:mit"", ""autotrain_compatible"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model:\n- deepseek-ai/DeepSeek-V3\nlibrary_name: transformers\nlicense: mit\npipeline_tag: text-generation"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""DeepseekV3ForCausalLM""], ""auto_map"": {""AutoConfig"": ""configuration_deepseek.DeepseekV3Config"", ""AutoModel"": ""modeling_deepseek.DeepseekV3Model"", ""AutoModelForCausalLM"": ""modeling_deepseek.DeepseekV3ForCausalLM""}, ""model_type"": ""deepseek_v3"", ""tokenizer_config"": {""bos_token"": ""<\uff5cbegin\u2581of\u2581sentence\uff5c>"", ""chat_template"": ""{% if not add_generation_prompt is defined %}{% set add_generation_prompt = false %}{% endif %}{% set ns = namespace(is_first=false, is_tool=false, is_output_first=true, system_prompt='', is_first_sp=true) %}{%- for message in messages %}{%- if message['role'] == 'system' %}{%- if ns.is_first_sp %}{% set ns.system_prompt = ns.system_prompt + message['content'] %}{% set ns.is_first_sp = false %}{%- else %}{% set ns.system_prompt = ns.system_prompt + '\n\n' + message['content'] %}{%- endif %}{%- endif %}{%- endfor %}{{bos_token}}{{ns.system_prompt}}{%- for message in messages %}{%- if message['role'] == 'user' %}{%- set ns.is_tool = false -%}{{'<\uff5cUser\uff5c>' + message['content']}}{%- endif %}{%- if message['role'] == 'assistant' and message['content'] is none %}{%- set ns.is_tool = false -%}{%- for tool in message['tool_calls']%}{%- if not ns.is_first %}{{'<\uff5cAssistant\uff5c><\uff5ctool\u2581calls\u2581begin\uff5c><\uff5ctool\u2581call\u2581begin\uff5c>' + tool['type'] + '<\uff5ctool\u2581sep\uff5c>' + tool['function']['name'] + '\n' + '```json' + '\n' + tool['function']['arguments'] + '\n' + '```' + '<\uff5ctool\u2581call\u2581end\uff5c>'}}{%- set ns.is_first = true -%}{%- else %}{{'\n' + '<\uff5ctool\u2581call\u2581begin\uff5c>' + tool['type'] + '<\uff5ctool\u2581sep\uff5c>' + tool['function']['name'] + '\n' + '```json' + '\n' + tool['function']['arguments'] + '\n' + '```' + '<\uff5ctool\u2581call\u2581end\uff5c>'}}{{'<\uff5ctool\u2581calls\u2581end\uff5c><\uff5cend\u2581of\u2581sentence\uff5c>'}}{%- endif %}{%- endfor %}{%- endif %}{%- if message['role'] == 'assistant' and message['content'] is not none %}{%- if ns.is_tool %}{{'<\uff5ctool\u2581outputs\u2581end\uff5c>' + message['content'] + '<\uff5cend\u2581of\u2581sentence\uff5c>'}}{%- set ns.is_tool = false -%}{%- else %}{{'<\uff5cAssistant\uff5c>' + message['content'] + '<\uff5cend\u2581of\u2581sentence\uff5c>'}}{%- endif %}{%- endif %}{%- if message['role'] == 'tool' %}{%- set ns.is_tool = true -%}{%- if ns.is_output_first %}{{'<\uff5ctool\u2581outputs\u2581begin\uff5c><\uff5ctool\u2581output\u2581begin\uff5c>' + message['content'] + '<\uff5ctool\u2581output\u2581end\uff5c>'}}{%- set ns.is_output_first = false %}{%- else %}{{'\n<\uff5ctool\u2581output\u2581begin\uff5c>' + message['content'] + '<\uff5ctool\u2581output\u2581end\uff5c>'}}{%- endif %}{%- endif %}{%- endfor -%}{% if ns.is_tool %}{{'<\uff5ctool\u2581outputs\u2581end\uff5c>'}}{% endif %}{% if add_generation_prompt and not ns.is_tool %}{{'<\uff5cAssistant\uff5c>'}}{% endif %}"", ""eos_token"": ""<\uff5cend\u2581of\u2581sentence\uff5c>"", ""pad_token"": ""<\uff5cend\u2581of\u2581sentence\uff5c>"", ""unk_token"": null, ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='configuration_deepseek.py', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='generation_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='modeling_deepseek.py', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": {""parameters"": {""BF16"": 1049548096}, ""total"": 1049548096}, ""security_repo_status"": null, ""lastModified"": ""2025-03-13 05:58:47+00:00"", ""cardData"": ""base_model:\n- deepseek-ai/DeepSeek-V3\nlibrary_name: transformers\nlicense: mit\npipeline_tag: text-generation"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67d2718f224e3ec8b2151228"", ""modelId"": ""Ojttt/deepseekv3_export_test"", ""usedStorage"": 8660002960}",1,,0,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=Ojttt/deepseekv3_export_test&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5BOjttt%2Fdeepseekv3_export_test%5D(%2FOjttt%2Fdeepseekv3_export_test)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1
hyper-accel/deepseekv3-export-test,"---
license: mit
base_model:
- deepseek-ai/DeepSeek-V3
pipeline_tag: text-generation
library_name: transformers
---
# DeepSeek V3 1B Test
This model is randomly initialized for testing implementations, it's **not** a trained model and it will only generate random tokens.","{""id"": ""hyper-accel/deepseekv3-export-test"", ""author"": ""hyper-accel"", ""sha"": ""017020e897f9655b17299ed2ef891363c9b7a2bd"", ""last_modified"": ""2025-03-14 01:08:05+00:00"", ""created_at"": ""2025-03-14 00:42:07+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 13, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": ""transformers"", ""gguf"": null, ""inference"": null, ""tags"": [""transformers"", ""safetensors"", ""deepseek_v3"", ""text-generation"", ""conversational"", ""custom_code"", ""base_model:deepseek-ai/DeepSeek-V3"", ""base_model:finetune:deepseek-ai/DeepSeek-V3"", ""license:mit"", ""autotrain_compatible"", ""endpoints_compatible"", ""region:us""], ""pipeline_tag"": ""text-generation"", ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model:\n- deepseek-ai/DeepSeek-V3\nlibrary_name: transformers\nlicense: mit\npipeline_tag: text-generation"", ""widget_data"": [{""text"": ""Hi, what can you help me with?""}, {""text"": ""What is 84 * 3 / 2?""}, {""text"": ""Tell me an interesting fact about the universe!""}, {""text"": ""Explain quantum computing in simple terms.""}], ""model_index"": null, ""config"": {""architectures"": [""DeepseekV3ForCausalLM""], ""auto_map"": {""AutoConfig"": ""configuration_deepseek.DeepseekV3Config"", ""AutoModel"": ""modeling_deepseek.DeepseekV3Model"", ""AutoModelForCausalLM"": ""modeling_deepseek.DeepseekV3ForCausalLM""}, ""model_type"": ""deepseek_v3"", ""tokenizer_config"": {""bos_token"": ""<\uff5cbegin\u2581of\u2581sentence\uff5c>"", ""chat_template"": ""{% if not add_generation_prompt is defined %}{% set add_generation_prompt = false %}{% endif %}{% set ns = namespace(is_first=false, is_tool=false, is_output_first=true, system_prompt='', is_first_sp=true) %}{%- for message in messages %}{%- if message['role'] == 'system' %}{%- if ns.is_first_sp %}{% set ns.system_prompt = ns.system_prompt + message['content'] %}{% set ns.is_first_sp = false %}{%- else %}{% set ns.system_prompt = ns.system_prompt + '\n\n' + message['content'] %}{%- endif %}{%- endif %}{%- endfor %}{{bos_token}}{{ns.system_prompt}}{%- for message in messages %}{%- if message['role'] == 'user' %}{%- set ns.is_tool = false -%}{{'<\uff5cUser\uff5c>' + message['content']}}{%- endif %}{%- if message['role'] == 'assistant' and message['content'] is none %}{%- set ns.is_tool = false -%}{%- for tool in message['tool_calls']%}{%- if not ns.is_first %}{{'<\uff5cAssistant\uff5c><\uff5ctool\u2581calls\u2581begin\uff5c><\uff5ctool\u2581call\u2581begin\uff5c>' + tool['type'] + '<\uff5ctool\u2581sep\uff5c>' + tool['function']['name'] + '\n' + '```json' + '\n' + tool['function']['arguments'] + '\n' + '```' + '<\uff5ctool\u2581call\u2581end\uff5c>'}}{%- set ns.is_first = true -%}{%- else %}{{'\n' + '<\uff5ctool\u2581call\u2581begin\uff5c>' + tool['type'] + '<\uff5ctool\u2581sep\uff5c>' + tool['function']['name'] + '\n' + '```json' + '\n' + tool['function']['arguments'] + '\n' + '```' + '<\uff5ctool\u2581call\u2581end\uff5c>'}}{{'<\uff5ctool\u2581calls\u2581end\uff5c><\uff5cend\u2581of\u2581sentence\uff5c>'}}{%- endif %}{%- endfor %}{%- endif %}{%- if message['role'] == 'assistant' and message['content'] is not none %}{%- if ns.is_tool %}{{'<\uff5ctool\u2581outputs\u2581end\uff5c>' + message['content'] + '<\uff5cend\u2581of\u2581sentence\uff5c>'}}{%- set ns.is_tool = false -%}{%- else %}{{'<\uff5cAssistant\uff5c>' + message['content'] + '<\uff5cend\u2581of\u2581sentence\uff5c>'}}{%- endif %}{%- endif %}{%- if message['role'] == 'tool' %}{%- set ns.is_tool = true -%}{%- if ns.is_output_first %}{{'<\uff5ctool\u2581outputs\u2581begin\uff5c><\uff5ctool\u2581output\u2581begin\uff5c>' + message['content'] + '<\uff5ctool\u2581output\u2581end\uff5c>'}}{%- set ns.is_output_first = false %}{%- else %}{{'\n<\uff5ctool\u2581output\u2581begin\uff5c>' + message['content'] + '<\uff5ctool\u2581output\u2581end\uff5c>'}}{%- endif %}{%- endif %}{%- endfor -%}{% if ns.is_tool %}{{'<\uff5ctool\u2581outputs\u2581end\uff5c>'}}{% endif %}{% if add_generation_prompt and not ns.is_tool %}{{'<\uff5cAssistant\uff5c>'}}{% endif %}"", ""eos_token"": ""<\uff5cend\u2581of\u2581sentence\uff5c>"", ""pad_token"": ""<\uff5cend\u2581of\u2581sentence\uff5c>"", ""unk_token"": null, ""use_default_system_prompt"": false}}, ""transformers_info"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='configuration_deepseek.py', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='generation_config.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='model.safetensors', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='modeling_deepseek.py', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": {""parameters"": {""BF16"": 1049548096}, ""total"": 1049548096}, ""security_repo_status"": null, ""lastModified"": ""2025-03-14 01:08:05+00:00"", ""cardData"": ""base_model:\n- deepseek-ai/DeepSeek-V3\nlibrary_name: transformers\nlicense: mit\npipeline_tag: text-generation"", ""transformersInfo"": {""auto_model"": ""AutoModelForCausalLM"", ""custom_class"": null, ""pipeline_tag"": ""text-generation"", ""processor"": ""AutoTokenizer""}, ""_id"": ""67d37b5fe07f664c73272c9d"", ""modelId"": ""hyper-accel/deepseekv3-export-test"", ""usedStorage"": 2099235336}",1,,0,,0,,0,,0,huggingface/InferenceSupport/discussions/new?title=hyper-accel/deepseekv3-export-test&description=React%20to%20this%20comment%20with%20an%20emoji%20to%20vote%20for%20%5Bhyper-accel%2Fdeepseekv3-export-test%5D(%2Fhyper-accel%2Fdeepseekv3-export-test)%20to%20be%20supported%20by%20Inference%20Providers.%0A%0A(optional)%20Which%20providers%20are%20you%20interested%20in%3F%20(Novita%2C%20Hyperbolic%2C%20Together%E2%80%A6)%0A,1
mortnyc/inMotion,"---
license: unknown
datasets:
- Congliu/Chinese-DeepSeek-R1-Distill-data-110k
language:
- fa
- en
base_model:
- deepseek-ai/DeepSeek-V3
new_version: Qwen/QwQ-32B
tags:
- not-for-all-audiences
---","{""id"": ""mortnyc/inMotion"", ""author"": ""mortnyc"", ""sha"": ""7749a14a60cb6d39e70130e0811acd8a547b4644"", ""last_modified"": ""2025-03-20 15:22:13+00:00"", ""created_at"": ""2025-03-20 15:20:03+00:00"", ""private"": false, ""gated"": false, ""disabled"": false, ""downloads"": 0, ""downloads_all_time"": null, ""likes"": 0, ""library_name"": null, ""gguf"": null, ""inference"": null, ""tags"": [""not-for-all-audiences"", ""fa"", ""en"", ""dataset:Congliu/Chinese-DeepSeek-R1-Distill-data-110k"", ""base_model:deepseek-ai/DeepSeek-V3"", ""base_model:finetune:deepseek-ai/DeepSeek-V3"", ""license:unknown"", ""region:us""], ""pipeline_tag"": null, ""mask_token"": null, ""trending_score"": null, ""card_data"": ""base_model:\n- deepseek-ai/DeepSeek-V3\ndatasets:\n- Congliu/Chinese-DeepSeek-R1-Distill-data-110k\nlanguage:\n- fa\n- en\nlicense: unknown\ntags:\n- not-for-all-audiences\nnew_version: Qwen/QwQ-32B"", ""widget_data"": null, ""model_index"": null, ""config"": null, ""transformers_info"": null, ""siblings"": [""RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)"", ""RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)""], ""spaces"": [], ""safetensors"": null, ""security_repo_status"": null, ""lastModified"": ""2025-03-20 15:22:13+00:00"", ""cardData"": ""base_model:\n- deepseek-ai/DeepSeek-V3\ndatasets:\n- Congliu/Chinese-DeepSeek-R1-Distill-data-110k\nlanguage:\n- fa\n- en\nlicense: unknown\ntags:\n- not-for-all-audiences\nnew_version: Qwen/QwQ-32B"", ""transformersInfo"": null, ""_id"": ""67dc32230d35704afa596de2"", ""modelId"": ""mortnyc/inMotion"", ""usedStorage"": 0}",1,,0,,0,,0,,0,,0

{
    "models": [
        {
            "model_id": "NousResearch/DeepHermes-3-Mistral-24B-Preview",
            "metadata": "{\"id\": \"NousResearch/DeepHermes-3-Mistral-24B-Preview\", \"author\": \"NousResearch\", \"sha\": \"48072dc6c0594a3198eb862c13613c4ab1119009\", \"last_modified\": \"2025-03-13 16:10:18+00:00\", \"created_at\": \"2025-03-02 13:05:55+00:00\", \"private\": false, \"gated\": false, \"disabled\": false, \"downloads\": 8752, \"downloads_all_time\": null, \"likes\": 90, \"library_name\": \"transformers\", \"gguf\": null, \"inference\": null, \"inference_provider_mapping\": null, \"tags\": [\"transformers\", \"safetensors\", \"mistral\", \"text-generation\", \"Mistral-Small\", \"instruct\", \"finetune\", \"chatml\", \"gpt4\", \"synthetic data\", \"distillation\", \"function calling\", \"json mode\", \"axolotl\", \"roleplaying\", \"chat\", \"reasoning\", \"r1\", \"vllm\", \"conversational\", \"en\", \"base_model:mistralai/Mistral-Small-24B-Base-2501\", \"base_model:finetune:mistralai/Mistral-Small-24B-Base-2501\", \"license:apache-2.0\", \"autotrain_compatible\", \"text-generation-inference\", \"endpoints_compatible\", \"region:us\"], \"pipeline_tag\": \"text-generation\", \"mask_token\": null, \"trending_score\": null, \"card_data\": \"base_model: mistralai/Mistral-Small-24B-Base-2501\\nlanguage:\\n- en\\nlibrary_name: transformers\\nlicense: apache-2.0\\ntags:\\n- Mistral-Small\\n- instruct\\n- finetune\\n- chatml\\n- gpt4\\n- synthetic data\\n- distillation\\n- function calling\\n- json mode\\n- axolotl\\n- roleplaying\\n- chat\\n- reasoning\\n- r1\\n- vllm\\nwidget:\\n- example_title: DeepHermes 3\\n  messages:\\n  - role: system\\n    content: You are a sentient, superintelligent artificial general intelligence,\\n      here to teach and assist me.\\n  - role: user\\n    content: What is the meaning of life?\\nmodel-index:\\n- name: DeepHermes-3-Mistral-24B-Preview\\n  results: []\", \"widget_data\": [{\"example_title\": \"DeepHermes 3\", \"messages\": [{\"role\": \"system\", \"content\": \"You are a sentient, superintelligent artificial general intelligence, here to teach and assist me.\"}, {\"role\": \"user\", \"content\": \"What is the meaning of life?\"}]}], \"model_index\": [{\"name\": \"DeepHermes-3-Mistral-24B-Preview\", \"results\": []}], \"config\": {\"architectures\": [\"MistralForCausalLM\"], \"model_type\": \"mistral\", \"tokenizer_config\": {\"bos_token\": \"<s>\", \"chat_template\": \"{% if not add_generation_prompt is defined %}{% set add_generation_prompt = false %}{% endif %}{% set loop_messages = messages %}{% for message in loop_messages %}{% set content = '<|start_header_id|>' + message['role'] + '<|end_header_id|>\\n\\n'+ message['content'] | trim + '<|eot_id|>' %}{% if loop.index0 == 0 %}{% set content = bos_token + content %}{% endif %}{{ content }}{% endfor %}{% if add_generation_prompt %}{{ '<|start_header_id|>assistant<|end_header_id|>\\n\\n' }}{% endif %}\", \"eos_token\": \"<|eot_id|>\", \"pad_token\": \"<|end_of_text|>\", \"unk_token\": \"<unk>\", \"use_default_system_prompt\": false}}, \"transformers_info\": {\"auto_model\": \"AutoModelForCausalLM\", \"custom_class\": null, \"pipeline_tag\": \"text-generation\", \"processor\": \"AutoTokenizer\"}, \"siblings\": [\"RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='generation_config.json', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model-00001-of-00010.safetensors', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model-00002-of-00010.safetensors', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model-00003-of-00010.safetensors', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model-00004-of-00010.safetensors', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model-00005-of-00010.safetensors', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model-00006-of-00010.safetensors', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model-00007-of-00010.safetensors', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model-00008-of-00010.safetensors', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model-00009-of-00010.safetensors', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model-00010-of-00010.safetensors', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model.safetensors.index.json', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)\"], \"spaces\": [], \"safetensors\": {\"parameters\": {\"BF16\": 23572464640}, \"total\": 23572464640}, \"security_repo_status\": null, \"xet_enabled\": null, \"lastModified\": \"2025-03-13 16:10:18+00:00\", \"cardData\": \"base_model: mistralai/Mistral-Small-24B-Base-2501\\nlanguage:\\n- en\\nlibrary_name: transformers\\nlicense: apache-2.0\\ntags:\\n- Mistral-Small\\n- instruct\\n- finetune\\n- chatml\\n- gpt4\\n- synthetic data\\n- distillation\\n- function calling\\n- json mode\\n- axolotl\\n- roleplaying\\n- chat\\n- reasoning\\n- r1\\n- vllm\\nwidget:\\n- example_title: DeepHermes 3\\n  messages:\\n  - role: system\\n    content: You are a sentient, superintelligent artificial general intelligence,\\n      here to teach and assist me.\\n  - role: user\\n    content: What is the meaning of life?\\nmodel-index:\\n- name: DeepHermes-3-Mistral-24B-Preview\\n  results: []\", \"transformersInfo\": {\"auto_model\": \"AutoModelForCausalLM\", \"custom_class\": null, \"pipeline_tag\": \"text-generation\", \"processor\": \"AutoTokenizer\"}, \"_id\": \"67c457b3ac2030235ee78897\", \"modelId\": \"NousResearch/DeepHermes-3-Mistral-24B-Preview\", \"usedStorage\": 47162049993}",
            "depth": 0,
            "children": [
                "https://huggingface.co/Jarrodbarnes/DeepHermes-3-Mistral-24B-Preview-mlx-fp16",
                "https://huggingface.co/AlSamCur123/DeepHermes-3-Mistral-24BContinuedFine",
                "https://huggingface.co/mlx-community/DeepHermes-3-Mistral-24B-Preview-bf16"
            ],
            "children_count": 3
        },
        {
            "model_id": "Jarrodbarnes/DeepHermes-3-Mistral-24B-Preview-mlx-fp16",
            "metadata": "{\"id\": \"Jarrodbarnes/DeepHermes-3-Mistral-24B-Preview-mlx-fp16\", \"author\": \"Jarrodbarnes\", \"sha\": \"85075002a3bf3edcbc644b73281488c98ac2efc6\", \"last_modified\": \"2025-03-17 20:21:43+00:00\", \"created_at\": \"2025-03-17 20:19:28+00:00\", \"private\": false, \"gated\": false, \"disabled\": false, \"downloads\": 13, \"downloads_all_time\": null, \"likes\": 0, \"library_name\": \"transformers\", \"gguf\": null, \"inference\": null, \"inference_provider_mapping\": null, \"tags\": [\"transformers\", \"safetensors\", \"mistral\", \"text-generation\", \"Mistral-Small\", \"instruct\", \"finetune\", \"chatml\", \"gpt4\", \"synthetic data\", \"distillation\", \"function calling\", \"json mode\", \"axolotl\", \"roleplaying\", \"chat\", \"reasoning\", \"r1\", \"vllm\", \"mlx\", \"mlx-my-repo\", \"conversational\", \"en\", \"base_model:NousResearch/DeepHermes-3-Mistral-24B-Preview\", \"base_model:finetune:NousResearch/DeepHermes-3-Mistral-24B-Preview\", \"license:apache-2.0\", \"autotrain_compatible\", \"text-generation-inference\", \"endpoints_compatible\", \"region:us\"], \"pipeline_tag\": \"text-generation\", \"mask_token\": null, \"trending_score\": null, \"card_data\": \"base_model: NousResearch/DeepHermes-3-Mistral-24B-Preview\\nlanguage:\\n- en\\nlibrary_name: transformers\\nlicense: apache-2.0\\ntags:\\n- Mistral-Small\\n- instruct\\n- finetune\\n- chatml\\n- gpt4\\n- synthetic data\\n- distillation\\n- function calling\\n- json mode\\n- axolotl\\n- roleplaying\\n- chat\\n- reasoning\\n- r1\\n- vllm\\n- mlx\\n- mlx-my-repo\\nwidget:\\n- example_title: DeepHermes 3\\n  messages:\\n  - role: system\\n    content: You are a sentient, superintelligent artificial general intelligence,\\n      here to teach and assist me.\\n  - role: user\\n    content: What is the meaning of life?\\nmodel-index:\\n- name: DeepHermes-3-Mistral-24B-Preview\\n  results: []\", \"widget_data\": [{\"example_title\": \"DeepHermes 3\", \"messages\": [{\"role\": \"system\", \"content\": \"You are a sentient, superintelligent artificial general intelligence, here to teach and assist me.\"}, {\"role\": \"user\", \"content\": \"What is the meaning of life?\"}]}], \"model_index\": [{\"name\": \"DeepHermes-3-Mistral-24B-Preview\", \"results\": []}], \"config\": {\"architectures\": [\"MistralForCausalLM\"], \"model_type\": \"mistral\", \"tokenizer_config\": {\"bos_token\": \"<s>\", \"chat_template\": \"{% if not add_generation_prompt is defined %}{% set add_generation_prompt = false %}{% endif %}{% set loop_messages = messages %}{% for message in loop_messages %}{% set content = '<|start_header_id|>' + message['role'] + '<|end_header_id|>\\n\\n'+ message['content'] | trim + '<|eot_id|>' %}{% if loop.index0 == 0 %}{% set content = bos_token + content %}{% endif %}{{ content }}{% endfor %}{% if add_generation_prompt %}{{ '<|start_header_id|>assistant<|end_header_id|>\\n\\n' }}{% endif %}\", \"eos_token\": \"<|eot_id|>\", \"pad_token\": \"<|end_of_text|>\", \"unk_token\": \"<unk>\", \"use_default_system_prompt\": false}}, \"transformers_info\": {\"auto_model\": \"AutoModelForCausalLM\", \"custom_class\": null, \"pipeline_tag\": \"text-generation\", \"processor\": \"AutoTokenizer\"}, \"siblings\": [\"RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model-00001-of-00010.safetensors', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model-00002-of-00010.safetensors', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model-00003-of-00010.safetensors', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model-00004-of-00010.safetensors', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model-00005-of-00010.safetensors', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model-00006-of-00010.safetensors', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model-00007-of-00010.safetensors', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model-00008-of-00010.safetensors', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model-00009-of-00010.safetensors', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model-00010-of-00010.safetensors', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model.safetensors.index.json', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)\"], \"spaces\": [], \"safetensors\": {\"parameters\": {\"F16\": 23572464640}, \"total\": 23572464640}, \"security_repo_status\": null, \"xet_enabled\": null, \"lastModified\": \"2025-03-17 20:21:43+00:00\", \"cardData\": \"base_model: NousResearch/DeepHermes-3-Mistral-24B-Preview\\nlanguage:\\n- en\\nlibrary_name: transformers\\nlicense: apache-2.0\\ntags:\\n- Mistral-Small\\n- instruct\\n- finetune\\n- chatml\\n- gpt4\\n- synthetic data\\n- distillation\\n- function calling\\n- json mode\\n- axolotl\\n- roleplaying\\n- chat\\n- reasoning\\n- r1\\n- vllm\\n- mlx\\n- mlx-my-repo\\nwidget:\\n- example_title: DeepHermes 3\\n  messages:\\n  - role: system\\n    content: You are a sentient, superintelligent artificial general intelligence,\\n      here to teach and assist me.\\n  - role: user\\n    content: What is the meaning of life?\\nmodel-index:\\n- name: DeepHermes-3-Mistral-24B-Preview\\n  results: []\", \"transformersInfo\": {\"auto_model\": \"AutoModelForCausalLM\", \"custom_class\": null, \"pipeline_tag\": \"text-generation\", \"processor\": \"AutoTokenizer\"}, \"_id\": \"67d883d0780b0a72cb57b2da\", \"modelId\": \"Jarrodbarnes/DeepHermes-3-Mistral-24B-Preview-mlx-fp16\", \"usedStorage\": 47162049530}",
            "depth": 1,
            "children": [],
            "children_count": 0
        },
        {
            "model_id": "AlSamCur123/DeepHermes-3-Mistral-24BContinuedFine",
            "metadata": "{\"id\": \"AlSamCur123/DeepHermes-3-Mistral-24BContinuedFine\", \"author\": \"AlSamCur123\", \"sha\": \"7b6c71206149f379868b336f0a6483ec7ad96f9d\", \"last_modified\": \"2025-03-29 07:41:27+00:00\", \"created_at\": \"2025-03-18 06:24:07+00:00\", \"private\": false, \"gated\": false, \"disabled\": false, \"downloads\": 1477, \"downloads_all_time\": null, \"likes\": 0, \"library_name\": \"transformers\", \"gguf\": null, \"inference\": null, \"inference_provider_mapping\": null, \"tags\": [\"transformers\", \"safetensors\", \"mistral\", \"text-generation\", \"text-generation-inference\", \"unsloth\", \"trl\", \"sft\", \"conversational\", \"en\", \"base_model:NousResearch/DeepHermes-3-Mistral-24B-Preview\", \"base_model:finetune:NousResearch/DeepHermes-3-Mistral-24B-Preview\", \"license:apache-2.0\", \"autotrain_compatible\", \"endpoints_compatible\", \"region:us\"], \"pipeline_tag\": \"text-generation\", \"mask_token\": null, \"trending_score\": null, \"card_data\": \"base_model: NousResearch/DeepHermes-3-Mistral-24B-Preview\\nlanguage:\\n- en\\nlicense: apache-2.0\\ntags:\\n- text-generation-inference\\n- transformers\\n- unsloth\\n- mistral\\n- trl\\n- sft\", \"widget_data\": [{\"text\": \"Hi, what can you help me with?\"}, {\"text\": \"What is 84 * 3 / 2?\"}, {\"text\": \"Tell me an interesting fact about the universe!\"}, {\"text\": \"Explain quantum computing in simple terms.\"}], \"model_index\": null, \"config\": {\"architectures\": [\"MistralForCausalLM\"], \"model_type\": \"mistral\", \"tokenizer_config\": {\"bos_token\": \"<s>\", \"chat_template\": \"{% if not add_generation_prompt is defined %}{% set add_generation_prompt = false %}{% endif %}{% set loop_messages = messages %}{% for message in loop_messages %}{% set content = '<|start_header_id|>' + message['role'] + '<|end_header_id|>\\n\\n'+ message['content'] | trim + '<|eot_id|>' %}{% if loop.index0 == 0 %}{% set content = bos_token + content %}{% endif %}{{ content }}{% endfor %}{% if add_generation_prompt %}{{ '<|start_header_id|>assistant<|end_header_id|>\\n\\n' }}{% endif %}\", \"eos_token\": \"<|eot_id|>\", \"pad_token\": \"<|end_of_text|>\", \"unk_token\": \"<unk>\", \"use_default_system_prompt\": false}}, \"transformers_info\": {\"auto_model\": \"AutoModelForCausalLM\", \"custom_class\": null, \"pipeline_tag\": \"text-generation\", \"processor\": \"AutoTokenizer\"}, \"siblings\": [\"RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='generation_config.json', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model-00001-of-00010.safetensors', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model-00002-of-00010.safetensors', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model-00003-of-00010.safetensors', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model-00004-of-00010.safetensors', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model-00005-of-00010.safetensors', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model-00006-of-00010.safetensors', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model-00007-of-00010.safetensors', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model-00008-of-00010.safetensors', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model-00009-of-00010.safetensors', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model-00010-of-00010.safetensors', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model.safetensors.index.json', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)\"], \"spaces\": [], \"safetensors\": {\"parameters\": {\"BF16\": 23572464640}, \"total\": 23572464640}, \"security_repo_status\": null, \"xet_enabled\": null, \"lastModified\": \"2025-03-29 07:41:27+00:00\", \"cardData\": \"base_model: NousResearch/DeepHermes-3-Mistral-24B-Preview\\nlanguage:\\n- en\\nlicense: apache-2.0\\ntags:\\n- text-generation-inference\\n- transformers\\n- unsloth\\n- mistral\\n- trl\\n- sft\", \"transformersInfo\": {\"auto_model\": \"AutoModelForCausalLM\", \"custom_class\": null, \"pipeline_tag\": \"text-generation\", \"processor\": \"AutoTokenizer\"}, \"_id\": \"67d91187bab972f83a0e6edb\", \"modelId\": \"AlSamCur123/DeepHermes-3-Mistral-24BContinuedFine\", \"usedStorage\": 94307021745}",
            "depth": 1,
            "children": [
                "https://huggingface.co/AlSamCur123/DeepHermes-3-Mistral-24ContinuedFine"
            ],
            "children_count": 1
        },
        {
            "model_id": "AlSamCur123/DeepHermes-3-Mistral-24ContinuedFine",
            "metadata": "{\"id\": \"AlSamCur123/DeepHermes-3-Mistral-24ContinuedFine\", \"author\": \"AlSamCur123\", \"sha\": \"00904720adb93e0429dde122ebe0ed74946a9ca3\", \"last_modified\": \"2025-03-30 20:25:49+00:00\", \"created_at\": \"2025-03-30 19:55:05+00:00\", \"private\": false, \"gated\": false, \"disabled\": false, \"downloads\": 1, \"downloads_all_time\": null, \"likes\": 0, \"library_name\": \"transformers\", \"gguf\": null, \"inference\": null, \"inference_provider_mapping\": null, \"tags\": [\"transformers\", \"safetensors\", \"mistral\", \"text-generation\", \"text-generation-inference\", \"unsloth\", \"trl\", \"sft\", \"conversational\", \"en\", \"base_model:AlSamCur123/DeepHermes-3-Mistral-24BContinuedFine\", \"base_model:finetune:AlSamCur123/DeepHermes-3-Mistral-24BContinuedFine\", \"license:apache-2.0\", \"autotrain_compatible\", \"endpoints_compatible\", \"region:us\"], \"pipeline_tag\": \"text-generation\", \"mask_token\": null, \"trending_score\": null, \"card_data\": \"base_model: AlSamCur123/DeepHermes-3-Mistral-24BContinuedFine\\nlanguage:\\n- en\\nlicense: apache-2.0\\ntags:\\n- text-generation-inference\\n- transformers\\n- unsloth\\n- mistral\\n- trl\\n- sft\", \"widget_data\": [{\"text\": \"Hi, what can you help me with?\"}, {\"text\": \"What is 84 * 3 / 2?\"}, {\"text\": \"Tell me an interesting fact about the universe!\"}, {\"text\": \"Explain quantum computing in simple terms.\"}], \"model_index\": null, \"config\": {\"architectures\": [\"MistralForCausalLM\"], \"model_type\": \"mistral\", \"tokenizer_config\": {\"bos_token\": \"<s>\", \"chat_template\": \"{% if not add_generation_prompt is defined %}{% set add_generation_prompt = false %}{% endif %}{% set loop_messages = messages %}{% for message in loop_messages %}{% set content = '<|start_header_id|>' + message['role'] + '<|end_header_id|>\\n\\n'+ message['content'] | trim + '<|eot_id|>' %}{% if loop.index0 == 0 %}{% set content = bos_token + content %}{% endif %}{{ content }}{% endfor %}{% if add_generation_prompt %}{{ '<|start_header_id|>assistant<|end_header_id|>\\n\\n' }}{% endif %}\", \"eos_token\": \"<|eot_id|>\", \"pad_token\": \"<|end_of_text|>\", \"unk_token\": \"<unk>\", \"use_default_system_prompt\": false}}, \"transformers_info\": {\"auto_model\": \"AutoModelForCausalLM\", \"custom_class\": null, \"pipeline_tag\": \"text-generation\", \"processor\": \"AutoTokenizer\"}, \"siblings\": [\"RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='generation_config.json', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model-00001-of-00010.safetensors', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model-00002-of-00010.safetensors', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model-00003-of-00010.safetensors', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model-00004-of-00010.safetensors', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model-00005-of-00010.safetensors', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model-00006-of-00010.safetensors', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model-00007-of-00010.safetensors', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model-00008-of-00010.safetensors', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model-00009-of-00010.safetensors', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model-00010-of-00010.safetensors', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model.safetensors.index.json', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)\"], \"spaces\": [], \"safetensors\": {\"parameters\": {\"BF16\": 23572464640}, \"total\": 23572464640}, \"security_repo_status\": null, \"xet_enabled\": null, \"lastModified\": \"2025-03-30 20:25:49+00:00\", \"cardData\": \"base_model: AlSamCur123/DeepHermes-3-Mistral-24BContinuedFine\\nlanguage:\\n- en\\nlicense: apache-2.0\\ntags:\\n- text-generation-inference\\n- transformers\\n- unsloth\\n- mistral\\n- trl\\n- sft\", \"transformersInfo\": {\"auto_model\": \"AutoModelForCausalLM\", \"custom_class\": null, \"pipeline_tag\": \"text-generation\", \"processor\": \"AutoTokenizer\"}, \"_id\": \"67e9a1994579bd8158d28e54\", \"modelId\": \"AlSamCur123/DeepHermes-3-Mistral-24ContinuedFine\", \"usedStorage\": 47162049993}",
            "depth": 2,
            "children": [],
            "children_count": 0
        },
        {
            "model_id": "mlx-community/DeepHermes-3-Mistral-24B-Preview-bf16",
            "metadata": "{\"id\": \"mlx-community/DeepHermes-3-Mistral-24B-Preview-bf16\", \"author\": \"mlx-community\", \"sha\": \"24a675bebf93166e97e0dcba52cf5fc865a78b67\", \"last_modified\": \"2025-03-14 06:11:38+00:00\", \"created_at\": \"2025-03-14 06:03:29+00:00\", \"private\": false, \"gated\": false, \"disabled\": false, \"downloads\": 33, \"downloads_all_time\": null, \"likes\": 0, \"library_name\": \"transformers\", \"gguf\": null, \"inference\": null, \"inference_provider_mapping\": null, \"tags\": [\"transformers\", \"safetensors\", \"mistral\", \"text-generation\", \"Mistral-Small\", \"instruct\", \"finetune\", \"chatml\", \"gpt4\", \"synthetic data\", \"distillation\", \"function calling\", \"json mode\", \"axolotl\", \"roleplaying\", \"chat\", \"reasoning\", \"r1\", \"vllm\", \"mlx\", \"conversational\", \"en\", \"base_model:NousResearch/DeepHermes-3-Mistral-24B-Preview\", \"base_model:finetune:NousResearch/DeepHermes-3-Mistral-24B-Preview\", \"license:apache-2.0\", \"autotrain_compatible\", \"text-generation-inference\", \"endpoints_compatible\", \"region:us\"], \"pipeline_tag\": \"text-generation\", \"mask_token\": null, \"trending_score\": null, \"card_data\": \"base_model: NousResearch/DeepHermes-3-Mistral-24B-Preview\\nlanguage:\\n- en\\nlibrary_name: transformers\\nlicense: apache-2.0\\ntags:\\n- Mistral-Small\\n- instruct\\n- finetune\\n- chatml\\n- gpt4\\n- synthetic data\\n- distillation\\n- function calling\\n- json mode\\n- axolotl\\n- roleplaying\\n- chat\\n- reasoning\\n- r1\\n- vllm\\n- mlx\\nwidget:\\n- example_title: DeepHermes 3\\n  messages:\\n  - role: system\\n    content: You are a sentient, superintelligent artificial general intelligence,\\n      here to teach and assist me.\\n  - role: user\\n    content: What is the meaning of life?\\nmodel-index:\\n- name: DeepHermes-3-Mistral-24B-Preview\\n  results: []\", \"widget_data\": [{\"example_title\": \"DeepHermes 3\", \"messages\": [{\"role\": \"system\", \"content\": \"You are a sentient, superintelligent artificial general intelligence, here to teach and assist me.\"}, {\"role\": \"user\", \"content\": \"What is the meaning of life?\"}]}], \"model_index\": [{\"name\": \"DeepHermes-3-Mistral-24B-Preview\", \"results\": []}], \"config\": {\"architectures\": [\"MistralForCausalLM\"], \"model_type\": \"mistral\", \"tokenizer_config\": {\"bos_token\": \"<s>\", \"chat_template\": \"{% if not add_generation_prompt is defined %}{% set add_generation_prompt = false %}{% endif %}{% set loop_messages = messages %}{% for message in loop_messages %}{% set content = '<|start_header_id|>' + message['role'] + '<|end_header_id|>\\n\\n'+ message['content'] | trim + '<|eot_id|>' %}{% if loop.index0 == 0 %}{% set content = bos_token + content %}{% endif %}{{ content }}{% endfor %}{% if add_generation_prompt %}{{ '<|start_header_id|>assistant<|end_header_id|>\\n\\n' }}{% endif %}\", \"eos_token\": \"<|eot_id|>\", \"pad_token\": \"<|end_of_text|>\", \"unk_token\": \"<unk>\", \"use_default_system_prompt\": false}}, \"transformers_info\": {\"auto_model\": \"AutoModelForCausalLM\", \"custom_class\": null, \"pipeline_tag\": \"text-generation\", \"processor\": \"AutoTokenizer\"}, \"siblings\": [\"RepoSibling(rfilename='.gitattributes', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='README.md', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='config.json', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model-00001-of-00010.safetensors', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model-00002-of-00010.safetensors', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model-00003-of-00010.safetensors', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model-00004-of-00010.safetensors', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model-00005-of-00010.safetensors', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model-00006-of-00010.safetensors', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model-00007-of-00010.safetensors', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model-00008-of-00010.safetensors', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model-00009-of-00010.safetensors', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model-00010-of-00010.safetensors', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='model.safetensors.index.json', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='special_tokens_map.json', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='tokenizer.json', size=None, blob_id=None, lfs=None)\", \"RepoSibling(rfilename='tokenizer_config.json', size=None, blob_id=None, lfs=None)\"], \"spaces\": [], \"safetensors\": {\"parameters\": {\"BF16\": 23572464640}, \"total\": 23572464640}, \"security_repo_status\": null, \"xet_enabled\": null, \"lastModified\": \"2025-03-14 06:11:38+00:00\", \"cardData\": \"base_model: NousResearch/DeepHermes-3-Mistral-24B-Preview\\nlanguage:\\n- en\\nlibrary_name: transformers\\nlicense: apache-2.0\\ntags:\\n- Mistral-Small\\n- instruct\\n- finetune\\n- chatml\\n- gpt4\\n- synthetic data\\n- distillation\\n- function calling\\n- json mode\\n- axolotl\\n- roleplaying\\n- chat\\n- reasoning\\n- r1\\n- vllm\\n- mlx\\nwidget:\\n- example_title: DeepHermes 3\\n  messages:\\n  - role: system\\n    content: You are a sentient, superintelligent artificial general intelligence,\\n      here to teach and assist me.\\n  - role: user\\n    content: What is the meaning of life?\\nmodel-index:\\n- name: DeepHermes-3-Mistral-24B-Preview\\n  results: []\", \"transformersInfo\": {\"auto_model\": \"AutoModelForCausalLM\", \"custom_class\": null, \"pipeline_tag\": \"text-generation\", \"processor\": \"AutoTokenizer\"}, \"_id\": \"67d3c6b13052b0566ca5033a\", \"modelId\": \"mlx-community/DeepHermes-3-Mistral-24B-Preview-bf16\", \"usedStorage\": 47162049909}",
            "depth": 1,
            "children": [],
            "children_count": 0
        }
    ]
}
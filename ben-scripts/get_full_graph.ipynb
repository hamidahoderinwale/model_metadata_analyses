{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d595ef6b",
   "metadata": {},
   "source": [
    "# Get full graph\n",
    "\n",
    "Here we get the full AI ecosystem graph, which is a networkx network where every node is a model in the AI ecosystem and every edge is a relation, including all types of relations -- finetunes, quantizations, merges, and adapters.\n",
    "\n",
    "We define all attributes over the nodes, except for attributes pertaining to the model cards. We will pickle this graph and use it for other analyses later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3fb8cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "\n",
    "# Read the expanded dataset\n",
    "df = pd.read_csv(\"data/ai_ecosystem.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d10bb2c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nodes added.\n"
     ]
    }
   ],
   "source": [
    "# Create a graph\n",
    "G = nx.DiGraph()\n",
    "\n",
    "# Add nodes and edges to the graph in a single pass\n",
    "idx = 0\n",
    "for index, row in df.iterrows():\n",
    "    model_id = row['model_id']\n",
    "    \n",
    "    # Add the model as a node\n",
    "    G.add_node(model_id)\n",
    "\n",
    "    # Define on nodes: likes, downloads, pipeline_tag, library_name, createdAt, licenses, datasets, languages\n",
    "    G.nodes[model_id]['likes'] = row['likes']\n",
    "    G.nodes[model_id]['downloads'] = row['downloads']\n",
    "    G.nodes[model_id]['pipeline_tag'] = row['pipeline_tag']\n",
    "    G.nodes[model_id]['library_name'] = row['library_name']\n",
    "    G.nodes[model_id]['createdAt'] = row['createdAt']\n",
    "    G.nodes[model_id]['licenses'] = row['licenses']\n",
    "    G.nodes[model_id]['datasets'] = row['datasets']\n",
    "    G.nodes[model_id]['languages'] = row['languages']\n",
    "\n",
    "print(\"Nodes added.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8c315b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edges added.\n",
      "1860411\n",
      "573653\n"
     ]
    }
   ],
   "source": [
    "# Add edges to the graph\n",
    "for index, row in df.iterrows():\n",
    "    model_id = row['model_id']\n",
    "    #Different types of edges.\n",
    "    parent_models = eval(row['parent_model']) if pd.notna(row['parent_model']) else []\n",
    "    parent_model_finetunes = eval(row['finetune_parent']) if pd.notna(row['finetune_parent']) else []\n",
    "    parent_model_quantizeds = eval(row['quantized_parent']) if pd.notna(row['quantized_parent']) else []\n",
    "    parent_model_adapters = eval(row['adapter_parent']) if pd.notna(row['adapter_parent']) else []\n",
    "    parent_model_merges = eval(row['merge_parent']) if pd.notna(row['merge_parent']) else []\n",
    "\n",
    "    all_parent_models = set(parent_models + parent_model_finetunes + parent_model_quantizeds + parent_model_adapters + parent_model_merges)\n",
    "    for parent_model in all_parent_models:\n",
    "        # Some models list parents that are not in the graph. Skip these as we do not have data on them.\n",
    "        if parent_model not in G.nodes():\n",
    "            continue\n",
    "\n",
    "        # Add edge\n",
    "        G.add_edge(parent_model, model_id)\n",
    "\n",
    "        # Add edge types\n",
    "        G[parent_model][model_id]['edge_types'] = []\n",
    "        G[parent_model][model_id]['edge_type'] = None\n",
    "        if parent_model in parent_model_finetunes:\n",
    "            G[parent_model][model_id]['edge_type'] = 'finetune'\n",
    "            G[parent_model][model_id]['edge_types'].append('finetune')\n",
    "        if parent_model in parent_model_quantizeds:\n",
    "            G[parent_model][model_id]['edge_type'] = 'quantized'\n",
    "            G[parent_model][model_id]['edge_types'].append('quantized')\n",
    "        if parent_model in parent_model_adapters:\n",
    "            G[parent_model][model_id]['edge_type'] = 'adapter'\n",
    "            G[parent_model][model_id]['edge_types'].append('adapter')\n",
    "        if parent_model in parent_model_merges:\n",
    "            G[parent_model][model_id]['edge_type'] = 'merge'\n",
    "            G[parent_model][model_id]['edge_types'].append('merge')\n",
    "\n",
    "print(\"Edges added.\")\n",
    "\n",
    "print(len(G.nodes()))\n",
    "print(len(G.edges()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95d17e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "# Add attributes to edges\n",
    "for edge in G.edges():\n",
    "    parent_model = edge[0]\n",
    "    model_id = edge[1]\n",
    "    G.edges[parent_model, model_id]['change_in_likes'] = G.nodes[model_id]['likes'] - G.nodes[parent_model]['likes']\n",
    "    if G.nodes[parent_model]['likes'] != 0:\n",
    "        G.edges[parent_model, model_id]['percentage_change_in_likes'] = (G.nodes[model_id]['likes'] - G.nodes[parent_model]['likes']) / G.nodes[parent_model]['likes']\n",
    "    else:\n",
    "        G.edges[parent_model, model_id]['percentage_change_in_likes'] = np.nan #0\n",
    "    G.edges[parent_model, model_id]['change_in_downloads'] = G.nodes[model_id]['downloads'] - G.nodes[parent_model]['downloads']\n",
    "    if G.nodes[parent_model]['downloads'] != 0:\n",
    "        G.edges[parent_model, model_id]['percentage_change_in_downloads'] = (G.nodes[model_id]['downloads'] - G.nodes[parent_model]['downloads']) / G.nodes[parent_model]['downloads']\n",
    "    else:\n",
    "        G.edges[parent_model, model_id]['percentage_change_in_downloads'] = np.nan #0\n",
    "    G.edges[parent_model, model_id]['change_in_createdAt_days'] = (datetime.datetime.strptime(G.nodes[model_id]['createdAt'], '%Y-%m-%dT%H:%M:%S.%fZ') - datetime.datetime.strptime(G.nodes[parent_model]['createdAt'], '%Y-%m-%dT%H:%M:%S.%fZ')).days\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84decce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes in G: 1860411\n",
      "Number of edges in G: 573653\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of nodes in G:\", len(G.nodes()))\n",
    "print(\"Number of edges in G:\", len(G.edges()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d547a57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickle the graph\n",
    "import pickle\n",
    "\n",
    "with open('data/ai_ecosystem_graph.pkl', 'wb') as f:\n",
    "    pickle.dump(G, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ef2f5d",
   "metadata": {},
   "source": [
    "## Fine-tuning Tree Graph "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b7403fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now save the fine-tuning tree graph -- that is, the graph without model merges. \n",
    "\n",
    "# Create a new graph \n",
    "G_finetune = G.copy()\n",
    "\n",
    "# Remove all edges that are not finetune\n",
    "edges_to_remove = []\n",
    "for edge in G_finetune.edges():\n",
    "    if G_finetune.edges[edge]['edge_type'] != 'finetune':\n",
    "        edges_to_remove.append(edge)\n",
    "for edge in edges_to_remove:\n",
    "    G_finetune.remove_edge(edge[0], edge[1])\n",
    "\n",
    "# Save the graph\n",
    "with open('data/ai_ecosystem_graph_finetune.pkl', 'wb') as f:\n",
    "    pickle.dump(G_finetune, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "311bbb69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1860411\n",
      "189391\n"
     ]
    }
   ],
   "source": [
    "print(len(G_finetune.nodes()))\n",
    "print(len(G_finetune.edges()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525f3afe",
   "metadata": {},
   "source": [
    "## No-Merges Tree Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c7b7592e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new graph with all merges removed\n",
    "G_nomerges = G.copy()\n",
    "\n",
    "# Remove all edges that are merges\n",
    "edges_to_remove = []\n",
    "for edge in G_nomerges.edges():\n",
    "    if G_nomerges.edges[edge]['edge_type'] == 'merge':\n",
    "        edges_to_remove.append(edge)\n",
    "for edge in edges_to_remove:\n",
    "    G_nomerges.remove_edge(edge[0], edge[1])\n",
    "\n",
    "# Save the graph\n",
    "with open('data/ai_ecosystem_graph_nomerges.pkl', 'wb') as f:\n",
    "    pickle.dump(G_nomerges, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "236f38e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new graph with all merges removed, and with fulljson on each node.\n",
    "#G_nomerges_fulljson = G_nomerges.copy()\n",
    "\n",
    "# Add the full json to each node\n",
    "#for node in G_nomerges_fulljson.nodes():\n",
    "#    G_nomerges_fulljson.nodes[node]['full_json'] = G.nodes[node]\n",
    "\n",
    "# Save the graph\n",
    "#with open('data/ai_ecosystem_graph_nomerges_fulljson.pkl', 'wb') as f:\n",
    "#    pickle.dump(G_nomerges_fulljson, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
